bringing up nodes...
bringing up nodes...

..................F..................F..Fs......F...F........F......F..............s....FF.......................F....F. [ 11%]
...............F.............FF........FF.F.F..............FF........FF......FF...............F.................F.FFF..F [ 22%]
F.....................F..F.......F..........F.......F...F...F.F....F.......F..F.........FFFF...F.FF...F.........F...FFF. [ 33%]
............F.F.FF.....ssssssss..F..Fs..s.s..xFF..F..F..F.....F..EEEEEFF.....F.FF..F.F..FF.FFFF.........F........F.F.FFF [ 44%]
..F..F.F....F.F..F..F..FF...FFF........F.FFFFF.....F.........F..F...F.FFF.F......F...F.E.F.....FF...........F.......F... [ 55%]
........F..F..FF.FFFFF.FFFFsFF.F.......FF.F....FF............FF...F.FFF............FF...FEE.EEE........EE....FF...F..... [ 66%]
.........FFF.F.FF...F...FsssssssssF.......F...................................F..............Fs.FFsssF...F...F..s..s.... [ 77%]
.FF.F.F...F.F..FF....F.F.....FFF.FFF.FFF.F.......F............F.sFF.FFFFFFFFFF..F...FFFFFFFF..F...F.F.FFF.FF.F........F. [ 89%]
..F....FFFFFFFFFF........F...F............FFFFFF..F...FF..FF.F..F.......................F...F.........F...F.FF.FF.F.F    [100%]
============================================================ ERRORS ============================================================
_____________________________________ ERROR collecting tests/test_portfolio_integration.py _____________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_portfolio_integration.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tests/test_portfolio_integration.py:10: in <module>
    from tests.mocks.validate_critical_fix_mocks import MockContext, MockSignal
E   ImportError: cannot import name 'MockSignal' from 'tests.mocks.validate_critical_fix_mocks' (/workspace/ai-trading-bot/tests/mocks/validate_critical_fix_mocks.py)
__________________________ ERROR at setup of TestKellyCalculator.test_kelly_calculator_initialization __________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyCalculator object at 0x7f1481f1bb50>

    def setup_method(self):
        """Set up test fixtures."""
>       self.calculator = KellyCalculator()
                          ^^^^^^^^^^^^^^^^^

tests/test_institutional_kelly.py:172: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
                           ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7f1481248150>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
____________________________ ERROR at setup of TestKellyCalculator.test_portfolio_kelly_calculation ____________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyCalculator object at 0x7f1481f192d0>

    def setup_method(self):
        """Set up test fixtures."""
>       self.calculator = KellyCalculator()
                          ^^^^^^^^^^^^^^^^^

tests/test_institutional_kelly.py:172: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
                           ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7f1481248390>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
_____________________________ ERROR at setup of TestKellyCalculator.test_dynamic_kelly_adjustment ______________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyCalculator object at 0x7f1481f19850>

    def setup_method(self):
        """Set up test fixtures."""
>       self.calculator = KellyCalculator()
                          ^^^^^^^^^^^^^^^^^

tests/test_institutional_kelly.py:172: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
                           ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7f148124b510>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
______________________________ ERROR at setup of TestKellyCalculator.test_kelly_with_correlation _______________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyCalculator object at 0x7f1481f19dd0>

    def setup_method(self):
        """Set up test fixtures."""
>       self.calculator = KellyCalculator()
                          ^^^^^^^^^^^^^^^^^

tests/test_institutional_kelly.py:172: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
                           ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7f14812ab850>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
___________________________ ERROR at setup of TestKellyCalculator.test_calculation_history_recording ___________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyCalculator object at 0x7f1481f19e10>

    def setup_method(self):
        """Set up test fixtures."""
>       self.calculator = KellyCalculator()
                          ^^^^^^^^^^^^^^^^^

tests/test_institutional_kelly.py:172: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
                           ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7f1481236b10>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
____________________________________ ERROR at teardown of test_validate_environment_missing ____________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
item = 'WEBHOOK_SECRET'

    def __delattr__(self, item: str) -> Any:
        cls = self.__class__
    
        if item in self.__private_attributes__:
            attribute = self.__private_attributes__[item]
            if hasattr(attribute, '__delete__'):
                attribute.__delete__(self)  # type: ignore
                return
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                del self.__pydantic_private__[item]  # type: ignore
                return
            except KeyError as exc:
                raise AttributeError(f'{cls.__name__!r} object has no attribute {item!r}') from exc
    
        # Allow cached properties to be deleted (even if the class is frozen):
        attr = getattr(cls, item, None)
        if isinstance(attr, cached_property):
            return object.__delattr__(self, item)
    
        _check_frozen(cls, name=item, value=None)
    
        if item in self.__pydantic_fields__:
            object.__delattr__(self, item)
        elif self.__pydantic_extra__ is not None and item in self.__pydantic_extra__:
            del self.__pydantic_extra__[item]
        else:
            try:
>               object.__delattr__(self, item)
E               AttributeError: 'Settings' object has no attribute 'WEBHOOK_SECRET'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1084: AttributeError

During handling of the above exception, another exception occurred:

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
item = 'WEBHOOK_SECRET'

    def __delattr__(self, item: str) -> Any:
        cls = self.__class__
    
        if item in self.__private_attributes__:
            attribute = self.__private_attributes__[item]
            if hasattr(attribute, '__delete__'):
                attribute.__delete__(self)  # type: ignore
                return
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                del self.__pydantic_private__[item]  # type: ignore
                return
            except KeyError as exc:
                raise AttributeError(f'{cls.__name__!r} object has no attribute {item!r}') from exc
    
        # Allow cached properties to be deleted (even if the class is frozen):
        attr = getattr(cls, item, None)
        if isinstance(attr, cached_property):
            return object.__delattr__(self, item)
    
        _check_frozen(cls, name=item, value=None)
    
        if item in self.__pydantic_fields__:
            object.__delattr__(self, item)
        elif self.__pydantic_extra__ is not None and item in self.__pydantic_extra__:
            del self.__pydantic_extra__[item]
        else:
            try:
                object.__delattr__(self, item)
            except AttributeError:
>               raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E               AttributeError: 'Settings' object has no attribute 'WEBHOOK_SECRET'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1086: AttributeError
_____________________ ERROR at setup of TestPortfolioOptimizer.test_portfolio_kelly_efficiency_calculation _____________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_portfolio_optimization.TestPortfolioOptimizer object at 0x7fdb4052ae90>

    def setup_method(self):
        """Set up test fixtures."""
>       self.optimizer = create_portfolio_optimizer()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_portfolio_optimization.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/portfolio/optimizer.py:531: in create_portfolio_optimizer
    return PortfolioOptimizer(
ai_trading/portfolio/optimizer.py:98: in __init__
    self.kelly_calculator = KellyCriterion()
                            ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7fdb41019910>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
_________________________ ERROR at setup of TestPortfolioOptimizer.test_correlation_impact_calculation _________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_portfolio_optimization.TestPortfolioOptimizer object at 0x7fdb403c3d90>

    def setup_method(self):
        """Set up test fixtures."""
>       self.optimizer = create_portfolio_optimizer()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_portfolio_optimization.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/portfolio/optimizer.py:531: in create_portfolio_optimizer
    return PortfolioOptimizer(
ai_trading/portfolio/optimizer.py:98: in __init__
    self.kelly_calculator = KellyCriterion()
                            ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7fdb400baa50>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
____________________________ ERROR at setup of TestPortfolioOptimizer.test_trade_impact_evaluation _____________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_portfolio_optimization.TestPortfolioOptimizer object at 0x7fdb406aaf50>

    def setup_method(self):
        """Set up test fixtures."""
>       self.optimizer = create_portfolio_optimizer()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_portfolio_optimization.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/portfolio/optimizer.py:531: in create_portfolio_optimizer
    return PortfolioOptimizer(
ai_trading/portfolio/optimizer.py:98: in __init__
    self.kelly_calculator = KellyCriterion()
                            ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7fdb4027bb50>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
___________________________ ERROR at setup of TestPortfolioOptimizer.test_portfolio_decision_making ____________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_portfolio_optimization.TestPortfolioOptimizer object at 0x7fdb406a8a50>

    def setup_method(self):
        """Set up test fixtures."""
>       self.optimizer = create_portfolio_optimizer()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_portfolio_optimization.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/portfolio/optimizer.py:531: in create_portfolio_optimizer
    return PortfolioOptimizer(
ai_trading/portfolio/optimizer.py:98: in __init__
    self.kelly_calculator = KellyCriterion()
                            ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7fdb3e66f310>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
____________________________ ERROR at setup of TestPortfolioOptimizer.test_rebalance_trigger_logic _____________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_portfolio_optimization.TestPortfolioOptimizer object at 0x7fdb406aaa10>

    def setup_method(self):
        """Set up test fixtures."""
>       self.optimizer = create_portfolio_optimizer()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_portfolio_optimization.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/portfolio/optimizer.py:531: in create_portfolio_optimizer
    return PortfolioOptimizer(
ai_trading/portfolio/optimizer.py:98: in __init__
    self.kelly_calculator = KellyCriterion()
                            ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7fdb3e66efd0>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
________________________ ERROR at setup of TestIntegration.test_integrated_portfolio_decision_workflow _________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_portfolio_optimization.TestIntegration object at 0x7fdb40673810>

    def setup_method(self):
        """Set up integrated test fixtures."""
>       self.optimizer = create_portfolio_optimizer()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_portfolio_optimization.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/portfolio/optimizer.py:531: in create_portfolio_optimizer
    return PortfolioOptimizer(
ai_trading/portfolio/optimizer.py:98: in __init__
    self.kelly_calculator = KellyCriterion()
                            ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7fdb3e5f2150>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
______________________________ ERROR at setup of TestIntegration.test_churn_reduction_validation _______________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_portfolio_optimization.TestIntegration object at 0x7fdb406730d0>

    def setup_method(self):
        """Set up integrated test fixtures."""
>       self.optimizer = create_portfolio_optimizer()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_portfolio_optimization.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/portfolio/optimizer.py:531: in create_portfolio_optimizer
    return PortfolioOptimizer(
ai_trading/portfolio/optimizer.py:98: in __init__
    self.kelly_calculator = KellyCriterion()
                            ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7fdb3fd0bd90>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
=========================================================== FAILURES ===========================================================
________________________________________________ test_positions_and_account_old ________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_positions_and_account_old():
        fake = FakeOld()
        b = AlpacaBroker(fake)
>       assert b.list_open_positions() == ["pos-old"]
E       AssertionError: assert [] == ['pos-old']
E         
E         Right contains one more item: 'pos-old'
E         Use -v to get more diff

tests/test_broker_alpaca_adapter.py:87: AssertionError
____________________________________________________ test_validate_env_main ____________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

mod_name = 'validate_env', error = <class 'ImportError'>

>   ???

<frozen runpy>:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'validate_env', package = None

>   ???
E   ValueError: validate_env.__spec__ is None

<frozen importlib.util>:115: ValueError

The above exception was the direct cause of the following exception:

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f471556cc50>

    def test_validate_env_main(monkeypatch):
        """Running validate_env as script calls _main."""
        # AI-AGENT-REF: Mock environment variables to ensure validation passes
        monkeypatch.setenv(
            "WEBHOOK_SECRET",
            "fake_test_webhook_secret_that_is_at_least_32_characters_long_for_security_not_real",
        )
        monkeypatch.setenv(
            "ALPACA_API_KEY", "FAKE_TEST_API_KEY_NOT_REAL_123456789012345"
        )  # Realistic length
        monkeypatch.setenv(
            "ALPACA_SECRET_KEY",
            "FAKE_TEST_SECRET_KEY_NOT_REAL_123456789012345678901234567890ABCDEFGHIJKLMN",
        )  # Realistic length
        monkeypatch.setenv("ALPACA_BASE_URL", "https://paper-api.alpaca.markets")
    
        # AI-AGENT-REF: Clear sys.argv to prevent pytest args from interfering with validate_env argument parsing
        original_argv = sys.argv[:]
        try:
            sys.argv = ["validate_env"]  # Simulate clean module execution
>           runpy.run_module("validate_env", run_name="__main__")

tests/test_additional_coverage.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
<frozen runpy>:222: in run_module
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

mod_name = 'validate_env', error = <class 'ImportError'>

>   ???
E   ImportError: Error while finding module specification for 'validate_env' (ValueError: validate_env.__spec__ is None)

<frozen runpy>:140: ImportError
___________________________________________________ test_submit_order_shadow ___________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f471556c910>

    def test_submit_order_shadow(monkeypatch):
        """submit_order returns a shadow status when SHADOW_MODE is enabled."""
        class DummyAPI:
            def submit_order(self, order_data=None):
                raise AssertionError("should not call in shadow")
    
        monkeypatch.setattr(alpaca_api, "SHADOW_MODE", True)
        log = types.SimpleNamespace(info=lambda *a, **k: None, warning=lambda *a, **k: None)
        resp = alpaca_api.submit_order(
            DummyAPI(),
            types.SimpleNamespace(symbol="AAPL", qty=1, side="buy", time_in_force="day"),
            log,
        )
>       assert resp["status"] == "shadow"
               ^^^^^^^^^^^^^^
E       TypeError: 'types.SimpleNamespace' object is not subscriptable

tests/test_advanced_features.py:50: TypeError
______________________________ TestDatetimeTimezoneAwareness.test_alpaca_api_format_compatibility ______________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_datetime_fixes.TestDatetimeTimezoneAwareness testMethod=test_alpaca_api_format_compatibility>

    def test_alpaca_api_format_compatibility(self):
        """Test that datetime format is compatible with Alpaca API RFC3339 requirements."""
>       from ai_trading.data_fetcher import ensure_datetime
E       ImportError: cannot import name 'ensure_datetime' from 'ai_trading.data_fetcher' (unknown location)

tests/test_critical_datetime_fixes.py:34: ImportError
__________________________ TestDatetimeTimezoneAwareness.test_ensure_datetime_returns_timezone_aware ___________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_datetime_fixes.TestDatetimeTimezoneAwareness testMethod=test_ensure_datetime_returns_timezone_aware>

    def test_ensure_datetime_returns_timezone_aware(self):
        """Test that ensure_datetime returns timezone-aware datetime objects."""
>       from ai_trading.data_fetcher import ensure_datetime
E       ImportError: cannot import name 'ensure_datetime' from 'ai_trading.data_fetcher' (unknown location)

tests/test_critical_datetime_fixes.py:23: ImportError
____________________________________________ test_ai_trading_import_without_alpaca _____________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_ai_trading_import_without_alpaca():
        """Test that ai_trading can be imported even when alpaca packages are missing."""
        # Remove alpaca modules from sys.modules to simulate missing packages
        alpaca_modules = [module for module in sys.modules.keys() if 'alpaca' in module.lower()]
        for module in alpaca_modules:
            sys.modules.pop(module, None)
    
        # Simulate missing alpaca packages by setting them to None
        sys.modules['alpaca_trade_api'] = None
        sys.modules['alpaca.trading'] = None
        sys.modules['alpaca.data'] = None
        sys.modules['alpaca'] = None
    
        # Set testing mode
        import os
        os.environ['TESTING'] = 'true'
    
        try:
            # This should not raise an exception
            import ai_trading
            import ai_trading.core.bot_engine
    
            # Check that ALPACA_AVAILABLE is False
            assert hasattr(ai_trading.core.bot_engine, 'ALPACA_AVAILABLE')
>           assert ai_trading.core.bot_engine.ALPACA_AVAILABLE is False
E           AssertionError: assert True is False
E            +  where True = <module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'>.ALPACA_AVAILABLE
E            +    where <module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'> = <module 'ai_trading.core' from '/workspace/ai-trading-bot/ai_trading/core/__init__.py'>.bot_engine
E            +      where <module 'ai_trading.core' from '/workspace/ai-trading-bot/ai_trading/core/__init__.py'> = <module 'ai_trading' from '/workspace/ai-trading-bot/ai_trading/__init__.py'>.core

tests/test_alpaca_import.py:30: AssertionError
______________________________________________ test_no_import_time_initialization ______________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f471535fcd0>

    def test_no_import_time_initialization(monkeypatch):
        """Test that importing bot_engine does not initialize Alpaca clients."""
        monkeypatch.setenv("SHADOW_MODE", "true")
        monkeypatch.setenv("TRADING_MODE", "DRY_RUN")
        monkeypatch.setenv("PYTEST_RUNNING", "true")
    
        # Test that we can import the module without triggering initialization
        import ai_trading.core.bot_engine as eng
        # trading_client should be None since no initialization at import time
>       assert eng.trading_client is None
E       AssertionError: assert <ai_trading.broker.alpaca.AlpacaBroker object at 0x7f47155a6b10> is None
E        +  where <ai_trading.broker.alpaca.AlpacaBroker object at 0x7f47155a6b10> = <module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'>.trading_client

tests/test_alpaca_init_contract.py:13: AssertionError
____________________________________________________ test_safe_account_none ____________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_safe_account_none():
        # AI-AGENT-REF: ensure None is returned when Alpaca client missing
        ctx = SimpleNamespace(api=None)
>       assert safe_alpaca_get_account(ctx) is None
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_broker_unavailable_paths.py:10: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pybreaker/__init__.py:321: in _inner_wrapper
    return self.call(func, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pybreaker/__init__.py:251: in call
    return self.state.call(func, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pybreaker/__init__.py:725: in call
    self._handle_error(e)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pybreaker/__init__.py:700: in _handle_error
    raise exc
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pybreaker/__init__.py:720: in call
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
ai_trading/core/bot_engine.py:3288: in safe_alpaca_get_account
    return ctx.api.get_account()
           ^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.broker.alpaca.AlpacaBroker object at 0x7fdb40194790>

    def get_account(self) -> Any:
        if self._is_new:
            return self._call_with_retry("get_account", self._api.get_account)
>       return self._call_with_retry("get_account", self._api.get_account)
                                                    ^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: '_TClient' object has no attribute 'get_account'

ai_trading/broker/alpaca.py:281: AttributeError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:25,728", "level": "INFO", "name": "ai_trading.logging", "msg": "ENV_…AULT override=True", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:25,729", "level": "INFO", "name": "ai_trading.core.bot_engine", "msg": "ALPACA_DIAG", "initialized": true, "has_key": "***REDACTED***", "has_secret": "***REDACTED***", "base_url": "https://paper-api.alpaca.markets", "paper": true, "shadow_mode": true, "cwd": "/workspace/ai-trading-bot", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.logging:__init__.py:293 ENV_…AULT override=True
DEBUG    ai_trading.core.bot_engine:bot_engine.py:5315 Successfully imported Alpaca SDK classes
INFO     ai_trading.core.bot_engine:bot_engine.py:5341 ALPACA_DIAG
____________________________________________ test_pdt_rule_skips_without_false_fail ____________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7fdb402a4ed0>

    def test_pdt_rule_skips_without_false_fail(caplog):
        # AI-AGENT-REF: verify PDT check logs skip and not failure
        ctx = SimpleNamespace(api=None)
        with caplog.at_level(logging.INFO):
>           assert check_pdt_rule(ctx) is False
E           assert namespace(api=None) is False
E            +  where namespace(api=None) = check_pdt_rule(namespace(api=None))

tests/test_broker_unavailable_paths.py:17: AssertionError
________________________________ TestSentimentCaching.test_sentiment_cache_rate_limit_handling _________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_datetime_fixes.TestSentimentCaching testMethod=test_sentiment_cache_rate_limit_handling>

    def test_sentiment_cache_rate_limit_handling(self):
        """Test that sentiment caching properly handles rate limits."""
        try:
            import time
    
            from requests.exceptions import HTTPError
    
            from ai_trading.core.bot_engine import _SENTIMENT_CACHE, fetch_sentiment
    
            # Clear cache
            _SENTIMENT_CACHE.clear()
    
            # Mock the API key variables in bot_engine module
            with patch("ai_trading.core.bot_engine.SENTIMENT_API_KEY", "test_key"):
                with patch("ai_trading.core.bot_engine.NEWS_API_KEY", "test_key"):
                    # Mock the requests to simulate rate limiting
                    with patch("requests.get") as mock_get:
                        # First call - simulate rate limit (429)
                        mock_response = MagicMock()
                        mock_response.status_code = 429
                        mock_response.raise_for_status.side_effect = HTTPError(
                            "429 Too Many Requests"
                        )
                        mock_get.return_value = mock_response
    
                        # Mock context for fetch_sentiment
                        mock_ctx = MagicMock()
    
                        # This should handle the rate limit gracefully and cache neutral score
>                       score = fetch_sentiment(mock_ctx, "AAPL")
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_critical_datetime_fixes.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

symbol_or_ctx = <MagicMock id='139726052145168'>, symbol = 'AAPL'

    def fetch_sentiment(
        symbol_or_ctx, symbol: str | None = None, *, ttl_s: int = 300
    ) -> float:
        global _SENTIMENT_FAILURES
        """Fetch sentiment score with basic caching and failure tracking."""
        if symbol is None:
            symbol = symbol_or_ctx  # backward compat: first arg was context
        now = time.time()
        cached = _SENTIMENT_CACHE.get(symbol)
        if cached and now - cached[0] < ttl_s:
            return cached[1]
        if _SENTIMENT_FAILURES >= SENTIMENT_FAILURE_THRESHOLD or not SENTIMENT_API_KEY:
            return 0.0
        params = {"symbol": symbol, "apikey": SENTIMENT_API_KEY}
        try:
            # fmt: off
            resp = requests.get(SENTIMENT_API_URL, params=params, timeout=HTTP_TIMEOUT)
            # fmt: on
>           if resp.status_code in {429, 500, 502, 503, 504}:
               ^^^^^^^^^^^^^^^^
E           AttributeError: 'NoneType' object has no attribute 'status_code'

ai_trading/core/bot_engine.py:462: AttributeError
---------------------------------------------------- Captured stdout setup -----------------------------------------------------
{"ts": "2025-08-22 13:32:25,832", "level": "INFO", "name": "ai_trading.core.bot_engine", "msg": "META…NALS", "signals": ["breakout", "mean_reversion", "momentum"], "total_signals_analyzed": 3, "signals_above_threshold": 3, "threshold": 0.1, "min_trades": 1, "total_trades": 2, "bot_phase": "GENERAL"}
_______________________________________ test_data_fetcher_json_decode_is_valueerror_only _______________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_data_fetcher_json_decode_is_valueerror_only():
        src = _source(df_mod)
        # The JSON decode guard around resp.json() should not be broad
>       assert re.search(r"resp\.json\(\)\n\s*except ValueError:\n\s*payload\s*=\s*\{\}", src)
E       assert None
E        +  where None = <function search at 0x7f450ba8e200>('resp\\.json\\(\\)\\n\\s*except ValueError:\\n\\s*payload\\s*=\\s*\\{\\}', 'from __future__ import annotations\n\nimport datetime as _dt\nimport os\nimport warnings  # AI-AGENT-REF: control yfi..._minute_yfinance",\n    "is_market_open",\n    "get_last_available_bar",\n    "fh_fetcher",\n    "get_minute_df",\n]\n')
E        +    where <function search at 0x7f450ba8e200> = re.search

tests/runtime/test_exception_narrowing_df_main.py:23: AssertionError
_____________________________________________ test_wrapped_get_retries_and_parses ______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db827450>

    def test_wrapped_get_retries_and_parses(monkeypatch):
        calls = []
    
        def fake_request(self, method, url, **kwargs):
            calls.append(kwargs)
            assert kwargs["timeout"] == clamp_timeout(None, default_non_test=HTTP_TIMEOUT)
            if len(calls) == 1:
                raise requests.exceptions.RequestException("boom")
            return DummyResp({"ok": True})
    
        # Patch session.request used by wrapper
        monkeypatch.setattr(requests.Session, "request", fake_request)
        # Patch requests.get per requirement, though wrapper uses session
        monkeypatch.setattr(requests, "get", lambda url, **kw: fake_request(None, "GET", url, **kw))
    
>       resp = http.get("https://example.com")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/runtime/test_http_wrapped.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/utils/http.py:196: in get
    return request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ai_trading/utils/http.py:131: in request
    resp = retry_call(
ai_trading/utils/retry.py:31: in retry_call
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
ai_trading/utils/http.py:119: in _do_request
    return sess.request(method, url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7f44f5b177d0>, method = 'GET', url = 'https://example.com'
kwargs = {'timeout': 0.25}, @py_assert0 = None, @py_assert4 = None, @py_assert7 = None, @py_assert2 = None

    def fake_request(self, method, url, **kwargs):
        calls.append(kwargs)
        assert kwargs["timeout"] == clamp_timeout(None, default_non_test=HTTP_TIMEOUT)
        if len(calls) == 1:
>           raise requests.exceptions.RequestException("boom")
E           Exception: boom

tests/runtime/test_http_wrapped.py:22: Exception
__________________________________________________ test_dependency_injection ___________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_dependency_injection():
        """Test dependency injection container."""
        sys.path.append('ai_trading')
        from core.interfaces import IConfigManager, SimpleDependencyContainer
    
        container = SimpleDependencyContainer()
    
        # Mock implementation
        # Register implementation
>       container.register(IConfigManager, MockConfigManager)
                                           ^^^^^^^^^^^^^^^^^
E       NameError: name 'MockConfigManager' is not defined

tests/test_critical_fixes_implementation.py:261: NameError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:26,454", "level": "INFO", "name": "security", "msg": "Secu…nfig initialized with encryption support", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:26,454", "level": "INFO", "name": "security", "msg": "Secu…ager initialized", "bot_phase": "GENERAL"}
________________________________________________ test_performance_optimizations ________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_performance_optimizations():
        """Test performance optimizations work correctly."""
        sys.path.append('ai_trading')
        from indicator_manager import IndicatorManager, IndicatorType
    
        manager = IndicatorManager()
    
        # Create indicators
>       sma_id = manager.create_indicator(IndicatorType.SIMPLE_MOVING_AVERAGE, "TEST", 5)
                 ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'IndicatorManager' object has no attribute 'create_indicator'

tests/test_critical_fixes_implementation.py:283: AttributeError
__________________________________________________ test_daily_uses_date_only ___________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

mock_rest_cls = <MagicMock name='TradeApiREST' id='139943280786064'>

    @patch("ai_trading.alpaca_api.TradeApiREST")
    def test_daily_uses_date_only(mock_rest_cls):
        mock_rest = MagicMock()
        mock_rest.get_bars.return_value = _Resp(pd.DataFrame({"open": [1.0], "close": [1.1]}))
        mock_rest_cls.return_value = mock_rest
    
>       df = get_bars_df("SPY", "Day", feed="iex", adjustment="all")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_alpaca_time_params.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:184: in get_bars_df
    df = rest.get_bars(
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:735: in get_bars
    bars = list(self.get_bars_iter(symbol,
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:718: in get_bars_iter
    for bar in bars:
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:594: in _data_get
    resp = self.data_get(path, data=data, feed=feed,
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:274: in data_get
    return self._request(
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:222: in _request
    return self._one_request(method, url, opts, retry)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:248: in _one_request
    raise_api_error(resp, http_error)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:81: in raise_api_error
    raise http_error from None
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:243: in _one_request
    resp.raise_for_status()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Response [403]>

    def raise_for_status(self):
        """Raises :class:`HTTPError`, if one occurred."""
    
        http_error_msg = ""
        if isinstance(self.reason, bytes):
            # We attempt to decode utf-8 first because some servers
            # choose to localize their reason strings. If the string
            # isn't utf-8, we fall back to iso-8859-1 for all other
            # encodings. (See PR #3538)
            try:
                reason = self.reason.decode("utf-8")
            except UnicodeDecodeError:
                reason = self.reason.decode("iso-8859-1")
        else:
            reason = self.reason
    
        if 400 <= self.status_code < 500:
            http_error_msg = (
                f"{self.status_code} Client Error: {reason} for url: {self.url}"
            )
    
        elif 500 <= self.status_code < 600:
            http_error_msg = (
                f"{self.status_code} Server Error: {reason} for url: {self.url}"
            )
    
        if http_error_msg:
>           raise HTTPError(http_error_msg, response=self)
E           requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://data.alpaca.markets/v2/stocks/SPY/bars?timeframe=1Day&adjustment=all&start=2025-02-03&end=2025-08-22&feed=iex

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/requests/models.py:1026: HTTPError
_________________________________ TestCriticalFixes.test_data_staleness_detection_improvement __________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_fixes_validation.TestCriticalFixes testMethod=test_data_staleness_detection_improvement>

    def test_data_staleness_detection_improvement(self):
        """Test 4: Data Staleness Detection - Weekend/holiday awareness."""
        from ai_trading.utils.base import is_market_holiday, is_weekend
    
        # Test weekend detection
        saturday = datetime(2024, 1, 6, 12, 0, tzinfo=UTC)  # Saturday
        sunday = datetime(2024, 1, 7, 12, 0, tzinfo=UTC)  # Sunday
        monday = datetime(2024, 1, 8, 12, 0, tzinfo=UTC)  # Monday
    
        self.assertTrue(is_weekend(saturday), "Saturday should be detected as weekend")
        self.assertTrue(is_weekend(sunday), "Sunday should be detected as weekend")
        self.assertFalse(is_weekend(monday), "Monday should not be detected as weekend")
    
        # Test holiday detection
        new_years = date(2024, 1, 1)  # New Year's Day
        christmas = date(2024, 12, 25)  # Christmas
        regular_day = date(2024, 3, 15)  # Regular Friday
    
        self.assertTrue(
            is_market_holiday(new_years), "New Year's should be detected as holiday"
        )
        self.assertTrue(
            is_market_holiday(christmas), "Christmas should be detected as holiday"
        )
>       self.assertFalse(
            is_market_holiday(regular_day),
            "Regular day should not be detected as holiday",
        )
E       AssertionError: True is not false : Regular day should not be detected as holiday

tests/test_critical_fixes_validation.py:72: AssertionError
____________________________________ TestCriticalFixes.test_meta_learning_price_validation _____________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_fixes_validation.TestCriticalFixes testMethod=test_meta_learning_price_validation>

    def test_meta_learning_price_validation(self):
        """Test 2: MetaLearning Data Validation - Price validation logic."""
        # Mock pandas for testing
        try:
            import pandas as pd
    
            # Test data with mixed price types
            test_data = {
                "entry_price": ["100.50", "200", "invalid", "50.25"],
                "exit_price": ["105.75", "195", "0", "55.00"],
                "side": ["buy", "sell", "buy", "sell"],
                "signal_tags": ["momentum", "mean_revert", "momentum", "trend"],
            }
            df = pd.DataFrame(test_data)
    
            # Apply the validation logic from meta_learning.py
            df["entry_price"] = pd.to_numeric(df["entry_price"], errors="coerce")
            df["exit_price"] = pd.to_numeric(df["exit_price"], errors="coerce")
            df = df.dropna(subset=["entry_price", "exit_price"])
    
            # Filter out non-positive prices
            df = df[(df["entry_price"] > 0) & (df["exit_price"] > 0)]
    
            # Should have 2 valid rows (first and last)
>           self.assertEqual(
                len(df), 2, "Should have 2 rows with valid positive prices"
            )
E           AssertionError: 3 != 2 : Should have 2 rows with valid positive prices

tests/test_critical_fixes_validation.py:101: AssertionError
_____________________________________ TestCriticalFixes.test_systemd_service_configuration _____________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_fixes_validation.TestCriticalFixes testMethod=test_systemd_service_configuration>

    def test_systemd_service_configuration(self):
        """Test 3: Service Configuration - systemd service file."""
        service_file = os.path.join(
            os.getcwd(), "packaging", "systemd", "ai-trading.service"
        )
        self.assertTrue(os.path.exists(service_file), "service file should exist")
    
        # Legacy service files should be absent
        self.assertFalse(os.path.exists("ai-trading-bot.service"))
        self.assertFalse(os.path.exists(os.path.join("deploy", "ai-trading.service")))
    
        with open(service_file) as f:
            content = f.read()
    
        # Check key configuration elements
        self.assertIn("User=aiuser", content, "Service should run as aiuser")
        self.assertIn("Group=aiuser", content, "Service should run as aiuser group")
        self.assertIn(
            "WorkingDirectory=/home/aiuser/ai-trading-bot",
            content,
            "Should have correct working directory",
        )
>       self.assertIn(
            "NoNewPrivileges=true", content, "Should have security restrictions"
        )
E       AssertionError: 'NoNewPrivileges=true' not found in '[Unit]\nDescription=AI Trading Bot\nAfter=network.target\n\n[Service]\nType=simple\nUser=aiuser\nGroup=aiuser\nWorkingDirectory=/home/aiuser/ai-trading-bot\nEnvironment=PATH=/home/aiuser/ai-trading-bot/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin\nEnvironment=AI_TRADER_MODEL_MODULE=ai_trading.models.baseline\nEnvironmentFile=-/home/aiuser/ai-trading-bot/.env\nExecStart=/home/aiuser/ai-trading-bot/venv/bin/python -m ai_trading.main\nRestart=always\nRestartSec=10\nStandardOutput=journal\nStandardError=journal\n\n[Install]\nWantedBy=multi-user.target\n' : Should have security restrictions

tests/test_critical_fixes_validation.py:137: AssertionError
_________________________________________________ test_intraday_uses_rfc3339z __________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

mock_rest_cls = <MagicMock name='TradeApiREST' id='139943271168720'>

    @patch("ai_trading.alpaca_api.TradeApiREST")
    def test_intraday_uses_rfc3339z(mock_rest_cls):
        mock_rest = MagicMock()
        mock_rest.get_bars.return_value = _Resp(pd.DataFrame({"open": [1.0], "close": [1.1]}))
        mock_rest_cls.return_value = mock_rest
    
        start = dt.datetime(2025, 8, 19, 15, 0, 5, tzinfo=dt.timezone.utc)
        end = dt.datetime(2025, 8, 19, 16, 0, 5, tzinfo=dt.timezone.utc)
>       df = get_bars_df("SPY", "5Min", start=start, end=end, feed="iex", adjustment="all")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_alpaca_time_params.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:184: in get_bars_df
    df = rest.get_bars(
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:735: in get_bars
    bars = list(self.get_bars_iter(symbol,
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:718: in get_bars_iter
    for bar in bars:
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:594: in _data_get
    resp = self.data_get(path, data=data, feed=feed,
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:274: in data_get
    return self._request(
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:222: in _request
    return self._one_request(method, url, opts, retry)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:248: in _one_request
    raise_api_error(resp, http_error)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:81: in raise_api_error
    raise http_error from None
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:243: in _one_request
    resp.raise_for_status()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Response [403]>

    def raise_for_status(self):
        """Raises :class:`HTTPError`, if one occurred."""
    
        http_error_msg = ""
        if isinstance(self.reason, bytes):
            # We attempt to decode utf-8 first because some servers
            # choose to localize their reason strings. If the string
            # isn't utf-8, we fall back to iso-8859-1 for all other
            # encodings. (See PR #3538)
            try:
                reason = self.reason.decode("utf-8")
            except UnicodeDecodeError:
                reason = self.reason.decode("iso-8859-1")
        else:
            reason = self.reason
    
        if 400 <= self.status_code < 500:
            http_error_msg = (
                f"{self.status_code} Client Error: {reason} for url: {self.url}"
            )
    
        elif 500 <= self.status_code < 600:
            http_error_msg = (
                f"{self.status_code} Server Error: {reason} for url: {self.url}"
            )
    
        if http_error_msg:
>           raise HTTPError(http_error_msg, response=self)
E           requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://data.alpaca.markets/v2/stocks/SPY/bars?timeframe=5Min&adjustment=all&start=2025-08-19T15%3A00%3A05Z&end=2025-08-19T16%3A00%3A05Z&feed=iex

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/requests/models.py:1026: HTTPError
________________________________________________ test_day_timeframe_normalized _________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

mock_rest_cls = <MagicMock name='TradeApiREST' id='139943271176592'>

    @patch("ai_trading.alpaca_api.TradeApiREST")
    def test_day_timeframe_normalized(mock_rest_cls):
        mock_rest = MagicMock()
        mock_rest.get_bars.return_value = _Resp(pd.DataFrame({"open": [1.0], "close": [1.1]}))
        mock_rest_cls.return_value = mock_rest
    
>       df = get_bars_df("SPY", "Day", feed="iex", adjustment="all")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_alpaca_timeframe_mapping.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:184: in get_bars_df
    df = rest.get_bars(
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:735: in get_bars
    bars = list(self.get_bars_iter(symbol,
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:718: in get_bars_iter
    for bar in bars:
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:594: in _data_get
    resp = self.data_get(path, data=data, feed=feed,
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:274: in data_get
    return self._request(
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:222: in _request
    return self._one_request(method, url, opts, retry)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:248: in _one_request
    raise_api_error(resp, http_error)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:81: in raise_api_error
    raise http_error from None
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:243: in _one_request
    resp.raise_for_status()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Response [403]>

    def raise_for_status(self):
        """Raises :class:`HTTPError`, if one occurred."""
    
        http_error_msg = ""
        if isinstance(self.reason, bytes):
            # We attempt to decode utf-8 first because some servers
            # choose to localize their reason strings. If the string
            # isn't utf-8, we fall back to iso-8859-1 for all other
            # encodings. (See PR #3538)
            try:
                reason = self.reason.decode("utf-8")
            except UnicodeDecodeError:
                reason = self.reason.decode("iso-8859-1")
        else:
            reason = self.reason
    
        if 400 <= self.status_code < 500:
            http_error_msg = (
                f"{self.status_code} Client Error: {reason} for url: {self.url}"
            )
    
        elif 500 <= self.status_code < 600:
            http_error_msg = (
                f"{self.status_code} Server Error: {reason} for url: {self.url}"
            )
    
        if http_error_msg:
>           raise HTTPError(http_error_msg, response=self)
E           requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://data.alpaca.markets/v2/stocks/SPY/bars?timeframe=1Day&adjustment=all&start=2025-02-03&end=2025-08-22&feed=iex

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/requests/models.py:1026: HTTPError
_______________________________________________ test_no_broad_except_in_hotpaths _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_no_broad_except_in_hotpaths():
        p = subprocess.run([sys.executable, "tools/audit_exceptions.py", "--paths", *HOTPATHS], capture_output=True, text=True)
        assert p.returncode == 0
        data = json.loads(p.stdout.splitlines()[0])
        by_file = data.get("by_file", {})
        offenders = {f: hits for f, hits in by_file.items() if hits}
>       assert offenders == {}, f"broad except present in: {list(offenders)}"
E       AssertionError: broad except present in: ['ai_trading/core/bot_engine.py', 'ai_trading/meta_learning.py']
E       assert {'ai_trading/...tal_rows\n'}]} == {}
E         
E         Left contains 2 more items:
E         {'ai_trading/core/bot_engine.py': [{'file': 'ai_trading/core/bot_engine.py',
E                                             'line': 5793,
E                                             'snippet': '    except Exception as e:  # '
E                                                        'AI-AGENT-REF: soft-fail if '
E                                                        'import missing\n'...
E         
E         ...Full output truncated (41 lines hidden), use '-vv' to show

tests/runtime/test_no_broad_except_in_hotpaths.py:22: AssertionError
______________________________ TestMetaLearningSystemFixes.test_reduced_minimum_trade_requirement ______________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_trading_fixes.TestMetaLearningSystemFixes testMethod=test_reduced_minimum_trade_requirement>

    def test_reduced_minimum_trade_requirement(self):
        """Test that minimum trade requirement is reduced from 20 to 10."""
        # Create test data with only 12 trades (would fail with old requirement)
        self._create_test_trade_log(12)
    
        # Mock pandas and sklearn for the test
        with patch('meta_learning.pd') as mock_pd, \
             patch('meta_learning.Path') as mock_path:
    
            mock_df = Mock()
            mock_df.empty = False
            mock_df.__len__ = Mock(return_value=12)
            mock_df.dropna.return_value = mock_df
            mock_df.to_numeric.return_value = mock_df
            mock_df.fillna.return_value = mock_df
            mock_df.__getitem__ = Mock(return_value=mock_df)
            mock_df.iloc = Mock()
            mock_df.iloc.__getitem__ = Mock(return_value=100.0)
    
            mock_pd.read_csv.return_value = mock_df
            mock_pd.to_numeric.return_value = mock_df
            mock_pd.notna.return_value = mock_df
    
            mock_path.return_value.exists.return_value = True
    
            # Should succeed with reduced requirement (10)
>           result = meta_learning.retrain_meta_learner(
                trade_log_path=self.trade_log_path,
                min_samples=10
            )

tests/test_critical_trading_fixes.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_log_path = '/tmp/tmpebod1_1_/test_trades.csv', model_path = 'meta_model.pkl', history_path = 'meta_retrain_history.pkl'
min_samples = 10

    def retrain_meta_learner(
        trade_log_path: str = None,
        model_path: str = "meta_model.pkl",
        history_path: str = "meta_retrain_history.pkl",
        min_samples: int = 10,  # AI-AGENT-REF: Reduced from 20 to 10 for faster activation
    ) -> bool:
        """Retrain the meta-learner model from trade logs.
    
        Parameters
        ----------
        trade_log_path : str
            CSV file containing historical trades.
        model_path : str
            Destination to write the trained model pickle.
        history_path : str
            Path to a pickle file storing retrain metrics history.
        min_samples : int
            Minimum number of samples required to train.
    
        Returns
        -------
        bool
            ``True`` if retraining succeeded and the checkpoint was written.
        """
    
        # Set default trade log path
        if trade_log_path is None:
            settings = get_settings()
            trade_log_path = settings.trade_log_file if config else "trades.csv"
    
        logger.info(
            "META_RETRAIN_START",
            extra={"trade_log": trade_log_path, "model_path": model_path},
        )
    
        # AI-AGENT-REF: Perform comprehensive data quality validation before training
        quality_report = validate_trade_data_quality(trade_log_path)
    
        try:
            if pd is None:
                logger.error("pandas not available for meta learning")
                return False
            df = pd.read_csv(trade_log_path)
        except (OSError, AttributeError) as exc:  # pragma: no cover - I/O failures
            logger.error("Failed reading trade log: %s", exc, exc_info=True)
            return False
    
        required_cols = {"entry_price", "exit_price", "side"}
        total_rows = len(df)
        valid = (
            df[["entry_price", "exit_price"]]
            .apply(pd.to_numeric, errors="coerce")
            .notna()
            .all(axis=1)
        )
        try:
            valid_rows = int(valid.sum())
        except Exception:  # pragma: no cover - tolerate mock objects
            valid_rows = total_rows
        cols_obj = getattr(df, "columns", [])
        try:
            cols = set(cols_obj)
        except TypeError:  # pragma: no cover - mocks may not be iterable
            cols = set()
        quality_report.update(
            {
                "file_exists": bool(total_rows),
                "has_valid_format": required_cols.issubset(cols),
                "row_count": total_rows,
                "valid_price_rows": valid_rows,
                "data_quality_score": (valid_rows / total_rows) if total_rows else 0.0,
            }
        )
    
        if total_rows > 0 and "Trade log file is empty" in quality_report["issues"]:
            try:
                quality_report["issues"].remove("Trade log file is empty")
            except ValueError:
                pass
    
        logger.info(
            "META_LEARNING_QUALITY_CHECK",
            extra={
                "file_exists": quality_report["file_exists"],
                "valid_format": quality_report["has_valid_format"],
                "total_rows": quality_report["row_count"],
                "valid_price_rows": quality_report["valid_price_rows"],
                "quality_score": quality_report["data_quality_score"],
            },
        )
    
        for issue in quality_report["issues"]:
            logger.warning(f"META_LEARNING_DATA_ISSUE: {issue}")
        for rec in quality_report["recommendations"]:
            logger.info(f"META_LEARNING_RECOMMENDATION: {rec}")
    
>       if not required_cols.issubset(df.columns):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: 'Mock' object is not iterable

ai_trading/meta_learning.py:747: TypeError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:27,198", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "META…TART", "trade_log": "/tmp/tmpebod1_1_/test_trades.csv", "model_path": "meta_model.pkl", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,200", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "META…HECK", "file_exists": true, "valid_format": false, "total_rows": 12, "valid_price_rows": 12, "quality_score": 1.0, "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,200", "level": "WARNING", "name": "ai_trading.meta_learning", "msg": "META…SSUE: Mixed log formats detected: 12 audit rows, 1 meta rows", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,200", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "META…TION: Separate audit and meta…ning logs or implement unified parsing", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.meta_learning:meta_learning.py:681 META…TART
DEBUG    ai_trading.meta_learning:meta_learning.py:312 Invalid price in meta format row: could not convert string to float: 'side'
INFO     ai_trading.meta_learning:meta_learning.py:731 META…HECK
WARNING  ai_trading.meta_learning:meta_learning.py:743 META…SSUE: Mixed log formats detected: 12 audit rows, 1 meta rows
INFO     ai_trading.meta_learning:meta_learning.py:745 META…TION: Separate audit and meta…ning logs or implement unified parsing
_______________________________ TestSystemMonitoringAndAlerting.test_meta_learning_configuration _______________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_trading_fixes.TestSystemMonitoringAndAlerting testMethod=test_meta_learning_configuration>

    def test_meta_learning_configuration(self):
        """Test meta-learning configuration parameters."""
        self.assertTrue(hasattr(config, 'META_LEARNING_BOOTSTRAP_ENABLED'))
        self.assertTrue(hasattr(config, 'META_LEARNING_MIN_TRADES_REDUCED'))
        self.assertTrue(hasattr(config, 'META_LEARNING_BOOTSTRAP_WIN_RATE'))
    
>       self.assertEqual(config.META_LEARNING_MIN_TRADES_REDUCED, 10)
E       AssertionError: True != 10

tests/test_critical_trading_fixes.py:386: AssertionError
____________________________ TestSystemMonitoringAndAlerting.test_sentiment_success_rate_monitoring ____________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_trading_fixes.TestSystemMonitoringAndAlerting testMethod=test_sentiment_success_rate_monitoring>

    def test_sentiment_success_rate_monitoring(self):
        """Test sentiment success rate monitoring configuration."""
        self.assertTrue(hasattr(config, 'SENTIMENT_SUCCESS_RATE_TARGET'))
>       self.assertEqual(config.SENTIMENT_SUCCESS_RATE_TARGET, 0.90)
E       AssertionError: 0.8 != 0.9

tests/test_critical_trading_fixes.py:378: AssertionError
__________________________________________________ test_tf_object_normalized ___________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

mock_rest_cls = <MagicMock name='TradeApiREST' id='139943272046992'>

    @patch("ai_trading.alpaca_api.TradeApiREST")
    def test_tf_object_normalized(mock_rest_cls):
        mock_rest = MagicMock()
        mock_rest.get_bars.return_value = _Resp(pd.DataFrame({"open": [1.0], "close": [1.1]}))
        mock_rest_cls.return_value = mock_rest
    
>       df = get_bars_df("SPY", TimeFrame(1, TimeFrameUnit.Day), feed="iex", adjustment="all")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_alpaca_timeframe_mapping.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:184: in get_bars_df
    df = rest.get_bars(
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:735: in get_bars
    bars = list(self.get_bars_iter(symbol,
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:718: in get_bars_iter
    for bar in bars:
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:594: in _data_get
    resp = self.data_get(path, data=data, feed=feed,
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:274: in data_get
    return self._request(
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:222: in _request
    return self._one_request(method, url, opts, retry)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:248: in _one_request
    raise_api_error(resp, http_error)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:81: in raise_api_error
    raise http_error from None
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:243: in _one_request
    resp.raise_for_status()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Response [403]>

    def raise_for_status(self):
        """Raises :class:`HTTPError`, if one occurred."""
    
        http_error_msg = ""
        if isinstance(self.reason, bytes):
            # We attempt to decode utf-8 first because some servers
            # choose to localize their reason strings. If the string
            # isn't utf-8, we fall back to iso-8859-1 for all other
            # encodings. (See PR #3538)
            try:
                reason = self.reason.decode("utf-8")
            except UnicodeDecodeError:
                reason = self.reason.decode("iso-8859-1")
        else:
            reason = self.reason
    
        if 400 <= self.status_code < 500:
            http_error_msg = (
                f"{self.status_code} Client Error: {reason} for url: {self.url}"
            )
    
        elif 500 <= self.status_code < 600:
            http_error_msg = (
                f"{self.status_code} Server Error: {reason} for url: {self.url}"
            )
    
        if http_error_msg:
>           raise HTTPError(http_error_msg, response=self)
E           requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://data.alpaca.markets/v2/stocks/SPY/bars?timeframe=%3Ctests.test_alpaca_timeframe_mapping.TimeFrame+object+at+0x7f4715be6890%3E&adjustment=all&start=2025-02-03T13%3A31%3A27Z&end=2025-08-22T13%3A31%3A27Z&feed=iex

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/requests/models.py:1026: HTTPError
____________________________________________ test_disable_daily_retrain_env_parsing ____________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_disable_daily_retrain_env_parsing():
        """Test DISABLE_DAILY_RETRAIN parsing for various values."""
        test_cases = [
            ("true", True),
            ("True", True),
            ("TRUE", True),
            ("1", True),
            ("false", False),
            ("False", False),
            ("FALSE", False),
            ("0", False),
            ("", False),  # empty string should default to False
            ("invalid", False),  # invalid values should default to False
        ]
    
        for env_value, expected in test_cases:
            # Set the environment variable
            os.environ["DISABLE_DAILY_RETRAIN"] = env_value
            os.environ["TESTING"] = "1"  # Enable testing mode
    
            # Clear module cache to force re-import
            if 'config' in os.sys.modules:
                del os.sys.modules['config']
    
            # Import config module
            import ai_trading.config as config
    
            # Test the result
>           actual = config.DISABLE_DAILY_RETRAIN
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_env_flags.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'DISABLE_DAILY_RETRAIN'

    def __getattr__(name: str):  # AI-AGENT-REF: lazy export for TradingConfig
        if name == "TradingConfig":
            from .management import TradingConfig as _TC
            return _TC
>       raise AttributeError(name)
E       AttributeError: DISABLE_DAILY_RETRAIN

ai_trading/config/__init__.py:46: AttributeError
_______________________________________________ test_disable_daily_retrain_unset _______________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_disable_daily_retrain_unset():
        """Test DISABLE_DAILY_RETRAIN when environment variable is unset."""
        # Remove the environment variable if it exists
        if "DISABLE_DAILY_RETRAIN" in os.environ:
            del os.environ["DISABLE_DAILY_RETRAIN"]
    
        os.environ["TESTING"] = "1"  # Enable testing mode
    
        # Clear module cache
        if 'config' in os.sys.modules:
            del os.sys.modules['config']
    
        # Import config module
        import ai_trading.config as config
    
        # Should default to False
>       assert config.DISABLE_DAILY_RETRAIN == False
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_env_flags.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'DISABLE_DAILY_RETRAIN'

    def __getattr__(name: str):  # AI-AGENT-REF: lazy export for TradingConfig
        if name == "TradingConfig":
            from .management import TradingConfig as _TC
            return _TC
>       raise AttributeError(name)
E       AttributeError: DISABLE_DAILY_RETRAIN

ai_trading/config/__init__.py:46: AttributeError
_________________________________________ test_disable_daily_retrain_fallback_settings _________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_disable_daily_retrain_fallback_settings():
        """Test DISABLE_DAILY_RETRAIN through fallback settings."""
        # Test the fallback _FallbackSettings class directly
        if 'config' in os.sys.modules:
            del os.sys.modules['config']
    
        os.environ["TESTING"] = "1"
        os.environ["DISABLE_DAILY_RETRAIN"] = "true"
    
        import ai_trading.config as config
    
        # Check that fallback settings work
>       fallback = config._FallbackSettings()
                   ^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_env_flags.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = '_FallbackSettings'

    def __getattr__(name: str):  # AI-AGENT-REF: lazy export for TradingConfig
        if name == "TradingConfig":
            from .management import TradingConfig as _TC
            return _TC
>       raise AttributeError(name)
E       AttributeError: _FallbackSettings

ai_trading/config/__init__.py:46: AttributeError
______________________ TestEnvironmentOrderAndLazyImport.test_dotenv_loaded_before_settings_construction _______________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <MagicMock name='load_dotenv' id='139726042624144'>

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
>           raise AssertionError(msg)
E           AssertionError: Expected 'load_dotenv' to have been called.

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:908: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7f14822ec5d0>

    def test_dotenv_loaded_before_settings_construction(self):
        """Test that .env is loaded before Settings is constructed."""
        # Create a temporary .env file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.env', delete=False) as f:
            f.write("TEST_DOTENV_ORDER=loaded_early\n")
            f.write("ALPACA_API_KEY=test_from_dotenv\n")
            temp_env_path = f.name
    
        try:
            # Clear any existing env var
            if 'TEST_DOTENV_ORDER' in os.environ:
                del os.environ['TEST_DOTENV_ORDER']
            if 'ALPACA_API_KEY' in os.environ:
                del os.environ['ALPACA_API_KEY']
    
            # Mock dotenv.load_dotenv to load our temp file
            with patch('dotenv.load_dotenv') as mock_load_dotenv:
                def side_effect(*args, **kwargs):
                    # Simulate loading the .env file
                    with open(temp_env_path) as env_file:
                        for line in env_file:
                            if '=' in line and not line.startswith('#'):
                                key, value = line.strip().split('=', 1)
                                os.environ[key] = value
    
                mock_load_dotenv.side_effect = side_effect
    
                # Import main module (this should load .env before Settings)
    
                # Verify .env was loaded before Settings construction
>               mock_load_dotenv.assert_called()
E               AssertionError: Expected 'load_dotenv' to have been called.

tests/test_env_order_and_lazy_import.py:48: AssertionError
_________________________ TestEnvironmentOrderAndLazyImport.test_lazy_engine_loading_caches_components _________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7f14822ecc90>

    def test_lazy_engine_loading_caches_components(self):
        """Test that engine components are cached after first load."""
        from ai_trading import runner
    
        # Reset the lazy import cache
        runner._bot_engine = None
        runner._bot_state_class = None
    
        with patch('ai_trading.core.bot_engine.run_all_trades_worker') as mock_worker:
            with patch('ai_trading.core.bot_engine.BotState') as mock_state:
                mock_worker.return_value = "cached_worker"
                mock_state.return_value = "cached_state"
    
                # First call should import
                worker1, state1 = runner._load_engine()
    
                # Second call should use cached values
                worker2, state2 = runner._load_engine()
    
                # Should be the same objects
>               assert worker1 == worker2 == "cached_worker"
E               AssertionError: assert <MagicMock name='run_all_trades_worker' id='139726042918928'> == 'cached_worker'

tests/test_env_order_and_lazy_import.py:130: AssertionError
_________________________________________________ test_main_starts_api_thread __________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db50df10>

    def test_main_starts_api_thread(monkeypatch):
        """main launches the API thread and runs a cycle."""
        monkeypatch.setenv("SCHEDULER_ITERATIONS", "1")
        # AI-AGENT-REF: Mock required environment variables for validation
        monkeypatch.setenv("WEBHOOK_SECRET", "test_secret")
        monkeypatch.setenv("ALPACA_API_KEY", "test_key")
        # AI-AGENT-REF: Use environment variables to avoid hardcoded secrets
        monkeypatch.setenv("TEST_ALPACA_SECRET_KEY", "test_secret_key")
    
        # AI-AGENT-REF: Mock the config object directly to ensure environment validation passes
        monkeypatch.setattr(main, "config", MockConfig())
    
        called = {}
    
        class DummyThread:
            def __init__(self, target, args=(), daemon=None):
                called["created"] = True
                self.target = target
                self.args = args
    
            def start(self):
                called["started"] = True
                self.target(*self.args)
    
            def is_alive(self):
                # AI-AGENT-REF: Add missing is_alive method to prevent AttributeError
                return True
    
        monkeypatch.setattr(main, "Thread", DummyThread)
        # AI-AGENT-REF: Fix lambda signature to accept ready_signal parameter
        monkeypatch.setattr(
            main, "start_api", lambda ready_signal=None: called.setdefault("api", True)
        )
        monkeypatch.setattr(
            main,
            "run_cycle",
            lambda: called.setdefault("cycle", 0)
            or called.update(cycle=called.get("cycle", 0) + 1),
        )
        monkeypatch.setattr(main.time, "sleep", lambda s: None)
    
>       main.main()

tests/test_additional_coverage.py:133: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/main.py:341: in main
    _validate_runtime_config(config, S)
ai_trading/main.py:166: in _validate_runtime_config
    setattr(tcfg, "max_position_size", float(fallback))
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:997: in __setattr__
    elif (setattr_handler := self._setattr_handler(name, value)) is not None:
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
name = 'max_position_size', value = 8000.0

    def _setattr_handler(self, name: str, value: Any) -> Callable[[BaseModel, str, Any], None] | None:
        """Get a handler for setting an attribute on the model instance.
    
        Returns:
            A handler for setting an attribute on the model instance. Used for memoization of the handler.
            Memoizing the handlers leads to a dramatic performance improvement in `__setattr__`
            Returns `None` when memoization is not safe, then the attribute is set directly.
        """
        cls = self.__class__
        if name in cls.__class_vars__:
            raise AttributeError(
                f'{name!r} is a ClassVar of `{cls.__name__}` and cannot be set on an instance. '
                f'If you want to set a value on the class, use `{cls.__name__}.{name} = value`.'
            )
        elif not _fields.is_valid_field_name(name):
            if (attribute := cls.__private_attributes__.get(name)) is not None:
                if hasattr(attribute, '__set__'):
                    return lambda model, _name, val: attribute.__set__(model, val)
                else:
                    return _SIMPLE_SETATTR_HANDLERS['private']
            else:
                _object_setattr(self, name, value)
                return None  # Can not return memoized handler with possibly freeform attr names
    
        attr = getattr(cls, name, None)
        # NOTE: We currently special case properties and `cached_property`, but we might need
        # to generalize this to all data/non-data descriptors at some point. For non-data descriptors
        # (such as `cached_property`), it isn't obvious though. `cached_property` caches the value
        # to the instance's `__dict__`, but other non-data descriptors might do things differently.
        if isinstance(attr, cached_property):
            return _SIMPLE_SETATTR_HANDLERS['cached_property']
    
        _check_frozen(cls, name, value)
    
        # We allow properties to be set only on non frozen models for now (to match dataclasses).
        # This can be changed if it ever gets requested.
        if isinstance(attr, property):
            return lambda model, _name, val: attr.__set__(model, val)
        elif cls.model_config.get('validate_assignment'):
            return _SIMPLE_SETATTR_HANDLERS['validate_assignment']
        elif name not in cls.__pydantic_fields__:
            if cls.model_config.get('extra') != 'allow':
                # TODO - matching error
>               raise ValueError(f'"{cls.__name__}" object has no field "{name}"')
E               ValueError: "Settings" object has no field "max_position_size"

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1044: ValueError
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.main:main.py:335 DATA_CONFIG feed=iex adjustment=all timeframe=1Day/1Min provider=alpaca
INFO     ai_trading.position_sizing:position_sizing.py:60 CONF…OFIX
CRITICAL ai_trading.main:main.py:343 RUNT…ALID
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 13:32:27,453", "level": "INFO", "name": "ai_trading.main", "msg": "DATA_CONFIG feed=iex adjustment=all timeframe=1Day/1Min provider=alpaca", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,455", "level": "INFO", "name": "ai_trading.position_sizing", "msg": "CONF…OFIX", "field": "max_position_size", "given": 0.0, "fallback": 8000.0, "reason": "derived_equity_cap", "equity": null, "capital_cap": 0.04, "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,455", "level": "CRITICAL", "name": "ai_trading.main", "msg": "RUNT…ALID", "error": "\"Settings\" object has no field \"max_position_size\"", "bot_phase": "GENERAL"}
______________________________ TestEnvironmentOrderAndLazyImport.test_run_cycle_uses_lazy_loading ______________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <MagicMock id='139726053515344'>, args = (<MagicMock name='mock()' id='139726043458512'>, None), kwargs = {}
msg = "Expected 'mock' to be called once. Called 0 times."

    def assert_called_once_with(self, /, *args, **kwargs):
        """assert that the mock was called exactly once and that that call was
        with the specified arguments."""
        if not self.call_count == 1:
            msg = ("Expected '%s' to be called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'mock' to be called once. Called 0 times.

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:950: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7f14822ee2d0>

    def test_run_cycle_uses_lazy_loading(self):
        """Test that run_cycle uses lazy loading for bot engine."""
        from ai_trading import runner
    
        # Reset lazy import cache
        runner._bot_engine = None
        runner._bot_state_class = None
    
        # Mock the components
        mock_worker = MagicMock()
        mock_state_class = MagicMock()
        mock_state_instance = MagicMock()
        mock_state_class.return_value = mock_state_instance
    
        with patch.object(runner, '_load_engine') as mock_load:
            mock_load.return_value = (mock_worker, mock_state_class)
    
            # Call run_cycle
            runner.run_cycle()
    
            # Verify lazy loading was called
            mock_load.assert_called_once()
    
            # Verify worker was called with state instance
>           mock_worker.assert_called_once_with(mock_state_instance, None)
E           AssertionError: Expected 'mock' to be called once. Called 0 times.

tests/test_env_order_and_lazy_import.py:161: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:27,552", "level": "WARNING", "name": "ai_trading.runner", "msg": "Failed to warm cache during state setup: 'Settings' object has no attribute 'data…days'", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,553", "level": "WARNING", "name": "ai_trading.logging", "msg": "DEPR…LIAS", "alias": "BOT_MODE", "use": "TRADING_MODE", "value": "balanced", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,553", "level": "INFO", "name": "ai_trading.runner", "msg": "PARA…TIVE", "CAPITAL_CAP": 0.04, "DOLLAR_RISK_LIMIT": 0.05, "MAX_POSITION_SIZE": 8000.0, "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,554", "level": "INFO", "name": "ai_trading.logging", "msg": "ENV_…AULT override=True", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,554", "level": "INFO", "name": "ai_trading.core.bot_engine", "msg": "ALPACA_DIAG", "initialized": true, "has_key": "***REDACTED***", "has_secret": "***REDACTED***", "base_url": "https://paper-api.alpaca.markets", "paper": true, "shadow_mode": true, "cwd": "/workspace/ai-trading-bot", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,555", "level": "INFO", "name": "ai_trading.core.bot_engine", "msg": "Risk engine: ai_trading.risk.engine.RiskEngine", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,555", "level": "INFO", "name": "ai_trading.logging", "msg": "Perf…ator initialized with 20 day window", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,555", "level": "INFO", "name": "ai_trading.logging", "msg": "Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,555", "level": "INFO", "name": "ai_trading.logging", "msg": "Loaded strategies: Mome…tegy", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,555", "level": "INFO", "name": "ai_trading.logging", "msg": "Draw…aker initialized", "max_drawdown": "8.00%", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,555", "level": "ERROR", "name": "ai_trading.core.bot_engine", "msg": "MODE…SING", "hint_paths": ["AI_TRADER_MODEL_PATH", "TradingConfig.ml_model_path"], "hint_modules": ["AI_TRADER_MODEL_MODULE", "TradingConfig.ml_model_module"], "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.runner:runner.py:140 Failed to warm cache during state setup: 'Settings' object has no attribute 'data_warmup_lookback_days'
WARNING  ai_trading.logging:__init__.py:293 DEPR…LIAS
INFO     ai_trading.runner:runner.py:161 PARA…TIVE
INFO     ai_trading.logging:__init__.py:293 ENV_…AULT override=True
DEBUG    ai_trading.core.bot_engine:bot_engine.py:5315 Successfully imported Alpaca SDK classes
INFO     ai_trading.core.bot_engine:bot_engine.py:5341 ALPACA_DIAG
INFO     ai_trading.core.bot_engine:bot_engine.py:550 Risk engine: ai_trading.risk.engine.RiskEngine
INFO     ai_trading.logging:performance_allocator.py:115 Perf…ator initialized with 20 day window
INFO     ai_trading.logging:__init__.py:293 Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate
INFO     ai_trading.logging:__init__.py:293 Loaded strategies: Mome…tegy
INFO     ai_trading.logging:emit_once.py:21 Draw…aker initialized
ERROR    ai_trading.core.bot_engine:bot_engine.py:531 MODE…SING
ERROR    ai_trading.runner:runner.py:177 Trading cycle failed: Model required but not configured. Set one of: AI_TRADER_MODEL_PATH=<abs path to .joblib/.pkl> or AI_TRADER_MODEL_MODULE=<import.path with get_model()/Model()>.
Traceback (most recent call last):
  File "/workspace/ai-trading-bot/ai_trading/runner.py", line 172, in run_cycle
    runtime = enhance_runtime_with_context(runtime, lazy_ctx)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/ai-trading-bot/ai_trading/core/runtime.py", line 112, in enhance_runtime_with_context
    runtime.api = getattr(lazy_context, 'api', None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/ai-trading-bot/ai_trading/core/bot_engine.py", line 5483, in api
    self._ensure_initialized()
  File "/workspace/ai-trading-bot/ai_trading/core/bot_engine.py", line 5453, in _ensure_initialized
    self._context.model = _load_required_model()
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/ai-trading-bot/ai_trading/core/bot_engine.py", line 538, in _load_required_model
    raise RuntimeError(msg)
RuntimeError: Model required but not configured. Set one of: AI_TRADER_MODEL_PATH=<abs path to .joblib/.pkl> or AI_TRADER_MODEL_MODULE=<import.path with get_model()/Model()>.
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 13:32:27,555", "level": "ERROR", "name": "ai_trading.runner", "msg": "Trading cycle failed: Model required but not configured. Set one of: AI_T…PATH=<abs path to .joblib/.pkl> or AI_T…DULE=<import.path with get_model()/Model()>.\nTraceback (most recent call last):\n  File \"/workspace/ai-t…-bot/ai_trading/runner.py\", line 172, in run_cycle\n    runtime = enha…text(runtime, lazy_ctx)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/ai-t…-bot/ai_trading/core/runtime.py\", line 112, in enha…text\n    runtime.api = getattr(lazy…text, 'api', None)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/ai-t…-bot/ai_trading/core/bot_engine.py\", line 5483, in api\n    self._ens…ized()\n  File \"/workspace/ai-t…-bot/ai_trading/core/bot_engine.py\", line 5453, in _ens…ized\n    self._context.model = _loa…odel()\n                          ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/ai-t…-bot/ai_trading/core/bot_engine.py\", line 538, in _loa…odel\n    raise Runt…rror(msg)\nRunt…rror: Model required but not configured. Set one of: AI_T…PATH=<abs path to .joblib/.pkl> or AI_T…DULE=<import.path with get_model()/Model()>.", "bot_phase": "GENERAL"}
__________________________________________________ test_ensure_datetime_none ___________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

value = None

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except Exception as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
>               raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
E               TypeError: Unsupported datetime type: NoneType

ai_trading/data/timeutils.py:45: TypeError

The above exception was the direct cause of the following exception:

value = None

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
>           return ensure_utc_datetime(value, allow_callables=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

ai_trading/data_fetcher.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except Exception as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
                raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
        except Exception as e:
            if default is not None:
                return ensure_utc_datetime(default, allow_callables=allow_callables, clamp_to=clamp_to)
>           raise ValueError(f"Invalid datetime input: {value!r}") from e
E           ValueError: Invalid datetime input: None

ai_trading/data/timeutils.py:49: ValueError

The above exception was the direct cause of the following exception:

    def test_ensure_datetime_none():
        with pytest.raises(ValueError):
>           data_fetcher.ensure_datetime(None)

tests/test_data_fetcher_datetime.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
            return ensure_utc_datetime(value, allow_callables=False)
        except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
>           raise TypeError(f"Invalid datetime input: {e}") from e
E           TypeError: Invalid datetime input: Invalid datetime input: None

ai_trading/data_fetcher.py:205: TypeError
____________________________________________________ test_minute_normalized ____________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

mock_rest_cls = <MagicMock name='TradeApiREST' id='139943270004560'>

    @patch("ai_trading.alpaca_api.TradeApiREST")
    def test_minute_normalized(mock_rest_cls):
        mock_rest = MagicMock()
        mock_rest.get_bars.return_value = _Resp(pd.DataFrame({"open": [1.0], "close": [1.1]}))
        mock_rest_cls.return_value = mock_rest
    
>       df = get_bars_df("SPY", "Minute", feed="iex", adjustment="all")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_alpaca_timeframe_mapping.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:184: in get_bars_df
    df = rest.get_bars(
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:735: in get_bars
    bars = list(self.get_bars_iter(symbol,
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:718: in get_bars_iter
    for bar in bars:
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:594: in _data_get
    resp = self.data_get(path, data=data, feed=feed,
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:274: in data_get
    return self._request(
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:222: in _request
    return self._one_request(method, url, opts, retry)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:248: in _one_request
    raise_api_error(resp, http_error)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:81: in raise_api_error
    raise http_error from None
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:243: in _one_request
    resp.raise_for_status()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Response [403]>

    def raise_for_status(self):
        """Raises :class:`HTTPError`, if one occurred."""
    
        http_error_msg = ""
        if isinstance(self.reason, bytes):
            # We attempt to decode utf-8 first because some servers
            # choose to localize their reason strings. If the string
            # isn't utf-8, we fall back to iso-8859-1 for all other
            # encodings. (See PR #3538)
            try:
                reason = self.reason.decode("utf-8")
            except UnicodeDecodeError:
                reason = self.reason.decode("iso-8859-1")
        else:
            reason = self.reason
    
        if 400 <= self.status_code < 500:
            http_error_msg = (
                f"{self.status_code} Client Error: {reason} for url: {self.url}"
            )
    
        elif 500 <= self.status_code < 600:
            http_error_msg = (
                f"{self.status_code} Server Error: {reason} for url: {self.url}"
            )
    
        if http_error_msg:
>           raise HTTPError(http_error_msg, response=self)
E           requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://data.alpaca.markets/v2/stocks/SPY/bars?timeframe=1Minute&adjustment=all&start=2025-02-03T13%3A31%3A27Z&end=2025-08-22T13%3A31%3A27Z&feed=iex

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/requests/models.py:1026: HTTPError
________________________________________________ test_ensure_datetime_empty_str ________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

value = ''

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except Exception as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
>               tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E               ValueError: Invalid isoformat string: ''

ai_trading/data/timeutils.py:42: ValueError

The above exception was the direct cause of the following exception:

value = ''

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
>           return ensure_utc_datetime(value, allow_callables=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

ai_trading/data_fetcher.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = ''

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except Exception as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
                raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
        except Exception as e:
            if default is not None:
                return ensure_utc_datetime(default, allow_callables=allow_callables, clamp_to=clamp_to)
>           raise ValueError(f"Invalid datetime input: {value!r}") from e
E           ValueError: Invalid datetime input: ''

ai_trading/data/timeutils.py:49: ValueError

The above exception was the direct cause of the following exception:

    def test_ensure_datetime_empty_str():
        with pytest.raises(ValueError):
>           data_fetcher.ensure_datetime("")

tests/test_data_fetcher_datetime.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = ''

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
            return ensure_utc_datetime(value, allow_callables=False)
        except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
>           raise TypeError(f"Invalid datetime input: {e}") from e
E           TypeError: Invalid datetime input: Invalid datetime input: ''

ai_trading/data_fetcher.py:205: TypeError
________________________ TestEnvironmentOrderAndLazyImport.test_main_loads_dotenv_before_runner_import _________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <MagicMock name='load_dotenv' id='139726042671056'>

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
>           raise AssertionError(msg)
E           AssertionError: Expected 'load_dotenv' to have been called.

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:908: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7f14822ee450>

    def test_main_loads_dotenv_before_runner_import(self):
        """Test that main.py loads .env before importing runner."""
        # Mock load_dotenv to track when it's called
        with patch('dotenv.load_dotenv') as mock_load_dotenv:
            with patch('ai_trading.runner.run_cycle') as mock_run_cycle:
                # Import and call run_bot from main
                from ai_trading.main import run_bot
    
                # Call run_bot
                result = run_bot()
    
                # Verify .env was loaded
>               mock_load_dotenv.assert_called()
E               AssertionError: Expected 'load_dotenv' to have been called.

tests/test_env_order_and_lazy_import.py:175: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:27,770", "level": "WARNING", "name": "ai_trading.logging", "msg": "WARNING: 5 handlers detected - possible duplicate logging setup", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,771", "level": "ERROR", "name": "ai_trading.logging", "msg": "Logging validation failed: ['Too many handlers detected: 5 (expected ≤ 2)']", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:27,771", "level": "ERROR", "name": "root", "msg": "Logging validation failed: ['Too many handlers detected: 5 (expected ≤ 2)']", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.logging:__init__.py:951 WARNING: 5 handlers detected - possible duplicate logging setup
ERROR    ai_trading.logging:__init__.py:967 Logging validation failed: ['Too many handlers detected: 5 (expected ≤ 2)']
ERROR    root:main.py:237 Logging validation failed: ['Too many handlers detected: 5 (expected ≤ 2)']
INFO     root:main.py:240 Application startup - logging configured once
ERROR    root:main.py:264 Bot startup failed: 'Settings' object has no attribute 'alpaca_secret_key_plain'
Traceback (most recent call last):
  File "/workspace/ai-trading-bot/ai_trading/main.py", line 245, in run_bot
    validate_environment()
  File "/workspace/ai-trading-bot/ai_trading/main.py", line 201, in validate_environment
    if not cfg.alpaca_api_key or not cfg.alpaca_secret_key_plain:
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py", line 991, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'Settings' object has no attribute 'alpaca_secret_key_plain'
___________________________ TestEnvironmentOrderAndLazyImport.test_env_loaded_multiple_times_safely ____________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7f14822efa50>

    def test_env_loaded_multiple_times_safely(self):
        """Test that loading .env multiple times is safe."""
        # Create temp .env with test values
        with tempfile.NamedTemporaryFile(mode='w', suffix='.env', delete=False) as f:
            f.write("MULTI_LOAD_TEST=safe_value\n")
            temp_env_path = f.name
    
        try:
            # Clear environment
            os.environ.pop('MULTI_LOAD_TEST', None)
    
            # Mock load_dotenv to use our temp file
            def mock_load_side_effect(*args, **kwargs):
                with open(temp_env_path) as env_file:
                    for line in env_file:
                        if '=' in line and not line.startswith('#'):
                            key, value = line.strip().split('=', 1)
                            os.environ[key] = value
    
            with patch('dotenv.load_dotenv', side_effect=mock_load_side_effect):
                # Load multiple times (simulating multiple imports)
                from ai_trading.main import load_dotenv
                load_dotenv(override=True)  # First load
                load_dotenv(override=True)  # Second load
                load_dotenv(override=True)  # Third load
    
                # Should still have the correct value
>               assert os.environ.get('MULTI_LOAD_TEST') == 'safe_value'
E               AssertionError: assert None == 'safe_value'
E                +  where None = get('MULTI_LOAD_TEST')
E                +    where get = environ({'COREPACK_ENABLE_AUTO_PIN': '0', 'PYENV_HOOK_PATH': '/root/.pyenv/pyenv.d:/usr/etc/pyenv.d:/usr/local/etc/pye..._and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_env_loaded_multiple_times_safely (call)', 'TESTING': '1'}).get
E                +      where environ({'COREPACK_ENABLE_AUTO_PIN': '0', 'PYENV_HOOK_PATH': '/root/.pyenv/pyenv.d:/usr/etc/pyenv.d:/usr/local/etc/pye..._and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_env_loaded_multiple_times_safely (call)', 'TESTING': '1'}) = os.environ

tests/test_env_order_and_lazy_import.py:210: AssertionError
______________________________ TestEnvironmentOrderAndLazyImport.test_lazy_import_error_handling _______________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7f14822ef490>

    def test_lazy_import_error_handling(self):
        """Test that lazy import handles import errors gracefully."""
        from ai_trading import runner
    
        # Reset cache
        runner._bot_engine = None
        runner._bot_state_class = None
    
        with patch('ai_trading.core.bot_engine.run_all_trades_worker', side_effect=ImportError("Mock import error")):
>           with pytest.raises(RuntimeError) as exc_info:
E           Failed: DID NOT RAISE <class 'RuntimeError'>

tests/test_env_order_and_lazy_import.py:238: Failed
_______________________________________________ test_ensure_datetime_invalid_str _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

value = 'notadate'

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except Exception as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
>               tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E               ValueError: Invalid isoformat string: 'notadate'

ai_trading/data/timeutils.py:42: ValueError

The above exception was the direct cause of the following exception:

value = 'notadate'

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
>           return ensure_utc_datetime(value, allow_callables=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

ai_trading/data_fetcher.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = 'notadate'

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except Exception as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
                raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
        except Exception as e:
            if default is not None:
                return ensure_utc_datetime(default, allow_callables=allow_callables, clamp_to=clamp_to)
>           raise ValueError(f"Invalid datetime input: {value!r}") from e
E           ValueError: Invalid datetime input: 'notadate'

ai_trading/data/timeutils.py:49: ValueError

The above exception was the direct cause of the following exception:

    def test_ensure_datetime_invalid_str():
        with pytest.raises(ValueError):
>           data_fetcher.ensure_datetime("notadate")

tests/test_data_fetcher_datetime.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = 'notadate'

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
            return ensure_utc_datetime(value, allow_callables=False)
        except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
>           raise TypeError(f"Invalid datetime input: {e}") from e
E           TypeError: Invalid datetime input: Invalid datetime input: 'notadate'

ai_trading/data_fetcher.py:205: TypeError
___________________________________________________ test_ensure_datetime_nat ___________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_ensure_datetime_nat():
>       with pytest.raises(ValueError):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/test_data_fetcher_datetime.py:49: Failed
___________________________________________________ test_get_historical_data ___________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44dbf30050>

    def test_get_historical_data(monkeypatch):
        df = make_df()
>       setup_tf(monkeypatch)

tests/test_data_fetcher_extended.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44dbf30050>

    def setup_tf(monkeypatch):
>       monkeypatch.setattr(data_fetcher, "TimeFrame", TF)
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute 'TimeFrame'

tests/test_data_fetcher_extended.py:37: AttributeError
____________________________________________ test_get_historical_data_bad_timeframe ____________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db566950>

    def test_get_historical_data_bad_timeframe(monkeypatch):
>       setup_tf(monkeypatch)

tests/test_data_fetcher_extended.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db566950>

    def setup_tf(monkeypatch):
>       monkeypatch.setattr(data_fetcher, "TimeFrame", TF)
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute 'TimeFrame'

tests/test_data_fetcher_extended.py:37: AttributeError
_______________________________________________ test_get_minute_df_market_closed _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db4fec50>

    def test_get_minute_df_market_closed(monkeypatch):
        monkeypatch.setattr(data_fetcher, "is_market_open", lambda: False)
        today = datetime.date.today()
>       result = data_fetcher.get_minute_df("AAPL", today, today)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_data_fetcher_extended.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/data_fetcher.py:531: in get_minute_df
    fh_fetcher.fetch(symbol, start_dt, end_dt, resolution="1")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.data_fetcher._FinnhubFetcherStub object at 0x7f44de0b8a50>
args = ('AAPL', datetime.datetime(2025, 8, 22, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2025, 8, 22, 0, 0, tzinfo=datetime.timezone.utc))
kwargs = {'resolution': '1'}

    def fetch(self, *args, **kwargs):
>       raise NotImplementedError
E       NotImplementedError

ai_trading/data_fetcher.py:149: NotImplementedError
______________________________________________ test_get_minute_df_missing_columns ______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44dba38c10>

    def test_get_minute_df_missing_columns(monkeypatch):
        df_bad = pd.DataFrame({"price": [1]}, index=[pd.Timestamp("2024-01-01")])
        df_good = make_df()
>       setup_tf(monkeypatch)

tests/test_data_fetcher_extended.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44dba38c10>

    def setup_tf(monkeypatch):
>       monkeypatch.setattr(data_fetcher, "TimeFrame", TF)
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute 'TimeFrame'

tests/test_data_fetcher_extended.py:37: AttributeError
______________________________________________ test_get_minute_df_invalid_inputs _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

value = None

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except Exception as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
>               raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
E               TypeError: Unsupported datetime type: NoneType

ai_trading/data/timeutils.py:45: TypeError

The above exception was the direct cause of the following exception:

value = None

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
>           return ensure_utc_datetime(value, allow_callables=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

ai_trading/data_fetcher.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except Exception as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
                raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
        except Exception as e:
            if default is not None:
                return ensure_utc_datetime(default, allow_callables=allow_callables, clamp_to=clamp_to)
>           raise ValueError(f"Invalid datetime input: {value!r}") from e
E           ValueError: Invalid datetime input: None

ai_trading/data/timeutils.py:49: ValueError

The above exception was the direct cause of the following exception:

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db603910>

    def test_get_minute_df_invalid_inputs(monkeypatch):
        monkeypatch.setattr(data_fetcher, "is_market_open", lambda: True)
        with pytest.raises(ValueError):
>           data_fetcher.get_minute_df("AAPL", None, datetime.date.today())

tests/test_data_fetcher_extended.py:81: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/data_fetcher.py:524: in get_minute_df
    start_dt = ensure_datetime(start)
               ^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
            return ensure_utc_datetime(value, allow_callables=False)
        except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
>           raise TypeError(f"Invalid datetime input: {e}") from e
E           TypeError: Invalid datetime input: Invalid datetime input: None

ai_trading/data_fetcher.py:205: TypeError
_________________________________________________ test_equity_curve_monotonic __________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_equity_curve_monotonic():
>       df = pd.read_csv("data/last_equity.txt", names=["equity"])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_equity_curve.py:5: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026: in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620: in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620: in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880: in _make_engine
    self.handles = get_handle(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path_or_buf = 'data/last_equity.txt', mode = 'r'

    @doc(compression_options=_shared_docs["compression_options"] % "path_or_buf")
    def get_handle(
        path_or_buf: FilePath | BaseBuffer,
        mode: str,
        *,
        encoding: str | None = None,
        compression: CompressionOptions | None = None,
        memory_map: bool = False,
        is_text: bool = True,
        errors: str | None = None,
        storage_options: StorageOptions | None = None,
    ) -> IOHandles[str] | IOHandles[bytes]:
        """
        Get file handle for given path/buffer and mode.
    
        Parameters
        ----------
        path_or_buf : str or file handle
            File path or object.
        mode : str
            Mode to open path_or_buf with.
        encoding : str or None
            Encoding to use.
        {compression_options}
    
               May be a dict with key 'method' as compression mode
               and other keys as compression options if compression
               mode is 'zip'.
    
               Passing compression options as keys in dict is
               supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.
    
            .. versionchanged:: 1.4.0 Zstandard support.
    
        memory_map : bool, default False
            See parsers._parser_params for more information. Only used by read_csv.
        is_text : bool, default True
            Whether the type of the content passed to the file/buffer is string or
            bytes. This is not the same as `"b" not in mode`. If a string content is
            passed to a binary file/buffer, a wrapper is inserted.
        errors : str, default 'strict'
            Specifies how encoding and decoding errors are to be handled.
            See the errors argument for :func:`open` for a full list
            of options.
        storage_options: StorageOptions = None
            Passed to _get_filepath_or_buffer
    
        Returns the dataclass IOHandles
        """
        # Windows does not default to utf-8. Set to utf-8 for a consistent behavior
        encoding = encoding or "utf-8"
    
        errors = errors or "strict"
    
        # read_csv does not know whether the buffer is opened in binary/text mode
        if _is_binary_mode(path_or_buf, mode) and "b" not in mode:
            mode += "b"
    
        # validate encoding and errors
        codecs.lookup(encoding)
        if isinstance(errors, str):
            codecs.lookup_error(errors)
    
        # open URLs
        ioargs = _get_filepath_or_buffer(
            path_or_buf,
            encoding=encoding,
            compression=compression,
            mode=mode,
            storage_options=storage_options,
        )
    
        handle = ioargs.filepath_or_buffer
        handles: list[BaseBuffer]
    
        # memory mapping needs to be the first step
        # only used for read_csv
        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)
    
        is_path = isinstance(handle, str)
        compression_args = dict(ioargs.compression)
        compression = compression_args.pop("method")
    
        # Only for write methods
        if "r" not in mode and is_path:
            check_parent_directory(str(handle))
    
        if compression:
            if compression != "zstd":
                # compression libraries do not like an explicit text-mode
                ioargs.mode = ioargs.mode.replace("t", "")
            elif compression == "zstd" and "b" not in ioargs.mode:
                # python-zstandard defaults to text mode, but we always expect
                # compression libraries to use binary mode.
                ioargs.mode += "b"
    
            # GZ Compression
            if compression == "gzip":
                if isinstance(handle, str):
                    # error: Incompatible types in assignment (expression has type
                    # "GzipFile", variable has type "Union[str, BaseBuffer]")
                    handle = gzip.GzipFile(  # type: ignore[assignment]
                        filename=handle,
                        mode=ioargs.mode,
                        **compression_args,
                    )
                else:
                    handle = gzip.GzipFile(
                        # No overload variant of "GzipFile" matches argument types
                        # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                        fileobj=handle,  # type: ignore[call-overload]
                        mode=ioargs.mode,
                        **compression_args,
                    )
    
            # BZ Compression
            elif compression == "bz2":
                # Overload of "BZ2File" to handle pickle protocol 5
                # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                handle = get_bz2_file()(  # type: ignore[call-overload]
                    handle,
                    mode=ioargs.mode,
                    **compression_args,
                )
    
            # ZIP Compression
            elif compression == "zip":
                # error: Argument 1 to "_BytesZipFile" has incompatible type
                # "Union[str, BaseBuffer]"; expected "Union[Union[str, PathLike[str]],
                # ReadBuffer[bytes], WriteBuffer[bytes]]"
                handle = _BytesZipFile(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
                if handle.buffer.mode == "r":
                    handles.append(handle)
                    zip_names = handle.buffer.namelist()
                    if len(zip_names) == 1:
                        handle = handle.buffer.open(zip_names.pop())
                    elif not zip_names:
                        raise ValueError(f"Zero files found in ZIP file {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in ZIP file. "
                            f"Only one file per ZIP: {zip_names}"
                        )
    
            # TAR Encoding
            elif compression == "tar":
                compression_args.setdefault("mode", ioargs.mode)
                if isinstance(handle, str):
                    handle = _BytesTarFile(name=handle, **compression_args)
                else:
                    # error: Argument "fileobj" to "_BytesTarFile" has incompatible
                    # type "BaseBuffer"; expected "Union[ReadBuffer[bytes],
                    # WriteBuffer[bytes], None]"
                    handle = _BytesTarFile(
                        fileobj=handle, **compression_args  # type: ignore[arg-type]
                    )
                assert isinstance(handle, _BytesTarFile)
                if "r" in handle.buffer.mode:
                    handles.append(handle)
                    files = handle.buffer.getnames()
                    if len(files) == 1:
                        file = handle.buffer.extractfile(files[0])
                        assert file is not None
                        handle = file
                    elif not files:
                        raise ValueError(f"Zero files found in TAR archive {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in TAR archive. "
                            f"Only one file per TAR archive: {files}"
                        )
    
            # XZ Compression
            elif compression == "xz":
                # error: Argument 1 to "LZMAFile" has incompatible type "Union[str,
                # BaseBuffer]"; expected "Optional[Union[Union[str, bytes, PathLike[str],
                # PathLike[bytes]], IO[bytes]], None]"
                handle = get_lzma_file()(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
    
            # Zstd Compression
            elif compression == "zstd":
                zstd = import_optional_dependency("zstandard")
                if "r" in ioargs.mode:
                    open_args = {"dctx": zstd.ZstdDecompressor(**compression_args)}
                else:
                    open_args = {"cctx": zstd.ZstdCompressor(**compression_args)}
                handle = zstd.open(
                    handle,
                    mode=ioargs.mode,
                    **open_args,
                )
    
            # Unrecognized Compression
            else:
                msg = f"Unrecognized compression type: {compression}"
                raise ValueError(msg)
    
            assert not isinstance(handle, str)
            handles.append(handle)
    
        elif isinstance(handle, str):
            # Check whether the filename is to be opened in binary mode.
            # Binary mode does not support 'encoding' and 'newline'.
            if ioargs.encoding and "b" not in ioargs.mode:
                # Encoding
>               handle = open(
                    handle,
                    ioargs.mode,
                    encoding=ioargs.encoding,
                    errors=errors,
                    newline="",
                )
E               FileNotFoundError: [Errno 2] No such file or directory: 'data/last_equity.txt'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/common.py:873: FileNotFoundError
________________________________________________ test_minute_fallback_on_empty _________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db4b8850>

    def test_minute_fallback_on_empty(monkeypatch):
        """Minute bars fall back to Yahoo when Alpaca yields empty."""  # AI-AGENT-REF
        monkeypatch.setattr(dfetch, "_fetch_bars", lambda *a, **k: pd.DataFrame())
>       monkeypatch.setattr(dfetch.yf, "download", _fake_yf)
E       AttributeError: None has no attribute 'download'

tests/test_data_fetcher_fallbacks.py:25: AttributeError
______________________________________________ test_minute_fallback_on_exception _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db63c050>

    def test_minute_fallback_on_exception(monkeypatch):
        """Minute bars fall back to Yahoo when Alpaca errors."""  # AI-AGENT-REF
        def _boom(*_, **__):
            raise ValueError("json error")
    
        monkeypatch.setattr(dfetch, "_fetch_bars", _boom)
        monkeypatch.setattr(dfetch, "fh_fetcher", None)
>       monkeypatch.setattr(dfetch.yf, "download", _fake_yf)
E       AttributeError: None has no attribute 'download'

tests/test_data_fetcher_fallbacks.py:39: AttributeError
_________________________________________________ test_daily_fallback_on_empty _________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db63d950>

    def test_daily_fallback_on_empty(monkeypatch):
        """Daily bars fall back to Yahoo when Alpaca yields empty."""  # AI-AGENT-REF
        monkeypatch.setattr(dfetch, "get_bars", lambda *a, **k: pd.DataFrame())
>       monkeypatch.setattr(dfetch.yf, "download", _fake_yf)
E       AttributeError: None has no attribute 'download'

tests/test_data_fetcher_fallbacks.py:48: AttributeError
______________________________________ test_yahoo_get_bars_accepts_various_datetime_types ______________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db63c690>

    def test_yahoo_get_bars_accepts_various_datetime_types(monkeypatch):
>       from ai_trading.data_fetcher import _yahoo_get_bars
E       ImportError: cannot import name '_yahoo_get_bars' from 'ai_trading.data_fetcher' (unknown location)

tests/test_data_fetcher_timezone.py:38: ImportError
___________________________________________________ test_position_none_safe ____________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db4f58d0>

    def test_position_none_safe(monkeypatch):
        class Dummy:
            def get_open_position(self, symbol):
                return None
    
        class Ctx:
            pass
    
        ctx = Ctx()
        ctx.api = Dummy()
        from ai_trading.core import bot_engine as be
    
>       assert be._current_position_qty(ctx, "SPY") == 0
               ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: module 'ai_trading.core.bot_engine' has no attribute '_current_position_qty'

tests/test_data_pipeline.py:35: AttributeError
_____________________________________________ test_bot_engine_deprecation_warning ______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_bot_engine_deprecation_warning():
        """Importing bot_engine emits DeprecationWarning."""  # AI-AGENT-REF
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")
            import ai_trading.core.bot_engine  # noqa: F401
>           assert any(issubclass(w.category, DeprecationWarning) for w in w)
E           assert False
E            +  where False = any(<generator object test_bot_engine_deprecation_warning.<locals>.<genexpr> at 0x7f44db435460>)

tests/test_deprecation_warnings.py:12: AssertionError
____________________________________________ test_data_fetcher_deprecation_warning _____________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_data_fetcher_deprecation_warning():
        """Test that importing data_fetcher shows deprecation warning."""
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")
            import ai_trading.data_fetcher  # noqa: F401
    
            # Check that a deprecation warning was raised
>           assert len(w) >= 1
E           assert 0 >= 1
E            +  where 0 = len([])

tests/test_deprecation_warnings.py:22: AssertionError
_______________________________________________ test_runner_deprecation_warning ________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_runner_deprecation_warning():
        """Test that importing runner shows deprecation warning."""
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")
            import ai_trading.runner  # noqa: F401
    
            # Check that a deprecation warning was raised
>           assert len(w) >= 1
E           assert 0 >= 1
E            +  where 0 = len([])

tests/test_deprecation_warnings.py:34: AssertionError
_________________________________________________ test_executor_env_validation _________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_executor_env_validation():
        """Test that environment variable parsing handles edge cases."""
        test_cases = [
            ("", 0),      # Empty string
            ("0", 0),     # Zero
            ("1", 1),     # Valid number
            ("10", 10),   # Valid number
            ("invalid", 0),  # Invalid should default to 0 (fallback to auto-size)
        ]
    
        for env_val, expected in test_cases:
            os.environ["EXECUTOR_WORKERS"] = env_val
    
>           _exec_env = int(os.getenv("EXECUTOR_WORKERS", "0") or "0")
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: invalid literal for int() with base 10: 'invalid'

tests/test_executors_sizing.py:119: ValueError
_________________________________________________ test_daily_fallback_parallel _________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f1481237a50>

    def test_daily_fallback_parallel(monkeypatch):
        # Force batch to return empty so we hit fallback path for all.
        ctx = types.SimpleNamespace()
        calls = {"single": []}
        monkeypatch.setattr(be, "get_bars_batch", lambda *a, **k: {})
        def fake_single(sym, *a, **k):
            calls["single"].append(sym)
            return _mk_df()
        monkeypatch.setattr(be, "get_bars", fake_single)
        out = be._fetch_universe_bars(ctx, ["A","B","C","D"], "1D", "2024-01-01", "2024-02-01", None)
>       assert set(out.keys()) == {"A","B","C","D"}
E       AssertionError: assert set() == {'A', 'B', 'C', 'D'}
E         
E         Extra items in the right set:
E         'C'
E         'D'
E         'A'
E         'B'
E         Use -v to get more diff

tests/test_fallback_concurrency.py:28: AssertionError
________________________________________________ test_parallel_execution_timing ________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f1481ba3090>

    def test_parallel_execution_timing(monkeypatch):
        """Test that parallel execution provides performance benefit."""
        ctx = types.SimpleNamespace()
        call_times = []
    
        monkeypatch.setattr(be, "get_bars_batch", lambda *a, **k: {})
    
        def slow_single(sym, *a, **k):
            # Simulate slow API call
            time.sleep(0.1)
            call_times.append((sym, time.time()))
            return _mk_df()
    
        monkeypatch.setattr(be, "get_bars", slow_single)
    
        # Test with 4 symbols that should run in parallel
        start_time = time.time()
        out = be._fetch_universe_bars(ctx, ["A","B","C","D"], "1D", "2024-01-01", "2024-02-01", None)
        end_time = time.time()
    
        # Should complete faster than sequential (0.4s) due to parallelism
        # Allow some overhead but should be significantly faster than sequential
        assert end_time - start_time < 0.3, f"Parallel execution took {end_time - start_time:.2f}s, expected < 0.3s"
>       assert len(out) == 4
E       assert 0 == 4
E        +  where 0 = len({})

tests/test_fallback_concurrency.py:67: AssertionError
___________________________________________ test_bounded_concurrency_respects_limit ____________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f1481ab2210>

    def test_bounded_concurrency_respects_limit(monkeypatch):
        """Test that the worker limit is respected."""
        ctx = types.SimpleNamespace()
        active_workers = []
        max_concurrent = 0
    
        # Mock settings to use only 2 workers
        def mock_get_settings():
            settings = types.SimpleNamespace()
            settings.batch_fallback_workers = 2
            return settings
    
        monkeypatch.setattr(be, "get_settings", mock_get_settings)
        monkeypatch.setattr(be, "get_bars_batch", lambda *a, **k: {})
    
        def track_concurrent(sym, *a, **k):
            thread_id = threading.current_thread().ident
            active_workers.append(thread_id)
    
            nonlocal max_concurrent
            current_count = len(set(active_workers))
            max_concurrent = max(max_concurrent, current_count)
    
            time.sleep(0.1)  # Simulate work
            return _mk_df()
    
        monkeypatch.setattr(be, "get_bars", track_concurrent)
    
        # Test with 6 symbols but limit to 2 workers
        out = be._fetch_universe_bars(ctx, ["A","B","C","D","E","F"], "1D", "2024-01-01", "2024-02-01", None)
    
>       assert len(out) == 6
E       assert 0 == 6
E        +  where 0 = len({})

tests/test_fallback_concurrency.py:109: AssertionError
_____________________________________ TestDrawdownIntegration.test_bot_context_integration _____________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1375: in patched
    with self.decoration_helper(patched,
/root/.pyenv/versions/3.11.12/lib/python3.11/contextlib.py:137: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1357: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/contextlib.py:517: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f44dbcd5710>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'> does not have the attribute 'ctx'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError
______________________________________ TestDrawdownIntegration.test_configuration_values _______________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_drawdown_integration.TestDrawdownIntegration testMethod=test_configuration_values>

    def test_configuration_values(self):
        """Test that configuration values are correctly set."""
>       self.assertEqual(config.MAX_DRAWDOWN_THRESHOLD, 0.15)
E       AssertionError: 0.08 != 0.15

tests/test_drawdown_integration.py:95: AssertionError
___________________________________ TestEnhancedRebalancer.test_enhanced_rebalancer_fallback ___________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_enhancements.TestEnhancedRebalancer testMethod=test_enhanced_rebalancer_fallback>

    def test_enhanced_rebalancer_fallback(self):
        """Test that enhanced rebalancer falls back gracefully."""
        import os
        import sys
        sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    
>       from ai_trading.rebalancer import enhanced_maybe_rebalance, rebalance_portfolio
E       ImportError: cannot import name 'enhanced_maybe_rebalance' from 'ai_trading.rebalancer' (unknown location)

tests/test_institutional_enhancements.py:419: ImportError
_______________________________________________ test_bot_engine_import_fallbacks _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_bot_engine_import_fallbacks():
        """Test that bot_engine import fallbacks work correctly."""
        # Test that the import patterns are present in the code
        # Check that the file contains the expected try/except patterns
        import inspect
    
        import ai_trading.core.bot_engine as bot_engine
    
        source = inspect.getsource(bot_engine)
    
        # Look for the expected import patterns
        expected_patterns = [
            "from ai_trading.meta_learning import optimize_signals",
            "from meta_learning import optimize_signals",
            "from ai_trading.pipeline import model_pipeline",
            "from pipeline import model_pipeline",
            "from ai_trading.data_fetcher import",
            "from data_fetcher import",
            "from ai_trading.indicators import rsi",
            "from indicators import rsi",
            "from ai_trading.signals import generate_position_hold_signals",
            "from signals import generate_position_hold_signals",
            "from ai_trading import portfolio",
            "import portfolio",
            "from ai_trading.alpaca_api import alpaca_get",
            "from alpaca_api import alpaca_get",
        ]
    
        for pattern in expected_patterns:
>           assert pattern in source, f"Expected import pattern not found: {pattern}"
E           AssertionError: Expected import pattern not found: from meta_learning import optimize_signals
E           assert 'from meta_learning import optimize_signals' in '# ruff: noqa\n# fmt: off\nfrom __future__ import annotations\n\nimport importlib\nimport importlib.util\nimport os\ni...eption\n            _log.exception("Scheduler loop error: %s", exc)\n        time.sleep(CFG.scheduler_sleep_seconds)\n'

tests/test_import_fallbacks.py:53: AssertionError
_________________________________________________ test_runner_import_fallbacks _________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_runner_import_fallbacks():
        """Test that runner.py import fallbacks are correctly implemented."""
        import inspect
    
        import ai_trading.runner as runner
    
        source = inspect.getsource(runner)
    
        # Check for expected fallback patterns
        expected_patterns = [
            "from ai_trading.indicators import",
            "from indicators import",
        ]
    
        for pattern in expected_patterns:
>           assert pattern in source, f"Expected import pattern not found in runner.py: {pattern}"
E           AssertionError: Expected import pattern not found in runner.py: from ai_trading.indicators import
E           assert 'from ai_trading.indicators import' in 'from __future__ import annotations\n\n# ruff: noqa\nimport os\nimport time as _time\nfrom threading import RLock\nimp...and-line invocation."""\n    run_cycle()\n\n\nif __name__ == "__main__":\n    _preflight_import_health()\n    main()\n'

tests/test_import_fallbacks.py:71: AssertionError
_______________________________________________ test_backtester_import_fallbacks _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_backtester_import_fallbacks():
        """Test that backtester.py import fallbacks are correctly implemented."""
        import inspect
    
        import ai_trading.strategies.backtester as backtester
    
        source = inspect.getsource(backtester)
    
        # Check for expected fallback patterns
        expected_patterns = [
            "import ai_trading.signals as signals",
            "import signals",
            "import ai_trading.data_fetcher as data_fetcher",
            "import data_fetcher",
        ]
    
        for pattern in expected_patterns:
>           assert pattern in source, f"Expected import pattern not found in backtester.py: {pattern}"
E           AssertionError: Expected import pattern not found in backtester.py: import ai_trading.signals as signals
E           assert 'import ai_trading.signals as signals' in 'from __future__ import annotations\n\nimport glob\nimport os\nimport sys\nfrom abc import ABC, abstractmethod\nfrom d...nore_index=True,\n    )\n    trades_df.to_csv("trades.csv", index=False)\n\n\nif __name__ == "__main__":\n    main()\n'

tests/test_import_fallbacks.py:91: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:28,217", "level": "INFO", "name": "ai_trading.core.bot_engine", "msg": "Risk engine: ai_trading.risk.engine.RiskEngine", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.core.bot_engine:bot_engine.py:550 Risk engine: ai_trading.risk.engine.RiskEngine
___________________________________________ test_profile_indicators_import_fallbacks ___________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_profile_indicators_import_fallbacks():
        """Test that profile_indicators.py import fallbacks are correctly implemented."""
        import inspect
    
>       import profile_indicators
E       ModuleNotFoundError: No module named 'profile_indicators'

tests/test_import_fallbacks.py:98: ModuleNotFoundError
_____________________________________________ test_data_fetcher_helpers_available ______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_data_fetcher_helpers_available():
        """Test that the new data_fetcher helper functions are available."""
        try:
>           from ai_trading.data_fetcher import (
                clear_cached_minute_cache,
                get_cached_age_seconds,
                get_cached_minute_timestamp,
                set_cached_minute_timestamp,
            )
E           ImportError: cannot import name 'clear_cached_minute_cache' from 'ai_trading.data_fetcher' (unknown location)

tests/test_import_fallbacks.py:143: ImportError

During handling of the above exception, another exception occurred:

    def test_data_fetcher_helpers_available():
        """Test that the new data_fetcher helper functions are available."""
        try:
            from ai_trading.data_fetcher import (
                clear_cached_minute_cache,
                get_cached_age_seconds,
                get_cached_minute_timestamp,
                set_cached_minute_timestamp,
            )
    
            assert callable(get_cached_minute_timestamp)
            assert callable(set_cached_minute_timestamp)
            assert callable(get_cached_age_seconds)
            assert callable(clear_cached_minute_cache)
        except ImportError:
>           from ai_trading.data_fetcher import (
                clear_cached_minute_cache,
                get_cached_age_seconds,
                get_cached_minute_timestamp,
                set_cached_minute_timestamp,
            )
E           ImportError: cannot import name 'clear_cached_minute_cache' from 'ai_trading.data_fetcher' (unknown location)

tests/test_import_fallbacks.py:155: ImportError
_______________________________________ TestKellyIntegration.test_kelly_with_risk_levels _______________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyIntegration object at 0x7f1481f8d090>

    def test_kelly_with_risk_levels(self):
        """Test Kelly integration with different risk levels."""
        # Conservative risk level
>       conservative_kelly = KellyCriterion(max_fraction=RiskLevel.CONSERVATIVE.max_position_size)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_institutional_kelly.py:279: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7f14812a5bd0>, config = None, min_sample_size = None
max_fraction = 0.02, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
___________________________________________ TestKellyIntegration.test_kelly_logging ____________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyIntegration object at 0x7f1481f19d10>
mock_logger = <MagicMock name='logger' id='139726052435920'>

    @patch('ai_trading.risk.kelly.logger')
    def test_kelly_logging(self, mock_logger):
        """Test Kelly Criterion logging functionality."""
>       kelly = KellyCriterion()
                ^^^^^^^^^^^^^^^^

tests/test_institutional_kelly.py:306: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7f14812a5a90>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
_____________________________________________ test_meta_learning_price_validation ______________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_meta_learning_price_validation():
        """Test that meta-learning filters out invalid price data."""
        from ai_trading.meta_learning import validate_trade_data_quality
    
        # Create test CSV with mixed valid/invalid data
        test_data = {
            'timestamp': ['2024-01-01 10:00:00', '2024-01-01 11:00:00', '2024-01-01 12:00:00'],
            'symbol': ['AAPL', 'MSFT', 'GOOGL'],
            'side': ['buy', 'sell', 'buy'],
            'entry_price': [150.50, -10.0, 2800.0],  # One negative price
            'exit_price': [155.0, 200.0, 2850.0],
            'quantity': [100, 50, 10],
            'pnl': [450.0, -500.0, 500.0],
            'signal_tags': ['momentum', 'mean_reversion', 'momentum']
        }
    
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv') as tmp:
            df = pd.DataFrame(test_data)
            df.to_csv(tmp.name, index=False)
            tmp_path = tmp.name
    
        try:
            quality_report = validate_trade_data_quality(tmp_path)
            assert quality_report['file_exists'] is True
            assert quality_report['has_valid_format'] is True
>           assert quality_report['row_count'] == 3
E           assert 4 == 3

tests/test_critical_trading_fixes.py:489: AssertionError
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.meta_learning:meta_learning.py:312 Invalid price in meta format row: could not convert string to float: 'side'
_____________________________________________________ test_bot_main_normal _____________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f14817e2490>

    def test_bot_main_normal(monkeypatch):
        monkeypatch.setenv("TRADING_MODE", "shadow")
        monkeypatch.setenv("ALPACA_API_KEY", "k")
        monkeypatch.setenv("ALPACA_SECRET_KEY", "s")
        monkeypatch.setenv("FINNHUB_API_KEY", "testkey")
        monkeypatch.setattr("config.ALPACA_API_KEY", "k", raising=False)
        monkeypatch.setattr("config.ALPACA_SECRET_KEY", "s", raising=False)
        monkeypatch.setattr("config.FINNHUB_API_KEY", "testkey", raising=False)
        monkeypatch.setattr(sys, "argv", ["bot.py"])
>       with patch("data_fetcher.get_minute_df", return_value=MagicMock()), patch(
            "alpaca_api.submit_order", return_value={"status": "mocked"}
        ), patch("signals.generate", return_value=1), patch("risk_engine.calculate_position_size", return_value=10), patch(
            "data_fetcher.get_daily_df",
            return_value=pd.DataFrame(
                {
                    "open": [1],
                    "high": [1],
                    "low": [1],
                    "close": [1],
                    "volume": [1],
                }
            ),
        ):

tests/test_integration_robust.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f147f5c9c90>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'data_fetcher' from '/workspace/ai-trading-bot/tests/../ai_trading/data_fetcher.py'> does not have the attribute 'get_daily_df'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError
__________________________________________________ test_quantity_tracking_fix __________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_quantity_tracking_fix():
        """Test the critical quantity tracking bug fix for accurate filled quantity reporting."""
        import io
        import logging
        from unittest.mock import Mock
    
        # Import trade execution module
        from ai_trading.execution.engine import ExecutionEngine
    
        # Create execution engine
        engine = ExecutionEngine()
    
        # Set up logging capture to verify correct behavior
        log_stream = io.StringIO()
        handler = logging.StreamHandler(log_stream)
        engine.logger.addHandler(handler)
        engine.logger.setLevel(logging.INFO)
    
        # Test Case 1: Partial fill scenario (like TSLA case - requested 32, submitted 16, filled 11)
        mock_order_partial = Mock()
        mock_order_partial.id = "order_123"
        mock_order_partial.filled_qty = "32"  # Alpaca API incorrectly reports original quantity
    
        # Call _reconcile_partial_fills with parameters matching production logs
        # requested_qty=32 (original), remaining_qty=21 (32-11), so filled should be 11
        engine._reconcile_partial_fills(
            symbol="TSLA",
            requested_qty=32,
            remaining_qty=21,  # 32 - 11 = 21 remaining
            side="buy",
            last_order=mock_order_partial
        )
    
        # Verify it correctly identified as partial fill (not full)
        log_output = log_stream.getvalue()
        assert "PARTIAL_FILL_DETECTED" in log_output
        assert "FULL_FILL_SUCCESS" not in log_output
    
        # Test Case 2: Actual full fill scenario
        log_stream.truncate(0)
        log_stream.seek(0)
    
        mock_order_full = Mock()
        mock_order_full.id = "order_456"
        mock_order_full.filled_qty = "16"  # Could be correct or incorrect - should not matter
    
        # Full fill: requested 16, remaining 0, so filled = 16
        engine._reconcile_partial_fills(
            symbol="MSFT",
            requested_qty=16,
            remaining_qty=0,  # No quantity remaining = full fill
            side="buy",
            last_order=mock_order_full
        )
    
        # Verify it correctly identified as full fill
        log_output = log_stream.getvalue()
>       assert "FULL_FILL_SUCCESS" in log_output
E       AssertionError: assert 'FULL_FILL_SUCCESS' in ''

tests/test_critical_trading_fixes.py:574: AssertionError
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.execution.engine:engine.py:721 PART…CTED
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 13:32:28,636", "level": "INFO", "name": "ai_trading.execution.engine", "msg": "PART…CTED", "symbol": "TSLA", "side": "buy", "filled": 11, "requested": 32, "bot_phase": "GENERAL"}
________________________________________________ test_bot_main_data_fetch_error ________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f1481298d90>

    def test_bot_main_data_fetch_error(monkeypatch):
        monkeypatch.setenv("ALPACA_API_KEY", "k")
        monkeypatch.setenv("ALPACA_SECRET_KEY", "s")
        monkeypatch.setenv("FINNHUB_API_KEY", "testkey")
        monkeypatch.setattr("config.ALPACA_API_KEY", "k", raising=False)
        monkeypatch.setattr("config.ALPACA_SECRET_KEY", "s", raising=False)
        monkeypatch.setattr("config.FINNHUB_API_KEY", "testkey", raising=False)
        monkeypatch.setattr(sys, "argv", ["bot.py"])
>       with patch("data_fetcher.get_minute_df", side_effect=Exception("API error")), patch(
            "data_fetcher.get_daily_df",
            return_value=pd.DataFrame(
                {
                    "open": [1],
                    "high": [1],
                    "low": [1],
                    "close": [1],
                    "volume": [1],
                }
            ),
        ):

tests/test_integration_robust.py:375: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f1481237d90>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'data_fetcher' from '/workspace/ai-trading-bot/tests/../ai_trading/data_fetcher.py'> does not have the attribute 'get_daily_df'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError
____________________________________ TestEllipsisFix.test_get_runtime_context_or_none_error ____________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_ellipsis_fix.TestEllipsisFix testMethod=test_get_runtime_context_or_none_error>

    def test_get_runtime_context_or_none_error(self):
        """Test runtime context accessor handles errors gracefully."""
        with patch('ai_trading.core.bot_engine.get_ctx') as mock_get_ctx:
            with patch('ai_trading.core.bot_engine._log') as mock_log:
                # Test error handling
                mock_get_ctx.side_effect = Exception("Context unavailable")
    
>               result = _get_runtime_context_or_none()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_ellipsis_fix.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:5596: in _get_runtime_context_or_none
    lbc = get_ctx()
          ^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1124: in __call__
    return self._mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1128: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='get_ctx' id='140579649403984'>, args = (), kwargs = {}, effect = Exception('Context unavailable')

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
>               raise effect
E               Exception: Context unavailable

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1183: Exception
___________________________________________________ test_bot_main_signal_nan ___________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f1481ba2090>

    def test_bot_main_signal_nan(monkeypatch):
        monkeypatch.setenv("ALPACA_API_KEY", "k")
        monkeypatch.setenv("ALPACA_SECRET_KEY", "s")
        monkeypatch.setenv("FINNHUB_API_KEY", "testkey")
        monkeypatch.setattr("config.ALPACA_API_KEY", "k", raising=False)
        monkeypatch.setattr("config.ALPACA_SECRET_KEY", "s", raising=False)
        monkeypatch.setattr("config.FINNHUB_API_KEY", "testkey", raising=False)
        monkeypatch.setattr(sys, "argv", ["bot.py"])
>       with patch("signals.generate", return_value=float("nan")), patch(
            "data_fetcher.get_minute_df", return_value=MagicMock()
        ), patch(
            "data_fetcher.get_daily_df",
            return_value=pd.DataFrame(
                {
                    "open": [1],
                    "high": [1],
                    "low": [1],
                    "close": [1],
                    "volume": [1],
                }
            ),
        ):

tests/test_integration_robust.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f148209b690>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'data_fetcher' from '/workspace/ai-trading-bot/tests/../ai_trading/data_fetcher.py'> does not have the attribute 'get_daily_df'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError
____________________________________ TestEllipsisFix.test_update_risk_engine_exposure_error ____________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <MagicMock name='_log.warning' id='140579649172944'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'warning' to have been called once. Called 0 times.

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:918: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.test_ellipsis_fix.TestEllipsisFix testMethod=test_update_risk_engine_exposure_error>

    def test_update_risk_engine_exposure_error(self):
        """Test risk exposure update handles errors gracefully."""
        with patch('ai_trading.core.bot_engine._get_runtime_context_or_none') as mock_get_ctx:
            with patch('ai_trading.core.bot_engine._log') as mock_log:
                # Setup mock context with failing risk engine
                mock_context = Mock()
                mock_risk_engine = Mock()
                mock_risk_engine.update_exposure.side_effect = Exception("Update failed")
                mock_context.risk_engine = mock_risk_engine
                mock_get_ctx.return_value = mock_context
    
                _update_risk_engine_exposure()
    
                # Should log warning about failure
>               mock_log.warning.assert_called_once()
E               AssertionError: Expected 'warning' to have been called once. Called 0 times.

tests/test_ellipsis_fix.py:154: AssertionError
_______________________________ TestEllipsisFix.test_update_risk_engine_exposure_no_risk_engine ________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_ellipsis_fix.TestEllipsisFix testMethod=test_update_risk_engine_exposure_no_risk_engine>

    def test_update_risk_engine_exposure_no_risk_engine(self):
        """Test risk exposure update handles missing risk engine gracefully."""
        with patch('ai_trading.core.bot_engine._get_runtime_context_or_none') as mock_get_ctx:
            with patch('ai_trading.core.bot_engine._log') as mock_log:
                # Setup mock context without risk engine
                mock_context = Mock()
                mock_context.risk_engine = None
                mock_get_ctx.return_value = mock_context
    
                _update_risk_engine_exposure()
    
                # Should log debug message about missing risk engine
                mock_log.debug.assert_called_once()
>               self.assertIn("No risk_engine", str(mock_log.debug.call_args))
E               AssertionError: 'No risk_engine' not found in "call('Skipping exposure update: runtime not ready')"

tests/test_ellipsis_fix.py:138: AssertionError
_______________________________________________ test_trade_execution_api_timeout _______________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f147f5c8ed0>

    def test_trade_execution_api_timeout(monkeypatch):
>       with patch(
            "ai_trading.broker.alpaca.AlpacaBroker.place_order",
            side_effect=TimeoutError("Timeout"),
        ):

tests/test_integration_robust.py:430: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f147f5cbed0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <class 'ai_trading.broker.alpaca.AlpacaBroker'> does not have the attribute 'place_order'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError
_______________________________________________________ test_integration _______________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_integration():
        """Test the basic integration points."""
        print("🧪 Testing DrawdownCircuitBreaker Integration")
        print("=" * 50)
    
        # Test 1: Configuration loading
        print(f"✅ MAX_DRAWDOWN_THRESHOLD: {config.MAX_DRAWDOWN_THRESHOLD}")
>       print(f"✅ DAILY_LOSS_LIMIT: {config.DAILY_LOSS_LIMIT}")
                                     ^^^^^^^^^^^^^^^^^^^^^^^

tests/test_integration_simple.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'DAILY_LOSS_LIMIT'

    def __getattr__(name: str):  # AI-AGENT-REF: lazy export for TradingConfig
        if name == "TradingConfig":
            from .management import TradingConfig as _TC
            return _TC
>       raise AttributeError(name)
E       AttributeError: DAILY_LOSS_LIMIT

ai_trading/config/__init__.py:46: AttributeError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
🧪 Testing DrawdownCircuitBreaker Integration
==================================================
✅ MAX_DRAWDOWN_THRESHOLD: 0.08
________________________________ TestEllipsisFix.test_update_risk_engine_exposure_with_context _________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <Mock name='_get_runtime_context_or_none().risk_engine.update_exposure' id='140579649199056'>
args = (<Mock name='_get_runtime_context_or_none()' id='140579650907600'>,), kwargs = {}
msg = "Expected 'update_exposure' to be called once. Called 0 times."

    def assert_called_once_with(self, /, *args, **kwargs):
        """assert that the mock was called exactly once and that that call was
        with the specified arguments."""
        if not self.call_count == 1:
            msg = ("Expected '%s' to be called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'update_exposure' to be called once. Called 0 times.

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:950: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.test_ellipsis_fix.TestEllipsisFix testMethod=test_update_risk_engine_exposure_with_context>

    def test_update_risk_engine_exposure_with_context(self):
        """Test risk exposure update works with valid context."""
        with patch('ai_trading.core.bot_engine._get_runtime_context_or_none') as mock_get_ctx:
            with patch('ai_trading.core.bot_engine._log') as mock_log:
                # Setup mock context with risk engine
                mock_context = Mock()
                mock_risk_engine = Mock()
                mock_context.risk_engine = mock_risk_engine
                mock_get_ctx.return_value = mock_context
    
                _update_risk_engine_exposure()
    
                # Verify risk engine update_exposure was called
>               mock_risk_engine.update_exposure.assert_called_once_with(mock_context)
E               AssertionError: Expected 'update_exposure' to be called once. Called 0 times.

tests/test_ellipsis_fix.py:123: AssertionError
_______________________________________ TestTrailingStopManager.test_stop_initialization _______________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestTrailingStopManager object at 0x7f148241eed0>

    def test_stop_initialization(self):
        """Test trailing stop initialization."""
>       position = MockPosition(
                   ^^^^^^^^^^^^
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:245: NameError
_________________________________________________ test_fetch_fallback_to_daily _________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb4025cc50>

    def test_fetch_fallback_to_daily(monkeypatch):
        df = _stub_df()
        monkeypatch.setattr(data_fetcher, "get_minute_df", lambda *a, **k: None)
>       monkeypatch.setattr(data_fetcher, "get_daily_df", lambda *a, **k: df)
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute 'get_daily_df'

tests/test_fetch_and_screen.py:25: AttributeError
___________________________________________________ test_get_bars_never_none ___________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb4025e890>

    def test_get_bars_never_none(monkeypatch):
        now = pd.Timestamp("2024-01-01", tz="UTC")
        df = pd.DataFrame(
            {
                "timestamp": [now],
                "open": [1.0],
                "high": [2.0],
                "low": [0.5],
                "close": [1.5],
                "volume": [100],
            }
        )
>       monkeypatch.setattr(
            data_fetcher,
            "_alpaca_get_bars",
            lambda client, symbol, start, end, timeframe="1Day": df,
        )
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute '_alpaca_get_bars'

tests/test_fetch_contract.py:34: AttributeError
__________________________________________ TestTrailingStopManager.test_stop_movement __________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestTrailingStopManager object at 0x7f148241e850>

    def test_stop_movement(self):
        """Test that stops move up with price for long positions."""
>       position = MockPosition(
                   ^^^^^^^^^^^^
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:261: NameError
_______________________________________________________ test_run_success _______________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

obj = <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'>, name = '_build_daily_url'
ann = 'ai_trading.data_fetcher'

    def annotated_getattr(obj: object, name: str, ann: str) -> object:
        try:
>           obj = getattr(obj, name)
                  ^^^^^^^^^^^^^^^^^^
E           AttributeError: module 'ai_trading.data_fetcher' has no attribute '_build_daily_url'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/_pytest/monkeypatch.py:90: AttributeError

The above exception was the direct cause of the following exception:

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb4025e510>

    def test_run_success(monkeypatch):
        urls_captured = []
        logged = []
    
        def fake_build(symbol, start, end):
            return f"https://example.com/{symbol}"
    
        def fake_map_get(urls, timeout=None):
            urls_captured.extend(urls)
            return [(u, 200, b"OK") for u in urls]
    
        def fake_info(msg, *args, **kwargs):
            logged.append((msg, kwargs.get("extra", {})))
    
>       monkeypatch.setattr("ai_trading.data_fetcher._build_daily_url", fake_build)

tests/test_fetch_sample_universe_cli.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/_pytest/monkeypatch.py:104: in derive_importpath
    annotated_getattr(target, attr, ann=module)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'>, name = '_build_daily_url'
ann = 'ai_trading.data_fetcher'

    def annotated_getattr(obj: object, name: str, ann: str) -> object:
        try:
            obj = getattr(obj, name)
        except AttributeError as e:
>           raise AttributeError(
                f"{type(obj).__name__!r} object at {ann} has no attribute {name!r}"
            ) from e
E           AttributeError: 'module' object at ai_trading.data_fetcher has no attribute '_build_daily_url'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/_pytest/monkeypatch.py:92: AttributeError
_____________________________________ TestTrailingStopManager.test_stop_trigger_detection ______________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestTrailingStopManager object at 0x7f148241c690>

    def test_stop_trigger_detection(self):
        """Test stop trigger detection."""
>       position = MockPosition(
                   ^^^^^^^^^^^^
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:281: NameError
_______________________________________ TestProfitTakingEngine.test_profit_plan_creation _______________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestProfitTakingEngine object at 0x7f148241ee90>

    def test_profit_plan_creation(self):
        """Test profit plan creation."""
>       position = MockPosition(
                   ^^^^^^^^^^^^
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:308: NameError
________________________________________ TestProfitTakingEngine.test_target_triggering _________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestProfitTakingEngine object at 0x7f1482114750>

    def test_target_triggering(self):
        """Test profit target triggering."""
>       position = MockPosition(
                   ^^^^^^^^^^^^
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:328: NameError
________________________________ TestPortfolioCorrelationAnalyzer.test_position_data_extraction ________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestPortfolioCorrelationAnalyzer object at 0x7f1482117390>

    def test_position_data_extraction(self):
        """Test position data extraction."""
        positions = [
>           MockPosition('AAPL', 100, 100.0, 11000.0),
            ^^^^^^^^^^^^
            MockPosition('MSFT', 50, 200.0, 10500.0),
            MockPosition('GOOGL', 25, 150.0, 3750.0)
        ]
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:357: NameError
_________________________________ TestPortfolioCorrelationAnalyzer.test_concentration_analysis _________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestPortfolioCorrelationAnalyzer object at 0x7f14821174d0>

    def test_concentration_analysis(self):
        """Test concentration level analysis."""
        positions = [
>           MockPosition('AAPL', 100, 100.0, 50000.0),  # 50% of portfolio
            ^^^^^^^^^^^^
            MockPosition('MSFT', 50, 200.0, 25000.0),   # 25% of portfolio
            MockPosition('GOOGL', 25, 150.0, 25000.0)   # 25% of portfolio
        ]
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:379: NameError
__________________________________ TestIntegrationScenarios.test_profitable_position_scenario __________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestIntegrationScenarios object at 0x7f148241e190>

    def test_profitable_position_scenario(self):
        """Test scenario with profitable position."""
>       position = MockPosition(
                   ^^^^^^^^^^^^
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=12000.0  # 20% gain
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:401: NameError
_____________________________________ TestIntegrationScenarios.test_loss_position_scenario _____________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestIntegrationScenarios object at 0x7f1482406710>

    def test_loss_position_scenario(self):
        """Test scenario with losing position."""
>       position = MockPosition(
                   ^^^^^^^^^^^^
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=9000.0  # 10% loss
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:419: NameError
________________________________ TestIntegrationScenarios.test_portfolio_level_recommendations _________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestIntegrationScenarios object at 0x7f14823d9210>

    def test_portfolio_level_recommendations(self):
        """Test portfolio-level analysis and recommendations."""
        positions = [
>           MockPosition('AAPL', 100, 100.0, 11000.0),
            ^^^^^^^^^^^^
            MockPosition('MSFT', 50, 200.0, 10500.0),
            MockPosition('TSLA', 30, 150.0, 4800.0)
        ]
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:436: NameError
_________________________________________ test_risk_management_sector_exposure_logging _________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_risk_management_sector_exposure_logging():
        """Test that sector exposure rejections include clear reasoning."""
        # This is a minimal test - full test would require bot_engine context
        # Testing the structure exists for enhanced logging
        from ai_trading.core.bot_engine import sector_exposure_ok
    
        # Mock BotContext
        mock_ctx = Mock()
        mock_ctx.api = Mock()
    
        # Mock account with zero portfolio value
        mock_account = Mock()
        mock_account.portfolio_value = 0
        mock_ctx.api.get_account.return_value = mock_account
    
        # Test empty portfolio logic
>       result = sector_exposure_ok(mock_ctx, "AAPL", 10, 150.0)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_critical_trading_fixes.py:620: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:6924: in sector_exposure_ok
    exposures = sector_exposure(ctx)
                ^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ctx = <Mock id='139943271899024'>

    def sector_exposure(ctx: BotContext) -> dict[str, float]:
        """Return current portfolio exposure by sector as fraction of equity."""
        try:
            positions = ctx.api.list_open_positions()
        except (
            FileNotFoundError,
            PermissionError,
            IsADirectoryError,
            JSONDecodeError,
            ValueError,
            KeyError,
            TypeError,
            OSError,
        ):  # AI-AGENT-REF: narrow exception
            return {}
        try:
            total = float(ctx.api.get_account().portfolio_value)
        except (
            FileNotFoundError,
            PermissionError,
            IsADirectoryError,
            JSONDecodeError,
            ValueError,
            KeyError,
            TypeError,
            OSError,
        ):  # AI-AGENT-REF: narrow exception
            total = 0.0
        exposure: dict[str, float] = {}
>       for pos in positions:
E       TypeError: 'Mock' object is not iterable

ai_trading/core/bot_engine.py:6908: TypeError
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.core.bot_engine:bot_engine.py:6860 Using fallback sector mapping for AAPL: Technology
________________________________________ test_json_formatter_custom_fields_and_masking _________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_json_formatter_custom_fields_and_masking():
        fmt = logger.JSONFormatter("%(asctime)sZ")
        rec = _make_record(symbol="AAPL", api_key="abcdef1234", pathname="skip")
        out = fmt.format(rec)
        data = json.loads(out)
        assert set(data) >= {"ts", "level", "name", "msg", "symbol", "api_key"}
>       assert data["api_key"].endswith("1234") and set(data["api_key"]) <= set("*1234")
E       AssertionError: assert (False)
E        +  where False = <built-in method endswith of str object at 0x7f1481b89e70>('1234')
E        +    where <built-in method endswith of str object at 0x7f1481b89e70> = 'ab***34'.endswith

tests/test_json_formatter.py:28: AssertionError
_____________________________________________ test_kelly_confidence_normalization ______________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_kelly_confidence_normalization():
        """Test that high confidence values are properly normalized to probabilities."""
        # Mock BotContext for testing
        # Import the actual function (if available)
        try:
            from ai_trading.core.bot_engine import fractional_kelly_size
    
>           ctx = MockBotContext()
                  ^^^^^^^^^^^^^^
E           NameError: name 'MockBotContext' is not defined

tests/test_kelly_confidence_fix.py:24: NameError
______________________________________________ test_health_check_empty_dataframe _______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb4017d350>

    def test_health_check_empty_dataframe(monkeypatch):
        monkeypatch.setenv("HEALTH_MIN_ROWS", "30")
        ctx = DummyCtx(pd.DataFrame())
        summary = pre_trade_health_check(ctx, ["AAA"])
>       assert summary["failures"] == ["AAA"]
E       AssertionError: assert [('AAA', 'no_data')] == ['AAA']
E         
E         At index 0 diff: ('AAA', 'no_data') != 'AAA'
E         Use -v to get more diff

tests/test_health.py:254: AssertionError
_________________________________________________ test_kelly_input_validation __________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_kelly_input_validation():
        """Test that Kelly calculation properly validates all inputs."""
        # Mock BotContext for testing
        try:
            from ai_trading.core.bot_engine import fractional_kelly_size
    
>           ctx = MockBotContext()
                  ^^^^^^^^^^^^^^
E           NameError: name 'MockBotContext' is not defined

tests/test_kelly_confidence_fix.py:77: NameError
________________________________________________ test_setup_logging_idempotent _________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f14817aa1d0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw4/test_setup_logging_idempotent0')

    def test_setup_logging_idempotent(monkeypatch, tmp_path):
        mod = reload_module(logger)
        created = []
    
        def fake_get_rotating(path, **_):
            created.append(path)
            return logging.StreamHandler()
    
        monkeypatch.setattr(mod, "get_rotating_handler", fake_get_rotating)
        lg = mod.setup_logging(debug=True, log_file=str(tmp_path / "f.log"))
        assert lg.level in (logging.DEBUG, logging.INFO)
>       assert created, f"No rotating handler paths created. Captured: {created}"
E       AssertionError: No rotating handler paths created. Captured: []
E       assert []

tests/test_logger.py:36: AssertionError
_______________________________________________________ test_get_logger ________________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_get_logger():
        mod = reload_module(logger)
        root = mod.setup_logging(debug=True)
        lg = mod.get_logger("test")
        assert lg is mod._loggers["test"]
>       assert len(lg.handlers) == len(root.handlers)
                   ^^^^^^^^^^^
E       AttributeError: 'SanitizingLoggerAdapter' object has no attribute 'handlers'

tests/test_logger.py:48: AttributeError
---------------------------------------------------- Captured stdout setup -----------------------------------------------------
{"ts": "2025-08-22 13:32:29,250", "level": "INFO", "name": "ai_trading.logging", "msg": "Logging configured succ…ully - no duplicates possible", "bot_phase": "GENERAL"}
_______________________________________________ test_host_semaphore_respects_env _______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb3ffb4a10>

    def test_host_semaphore_respects_env(monkeypatch):
        def fake_get(url, timeout=None, headers=None):
            return DummyResp()
    
        monkeypatch.setattr(H, "get", fake_get)
        monkeypatch.setenv("HTTP_MAX_PER_HOST", "3")
        _ = H.map_get(["https://example.com"])
>       assert H.pool_stats()["per_host"] == 3
E       assert 6 == 3

tests/test_http_pooling.py:25: AssertionError
_________________________________________________ test_setup_logging_with_file _________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f147f3ef5d0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw4/test_setup_logging_with_file0')

    def test_setup_logging_with_file(monkeypatch, tmp_path):
        """File handler is added when log_file is provided."""
        logger._configured = False
        fake = logging.NullHandler()
    
        def fake_makedirs(path, exist_ok=False):
            pass
    
        calls = []
    
        def fake_get_handler(*args, **kwargs):
            calls.append((args, kwargs))
            return fake
    
        monkeypatch.setattr(logger.os, "makedirs", fake_makedirs)
        monkeypatch.setattr(logger, "get_rotating_handler", fake_get_handler)
    
        log_file = tmp_path / "x" / "app.log"
        logger.setup_logging(log_file=str(log_file))
>       assert calls
E       assert []

tests/test_logger_file.py:25: AssertionError
__________________________________________________ test_get_logger_singleton ___________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw4/test_get_logger_singleton0')

    def test_get_logger_singleton(tmp_path):
        lg1 = logger.get_logger("test")
        lg2 = logger.get_logger("test")
        assert lg1 is lg2
        # Updated test: With our new design, child loggers use propagation
        # instead of having their own handlers to prevent duplicates
>       assert lg1.propagate  # Should propagate to root logger
               ^^^^^^^^^^^^^
E       AttributeError: 'SanitizingLoggerAdapter' object has no attribute 'propagate'

tests/test_logger_module.py:15: AttributeError
____________________________________________ test_httpsession_sets_default_timeout _____________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb400da850>

    def test_httpsession_sets_default_timeout(monkeypatch):
>       s = http.HTTPSession(timeout=7)
            ^^^^^^^^^^^^^^^^
E       AttributeError: module 'ai_trading.utils.http' has no attribute 'HTTPSession'

tests/test_http_timeouts.py:25: AttributeError
________________________________________________ test_emergency_data_validation ________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_emergency_data_validation():
        """Test emergency data validation for critical trades."""
        from ai_trading.data_validation import emergency_data_check
    
        # Test with valid data
        valid_data = pd.DataFrame({
            'Close': [150.0, 151.0, 152.0],
            'Volume': [1000, 1100, 1200]
        }, index=pd.date_range('2024-01-01 09:30:00', periods=3, freq='1min', tz='UTC'))
    
        # Should pass emergency validation
        assert emergency_data_check(valid_data, "AAPL") is True
    
        # Test with empty data
        empty_data = pd.DataFrame()
        assert emergency_data_check(empty_data, "AAPL") is False
    
        # Test with invalid price data
        invalid_data = pd.DataFrame({
            'Close': [150.0, 151.0, -10.0],  # Invalid negative price
            'Volume': [1000, 1100, 1200]
        }, index=pd.date_range('2024-01-01 09:30:00', periods=3, freq='1min', tz='UTC'))
    
>       assert emergency_data_check(invalid_data, "AAPL") is False
E       AssertionError: assert True is False
E        +  where True = <function emergency_data_check at 0x7f4715fec4a0>(                           Close  Volume\n2024-01-01 09:30:00+00:00  150.0    1000\n2024-01-01 09:31:00+00:00  151.0    1100\n2024-01-01 09:32:00+00:00  -10.0    1200, 'AAPL')

tests/test_critical_trading_fixes.py:725: AssertionError
_____________________________________________ test_update_signal_weights_norm_zero _____________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7f147f5d7c50>

    def test_update_signal_weights_norm_zero(caplog):
        caplog.set_level("WARNING")
        w = {"a": 0.0}
        perf = {"a": 1.0}
        res = meta_learning.update_signal_weights(w, perf)
        assert res == w
>       assert "Normalization factor zero" in caplog.text
E       AssertionError: assert 'Normalization factor zero' in 'WARNING  ai_trading.meta_learning:meta_learning.py:616 Norm…tion factor zero in weight update\n'
E        +  where 'WARNING  ai_trading.meta_learning:meta_learning.py:616 Norm…tion factor zero in weight update\n' = <_pytest.logging.LogCaptureFixture object at 0x7f147f5d7c50>.text

tests/test_meta_learning.py:154: AssertionError
---------------------------------------------------- Captured stdout setup -----------------------------------------------------
{"ts": "2025-08-22 13:32:29,326", "level": "ERROR", "name": "ai_trading.meta_learning", "msg": "Empty weights or performance dict passed to upda…ghts", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.meta_learning:meta_learning.py:616 Norm…tion factor zero in weight update
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 13:32:29,330", "level": "WARNING", "name": "ai_trading.meta_learning", "msg": "Norm…tion factor zero in weight update", "bot_phase": "GENERAL"}
__________________________________________________ test_portfolio_rl_trigger ___________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f1481249ad0>

    def test_portfolio_rl_trigger(monkeypatch):
        torch = pytest.importorskip("torch")
        # AI-AGENT-REF: ensure real torch is loaded during tests
        # if not hasattr(torch, "nn") or not hasattr(torch.nn, "Parameter"):
        #     pytest.skip("torch stubs active")
        class FakeLinear(nn.Module):
            def __init__(self, *a, **k):
                super().__init__()
                self.weight = nn.Parameter(torch.tensor([0.0]))
    
            def forward(self, x):
                return x
    
        monkeypatch.setattr(nn, "Linear", lambda *a, **k: FakeLinear())
>       import portfolio_rl
E       ModuleNotFoundError: No module named 'portfolio_rl'

tests/test_meta_learning.py:171: ModuleNotFoundError
___________________________________________________ test_no_secrets_in_logs ____________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7fdb3fda7b50>
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb3fda6410>

    def test_no_secrets_in_logs(caplog, monkeypatch):
        caplog.set_level(logging.INFO)
        monkeypatch.setenv("NEWS_API_KEY", "TOPSECRETKEY")
        logger = get_logger(__name__)
        logger.info("boot with key=%s", os.getenv("NEWS_API_KEY"))
        joined = "\n".join(m.message for m in caplog.records)
>       assert "TOPSECRETKEY" not in joined
E       AssertionError: assert 'TOPSECRETKEY' not in 'boot with key=TOPSECRETKEY'
E         
E         'TOPSECRETKEY' is contained here:
E           boot with key=TOPSECRETKEY

tests/test_logging_scrubbed.py:13: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:29,357", "level": "INFO", "name": "tests.test_logging_scrubbed", "msg": "boot with key=TOPS…TKEY", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     tests.test_logging_scrubbed:test_logging_scrubbed.py:11 boot with key=TOPSECRETKEY
______________________________________________________ test_run_flask_app ______________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb3fda74d0>

    def test_run_flask_app(monkeypatch):
        """Flask app runs on provided port."""
        called = {}
    
        class App:
            def run(self, host, port):
                called["args"] = (host, port)
    
        monkeypatch.setattr(app, "create_app", lambda: App())
>       main.run_flask_app(1234)

tests/test_main_extended2.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

port = 1234, ready_signal = None

    def run_flask_app(port: int = 5000, ready_signal: threading.Event = None) -> None:
        """Launch Flask API on an available port."""
        # AI-AGENT-REF: simplified port fallback logic with get_free_port fallback
        max_attempts = 10
        original_port = port
    
        for _attempt in range(max_attempts):
            if not get_pid_on_port(port):
                break
            port += 1
        else:
            # If consecutive ports are all occupied, use get_free_port as fallback
            free_port = get_free_port()
            if free_port is None:
                raise RuntimeError(
                    f"Could not find available port starting from {original_port}"
                )
            port = free_port
    
        # Defer app import to avoid import-time side effects
        import ai_trading.app as app
    
        application = app.create_app()
    
        # AI-AGENT-REF: Signal ready immediately after Flask app creation for faster startup
        if ready_signal is not None:
            logger.info(f"Flask app created successfully, signaling ready on port {port}")
            ready_signal.set()
    
        logger.info(f"Starting Flask app on 0.0.0.0:{port}")
        # AI-AGENT-REF: disable debug mode in production server
>       application.run(host="0.0.0.0", port=port, debug=False)
E       TypeError: test_run_flask_app.<locals>.App.run() got an unexpected keyword argument 'debug'

ai_trading/main.py:299: TypeError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:29,363", "level": "INFO", "name": "ai_trading.main", "msg": "Starting Flask app on 0.0.0.0:1234", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.main:main.py:297 Starting Flask app on 0.0.0.0:1234
________________________________________________ test_run_flask_app_port_in_use ________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb40147990>

    def test_run_flask_app_port_in_use(monkeypatch):
        """Port conflict triggers fallback port."""
        called = []
    
        class App:
            def run(self, host, port):
                called.append(port)
    
        monkeypatch.setattr(app, "create_app", lambda: App())
>       monkeypatch.setattr(main.utils, "get_pid_on_port", lambda p: 111)
                            ^^^^^^^^^^
E       AttributeError: module 'ai_trading.main' has no attribute 'utils'

tests/test_main_extended2.py:45: AttributeError
_________________________________________________ test_load_weights_save_fail __________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f1481275f10>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw4/test_load_weights_save_fail0')
caplog = <_pytest.logging.LogCaptureFixture object at 0x7f1481276cd0>

    def test_load_weights_save_fail(monkeypatch, tmp_path, caplog):
        """Failure to write default weights is logged and default returned."""
        p = tmp_path / "w.csv"
        monkeypatch.setattr(meta_learning.Path, "exists", lambda self: False)
        def fail(*a, **k):
            raise IOError("fail")
        monkeypatch.setattr(meta_learning.np, "savetxt", fail)
        caplog.set_level("ERROR")
>       arr = meta_learning.load_weights(str(p), default=np.array([1.0]))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/workspace/ai-trading-bot/tests/test_meta_learning_additional.py:18: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/ai-trading-bot/ai_trading/meta_learning.py:540: in load_weights
    np.savetxt(p, default, delimiter=",")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = (PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw4/test_load_weights_save_fail0/w.csv'), array([1.]))
k = {'delimiter': ','}

    def fail(*a, **k):
>       raise IOError("fail")
E       OSError: fail

/workspace/ai-trading-bot/tests/test_meta_learning_additional.py:15: OSError
___________________________________________________ test_run_bot_calls_cycle ___________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb40147550>

    def test_run_bot_calls_cycle(monkeypatch):
        """run_bot executes a trading cycle in-process."""
        called = {}
    
        monkeypatch.setattr(
            main, "run_cycle", lambda: called.setdefault("ran", True)
        )
>       assert main.run_bot() == 0
E       assert 1 == 0
E        +  where 1 = <function run_bot at 0x7fdb40af3060>()
E        +    where <function run_bot at 0x7fdb40af3060> = main.run_bot

tests/test_main_extended2.py:58: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:29,385", "level": "WARNING", "name": "ai_trading.logging", "msg": "WARNING: 5 handlers detected - possible duplicate logging setup", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:29,386", "level": "ERROR", "name": "ai_trading.logging", "msg": "Logging validation failed: ['Too many handlers detected: 5 (expected ≤ 2)']", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:29,386", "level": "ERROR", "name": "root", "msg": "Logging validation failed: ['Too many handlers detected: 5 (expected ≤ 2)']", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:29,386", "level": "INFO", "name": "root", "msg": "Application startup - logging configured once", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:29,386", "level": "ERROR", "name": "root", "msg": "Bot startup failed: 'Settings' object has no attribute 'alpa…lain'\nTraceback (most recent call last):\n  File \"/workspace/ai-t…-bot/ai_trading/main.py\", line 245, in run_bot\n    vali…ment()\n  File \"/workspace/ai-t…-bot/ai_trading/main.py\", line 201, in vali…ment\n    if not cfg.alpa…_key or not cfg.alpa…lain:\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/.pyenv/versions/3.11.12/lib/python3.11/site…ages/pydantic/main.py\", line 991, in __getattr__\n    raise Attr…rror(f'{type(self).__name__!r} object has no attribute {item!r}')\nAttr…rror: 'Settings' object has no attribute 'alpa…lain'", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.logging:__init__.py:951 WARNING: 5 handlers detected - possible duplicate logging setup
ERROR    ai_trading.logging:__init__.py:967 Logging validation failed: ['Too many handlers detected: 5 (expected ≤ 2)']
ERROR    root:main.py:237 Logging validation failed: ['Too many handlers detected: 5 (expected ≤ 2)']
INFO     root:main.py:240 Application startup - logging configured once
ERROR    root:main.py:264 Bot startup failed: 'Settings' object has no attribute 'alpaca_secret_key_plain'
Traceback (most recent call last):
  File "/workspace/ai-trading-bot/ai_trading/main.py", line 245, in run_bot
    validate_environment()
  File "/workspace/ai-trading-bot/ai_trading/main.py", line 201, in validate_environment
    if not cfg.alpaca_api_key or not cfg.alpaca_secret_key_plain:
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py", line 991, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'Settings' object has no attribute 'alpaca_secret_key_plain'
______________________________________________ test_validate_environment_missing _______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb402865d0>

    def test_validate_environment_missing(monkeypatch):
        """validate_environment errors when secret missing."""
>       monkeypatch.setattr(main.config, 'WEBHOOK_SECRET', '', raising=False)

tests/test_main_extended2.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:997: in __setattr__
    elif (setattr_handler := self._setattr_handler(name, value)) is not None:
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
name = 'WEBHOOK_SECRET', value = ''

    def _setattr_handler(self, name: str, value: Any) -> Callable[[BaseModel, str, Any], None] | None:
        """Get a handler for setting an attribute on the model instance.
    
        Returns:
            A handler for setting an attribute on the model instance. Used for memoization of the handler.
            Memoizing the handlers leads to a dramatic performance improvement in `__setattr__`
            Returns `None` when memoization is not safe, then the attribute is set directly.
        """
        cls = self.__class__
        if name in cls.__class_vars__:
            raise AttributeError(
                f'{name!r} is a ClassVar of `{cls.__name__}` and cannot be set on an instance. '
                f'If you want to set a value on the class, use `{cls.__name__}.{name} = value`.'
            )
        elif not _fields.is_valid_field_name(name):
            if (attribute := cls.__private_attributes__.get(name)) is not None:
                if hasattr(attribute, '__set__'):
                    return lambda model, _name, val: attribute.__set__(model, val)
                else:
                    return _SIMPLE_SETATTR_HANDLERS['private']
            else:
                _object_setattr(self, name, value)
                return None  # Can not return memoized handler with possibly freeform attr names
    
        attr = getattr(cls, name, None)
        # NOTE: We currently special case properties and `cached_property`, but we might need
        # to generalize this to all data/non-data descriptors at some point. For non-data descriptors
        # (such as `cached_property`), it isn't obvious though. `cached_property` caches the value
        # to the instance's `__dict__`, but other non-data descriptors might do things differently.
        if isinstance(attr, cached_property):
            return _SIMPLE_SETATTR_HANDLERS['cached_property']
    
        _check_frozen(cls, name, value)
    
        # We allow properties to be set only on non frozen models for now (to match dataclasses).
        # This can be changed if it ever gets requested.
        if isinstance(attr, property):
            return lambda model, _name, val: attr.__set__(model, val)
        elif cls.model_config.get('validate_assignment'):
            return _SIMPLE_SETATTR_HANDLERS['validate_assignment']
        elif name not in cls.__pydantic_fields__:
            if cls.model_config.get('extra') != 'allow':
                # TODO - matching error
>               raise ValueError(f'"{cls.__name__}" object has no field "{name}"')
E               ValueError: "Settings" object has no field "WEBHOOK_SECRET"

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1044: ValueError
________________________________________________ test_optimize_signals_fallback ________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f14812347d0>

    def test_optimize_signals_fallback(monkeypatch):
        # Force missing meta module -> fallback should return input unchanged
        sys.modules.pop("ai_trading.meta_learning", None)
        import importlib
        eng = importlib.import_module("ai_trading.core.bot_engine")
        dummy = [{"sym":"AAPL","score":0.5}, {"sym":"MSFT","score":0.4}]
>       out = eng.optimize_signals(dummy)  # type: ignore[attr-defined]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: optimize_signals() missing 1 required positional argument: 'cfg'

tests/test_meta_learning_optional.py:21: TypeError
_____________________________________________________ test_main_runs_once ______________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb3fd38ad0>

    def test_main_runs_once(monkeypatch):
        """main executes a single cycle when configured."""
        monkeypatch.setenv("SCHEDULER_ITERATIONS", "1")
        called = {}
    
        # AI-AGENT-REF: Fix lambda signature to accept ready_signal parameter and set it
        def mock_start_api(ready_signal=None):
            called.setdefault("api", True)
            if ready_signal:
                ready_signal.set()  # Important: signal that API is ready
        monkeypatch.setattr(main, "start_api", mock_start_api)
        def _cycle():
            called["cycle"] = called.get("cycle", 0) + 1
        monkeypatch.setattr(main, "run_cycle", _cycle)
        monkeypatch.setattr(main.time, "sleep", lambda s: None)
>       main.main()

tests/test_main_extended2.py:84: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/main.py:341: in main
    _validate_runtime_config(config, S)
ai_trading/main.py:166: in _validate_runtime_config
    setattr(tcfg, "max_position_size", float(fallback))
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:997: in __setattr__
    elif (setattr_handler := self._setattr_handler(name, value)) is not None:
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
name = 'max_position_size', value = 8000.0

    def _setattr_handler(self, name: str, value: Any) -> Callable[[BaseModel, str, Any], None] | None:
        """Get a handler for setting an attribute on the model instance.
    
        Returns:
            A handler for setting an attribute on the model instance. Used for memoization of the handler.
            Memoizing the handlers leads to a dramatic performance improvement in `__setattr__`
            Returns `None` when memoization is not safe, then the attribute is set directly.
        """
        cls = self.__class__
        if name in cls.__class_vars__:
            raise AttributeError(
                f'{name!r} is a ClassVar of `{cls.__name__}` and cannot be set on an instance. '
                f'If you want to set a value on the class, use `{cls.__name__}.{name} = value`.'
            )
        elif not _fields.is_valid_field_name(name):
            if (attribute := cls.__private_attributes__.get(name)) is not None:
                if hasattr(attribute, '__set__'):
                    return lambda model, _name, val: attribute.__set__(model, val)
                else:
                    return _SIMPLE_SETATTR_HANDLERS['private']
            else:
                _object_setattr(self, name, value)
                return None  # Can not return memoized handler with possibly freeform attr names
    
        attr = getattr(cls, name, None)
        # NOTE: We currently special case properties and `cached_property`, but we might need
        # to generalize this to all data/non-data descriptors at some point. For non-data descriptors
        # (such as `cached_property`), it isn't obvious though. `cached_property` caches the value
        # to the instance's `__dict__`, but other non-data descriptors might do things differently.
        if isinstance(attr, cached_property):
            return _SIMPLE_SETATTR_HANDLERS['cached_property']
    
        _check_frozen(cls, name, value)
    
        # We allow properties to be set only on non frozen models for now (to match dataclasses).
        # This can be changed if it ever gets requested.
        if isinstance(attr, property):
            return lambda model, _name, val: attr.__set__(model, val)
        elif cls.model_config.get('validate_assignment'):
            return _SIMPLE_SETATTR_HANDLERS['validate_assignment']
        elif name not in cls.__pydantic_fields__:
            if cls.model_config.get('extra') != 'allow':
                # TODO - matching error
>               raise ValueError(f'"{cls.__name__}" object has no field "{name}"')
E               ValueError: "Settings" object has no field "max_position_size"

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1044: ValueError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:29,464", "level": "INFO", "name": "ai_trading.main", "msg": "DATA_CONFIG feed=iex adjustment=all timeframe=1Day/1Min provider=alpaca", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:29,465", "level": "INFO", "name": "ai_trading.position_sizing", "msg": "CONF…OFIX", "field": "max_position_size", "given": 0.0, "fallback": 8000.0, "reason": "derived_equity_cap", "equity": null, "capital_cap": 0.04, "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:29,465", "level": "CRITICAL", "name": "ai_trading.main", "msg": "RUNT…ALID", "error": "\"Settings\" object has no field \"max_position_size\"", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.main:main.py:335 DATA_CONFIG feed=iex adjustment=all timeframe=1Day/1Min provider=alpaca
INFO     ai_trading.position_sizing:position_sizing.py:60 CONF…OFIX
CRITICAL ai_trading.main:main.py:343 RUNT…ALID
_______________________________________________ test_generate_insufficient_data ________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7fdb3e6750d0>

    def test_generate_insufficient_data(caplog):
        """Insufficient history skips generation."""
        df = pd.DataFrame({"close": [1, 2]})
        ctx = Ctx(df)
        strat = MeanReversionStrategy(lookback=5)
        caplog.set_level('WARNING')
        assert strat.generate(ctx) == []
>       assert "insufficient" in caplog.text
E       AssertionError: assert 'insufficient' in 'WARNING  ai_trading.logging:mean_reversion.py:27 mean…sion: insu…ient data\n'
E        +  where 'WARNING  ai_trading.logging:mean_reversion.py:27 mean…sion: insu…ient data\n' = <_pytest.logging.LogCaptureFixture object at 0x7fdb3e6750d0>.text

tests/test_mean_reversion_extra.py:25: AssertionError
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.logging:mean_reversion.py:27 mean…sion: insu…ient data
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 13:32:29,782", "level": "WARNING", "name": "ai_trading.logging", "msg": "mean…sion: insu…ient data", "bot_phase": "GENERAL"}
_________________________________________________ test_generate_invalid_stats __________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7fdb3fda4290>

    def test_generate_invalid_stats(caplog):
        """Invalid rolling statistics skip generation."""
        df = pd.DataFrame({"close": [1]*10})
        ctx = Ctx(df)
        strat = MeanReversionStrategy(lookback=3)
        caplog.set_level('WARNING')
        ctx.data_fetcher.df.loc[ctx.data_fetcher.df.index[-1], "close"] = float('nan')
        assert strat.generate(ctx) == []
>       assert "invalid rolling" in caplog.text
E       AssertionError: assert 'invalid rolling' in 'WARNING  ai_trading.logging:mean_reversion.py:33 mean…sion: invalid stats\n'
E        +  where 'WARNING  ai_trading.logging:mean_reversion.py:33 mean…sion: invalid stats\n' = <_pytest.logging.LogCaptureFixture object at 0x7fdb3fda4290>.text

tests/test_mean_reversion_extra.py:36: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:29,793", "level": "WARNING", "name": "ai_trading.logging", "msg": "mean…sion: invalid stats", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.logging:mean_reversion.py:33 mean…sion: invalid stats
_____________________________________________________ test_fit_and_predict _____________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw3/test_fit_and_predict0')

    def test_fit_and_predict(tmp_path):
        model = MLModel(DummyPipe())
        df = make_df()
        mse = model.fit(df, np.array([0, 1]))
>       assert mse >= 0
               ^^^^^^^^
E       TypeError: '>=' not supported between instances of 'MLModel' and 'int'

tests/test_ml_model_extra.py:46: TypeError
_____________________________________________________ test_load_real_model _____________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw3/test_load_real_model0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb3e6e7750>

    def test_load_real_model(tmp_path, monkeypatch):
        models_dir = tmp_path / "models"
        models_dir.mkdir()
        model = DummyClassifier(strategy="most_frequent")
        X = np.array([[0], [1]])
        y = np.array([0, 1])
        model.fit(X, y)
        path = models_dir / "TESTSYM.pkl"
        with open(path, "wb") as f:
            pickle.dump(model, f)
        monkeypatch.chdir(tmp_path)
        with open(path, "rb") as f:
            stub.ML_MODELS["TESTSYM"] = pickle.load(f)
        loaded = _load_ml_model("TESTSYM")
>       assert loaded is not None
E       assert None is not None

/workspace/ai-trading-bot/tests/test_ml_model_loading.py:43: AssertionError
__________________________________________ test_model_registry_multiple_registrations __________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_model_registry_multiple_registrations():
        """Test registry handles multiple models correctly."""
        with tempfile.TemporaryDirectory() as tmpdir:
            registry = ModelRegistry(base_path=tmpdir)
    
            # Register multiple models
            model1 = LinearRegression()
            model2 = LinearRegression()
    
            id1 = registry.register_model(model1, "strat1", "linear", metadata={"version": 1})
            id2 = registry.register_model(model2, "strat1", "linear", metadata={"version": 2})
    
            # Latest should return the most recent
            latest = registry.latest_for("strat1", "linear")
            assert latest == id2
    
            # Both models should be loadable
            loaded1, meta1 = registry.load_model(id1)
            loaded2, meta2 = registry.load_model(id2)
    
>           assert meta1["version"] == 1
E           assert 2 == 1

tests/test_model_registry_roundtrip.py:90: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:30,032", "level": "INFO", "name": "ai_trading.logging", "msg": "Mode…stry initialized at /tmp/tmpb67kmznc", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:30,032", "level": "INFO", "name": "ai_trading.logging", "msg": "Registered model stra…825f", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:30,033", "level": "INFO", "name": "ai_trading.logging", "msg": "Registered model stra…825f", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.logging:model_registry.py:32 Mode…stry initialized at /tmp/tmpb67kmznc
INFO     ai_trading.logging:model_registry.py:95 Registered model strat1-linear-b8d038c28914825f
INFO     ai_trading.logging:model_registry.py:95 Registered model strat1-linear-b8d038c28914825f
_______________________________________________ test_generate_insufficient_data ________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7fdb3e6415d0>

    def test_generate_insufficient_data(caplog):
        df = pd.DataFrame({"close": [1]})
        ctx = Ctx(df)
        strat = MomentumStrategy(lookback=2)
        caplog.set_level('WARNING')
        assert strat.generate(ctx) == []
>       assert "Insufficient data" in caplog.text
E       AssertionError: assert 'Insufficient data' in 'INFO     ai_trading.logging:__init__.py:293 Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate\n'
E        +  where 'INFO     ai_trading.logging:__init__.py:293 Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate\n' = <_pytest.logging.LogCaptureFixture object at 0x7fdb3e6415d0>.text

tests/test_momentum_extra.py:25: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:30,047", "level": "INFO", "name": "ai_trading.logging", "msg": "Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.logging:__init__.py:293 Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate
_______________________________________________ test_generate_insufficient_data ________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7fdb3e677c10>

    def test_generate_insufficient_data(caplog):
        df = pd.DataFrame({"close": [1, 2]})
        ctx = Ctx(df)
>       strat = MovingAverageCrossoverStrategy(short=3, long=5)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: MovingAverageCrossoverStrategy.__init__() got an unexpected keyword argument 'short'

tests/test_moving_average_crossover_extra.py:27: TypeError
___________________________________________________ test_generate_buy_signal ___________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_generate_buy_signal():
        df = pd.DataFrame({"close": [1, 2, 3, 4, 5, 6]})
        ctx = Ctx(df)
>       strat = MovingAverageCrossoverStrategy(short=2, long=3)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: MovingAverageCrossoverStrategy.__init__() got an unexpected keyword argument 'short'

tests/test_moving_average_crossover_extra.py:36: TypeError
______________________________________ TestMyFixes.test_confidence_normalization_improved ______________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_my_fixes.TestMyFixes testMethod=test_confidence_normalization_improved>

    def test_confidence_normalization_improved(self):
        """Test that confidence score normalization is improved."""
>       with open("strategy_allocator.py", 'r') as f:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       FileNotFoundError: [Errno 2] No such file or directory: 'strategy_allocator.py'

tests/test_my_fixes.py:43: FileNotFoundError
_______________________________________ TestMyFixes.test_data_quality_handling_improved ________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_my_fixes.TestMyFixes testMethod=test_data_quality_handling_improved>

    def test_data_quality_handling_improved(self):
        """Test that data quality validation is improved."""
>       with open("trade_execution.py", 'r') as f:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       FileNotFoundError: [Errno 2] No such file or directory: 'trade_execution.py'

tests/test_my_fixes.py:86: FileNotFoundError
____________________________________________ TestMyFixes.test_duplicate_logging_fix ____________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_my_fixes.TestMyFixes testMethod=test_duplicate_logging_fix>

    def test_duplicate_logging_fix(self):
        """Test that duplicate event logging is eliminated."""
        debug_tracker_path = "ai_trading/execution/debug_tracker.py"
        if os.path.exists(debug_tracker_path):
            with open(debug_tracker_path, 'r') as f:
                content = f.read()
    
            # Should use elif instead of else to prevent double logging
>           self.assertIn('elif phase in [ExecutionPhase.SIGNAL_GENERATED', content)
E           AssertionError: 'elif phase in [ExecutionPhase.SIGNAL_GENERATED' not found in '"""Enhanced trade execution debugging and tracking system.\n\nThis module provides comprehensive logging and tracking for the complete\nsignal-to-execution pipeline, including correlation IDs, order lifecycle\ntracking, and detailed execution logging.\n"""\n\nfrom __future__ import annotations\n\nimport logging\nimport time\nimport uuid\nfrom collections import defaultdict, deque\nfrom datetime import UTC, datetime\nfrom enum import Enum\nfrom threading import Lock\nfrom typing import Any\n\nfrom ai_trading.logging import get_logger\n\n\ndef get_phase_logger(name: str, phase: str) -> logging.Logger:\n    """Get a logger for a specific phase - fallback implementation."""\n    logger_name = f"{name}.{phase}" if phase else name\n    return get_logger(logger_name)\n\n\nclass ExecutionPhase(Enum):\n    """Phases of order execution lifecycle."""\n\n    SIGNAL_GENERATED = "signal_generated"\n    RISK_CHECK = "risk_check"\n    ORDER_PREPARED = "order_prepared"\n    ORDER_SUBMITTED = "order_submitted"\n    ORDER_ACKNOWLEDGED = "order_acknowledged"\n    ORDER_FILLED = "order_filled"\n    ORDER_PARTIALLY_FILLED = "order_partially_filled"\n    ORDER_REJECTED = "order_rejected"\n    ORDER_CANCELLED = "order_cancelled"\n    POSITION_UPDATED = "position_updated"\n    PNL_CALCULATED = "pnl_calculated"\n\n\nclass OrderStatus(Enum):\n    """Order execution status."""\n\n    PENDING = "pending"\n    SUBMITTED = "submitted"\n    ACKNOWLEDGED = "acknowledged"\n    FILLED = "filled"\n    PARTIALLY_FILLED = "partially_filled"\n    REJECTED = "rejected"\n    CANCELLED = "cancelled"\n    FAILED = "failed"\n\n\nclass ExecutionDebugTracker:\n    """Comprehensive execution debugging and correlation tracking."""\n\n    def __init__(self):\n        self.logger = get_phase_logger(__name__, "EXEC_DEBUG")\n        self._lock = Lock()\n\n        # Track active orders by correlation ID\n        self._active_orders: dict[str, dict[str, Any]] = {}\n\n        # Track execution timeline for each correlation ID\n        self._execution_timelines: dict[str, list[dict[str, Any]]] = defaultdict(list)\n\n        # Track order lifecycle events\n        self._order_events: dict[str, list[dict[str, Any]]] = defaultdict(list)\n\n        # Track recent execution statistics\n        self._recent_executions: deque = deque(maxlen=1000)\n\n        # Track failed executions for analysis\n        self._failed_executions: deque = deque(maxlen=500)\n\n        # Track position updates\n        self._position_updates: deque = deque(maxlen=500)\n\n        # Debug flags\n        self.verbose_logging = False\n        self.trace_mode = False\n\n    def generate_correlation_id(self, symbol: str, side: str) -> str:\n        """Generate unique correlation ID for tracking order lifecycle."""\n        timestamp = int(time.time() * 1000)  # milliseconds\n        unique_id = str(uuid.uuid4())[:8]\n        return f"{symbol}_{side}_{timestamp}_{unique_id}"\n\n    def start_execution_tracking(\n        self,\n        correlation_id: str,\n        symbol: str,\n        qty: int,\n        side: str,\n        signal_data: dict | None = None,\n    ) -> None:\n        """Start tracking a new order execution."""\n        execution_start = {\n            "correlation_id": correlation_id,\n            "symbol": symbol,\n            "qty": qty,\n            "side": side,\n            "start_time": datetime.now(UTC).isoformat(),\n            "signal_data": signal_data or {},\n            "status": OrderStatus.PENDING.value,\n            "phases": [],\n        }\n\n        # AI-AGENT-REF: Use timeout-based lock to prevent deadlock\n        lock_acquired = False\n        try:\n            lock_acquired = self._lock.acquire(timeout=5.0)\n            if lock_acquired:\n                self._active_orders[correlation_id] = execution_start\n        except Exception as e:\n            self.logger.error(\n                "START_TRACKING_ERROR",\n                extra={"correlation_id": correlation_id, "error": str(e)},\n            )\n        finally:\n            if lock_acquired:\n                self._lock.release()\n\n        # AI-AGENT-REF: Call log_execution_event outside of lock to prevent recursive deadlock\n        self.log_execution_event(\n            correlation_id,\n            ExecutionPhase.SIGNAL_GENERATED,\n            {"symbol": symbol, "qty": qty, "side": side, "signal_data": signal_data},\n        )\n\n    def log_execution_event(\n        self,\n        correlation_id: str,\n        phase: ExecutionPhase,\n        data: dict[str, Any] | None = None,\n    ) -> None:\n        """Log an execution phase event with correlation ID."""\n        timestamp = datetime.now(UTC).isoformat()\n\n        event = {\n            "timestamp": timestamp,\n            "correlation_id": correlation_id,\n            "phase": phase.value,\n            "data": data or {},\n        }\n\n        # AI-AGENT-REF: Use timeout-based lock acquisition to prevent deadlock\n        lock_acquired = False\n        try:\n            lock_acquired = self._lock.acquire(timeout=5.0)  # 5 second timeout\n            if not lock_acquired:\n                # Fallback: log without state update to prevent blocking\n                self.logger.warning(\n                    "LOCK_TIMEOUT_EXECUTION_EVENT",\n                    extra={\n                        "correlation_id": correlation_id,\n                        "phase": phase.value,\n                        "message": "Failed to acquire lock within timeout, logging without state update",\n                    },\n                )\n                return\n\n            self._execution_timelines[correlation_id].append(event)\n\n            # Update active order status if relevant\n            if correlation_id in self._active_orders:\n                self._active_orders[correlation_id]["phases"].append(event)\n\n                # Update status based on phase\n                if phase == ExecutionPhase.ORDER_SUBMITTED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.SUBMITTED.value\n                elif phase == ExecutionPhase.ORDER_ACKNOWLEDGED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.ACKNOWLEDGED.value\n                elif phase == ExecutionPhase.ORDER_FILLED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.FILLED.value\n                elif phase == ExecutionPhase.ORDER_PARTIALLY_FILLED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.PARTIALLY_FILLED.value\n                elif phase == ExecutionPhase.ORDER_REJECTED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.REJECTED.value\n                elif phase == ExecutionPhase.ORDER_CANCELLED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.CANCELLED.value\n        except Exception as e:\n            # AI-AGENT-REF: Graceful error handling for lock operations\n            self.logger.error(\n                "EXECUTION_EVENT_ERROR",\n                extra={\n                    "correlation_id": correlation_id,\n                    "phase": phase.value,\n                    "error": str(e),\n                    "message": "Error updating execution event state",\n                },\n            )\n        finally:\n            if lock_acquired:\n                self._lock.release()\n\n        # Log the event (moved outside lock to prevent circular logging)\n        log_data = {\n            "correlation_id": correlation_id,\n            "phase": phase.value,\n            "timestamp": timestamp,\n        }\n        log_data.update(data or {})\n\n        try:\n            if self.verbose_logging or self.trace_mode:\n                self.logger.info(f"EXEC_EVENT_{phase.value.upper()}", extra=log_data)\n            elif phase in [\n                ExecutionPhase.SIGNAL_GENERATED,\n                ExecutionPhase.ORDER_SUBMITTED,\n                ExecutionPhase.ORDER_FILLED,\n                ExecutionPhase.ORDER_REJECTED,\n            ]:\n                # Log only key phases in normal mode (but not if already logged in verbose mode)\n                self.logger.info(f"EXEC_EVENT_{phase.value.upper()}", extra=log_data)\n        except (ValueError, TypeError, AttributeError) as e:\n            # AI-AGENT-REF: Prevent logging errors from cascading\n            self.logger.exception(\n                "debug_tracker: logging error during execution event", exc_info=e\n            )\n\n    def log_order_result(\n        self,\n        correlation_id: str,\n        success: bool,\n        order_data: dict | None = None,\n        error: str | None = None,\n    ) -> None:\n        """Log the final result of an order execution."""\n        timestamp = datetime.now(UTC).isoformat()\n\n        result_data = {\n            "correlation_id": correlation_id,\n            "success": success,\n            "timestamp": timestamp,\n            "order_data": order_data or {},\n            "error": error,\n        }\n\n        # AI-AGENT-REF: Use timeout-based lock to prevent deadlock\n        lock_acquired = False\n        order_info = None\n        found_order = False\n\n        try:\n            lock_acquired = self._lock.acquire(timeout=5.0)\n            if lock_acquired and correlation_id in self._active_orders:\n                order_info = self._active_orders[correlation_id].copy()\n                order_info.update(result_data)\n                found_order = True\n\n                if success:\n                    self._recent_executions.append(order_info)\n                else:\n                    self._failed_executions.append(order_info)\n\n                # Remove from active orders\n                del self._active_orders[correlation_id]\n        except Exception as e:\n            self.logger.error(\n                "ORDER_RESULT_ERROR",\n                extra={"correlation_id": correlation_id, "error": str(e)},\n            )\n        finally:\n            if lock_acquired:\n                self._lock.release()\n\n        # AI-AGENT-REF: Log outside of lock to prevent circular logging deadlock\n        try:\n            if found_order:\n                if success:\n                    self.logger.info("ORDER_EXECUTION_SUCCESS", extra=result_data)\n                else:\n                    self.logger.error("ORDER_EXECUTION_FAILED", extra=result_data)\n            else:\n                self.logger.warning(\n                    "UNKNOWN_CORRELATION_ID",\n                    extra={\n                        "correlation_id": correlation_id,\n                        "message": "Attempted to log result for unknown correlation ID",\n                    },\n                )\n        except (ValueError, TypeError, AttributeError) as e:\n            # AI-AGENT-REF: Prevent logging errors from cascading\n            self.logger.exception(\n                "debug_tracker: logging error during order result", exc_info=e\n            )\n\n    def log_position_update(\n        self,\n        symbol: str,\n        old_qty: float,\n        new_qty: float,\n        correlation_id: str | None = None,\n    ) -> None:\n        """Log position updates with optional correlation to order."""\n        position_update = {\n            "timestamp": datetime.now(UTC).isoformat(),\n            "symbol": symbol,\n            "old_qty": old_qty,\n            "new_qty": new_qty,\n            "qty_change": new_qty - old_qty,\n            "correlation_id": correlation_id,\n        }\n\n        with self._lock:\n            self._position_updates.append(position_update)\n\n        if correlation_id:\n            self.log_execution_event(\n                correlation_id, ExecutionPhase.POSITION_UPDATED, position_update\n            )\n\n        self.logger.info("POSITION_UPDATE", extra=position_update)\n\n    def get_active_orders(self) -> dict[str, dict[str, Any]]:\n        """Get all currently active orders being tracked."""\n        with self._lock:\n            return self._active_orders.copy()\n\n    def get_execution_timeline(self, correlation_id: str) -> list[dict[str, Any]]:\n        """Get the complete execution timeline for a correlation ID."""\n        with self._lock:\n            return self._execution_timelines[correlation_id].copy()\n\n    def get_recent_executions(self, limit: int = 50) -> list[dict[str, Any]]:\n        """Get recent successful executions."""\n        with self._lock:\n            return list(self._recent_executions)[-limit:]\n\n    def get_failed_executions(self, limit: int = 50) -> list[dict[str, Any]]:\n        """Get recent failed executions for analysis."""\n        with self._lock:\n            return list(self._failed_executions)[-limit:]\n\n    def get_position_updates(\n        self, symbol: str | None = None, limit: int = 50\n    ) -> list[dict[str, Any]]:\n        """Get recent position updates, optionally filtered by symbol."""\n        with self._lock:\n            updates = list(self._position_updates)[-limit:]\n            if symbol:\n                updates = [u for u in updates if u["symbol"] == symbol]\n            return updates\n\n    def set_debug_mode(self, verbose: bool = True, trace: bool = False) -> None:\n        """Enable/disable debug logging modes."""\n        self.verbose_logging = verbose\n        self.trace_mode = trace\n\n        mode = "TRACE" if trace else "VERBOSE" if verbose else "NORMAL"\n        self.logger.info("DEBUG_MODE_CHANGED", extra={"mode": mode})\n\n    def get_execution_stats(self) -> dict[str, Any]:\n        """Get execution statistics for monitoring."""\n        with self._lock:\n            active_count = len(self._active_orders)\n            recent_success_count = len(self._recent_executions)\n            recent_failure_count = len(self._failed_executions)\n\n            # Calculate success rate from recent executions\n            total_recent = recent_success_count + recent_failure_count\n            success_rate = (\n                recent_success_count / total_recent if total_recent > 0 else 0\n            )\n\n            # Get status breakdown of active orders\n            status_breakdown = {}\n            for order in self._active_orders.values():\n                status = order.get("status", "unknown")\n                status_breakdown[status] = status_breakdown.get(status, 0) + 1\n\n            return {\n                "active_orders": active_count,\n                "recent_successes": recent_success_count,\n                "recent_failures": recent_failure_count,\n                "success_rate": success_rate,\n                "status_breakdown": status_breakdown,\n                "position_updates_count": len(self._position_updates),\n            }\n\n\n# Global debug tracker instance\n_debug_tracker: ExecutionDebugTracker | None = None\n_tracker_lock = Lock()\n\n\ndef get_debug_tracker() -> ExecutionDebugTracker:\n    """Get or create the global debug tracker instance."""\n    global _debug_tracker\n    with _tracker_lock:\n        if _debug_tracker is None:\n            _debug_tracker = ExecutionDebugTracker()\n        return _debug_tracker\n\n\ndef enable_debug_mode(verbose: bool = True, trace: bool = False) -> None:\n    """Enable debug mode for execution tracking."""\n    tracker = get_debug_tracker()\n    tracker.set_debug_mode(verbose, trace)\n\n\ndef log_signal_to_execution(\n    symbol: str, side: str, qty: int, signal_data: dict | None = None\n) -> str:\n    """Start tracking a signal-to-execution flow and return correlation ID."""\n    tracker = get_debug_tracker()\n    correlation_id = tracker.generate_correlation_id(symbol, side)\n    tracker.start_execution_tracking(correlation_id, symbol, qty, side, signal_data)\n    return correlation_id\n\n\ndef log_execution_phase(\n    correlation_id: str, phase: ExecutionPhase, data: dict | None = None\n) -> None:\n    """Log an execution phase with correlation ID."""\n    tracker = get_debug_tracker()\n    tracker.log_execution_event(correlation_id, phase, data)\n\n\ndef log_order_outcome(\n    correlation_id: str,\n    success: bool,\n    order_data: dict | None = None,\n    error: str | None = None,\n) -> None:\n    """Log the final outcome of an order execution."""\n    tracker = get_debug_tracker()\n    tracker.log_order_result(correlation_id, success, order_data, error)\n\n\ndef log_position_change(\n    symbol: str, old_qty: float, new_qty: float, correlation_id: str | None = None\n) -> None:\n    """Log a position change with optional correlation to order."""\n    tracker = get_debug_tracker()\n    tracker.log_position_update(symbol, old_qty, new_qty, correlation_id)\n\n\ndef get_execution_statistics() -> dict[str, Any]:\n    """Get current execution statistics."""\n    tracker = get_debug_tracker()\n    return tracker.get_execution_stats()\n'

tests/test_my_fixes.py:33: AssertionError
_______________________________________ TestMyFixes.test_liquidity_thresholds_increased ________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_my_fixes.TestMyFixes testMethod=test_liquidity_thresholds_increased>

    def test_liquidity_thresholds_increased(self):
        """Test that liquidity thresholds are made less aggressive."""
>       with open("config.py", 'r') as f:
             ^^^^^^^^^^^^^^^^^^^^^^
E       FileNotFoundError: [Errno 2] No such file or directory: 'config.py'

tests/test_my_fixes.py:73: FileNotFoundError
______________________________________ TestMyFixes.test_meta_learning_thresholds_reduced _______________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_my_fixes.TestMyFixes testMethod=test_meta_learning_thresholds_reduced>

    def test_meta_learning_thresholds_reduced(self):
        """Test that meta-learning thresholds are reduced to allow easier activation."""
>       with open("bot_engine.py", 'r') as f:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
E       FileNotFoundError: [Errno 2] No such file or directory: 'bot_engine.py'

tests/test_my_fixes.py:14: FileNotFoundError
_________________________________________ TestMyFixes.test_position_limit_rebalancing __________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_my_fixes.TestMyFixes testMethod=test_position_limit_rebalancing>

    def test_position_limit_rebalancing(self):
        """Test that position limits allow rebalancing."""
>       with open("bot_engine.py", 'r') as f:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
E       FileNotFoundError: [Errno 2] No such file or directory: 'bot_engine.py'

tests/test_my_fixes.py:59: FileNotFoundError
_____________________________________________ test_bot_engine_import_no_nameerror ______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_bot_engine_import_no_nameerror():
        """Test that bot_engine can be imported without NameError for BUY_THRESHOLD.
    
        This test creates a controlled environment and tries to import bot_engine,
        specifically checking for the NameError that was occurring before the fix.
        """
    
        # Create a test script that tries to import bot_engine
        test_script = '''
    import os
    import sys
    
    # Set test environment BEFORE any imports
    os.environ["PYTEST_RUNNING"] = "1"
    
    # Set minimal required environment variables to prevent hangs/errors
    os.environ.update({
        "ALPACA_API_KEY": "FAKE_TEST_API_KEY_NOT_REAL_123456789",  # Valid format
        "ALPACA_SECRET_KEY": "FAKE_TEST_SECRET_KEY_NOT_REAL_123456789",  # Valid format
        "ALPACA_BASE_URL": "https://paper-api.alpaca.markets",
        "WEBHOOK_SECRET": "fake-test-webhook-not-real",
        "FLASK_PORT": "9000",
        "BOT_MODE": "balanced",
        "DOLLAR_RISK_LIMIT": "0.05",
        "TESTING": "1",  # Enable testing mode to avoid expensive validations
        "TRADE_LOG_FILE": "test_trades.csv",
        "SEED": "42",
        "RATE_LIMIT_BUDGET": "190",
        # Add more environment variables that could prevent import hangs
        "DISABLE_DAILY_RETRAIN": "True",
        "DRY_RUN": "True",
        "SHADOW_MODE": "True",
        "PYTEST_RUNNING": "1",  # AI-AGENT-REF: Enable fast import mode for bot_engine
    })
    
    try:
        # This should trigger validate_trading_parameters() during import
    from ai_trading.core import bot_engine
    
        print("SUCCESS: bot_engine imported without NameError")
        exit_code = 0
    except NameError as e:
        if "BUY_THRESHOLD" in str(e):
            print(f"FAILURE: NameError for BUY_THRESHOLD still occurs: {e}")
            exit_code = 1
        elif any(param in str(e) for param in ["CAPITAL_CAP", "CONF_THRESHOLD", "DOLLAR_RISK_LIMIT"]):
            print(f"FAILURE: NameError for trading parameter: {e}")
            exit_code = 1
        else:
            print(f"OTHER_NAMEERROR: {e}")
            exit_code = 2
    except Exception as e:
        # Other exceptions are expected due to missing dependencies, incomplete env, etc.
        print(f"OTHER_EXCEPTION: {type(e).__name__}: {e}")
        exit_code = 0  # This is OK
    
    sys.exit(exit_code)
    '''
    
        # Write the test script to a temporary file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(test_script)
            script_path = f.name
    
        try:
            # Get the project root directory
            project_root = Path(__file__).resolve().parents[1]
    
            # Run the test script in a subprocess with proper PYTHONPATH
            env = os.environ.copy()
            env['PYTHONPATH'] = str(project_root)
    
            try:
>               result = subprocess.run(
                    [sys.executable, script_path],
                    capture_output=True,
                    text=True,
                    env=env,
                    timeout=15,  # AI-AGENT-REF: Increase timeout to 15 seconds for more realistic import time
                    check=True
                )

tests/test_nameerror_integration.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 15, check = True
popenargs = (['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmpo9f8mrxq.py'],)
kwargs = {'env': {'AI_HTTP_TIMEOUT': '10', 'AI_TRADER_HEALTH_TICK_SECONDS': '2', 'ALPACA_API_KEY': 'FAKE_TEST_API_KEY_NOT_REAL_123456789', 'ALPACA_BASE_URL': 'https://paper-api.alpaca.markets', ...}, 'stderr': -1, 'stdout': -1, 'text': True}
process = <Popen: returncode: 1 args: ['/root/.pyenv/versions/3.11.12/bin/python3.11',...>, stdout = ''
stderr = '  File "/tmp/tmpo9f8mrxq.py", line 30\n    from ai_trading.core import bot_engine\n    ^\nIndentationError: expected an indented block after \'try\' statement on line 28\n'
retcode = 1

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired as exc:
                process.kill()
                if _mswindows:
                    # Windows accumulates the output in a single blocking
                    # read() call run on child threads, with the timeout
                    # being done in a join() on those threads.  communicate()
                    # _after_ kill() is required to collect that and add it
                    # to the exception.
                    exc.stdout, exc.stderr = process.communicate()
                else:
                    # POSIX _communicate already populated the output so
                    # far into the TimeoutExpired exception.
                    process.wait()
                raise
            except:  # Including KeyboardInterrupt, communicate handled that.
                process.kill()
                # We don't call process.wait() as .__exit__ does that for us.
                raise
            retcode = process.poll()
            if check and retcode:
>               raise CalledProcessError(retcode, process.args,
                                         output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmpo9f8mrxq.py']' returned non-zero exit status 1.

/root/.pyenv/versions/3.11.12/lib/python3.11/subprocess.py:571: CalledProcessError

During handling of the above exception, another exception occurred:

    def test_bot_engine_import_no_nameerror():
        """Test that bot_engine can be imported without NameError for BUY_THRESHOLD.
    
        This test creates a controlled environment and tries to import bot_engine,
        specifically checking for the NameError that was occurring before the fix.
        """
    
        # Create a test script that tries to import bot_engine
        test_script = '''
    import os
    import sys
    
    # Set test environment BEFORE any imports
    os.environ["PYTEST_RUNNING"] = "1"
    
    # Set minimal required environment variables to prevent hangs/errors
    os.environ.update({
        "ALPACA_API_KEY": "FAKE_TEST_API_KEY_NOT_REAL_123456789",  # Valid format
        "ALPACA_SECRET_KEY": "FAKE_TEST_SECRET_KEY_NOT_REAL_123456789",  # Valid format
        "ALPACA_BASE_URL": "https://paper-api.alpaca.markets",
        "WEBHOOK_SECRET": "fake-test-webhook-not-real",
        "FLASK_PORT": "9000",
        "BOT_MODE": "balanced",
        "DOLLAR_RISK_LIMIT": "0.05",
        "TESTING": "1",  # Enable testing mode to avoid expensive validations
        "TRADE_LOG_FILE": "test_trades.csv",
        "SEED": "42",
        "RATE_LIMIT_BUDGET": "190",
        # Add more environment variables that could prevent import hangs
        "DISABLE_DAILY_RETRAIN": "True",
        "DRY_RUN": "True",
        "SHADOW_MODE": "True",
        "PYTEST_RUNNING": "1",  # AI-AGENT-REF: Enable fast import mode for bot_engine
    })
    
    try:
        # This should trigger validate_trading_parameters() during import
    from ai_trading.core import bot_engine
    
        print("SUCCESS: bot_engine imported without NameError")
        exit_code = 0
    except NameError as e:
        if "BUY_THRESHOLD" in str(e):
            print(f"FAILURE: NameError for BUY_THRESHOLD still occurs: {e}")
            exit_code = 1
        elif any(param in str(e) for param in ["CAPITAL_CAP", "CONF_THRESHOLD", "DOLLAR_RISK_LIMIT"]):
            print(f"FAILURE: NameError for trading parameter: {e}")
            exit_code = 1
        else:
            print(f"OTHER_NAMEERROR: {e}")
            exit_code = 2
    except Exception as e:
        # Other exceptions are expected due to missing dependencies, incomplete env, etc.
        print(f"OTHER_EXCEPTION: {type(e).__name__}: {e}")
        exit_code = 0  # This is OK
    
    sys.exit(exit_code)
    '''
    
        # Write the test script to a temporary file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(test_script)
            script_path = f.name
    
        try:
            # Get the project root directory
            project_root = Path(__file__).resolve().parents[1]
    
            # Run the test script in a subprocess with proper PYTHONPATH
            env = os.environ.copy()
            env['PYTHONPATH'] = str(project_root)
    
            try:
                result = subprocess.run(
                    [sys.executable, script_path],
                    capture_output=True,
                    text=True,
                    env=env,
                    timeout=15,  # AI-AGENT-REF: Increase timeout to 15 seconds for more realistic import time
                    check=True
                )
            except (subprocess.TimeoutExpired, subprocess.CalledProcessError) as e:
                # Handle subprocess timeout gracefully
                print("Subprocess timeout after 5 seconds")
                print(f"Stdout so far: {e.stdout}")
                print(f"Stderr so far: {e.stderr}")
>               assert False, "Subprocess timeout - bot_engine import took longer than 5 seconds"
E               AssertionError: Subprocess timeout - bot_engine import took longer than 5 seconds
E               assert False

tests/test_nameerror_integration.py:95: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
Subprocess timeout after 5 seconds
Stdout so far: 
Stderr so far:   File "/tmp/tmpo9f8mrxq.py", line 30
    from ai_trading.core import bot_engine
    ^
IndentationError: expected an indented block after 'try' statement on line 28

_________________________________________ test_timeoutsession_injects_default_timeout __________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb3e52d990>

    def test_timeoutsession_injects_default_timeout(monkeypatch):
        captured = {}
    
        def fake_request(self, method, url, **kwargs):  # AI-AGENT-REF: capture timeout
            captured.update(kwargs)
            return types.SimpleNamespace(ok=True)
    
>       monkeypatch.setattr(requests.Session, "request", fake_request, raising=True)
                            ^^^^^^^^^^^^^^^^
E       AttributeError: module 'requests' has no attribute 'Session'

tests/test_net_http_timeout.py:17: AttributeError
_____________________________________________ test_build_retrying_session_defaults _____________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb3e52c210>

    def test_build_retrying_session_defaults(monkeypatch):
        captured = {}
    
        def fake_request(self, method, url, **kwargs):  # AI-AGENT-REF: capture timeout
            captured.update(kwargs)
            return types.SimpleNamespace(ok=True)
    
>       monkeypatch.setattr(requests.Session, "request", fake_request, raising=True)
                            ^^^^^^^^^^^^^^^^
E       AttributeError: module 'requests' has no attribute 'Session'

tests/test_net_http_timeout.py:35: AttributeError
______________________________________________ test_legacy_modules_not_importable ______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    @pytest.mark.unit
    def test_legacy_modules_not_importable():  # AI-AGENT-REF
        for name in BANNED:
>           assert importlib.util.find_spec(name) is None
E           AssertionError: assert ModuleSpec(name='metrics', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7fdb4017e890>, origin='/wor.../ai_trading/metrics/__init__.py', submodule_search_locations=['/workspace/ai-trading-bot/tests/../ai_trading/metrics']) is None
E            +  where ModuleSpec(name='metrics', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7fdb4017e890>, origin='/wor.../ai_trading/metrics/__init__.py', submodule_search_locations=['/workspace/ai-trading-bot/tests/../ai_trading/metrics']) = <function find_spec at 0x7fdb6f65d8a0>('metrics')
E            +    where <function find_spec at 0x7fdb6f65d8a0> = <module 'importlib.util' (frozen)>.find_spec
E            +      where <module 'importlib.util' (frozen)> = importlib.util

tests/test_no_legacy_imports.py:19: AssertionError
_________________________________________________ test_no_raw_requests_in_src __________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_no_raw_requests_in_src():
        root = pathlib.Path(__file__).resolve().parents[1] / "ai_trading"
        banned = []
        for p in root.rglob("*.py"):
            if "utils/http.py" in str(p):
                continue
            txt = p.read_text(encoding="utf-8", errors="ignore")
            if re.search(r"\brequests\.(get|post|put|delete|patch|head|options)\b", txt):
                banned.append(str(p))
>       assert not banned, f"Raw requests.* found in: {banned}"
E       AssertionError: Raw requests.* found in: ['/workspace/ai-trading-bot/ai_trading/data_fetcher.py', '/workspace/ai-trading-bot/ai_trading/predict.py', '/workspace/ai-trading-bot/ai_trading/analysis/sentiment.py', '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py']
E       assert not ['/workspace/ai-trading-bot/ai_trading/data_fetcher.py', '/workspace/ai-trading-bot/ai_trading/predict.py', '/workspace/ai-trading-bot/ai_trading/analysis/sentiment.py', '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py']

tests/test_no_raw_requests.py:14: AssertionError
________________________________________ test_no_root_level_imports_of_migrated_modules ________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_no_root_level_imports_of_migrated_modules():
        root = pathlib.Path(__file__).resolve().parents[1]
        banned = {
            r"\bfrom\s+signals\s+import\b",
            r"\bfrom\s+data_fetcher\s+import\b",
            r"\bfrom\s+trade_execution\s+import\b",
            r"\bfrom\s+pipeline\s+import\b",
            r"\bfrom\s+indicators\s+import\b",
            r"\bfrom\s+portfolio\s+import\b",
            r"\bfrom\s+rebalancer\s+import\b",
            r"^\s*import\s+signals\b",
            r"^\s*import\s+data_fetcher\b",
            r"^\s*import\s+trade_execution\b",
            r"^\s*import\s+pipeline\b",
            r"^\s*import\s+indicators\b",
            r"^\s*import\s+portfolio\b",
            r"^\s*import\s+rebalancer\b",
        }
        offenders = []
        for p in root.rglob("*.py"):
            text = p.read_text(encoding="utf-8", errors="ignore")
            for pat in banned:
                if re.search(pat, text, re.MULTILINE):
                    offenders.append(f"{p}:{pat}")
                    break
>       assert not offenders, f"Root imports are no longer supported. Offenders: {offenders}"
E       AssertionError: Root imports are no longer supported. Offenders: ['/workspace/ai-trading-bot/scripts/production_validator.py:^\\s*import\\s+indicators\\b', '/workspace/ai-trading-bot/scripts/integration_test.py:\\bfrom\\s+pipeline\\s+import\\b', '/workspace/ai-trading-bot/scripts/critical_fixes_validation.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-trading-bot/scripts/system_health_checker.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-trading-bot/scripts/demo_short_selling_implementation.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-trading-bot/scripts/health_check.py:^\\s*import\\s+trade_execution\\b', '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py:\\bfrom\\s+pipeline\\s+import\\b', '/workspace/ai-trading-bot/tests/test_bot_engine_imports.py:\\bfrom\\s+pipeline\\s+import\\b', '/workspace/ai-trading-bot/tests/test_import_fallbacks.py:\\bfrom\\s+pipeline\\s+import\\b']
E       assert not ['/workspace/ai-trading-bot/scripts/production_validator.py:^\\s*import\\s+indicators\\b', '/workspace/ai-trading-bot/...de_execution\\s+import\\b', '/workspace/ai-trading-bot/scripts/health_check.py:^\\s*import\\s+trade_execution\\b', ...]

tests/test_no_root_imports.py:30: AssertionError
________________________________________________ test_ai_trading_module_imports ________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_ai_trading_module_imports():
        # Test that modules can be imported from the package
        import importlib
    
        # Test each moved module can be imported from ai_trading
        modules = ["signals", "data_fetcher", "trade_execution", "indicators", "pipeline", "portfolio", "rebalancer"]
        for module_name in modules:
>           pkg_module = importlib.import_module(f"ai_trading.{module_name}")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_package_first_smoke.py:15: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap>:1204: in _gcd_import
    ???
<frozen importlib._bootstrap>:1176: in _find_and_load
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'ai_trading.trade_execution', import_ = <function _gcd_import at 0x7fdb707afd80>

>   ???
E   ModuleNotFoundError: No module named 'ai_trading.trade_execution'

<frozen importlib._bootstrap>:1140: ModuleNotFoundError
_________________________________________________ test_ai_trading_init_exports _________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_ai_trading_init_exports():
        # Test that ai_trading.__init__ properly exports the modules
        import ai_trading
    
        modules = ["signals", "data_fetcher", "trade_execution", "indicators", "pipeline", "portfolio", "rebalancer"]
        for module_name in modules:
>           assert hasattr(ai_trading, module_name)
E           AssertionError: assert False
E            +  where False = hasattr(<module 'ai_trading' from '/workspace/ai-trading-bot/ai_trading/__init__.py'>, 'trade_execution')

tests/test_package_first_smoke.py:24: AssertionError
______________________________________________ test_kelly_parameters_optimization ______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_kelly_parameters_optimization():
        """Test that Kelly parameters are optimized correctly."""
        from ai_trading.core.constants import KELLY_PARAMETERS
    
        # Verify optimized Kelly parameters
>       assert KELLY_PARAMETERS["MAX_KELLY_FRACTION"] == 0.15, f"Expected 0.15, got {KELLY_PARAMETERS['MAX_KELLY_FRACTION']}"
E       AssertionError: Expected 0.15, got 0.3
E       assert 0.3 == 0.15

tests/test_parameter_optimization.py:21: AssertionError
______________________________________________ test_adaptive_sizing_optimization _______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_adaptive_sizing_optimization():
        """Test that adaptive sizing uses optimized parameters."""
        try:
            from ai_trading.core.enums import RiskLevel
            from ai_trading.risk.adaptive_sizing import AdaptivePositionSizer
    
            # Test that sizer can be instantiated with optimized parameters
>           sizer = AdaptivePositionSizer(RiskLevel.MODERATE)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           TypeError: object() takes no arguments

tests/test_parameter_optimization.py:101: TypeError
____________________________________________ test_execution_algorithm_optimization _____________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_execution_algorithm_optimization():
        """Test that execution algorithms use optimized parameters."""
        try:
            # Test VWAP participation rate
            from ai_trading.execution.algorithms import VWAPExecutor
    
            # Mock order manager for testing
>           vwap = VWAPExecutor(MockOrderManager())
                                ^^^^^^^^^^^^^^^^
E           NameError: name 'MockOrderManager' is not defined

tests/test_parameter_optimization.py:123: NameError
_________________________________________________ test_adaptive_risk_controls __________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_adaptive_risk_controls():
        """Test adaptive risk control system."""
        from ai_trading.portfolio.risk_controls import AdaptiveRiskController
    
        # Create test data
        np.random.seed(42)
        dates = pd.date_range('2023-01-01', periods=100, freq='D')
        symbols = ['AAPL', 'GOOGL', 'MSFT']
    
        returns_data = pd.DataFrame(
            np.random.normal(0, 0.02, (100, 3)),
            index=dates,
            columns=symbols
        )
    
        controller = AdaptiveRiskController()
    
        # Test volatility calculation
        vols = controller.calculate_volatilities(returns_data)
        assert len(vols) == 3
        for symbol in symbols:
            assert symbol in vols
            assert vols[symbol] > 0
    
        # Test correlation clustering (skip if scipy not available)
        try:
>           clusters = controller.calculate_correlation_clusters(returns_data)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_peak_performance.py:188: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/portfolio/risk_controls.py:185: in calculate_correlation_clusters
    fcluster, linkage, squareform, clustering_available = _import_clustering()
                                                          ^^^^^^^^^^^^^^^^^^^^
ai_trading/portfolio/risk_controls.py:23: in _import_clustering
    if not S.ENABLE_PORTFOLIO_FEATURES:
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
item = 'ENABLE_PORTFOLIO_FEATURES'

    def __getattr__(self, item: str) -> Any:
        private_attributes = object.__getattribute__(self, '__private_attributes__')
        if item in private_attributes:
            attribute = private_attributes[item]
            if hasattr(attribute, '__get__'):
                return attribute.__get__(self, type(self))  # type: ignore
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                return self.__pydantic_private__[item]  # type: ignore
            except KeyError as exc:
                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
        else:
            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.
            # See `BaseModel.__repr_args__` for more details
            try:
                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')
            except AttributeError:
                pydantic_extra = None
    
            if pydantic_extra:
                try:
                    return pydantic_extra[item]
                except KeyError as exc:
                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
            else:
                if hasattr(self.__class__, item):
                    return super().__getattribute__(item)  # Raises AttributeError if appropriate
                else:
                    # this is the current error
>                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E                   AttributeError: 'Settings' object has no attribute 'ENABLE_PORTFOLIO_FEATURES'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:991: AttributeError
_______________________________________________________ test_determinism _______________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_determinism():
        """Test deterministic training setup."""
        from ai_trading.utils.determinism import hash_data, set_random_seeds
    
        # Test seed setting
>       set_random_seeds(42)

tests/test_peak_performance.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

seed = 42

    def set_random_seeds(seed: int = 42) -> None:
        """
        Set random seeds for reproducible results.
    
        Args:
            seed: Random seed value
        """
        # Python random
        random.seed(seed)
    
        # NumPy (if available)
>       if HAS_NUMPY:
           ^^^^^^^^^
E       NameError: name 'HAS_NUMPY' is not defined

ai_trading/utils/determinism.py:35: NameError
________________________________________________ test_backtest_cost_enforcement ________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_backtest_cost_enforcement():
        """Test that backtester respects cost model."""
        # This would be a more complex integration test
        # For now, just ensure the cost model can be imported and used
    
        from ai_trading.execution.costs import get_cost_model
    
        model = get_cost_model()
    
        # Test cost adjustment
        adjusted_size, cost_info = model.adjust_position_size(
            symbol="TEST",
            target_size=10000,
            max_cost_bps=15.0,
            volume_ratio=1.0
        )
    
>       assert isinstance(adjusted_size, float)
E       assert False
E        +  where False = isinstance(10000, float)

tests/test_peak_performance.py:366: AssertionError
_______________________________________ test_allocator_confidence_gate_filters_and_logs ________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7fdb3fd0da50>

    def test_allocator_confidence_gate_filters_and_logs(caplog):
        caplog.set_level(logging.INFO)
        alloc = PerformanceBasedAllocator()
        cfg = TradingConfig(score_confidence_min=0.7)
        inputs = {
            "momentum": [Sig("AAPL", 0.65), Sig("MSFT", 0.71), Sig("NVDA", 0.90)],
            "meanrev": [Sig("TSLA", 0.40), Sig("AMZN", 0.72)],
        }
    
        out = alloc.allocate(inputs, cfg)
    
        kept_symbols = {s.symbol for xs in out.values() for s in xs}
        assert kept_symbols == {"MSFT", "NVDA", "AMZN"}
    
        drops = [rec for rec in caplog.records if rec.message == "CONFIDENCE_DROP"]
>       assert len(drops) >= 2
E       assert 0 >= 2
E        +  where 0 = len([])

tests/test_performance_allocator_conf_gate.py:41: AssertionError
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.logging:performance_allocator.py:115 Perf…ator initialized with 20 day window
INFO     ai_trading.logging:performance_allocator.py:168 CONF…DROP
INFO     ai_trading.logging:performance_allocator.py:168 CONF…DROP
_______________________________________________ test_meta_learning_mixed_format ________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_meta_learning_mixed_format():
        """Test that meta-learning can handle mixed audit/meta-learning log formats."""
        print("Testing meta-learning mixed format handling")
    
        from ai_trading.meta_learning import (
            retrain_meta_learner,
            validate_trade_data_quality,
        )
    
        # Test with the actual trades.csv file
        quality_report = validate_trade_data_quality('trades.csv')
    
        # Verify mixed format detection
        assert quality_report['file_exists'], "Trade log file should exist"
        assert quality_report['has_valid_format'], "Should have valid format"
>       assert quality_report['mixed_format_detected'], "Should detect mixed formats"
E       AssertionError: Should detect mixed formats
E       assert False

tests/test_performance_fixes.py:37: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
Testing meta-learning mixed format handling
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.meta_learning:meta_learning.py:312 Invalid price in meta format row: could not convert string to float: 'entry_price'
______________________________________________ test_cache_performance_monitoring _______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_cache_performance_monitoring():
        """Test that cache performance monitoring is working."""
        print("Testing cache performance monitoring")
    
>       from ai_trading.data_fetcher import _CACHE_STATS, get_cache_stats
E       ImportError: cannot import name '_CACHE_STATS' from 'ai_trading.data_fetcher' (unknown location)

tests/test_performance_fixes.py:57: ImportError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
Testing cache performance monitoring
__________________________________ TestConfigurationEnhancements.test_order_management_config __________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_phase2_enhancements.TestConfigurationEnhancements testMethod=test_order_management_config>

    def test_order_management_config(self):
        """Test order management configuration parameters."""
        required_params = [
            'ORDER_TIMEOUT_SECONDS',
            'ORDER_STALE_CLEANUP_INTERVAL',
            'ORDER_FILL_RATE_TARGET',
            'ORDER_MAX_RETRY_ATTEMPTS'
        ]
    
        for param in required_params:
>           self.assertTrue(hasattr(config, param), f"Missing parameter: {param}")
E           AssertionError: False is not true : Missing parameter: ORDER_MAX_RETRY_ATTEMPTS

tests/test_phase2_enhancements.py:232: AssertionError
___________________________________ TestConfigurationEnhancements.test_system_health_config ____________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_phase2_enhancements.TestConfigurationEnhancements testMethod=test_system_health_config>

    def test_system_health_config(self):
        """Test system health monitoring configuration parameters."""
        required_params = [
            'SYSTEM_HEALTH_CHECK_INTERVAL',
            'SYSTEM_HEALTH_ALERT_THRESHOLD',
            'SYSTEM_HEALTH_EXPORT_ENABLED',
            'SYSTEM_HEALTH_REPORT_PATH'
        ]
    
        for param in required_params:
>           self.assertTrue(hasattr(config, param), f"Missing parameter: {param}")
E           AssertionError: False is not true : Missing parameter: SYSTEM_HEALTH_CHECK_INTERVAL

tests/test_phase2_enhancements.py:250: AssertionError
___________________________________________________ test_short_close_queued ____________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb40484990>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7fdb3fd48690>

    def test_short_close_queued(monkeypatch, caplog):
        state = bot_engine.BotState()
        state.position_cache = {"TSLA": -44}
        bot_engine.state = state
        caplog.set_level("INFO")
    
        orders = []
        monkeypatch.setattr(bot_engine, "submit_order", lambda ctx, symbol, qty, side: orders.append((symbol, qty, side)))
        monkeypatch.setattr(bot_engine, "is_market_open", lambda: True)
        monkeypatch.setattr(bot_engine, "fetch_minute_df_safe", lambda s: pd.DataFrame({"close": [1]}, index=[pd.Timestamp("2023-01-01")]))
        monkeypatch.setattr(bot_engine, "_safe_trade", lambda *a, **k: None)
>       monkeypatch.setattr(bot_engine.prediction_executor, "submit", lambda fn, s: types.SimpleNamespace(result=lambda: fn(s)))
E       AttributeError: None has no attribute 'submit'

tests/test_portfolio.py:19: AttributeError
__________________________________________________ test_meta_learning_trigger __________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_meta_learning_trigger():
        """Test meta-learning conversion trigger."""
>       with patch('meta_learning.config') as mock_config, \
             patch('meta_learning.pd') as mock_pd, \
             patch('ai_trading.meta_learning.Path') as mock_path:

tests/test_position_holding.py:108: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7fdb3fd24350>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'ai_trading.meta_learning' from '/workspace/ai-trading-bot/ai_trading/meta_learning.py'> does not have the attribute 'config'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError
________________________________________________ test_position_manager_cleanup _________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_position_manager_cleanup():
        """Test position manager cleanup of stale positions."""
        from ai_trading.position.legacy_manager import PositionManager
    
        # Create mock context
        ctx = Mock()
        ctx.api = Mock()
    
        # Mock current positions (only AAPL exists now)
        current_positions = [Mock(symbol="AAPL")]
        ctx.api.get_all_positions.return_value = current_positions
    
        # Create position manager with existing tracked positions
        pm = PositionManager(ctx)
        pm.positions = {
            "AAPL": Mock(),
            "GOOGL": Mock(),  # This should be cleaned up
            "MSFT": Mock()    # This should be cleaned up
        }
    
        # Test cleanup
        pm.cleanup_stale_positions()
    
        # Only AAPL should remain
        assert "AAPL" in pm.positions
>       assert "GOOGL" not in pm.positions
E       AssertionError: assert 'GOOGL' not in {'AAPL': <Mock id='140579655071824'>, 'GOOGL': <Mock id='140579654890832'>, 'MSFT': <Mock id='140579654889232'>}
E        +  where {'AAPL': <Mock id='140579655071824'>, 'GOOGL': <Mock id='140579654890832'>, 'MSFT': <Mock id='140579654889232'>} = <ai_trading.position.legacy_manager.PositionManager object at 0x7fdb4018a990>.positions

tests/test_position_holding.py:183: AssertionError
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.position.legacy_manager.PositionManager:legacy_manager.py:86 Intelligent position manager not available: No module named 'intelligent_manager'; using legacy
WARNING  ai_trading.position.legacy_manager.PositionManager:legacy_manager.py:432 clea…ions failed: 'Mock' object is not iterable
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
                                                                                                                                                                                                                                           {"ts": "2025-08-22 13:32:32,497", "level": "WARNING", "name": "ai_trading.position.legacy_manager.PositionManager", "msg": "clea…ions failed: 'Mock' object is not iterable", "bot_phase": "GENERAL"}
_________________________________________________ test_meta_learning_functions _________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_meta_learning_functions():
        """Test meta-learning conversion functions."""
    
>       with patch('meta_learning.config') as mock_config:

tests/test_position_holding_simple.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7fdb400b81d0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'ai_trading.meta_learning' from '/workspace/ai-trading-bot/ai_trading/meta_learning.py'> does not have the attribute 'config'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError
___________________________ TestProblemStatementFixes.test_meta_learning_minimum_trades_requirement ____________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_problem_statement_fixes.TestProblemStatementFixes testMethod=test_meta_learning_minimum_trades_requirement>

    def test_meta_learning_minimum_trades_requirement(self):
        """Test that meta-learning minimum trade requirement is reduced to 2."""
        # Test by reading the source code directly to avoid import issues
        bot_engine_path = "bot_engine.py"
        if os.path.exists(bot_engine_path):
            with open(bot_engine_path, 'r') as f:
                content = f.read()
    
            # Look for the environment variable default
            import re
            pattern = r'METALEARN_MIN_TRADES.*"(\d+)"'
            match = re.search(pattern, content)
            if match:
                current_value = int(match.group(1))
                expected_value = 2  # Updated from 3 to 2
                self.assertEqual(current_value, expected_value,
                               f"METALEARN_MIN_TRADES default should be {expected_value}, got {current_value}")
                print("✓ Meta-learning minimum trades meets problem statement requirements")
            else:
                self.fail("Could not find METALEARN_MIN_TRADES parameter in load_global_signal_performance")
        else:
>           self.fail("bot_engine.py not found")
E           AssertionError: bot_engine.py not found

tests/test_problem_statement_fixes.py:65: AssertionError
________________________________ TestProblemStatementFixes.test_order_quantity_tracking_clarity ________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_problem_statement_fixes.TestProblemStatementFixes testMethod=test_order_quantity_tracking_clarity>

    def test_order_quantity_tracking_clarity(self):
        """Test that order quantity tracking provides clear distinction between
        requested, submitted, and filled quantities."""
        # Check that the trade execution logs have clear field names
        trade_execution_path = "trade_execution.py"
        if os.path.exists(trade_execution_path):
            with open(trade_execution_path, 'r') as f:
                content = f.read()
    
                # Check for clear quantity field names in FULL_FILL_SUCCESS
                self.assertIn('"requested_qty":', content,
                            "FULL_FILL_SUCCESS should include clear requested_qty field")
                self.assertIn('"filled_qty":', content,
                            "FULL_FILL_SUCCESS should include clear filled_qty field")
    
                # Check for clear quantity field names in ORDER_FILL_CONSOLIDATED
                self.assertIn('"total_filled_qty":', content,
                            "ORDER_FILL_CONSOLIDATED should use clear total_filled_qty field name")
    
                print("✓ Order quantity tracking has clear field names")
        else:
>           self.fail("trade_execution.py not found")
E           AssertionError: trade_execution.py not found

tests/test_problem_statement_fixes.py:104: AssertionError
__________________________________ TestProblemStatementFixes.test_pltr_sector_classification ___________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_problem_statement_fixes.TestProblemStatementFixes testMethod=test_pltr_sector_classification>

    def test_pltr_sector_classification(self):
        """Test that PLTR is classified as Technology sector."""
        # Test by reading the source code directly to avoid import issues
        bot_engine_path = "bot_engine.py"
        if os.path.exists(bot_engine_path):
            with open(bot_engine_path, 'r') as f:
                content = f.read()
    
            # Check if PLTR is in the Technology sector mapping
            if '"PLTR": "Technology"' in content:
                print("✓ PLTR sector classification meets problem statement requirements")
            else:
                self.fail("PLTR not found in Technology sector mapping")
        else:
>           self.fail("bot_engine.py not found")
E           AssertionError: bot_engine.py not found

tests/test_problem_statement_fixes.py:81: AssertionError
______________________________________________ test_alpaca_availability_detection ______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_alpaca_availability_detection():
        """Test that _alpaca_available() function works correctly."""
        # Set test environment
        os.environ['PYTEST_RUNNING'] = '1'
        os.environ['TESTING'] = '1'
    
        # Import the function
>       from ai_trading.core.bot_engine import _alpaca_available
E       ImportError: cannot import name '_alpaca_available' from 'ai_trading.core.bot_engine' (/workspace/ai-trading-bot/ai_trading/core/bot_engine.py)

tests/test_problem_statement_validation.py:19: ImportError
____________________________________________ test_alpaca_import_exception_handling _____________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_alpaca_import_exception_handling():
        """Test that Alpaca imports handle TypeErrors and other exceptions gracefully."""
        # Set test environment
        os.environ['PYTEST_RUNNING'] = '1'
        os.environ['TESTING'] = '1'
    
        # Mock alpaca to raise TypeError (the specific error mentioned in requirements)
        with patch.dict('sys.modules', {'alpaca': MagicMock()}):
>           with patch('ai_trading.core.bot_engine._alpaca_available') as mock_available:

tests/test_problem_statement_validation.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7fdb3e649d10>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'> does not have the attribute '_alpaca_available'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError
__________________________________________________ test_package_safe_imports ___________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_package_safe_imports():
        """Test that package imports work correctly from ai_trading namespace."""
        # Set test environment
        os.environ['PYTEST_RUNNING'] = '1'
        os.environ['TESTING'] = '1'
    
        # Test logging import
        from ai_trading.logging import get_logger, setup_logging
        assert callable(setup_logging)
        assert callable(get_logger)
        print("✓ ai_trading.logging imports work")
    
        # Test core imports
>       from ai_trading.core.bot_engine import _alpaca_available
E       ImportError: cannot import name '_alpaca_available' from 'ai_trading.core.bot_engine' (/workspace/ai-trading-bot/ai_trading/core/bot_engine.py)

tests/test_problem_statement_validation.py:59: ImportError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
✓ ai_trading.logging imports work
_______________________________________________ test_python_version_requirements _______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_python_version_requirements():
        """Test that pyproject.toml has correct Python version requirements."""
        with open('pyproject.toml', 'r') as f:
            content = f.read()
    
        # Should use flexible version range
>       assert 'requires-python = ">=3.12,<3.13"' in content, "Should use flexible Python 3.12 range"
E       AssertionError: Should use flexible Python 3.12 range
E       assert 'requires-python = ">=3.12,<3.13"' in '[project]\nname = "ai-trading-bot"\nversion = "0.0.0"\ndescription = "AI trading bot (lightweight testable build)"\nr...e\n\n[tool.ruff.per-file-ignores]\n"**/__init__.py" = ["F401", "F403"]\n"tests/**" = ["E402"]\n"tools/**" = ["E402"]\n'

tests/test_problem_statement_validation.py:141: AssertionError
_____________________________ TestSentimentAPIConfiguration.test_sentiment_api_env_vars_in_config ______________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_production_fixes.TestSentimentAPIConfiguration testMethod=test_sentiment_api_env_vars_in_config>

    def test_sentiment_api_env_vars_in_config(self):
        """Test that sentiment API variables are properly configured."""
        import ai_trading.config as config
    
        # Test that the new environment variables are accessible
>       self.assertTrue(hasattr(config, 'SENTIMENT_API_KEY') or 'SENTIMENT_API_KEY' in dir(config))
E       AssertionError: False is not true

tests/test_production_fixes.py:41: AssertionError
_________________________________________ TestIntegration.test_all_modules_importable __________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_production_fixes.TestIntegration testMethod=test_all_modules_importable>

    def test_all_modules_importable(self):
        """Test that all modified modules can be imported without errors."""
        modules_to_test = [
            'performance_monitor',
            'data_validation',
            'validate_env'
        ]
    
        for module_name in modules_to_test:
            try:
>               __import__(module_name)
E               ModuleNotFoundError: No module named 'performance_monitor'

tests/test_production_fixes.py:287: ModuleNotFoundError

During handling of the above exception, another exception occurred:

self = <tests.test_production_fixes.TestIntegration testMethod=test_all_modules_importable>

    def test_all_modules_importable(self):
        """Test that all modified modules can be imported without errors."""
        modules_to_test = [
            'performance_monitor',
            'data_validation',
            'validate_env'
        ]
    
        for module_name in modules_to_test:
            try:
                __import__(module_name)
            except ImportError as e:
                # Allow for missing dependencies in test environment
                if 'pandas' in str(e) or 'pydantic' in str(e):
                    continue
                else:
>                   self.fail(f"Failed to import {module_name}: {e}")
E                   AssertionError: Failed to import performance_monitor: No module named 'performance_monitor'

tests/test_production_fixes.py:293: AssertionError
____________________________________________________ test_submodules_import ____________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_submodules_import() -> None:
        pkg = importlib.import_module("ai_trading")
        for modinfo in pkgutil.walk_packages(pkg.__path__, pkg.__name__ + "."):
>           _safe_import(modinfo.name)

tests/test_imports_smoke.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_imports_smoke.py:16: in _safe_import
    importlib.import_module(name)
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap>:1204: in _gcd_import
    ???
<frozen importlib._bootstrap>:1176: in _find_and_load
    ???
<frozen importlib._bootstrap>:1147: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:690: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:940: in exec_module
    ???
<frozen importlib._bootstrap>:241: in _call_with_frames_removed
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Production trading system integration module.
    
    Integrates all production-ready components into a unified trading system
    with comprehensive risk management, monitoring, and execution capabilities.
    """
    
    from datetime import UTC, datetime
    from typing import Any
    
    from ai_trading.core.enums import OrderSide, OrderType, RiskLevel
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    from ai_trading.execution.liquidity import LiquidityManager
    from ai_trading.execution.production_engine import ProductionExecutionCoordinator
    
    # Use the centralized logger as per AGENTS.md
    from ai_trading.logging import logger
    from ai_trading.monitoring import (
        AlertManager,
        AlertSeverity,
        PerformanceDashboard,
    )
>   from ai_trading.risk import (
        DynamicPositionSizer,
        RiskManager,
        TradingHaltManager,
    )
E   ImportError: cannot import name 'DynamicPositionSizer' from 'ai_trading.risk' (unknown location)

ai_trading/production_system.py:23: ImportError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:33,355", "level": "INFO", "name": "ai_trading.logging", "msg": "Para…ator initialized with inst…onal safety bounds", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.logging:parameter_validator.py:54 Para…ator initialized with inst…onal safety bounds
_____________________________________________ test_partial_initial_rebalance_fill ______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db109010>

    def test_partial_initial_rebalance_fill(monkeypatch):
        ctx = types.SimpleNamespace(
            api=DummyAPI(),
            data_fetcher=DummyFetcher(),
            rebalance_ids={},
            rebalance_attempts={},
            rebalance_buys={},
        )
    
        class FakeDateTime(datetime.datetime):
            @classmethod
            def now(cls, tz=None):
                return datetime.datetime(2025, 7, 26, 0, 16, tzinfo=datetime.UTC)
    
        monkeypatch.setattr(bot_engine, "datetime", FakeDateTime)
    
        def fake_submit(ctx_, symbol, qty, side):
            ctx_.api.orders.append((symbol, qty, side))
            ctx_.api.positions[symbol] = ctx_.api.positions.get(symbol, 0) + qty // 2
            return object()
    
        monkeypatch.setattr(bot_engine, "submit_order", fake_submit)
    
>       bot_engine.initial_rebalance(ctx, ["AAPL"])

tests/test_initial_rebalance.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ctx = namespace(api=<tests.test_initial_rebalance.DummyAPI object at 0x7f44db10b650>, data_fetcher=<tests.test_initial_rebalance.DummyFetcher object at 0x7f44db921450>, rebalance_ids={}, rebalance_attempts={}, rebalance_buys={})
symbols = ['AAPL']

    def initial_rebalance(ctx: BotContext, symbols: list[str]) -> None:
        """Initial portfolio rebalancing."""
    
        if ctx.api is None:
            _log.warning("ctx.api is None - cannot perform initial rebalance")
            return
    
        try:
            datetime.now(UTC).astimezone(PACIFIC)
            acct = ctx.api.get_account()
            float(acct.equity)
    
            cash = float(acct.cash)
            buying_power = float(getattr(acct, "buying_power", cash))
            n = len(symbols)
            if n == 0 or cash <= 0 or buying_power <= 0:
                _log.info("INITIAL_REBALANCE_NO_SYMBOLS_OR_NO_CASH")
                return
        except (
            APIError,
            TimeoutError,
            ConnectionError,
        ) as e:  # AI-AGENT-REF: tighten rebalance account fetch errors
            _log.warning(
                "INITIAL_REBALANCE_ACCOUNT_FAIL",
                extra={"cause": e.__class__.__name__, "detail": str(e)},
            )
            return
    
        # Determine current UTC time
        now_utc = datetime.now(UTC)
        # If it’s between 00:00 and 00:15 UTC, daily bars may not be published yet.
        if now_utc.hour == 0 and now_utc.minute < 15:
            _log.info("INITIAL_REBALANCE: Too early—daily bars not live yet.")
        else:
            # Gather all symbols that have a valid, nonzero close
            valid_symbols = []
            valid_prices = {}
            for symbol in symbols:
                df_daily = ctx.data_fetcher.get_daily_df(ctx, symbol)
                price = get_latest_close(df_daily)
                if price <= 0:
                    # skip symbols with no real close data
                    continue
                valid_symbols.append(symbol)
                valid_prices[symbol] = price
    
            if not valid_symbols:
                log_level = logging.ERROR if in_trading_hours(now_utc) else logging.WARNING
                _log.log(
                    log_level,
                    (
                        "INITIAL_REBALANCE: No valid prices for any symbol—skipping "
                        "rebalance. Possible data outage or market holiday. "
                        "Check data provider/API status."
                    ),
                )
            else:
                # Compute equal weights on valid symbols only
                total_capital = cash
                weight_per = 1.0 / len(valid_symbols)
    
>               positions = {p.symbol: int(p.qty) for p in ctx.api.list_open_positions()}
                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E               AttributeError: 'DummyAPI' object has no attribute 'list_open_positions'

ai_trading/core/bot_engine.py:12988: AttributeError
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.core.bot_engine:bot_engine.py:1913 get_latest_close called with df: DataFrame
DEBUG    ai_trading.core.bot_engine:bot_engine.py:1938 get_latest_close last_valid_close length: 1
DEBUG    ai_trading.core.bot_engine:bot_engine.py:1944 get_latest_close price from iloc[-1]: 100 (type: int64)
DEBUG    ai_trading.core.bot_engine:bot_engine.py:1959 get_latest_close returning: 100.0
______________________________________________ test_soft_budget_elapsed_and_over _______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_soft_budget_elapsed_and_over():
        b = SoftBudget(interval_sec=0.1, fraction=0.5)
        time.sleep(0.02)
        assert b.elapsed_ms() >= 20
        time.sleep(0.05)
>       assert b.over() is True or b.remaining() == 0.0
E       assert (False is True or 0.00957063700479921 == 0.0)
E        +  where False = over()
E        +    where over = <ai_trading.utils.prof.SoftBudget object at 0x7fdb3e60c890>.over
E        +  and   0.00957063700479921 = remaining()
E        +    where remaining = <ai_trading.utils.prof.SoftBudget object at 0x7fdb3e60c890>.remaining

tests/test_prof_budget.py:11: AssertionError
_____________________________________________________ test_regime_changes ______________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_regime_changes():
>       df = pd.read_csv(
            "data/trades.csv",
            engine="python",
            on_bad_lines="skip",
            skip_blank_lines=True,
        )

tests/test_regime_filters.py:6: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026: in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620: in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620: in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880: in _make_engine
    self.handles = get_handle(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path_or_buf = 'data/trades.csv', mode = 'r'

    @doc(compression_options=_shared_docs["compression_options"] % "path_or_buf")
    def get_handle(
        path_or_buf: FilePath | BaseBuffer,
        mode: str,
        *,
        encoding: str | None = None,
        compression: CompressionOptions | None = None,
        memory_map: bool = False,
        is_text: bool = True,
        errors: str | None = None,
        storage_options: StorageOptions | None = None,
    ) -> IOHandles[str] | IOHandles[bytes]:
        """
        Get file handle for given path/buffer and mode.
    
        Parameters
        ----------
        path_or_buf : str or file handle
            File path or object.
        mode : str
            Mode to open path_or_buf with.
        encoding : str or None
            Encoding to use.
        {compression_options}
    
               May be a dict with key 'method' as compression mode
               and other keys as compression options if compression
               mode is 'zip'.
    
               Passing compression options as keys in dict is
               supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.
    
            .. versionchanged:: 1.4.0 Zstandard support.
    
        memory_map : bool, default False
            See parsers._parser_params for more information. Only used by read_csv.
        is_text : bool, default True
            Whether the type of the content passed to the file/buffer is string or
            bytes. This is not the same as `"b" not in mode`. If a string content is
            passed to a binary file/buffer, a wrapper is inserted.
        errors : str, default 'strict'
            Specifies how encoding and decoding errors are to be handled.
            See the errors argument for :func:`open` for a full list
            of options.
        storage_options: StorageOptions = None
            Passed to _get_filepath_or_buffer
    
        Returns the dataclass IOHandles
        """
        # Windows does not default to utf-8. Set to utf-8 for a consistent behavior
        encoding = encoding or "utf-8"
    
        errors = errors or "strict"
    
        # read_csv does not know whether the buffer is opened in binary/text mode
        if _is_binary_mode(path_or_buf, mode) and "b" not in mode:
            mode += "b"
    
        # validate encoding and errors
        codecs.lookup(encoding)
        if isinstance(errors, str):
            codecs.lookup_error(errors)
    
        # open URLs
        ioargs = _get_filepath_or_buffer(
            path_or_buf,
            encoding=encoding,
            compression=compression,
            mode=mode,
            storage_options=storage_options,
        )
    
        handle = ioargs.filepath_or_buffer
        handles: list[BaseBuffer]
    
        # memory mapping needs to be the first step
        # only used for read_csv
        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)
    
        is_path = isinstance(handle, str)
        compression_args = dict(ioargs.compression)
        compression = compression_args.pop("method")
    
        # Only for write methods
        if "r" not in mode and is_path:
            check_parent_directory(str(handle))
    
        if compression:
            if compression != "zstd":
                # compression libraries do not like an explicit text-mode
                ioargs.mode = ioargs.mode.replace("t", "")
            elif compression == "zstd" and "b" not in ioargs.mode:
                # python-zstandard defaults to text mode, but we always expect
                # compression libraries to use binary mode.
                ioargs.mode += "b"
    
            # GZ Compression
            if compression == "gzip":
                if isinstance(handle, str):
                    # error: Incompatible types in assignment (expression has type
                    # "GzipFile", variable has type "Union[str, BaseBuffer]")
                    handle = gzip.GzipFile(  # type: ignore[assignment]
                        filename=handle,
                        mode=ioargs.mode,
                        **compression_args,
                    )
                else:
                    handle = gzip.GzipFile(
                        # No overload variant of "GzipFile" matches argument types
                        # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                        fileobj=handle,  # type: ignore[call-overload]
                        mode=ioargs.mode,
                        **compression_args,
                    )
    
            # BZ Compression
            elif compression == "bz2":
                # Overload of "BZ2File" to handle pickle protocol 5
                # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                handle = get_bz2_file()(  # type: ignore[call-overload]
                    handle,
                    mode=ioargs.mode,
                    **compression_args,
                )
    
            # ZIP Compression
            elif compression == "zip":
                # error: Argument 1 to "_BytesZipFile" has incompatible type
                # "Union[str, BaseBuffer]"; expected "Union[Union[str, PathLike[str]],
                # ReadBuffer[bytes], WriteBuffer[bytes]]"
                handle = _BytesZipFile(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
                if handle.buffer.mode == "r":
                    handles.append(handle)
                    zip_names = handle.buffer.namelist()
                    if len(zip_names) == 1:
                        handle = handle.buffer.open(zip_names.pop())
                    elif not zip_names:
                        raise ValueError(f"Zero files found in ZIP file {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in ZIP file. "
                            f"Only one file per ZIP: {zip_names}"
                        )
    
            # TAR Encoding
            elif compression == "tar":
                compression_args.setdefault("mode", ioargs.mode)
                if isinstance(handle, str):
                    handle = _BytesTarFile(name=handle, **compression_args)
                else:
                    # error: Argument "fileobj" to "_BytesTarFile" has incompatible
                    # type "BaseBuffer"; expected "Union[ReadBuffer[bytes],
                    # WriteBuffer[bytes], None]"
                    handle = _BytesTarFile(
                        fileobj=handle, **compression_args  # type: ignore[arg-type]
                    )
                assert isinstance(handle, _BytesTarFile)
                if "r" in handle.buffer.mode:
                    handles.append(handle)
                    files = handle.buffer.getnames()
                    if len(files) == 1:
                        file = handle.buffer.extractfile(files[0])
                        assert file is not None
                        handle = file
                    elif not files:
                        raise ValueError(f"Zero files found in TAR archive {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in TAR archive. "
                            f"Only one file per TAR archive: {files}"
                        )
    
            # XZ Compression
            elif compression == "xz":
                # error: Argument 1 to "LZMAFile" has incompatible type "Union[str,
                # BaseBuffer]"; expected "Optional[Union[Union[str, bytes, PathLike[str],
                # PathLike[bytes]], IO[bytes]], None]"
                handle = get_lzma_file()(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
    
            # Zstd Compression
            elif compression == "zstd":
                zstd = import_optional_dependency("zstandard")
                if "r" in ioargs.mode:
                    open_args = {"dctx": zstd.ZstdDecompressor(**compression_args)}
                else:
                    open_args = {"cctx": zstd.ZstdCompressor(**compression_args)}
                handle = zstd.open(
                    handle,
                    mode=ioargs.mode,
                    **open_args,
                )
    
            # Unrecognized Compression
            else:
                msg = f"Unrecognized compression type: {compression}"
                raise ValueError(msg)
    
            assert not isinstance(handle, str)
            handles.append(handle)
    
        elif isinstance(handle, str):
            # Check whether the filename is to be opened in binary mode.
            # Binary mode does not support 'encoding' and 'newline'.
            if ioargs.encoding and "b" not in ioargs.mode:
                # Encoding
>               handle = open(
                    handle,
                    ioargs.mode,
                    encoding=ioargs.encoding,
                    errors=errors,
                    newline="",
                )
E               FileNotFoundError: [Errno 2] No such file or directory: 'data/trades.csv'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/common.py:873: FileNotFoundError
______________________________________________ test_position_size_division_error _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_position_size_division_error():
        """Errors during quantity calc return zero."""
        eng = risk_engine.RiskEngine()
>       sig = TradeSignal(symbol='A', side='buy', confidence=1.0, strategy='s')
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_additional.py:43: TypeError
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 13:32:33,848", "level": "ERROR", "name": "ai_trading.risk.engine", "msg": "can_trade called with invalid signal type", "bot_phase": "GENERAL"}
___________________________________________________ test_apply_weight_limits ___________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_apply_weight_limits():
        """Weight adjustments respect caps."""
        eng = risk_engine.RiskEngine()
        eng.asset_limits['equity'] = 0.5
        eng.strategy_limits['s'] = 0.3
        eng.exposure['equity'] = 0.4
>       sig = TradeSignal(symbol='A', side='buy', confidence=1.0, strategy='s', weight=1.0)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_additional.py:54: TypeError
____________________________________________ test_get_daily_bars_resamples_minutes _____________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fa3140c6f50>

    def test_get_daily_bars_resamples_minutes(monkeypatch):
        """When daily bars are empty, minute bars are resampled."""  # AI-AGENT-REF
        empty = pd.DataFrame()
        monkeypatch.setattr(
            bars,
            "_fetch_daily_bars",
            lambda client, symbol, start, end, feed=None: empty,
        )
    
        idx = pd.date_range(
            "2024-01-02 14:30",
            periods=5,
            freq="1min",
            tz="UTC",
        )
        data = pd.DataFrame(
            {
                "open": [1, 2, 3, 4, 5],
                "high": [1, 2, 3, 4, 5],
                "low": [1, 2, 3, 4, 5],
                "close": [1, 2, 3, 4, 5],
                "volume": [10, 10, 10, 10, 10],
            },
            index=idx,
        )
        monkeypatch.setattr(
            bars, "_get_minute_bars", lambda symbol, start_dt, end_dt, feed: data
        )
    
>       out = bars.get_daily_bars(
            "SPY", None, datetime(2024, 1, 2, tzinfo=UTC), datetime(2024, 1, 3, tzinfo=UTC)
        )

tests/test_resample_daily.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

symbol = 'SPY', client = None, start = datetime.datetime(2024, 1, 2, 0, 0, tzinfo=datetime.timezone.utc)
end = datetime.datetime(2024, 1, 3, 0, 0, tzinfo=datetime.timezone.utc), feed = 'iex'

    def get_daily_bars(
        symbol: str,
        client,
        start: datetime,
        end: datetime,
        feed: str | None = None,
    ):
        """Fetch daily bars; fallback to alternate feed then resampled minutes."""  # AI-AGENT-REF
        S = get_settings()
        if feed is None:
            feed = S.alpaca_data_feed
        adjustment = S.alpaca_adjustment
        start = ensure_utc_datetime(start)
        end = ensure_utc_datetime(end)
>       df = _fetch_daily_bars(client, symbol, start, end, feed=feed, adjustment=adjustment)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: test_get_daily_bars_resamples_minutes.<locals>.<lambda>() got an unexpected keyword argument 'adjustment'

ai_trading/data/bars.py:333: TypeError
______________________________________________ test_pydantic_v2_migration_syntax _______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_pydantic_v2_migration_syntax():
        """Test that validate_env.py uses correct Pydantic V2 syntax."""
        validate_env_path = os.path.join(
            os.path.dirname(__file__), '..', 'ai_trading', 'validation', 'validate_env.py'
        )
    
        with open(validate_env_path, 'r') as f:
            content = f.read()
    
        # Verify V2 imports
>       assert 'from pydantic import field_validator, Field' in content
E       assert 'from pydantic import field_validator, Field' in 'from __future__ import annotations\n\nimport os\nfrom typing import Optional\n\nfrom pydantic import BaseModel, Field...}")\n    return val\n\n\n__all__ = [\n    "Settings",\n    "debug_environment",\n    "validate_specific_env_var",\n]\n'

tests/test_pydantic_v2_migration.py:24: AssertionError
____________________________________________________ test_can_trade_limits _____________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_can_trade_limits():
        eng = RiskEngine()
>       sig = make_signal()
              ^^^^^^^^^^^^^

tests/test_risk_engine_module.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def make_signal():
>       return TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_module.py:25: TypeError
_____________________________________________ test_retrain_detect_regime_and_dump ______________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw2/test_retrain_detect_regime_and0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fa3137e3ed0>

    @pytest.mark.smoke
    def test_retrain_detect_regime_and_dump(tmp_path, monkeypatch):
>       retrain = _import_retrain(monkeypatch)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_retrain_smoke.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_retrain_smoke.py:80: in _import_retrain
    return importlib.import_module("retrain")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap>:1204: in _gcd_import
    ???
<frozen importlib._bootstrap>:1176: in _find_and_load
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'retrain', import_ = <function _gcd_import at 0x7fa347c0fd80>

>   ???
E   ModuleNotFoundError: No module named 'retrain'

<frozen importlib._bootstrap>:1140: ModuleNotFoundError
_______________________________________________ test_register_and_position_size ________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db05fc10>

    def test_register_and_position_size(monkeypatch):
        eng = RiskEngine()
>       sig = make_signal()
              ^^^^^^^^^^^^^

tests/test_risk_engine_module.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def make_signal():
>       return TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_module.py:25: TypeError
______________________________________________ test_retry_idempotency_integration ______________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_retry_idempotency_integration():
        """Test that retry mechanism works with idempotency protection."""
>       broker = MockBrokerAPI(fail_count=2)  # Fail 2 times, succeed on 3rd
                 ^^^^^^^^^^^^^
E       NameError: name 'MockBrokerAPI' is not defined

tests/test_retry_idempotency_integration.py:77: NameError
_______________________________________________ test_reconciliation_heals_state ________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_reconciliation_heals_state():
        """Test that reconciliation heals local/broker state after submission."""
>       broker = MockBrokerAPI(fail_count=0)  # No failures
                 ^^^^^^^^^^^^^
E       NameError: name 'MockBrokerAPI' is not defined

tests/test_retry_idempotency_integration.py:122: NameError
________________________________________________ test_hard_stop_blocks_trading _________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_hard_stop_blocks_trading():
        eng = RiskEngine()
        eng.hard_stop = True
>       sig = make_signal()
              ^^^^^^^^^^^^^

tests/test_risk_engine_module.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def make_signal():
>       return TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_module.py:25: TypeError
__________________________________ TestRiskEnginePackage.test_risk_engine_import_from_package __________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_risk_engine_package.TestRiskEnginePackage testMethod=test_risk_engine_import_from_package>

    def test_risk_engine_import_from_package(self):
        """Test that RiskEngine can be imported from ai_trading.risk."""
>       from ai_trading.risk import RiskEngine
E       ImportError: cannot import name 'RiskEngine' from 'ai_trading.risk' (unknown location)

tests/test_risk_engine_package.py:14: ImportError
____________________________________________ test_retry_exhaustion_with_idempotency ____________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_retry_exhaustion_with_idempotency():
        """Test behavior when all retries are exhausted."""
>       broker = MockBrokerAPI(fail_count=5)  # Fail more times than retry limit
                 ^^^^^^^^^^^^^
E       NameError: name 'MockBrokerAPI' is not defined

tests/test_retry_idempotency_integration.py:151: NameError
_________________________________ TestRiskEnginePackage.test_update_exposure_requires_context __________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_risk_engine_package.TestRiskEnginePackage testMethod=test_update_exposure_requires_context>

    def test_update_exposure_requires_context(self):
        """Test that update_exposure requires context parameter."""
>       from ai_trading.risk import RiskEngine
E       ImportError: cannot import name 'RiskEngine' from 'ai_trading.risk' (unknown location)

tests/test_risk_engine_package.py:59: ImportError
________________________________ TestRiskEnginePackage.test_update_exposure_works_with_context _________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_risk_engine_package.TestRiskEnginePackage testMethod=test_update_exposure_works_with_context>

    def test_update_exposure_works_with_context(self):
        """Test that update_exposure works with context parameter."""
>       from ai_trading.risk import RiskEngine
E       ImportError: cannot import name 'RiskEngine' from 'ai_trading.risk' (unknown location)

tests/test_risk_engine_package.py:71: ImportError
_____________________________________________________ test_top_level_shims _____________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_top_level_shims():
        """Test that top-level shim files exist"""
        print("\nTesting top-level shim files")
    
        shims = ["signals.py", "rebalancer.py", "indicators.py"]
        success = True
    
        for shim in shims:
            if os.path.exists(shim):
                print(f"✓ {shim} shim exists")
            else:
                print(f"✗ {shim} shim missing")
                success = False
    
        # Check bot_engine.py has prepare_indicators
>       with open("bot_engine.py", 'r') as f:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
E       FileNotFoundError: [Errno 2] No such file or directory: 'bot_engine.py'

tests/test_runtime_fixes.py:122: FileNotFoundError
----------------------------------------------------- Captured stdout call -----------------------------------------------------

Testing top-level shim files
✗ signals.py shim missing
✗ rebalancer.py shim missing
✗ indicators.py shim missing
___________________________________________________ test_rl_train_and_infer ____________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb3e596b90>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw3/test_rl_train_and_infer0')

    def test_rl_train_and_infer(monkeypatch, tmp_path):
        data = np.random.rand(20, 4)
        class DummyPPO:
            def __init__(self, *_a, **_k): pass
            def learn(self, *a, **k): return None
            def save(self, path): open(path, 'wb').write(b'0')
            def predict(self, state, deterministic=True): return (1, None)
            @classmethod
            def load(cls, path):
                return cls()
        monkeypatch.setattr(train_mod, "PPO", DummyPPO)
        import ai_trading.rl_trading as rl
        monkeypatch.setattr(rl, "PPO", DummyPPO)
        path = tmp_path / "model.zip"
>       train_mod.train(data, path, timesteps=10)
        ^^^^^^^^^^^^^^^
E       AttributeError: module 'ai_trading.rl_trading.train' has no attribute 'train'

tests/test_rl_module.py:21: AttributeError
_____________________________________________ test_run_forever_system_exit_nonzero _____________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fa3137e13d0>

    def test_run_forever_system_exit_nonzero(monkeypatch):
        mod = load_runner(monkeypatch)
        seq = [SystemExit(1), SystemExit(0)]
    
        def side():
            exc = seq.pop(0)
            raise exc
    
        monkeypatch.setattr(mod, "main", side)
>       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
                            ^^^^^^^^
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:53: AttributeError
_________________________________________ test_trading_config_has_required_parameters __________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trading_config_has_required_parameters():
        """Test that TradingConfig includes required trading parameters."""
        from ai_trading.config.management import TradingConfig
    
        cfg = TradingConfig()
    
        # Verify required parameters are present as attributes
        assert hasattr(cfg, 'capital_cap')
        assert hasattr(cfg, 'dollar_risk_limit')
        assert hasattr(cfg, 'max_position_size')
    
        # Verify default values
>       assert cfg.capital_cap == 0.04
E       assert 0.25 == 0.04
E        +  where 0.25 = TradingConfig(daily_loss_limit=0.03, conf_threshold=0.75, kelly_fraction=0.6, slow_period=21, confirmation_count=3, ca...r_hour=10, max_trades_per_day=100, volume_threshold=50000, seed=42, entry_start_offset_min=0, entry_end_offset_min=390).capital_cap

tests/test_runtime_params_hydration.py:25: AssertionError
_____________________________________________________ test_runner_as_main ______________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fa31414c690>

    def test_runner_as_main(monkeypatch):
        mod = load_runner(monkeypatch)
        monkeypatch.setattr(mod, "main", lambda: (_ for _ in ()).throw(SystemExit(0)))
>       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
                            ^^^^^^^^
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:62: AttributeError
________________________________________ test_trading_config_from_env_loads_parameters _________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trading_config_from_env_loads_parameters():
        """Test that TradingConfig.from_env() loads parameters from environment."""
        from ai_trading.config.management import TradingConfig
    
        # Test with environment variables
        env_vars = {
            'CAPITAL_CAP': '0.06',
            'DOLLAR_RISK_LIMIT': '0.08',
            'MAX_POSITION_SIZE': '2.0',
        }
    
        with patch.dict(os.environ, env_vars):
            cfg = TradingConfig.from_env()
    
            assert cfg.capital_cap == 0.06
            assert cfg.dollar_risk_limit == 0.08
>           assert cfg.max_position_size == 2.0
E           AssertionError: assert 8000.0 == 2.0
E            +  where 8000.0 = TradingConfig(daily_loss_limit=0.03, conf_threshold=0.75, kelly_fraction=0.6, slow_period=21, confirmation_count=2, ca...er_day=200, volume_threshold=0.0, seed=42, entry_start_offset_min=0, entry_end_offset_min=390, trading_mode='balanced').max_position_size

tests/test_runtime_params_hydration.py:46: AssertionError
_________________________________________________ test_runner_import_fallback __________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fa3131d1b10>

    def test_runner_import_fallback(monkeypatch):
        monkeypatch.setitem(sys.modules, "bot", None)
        bot_engine_mod = types.ModuleType("bot_engine")
        bot_engine_mod.main = lambda: None
        monkeypatch.setitem(sys.modules, "bot_engine", bot_engine_mod)
        import importlib
        r = importlib.reload(importlib.import_module("runner"))
>       assert r.main is bot_engine_mod.main
E       AssertionError: assert <function main at 0x7fa3140cd1c0> is <function test_runner_import_fallback.<locals>.<lambda> at 0x7fa3140cd440>
E        +  where <function main at 0x7fa3140cd1c0> = <module 'runner' from '/workspace/ai-trading-bot/tests/../ai_trading/runner.py'>.main
E        +  and   <function test_runner_import_fallback.<locals>.<lambda> at 0x7fa3140cd440> = <module 'bot_engine'>.main

tests/test_runner.py:74: AssertionError
__________________________________________ test_build_runtime_hydrates_all_parameters __________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_build_runtime_hydrates_all_parameters():
        """Test that build_runtime creates runtime with all required parameters."""
        from ai_trading.config.management import TradingConfig
        from ai_trading.core.runtime import REQUIRED_PARAM_DEFAULTS, build_runtime
    
        cfg = TradingConfig()
        runtime = build_runtime(cfg)
    
        # Verify runtime has params dict
        assert hasattr(runtime, 'params')
        assert isinstance(runtime.params, dict)
    
        # Verify all required parameters are present
        for key in REQUIRED_PARAM_DEFAULTS.keys():
            assert key in runtime.params, f"Missing required parameter: {key}"
    
        # Verify specific values
>       assert runtime.params['CAPITAL_CAP'] == 0.04
E       assert 0.25 == 0.04

tests/test_runtime_params_hydration.py:75: AssertionError
______________________________________________________ test_runner_starts ______________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_runner_starts():
>       ctx = bot_engine.ctx
              ^^^^^^^^^^^^^^
E       AttributeError: module 'ai_trading.core.bot_engine' has no attribute 'ctx'

tests/test_runner_additional.py:6: AttributeError
____________________________________________ test_build_runtime_uses_config_values _____________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_build_runtime_uses_config_values():
        """Test that build_runtime uses values from TradingConfig."""
        from ai_trading.config.management import TradingConfig
        from ai_trading.core.runtime import build_runtime
    
        # Create config with custom values
>       cfg = TradingConfig(
            capital_cap=0.08,
            dollar_risk_limit=0.10,
            max_position_size=2.5,
            kelly_fraction=0.7,
            buy_threshold=0.8,
            conf_threshold=0.9
        )
E       pydantic_core._pydantic_core.ValidationError: 1 validation error for TradingConfig
E         Value error, capital_cap must be >= dollar_risk_limit [type=value_error, input_value={'capital_cap': 0.08, 'do..., 'conf_threshold': 0.9}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.11/v/value_error

tests/test_runtime_params_hydration.py:86: ValidationError
________________________________________________ test_http_utilities_available _________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_http_utilities_available():
        """Test that HTTP utilities are available."""
        from ai_trading.utils import http
    
        assert hasattr(http, 'get')
        assert hasattr(http, 'post')
        assert hasattr(http, 'put')
>       assert hasattr(http, 'delete')
E       AssertionError: assert False
E        +  where False = hasattr(<module 'ai_trading.utils.http' from '/workspace/ai-trading-bot/ai_trading/utils/http.py'>, 'delete')

tests/test_runtime_paths.py:62: AssertionError
__________________________________________________ test_settings_invalid_risk __________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fa314168050>

    def test_settings_invalid_risk(monkeypatch):
        """Invalid risk values raise ValidationError."""  # AI-AGENT-REF
        monkeypatch.setenv("CAPITAL_CAP", "0")
        monkeypatch.setenv("DOLLAR_RISK_LIMIT", "0")
>       with pytest.raises(ValidationError):
E       Failed: DID NOT RAISE <class 'pydantic_core._pydantic_core.ValidationError'>

tests/test_settings_config.py:30: Failed
______________________________________________ test_prepare_indicators_calculates ______________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

sample_df =          high        low      close      volume
0   10.000000   9.000000   9.500000  100.000000
1   10.172414   9.1724...  14.155172  127.931034
28  14.827586  13.827586  14.327586  128.965517
29  15.000000  14.000000  14.500000  130.000000
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fa31414d450>

    def test_prepare_indicators_calculates(sample_df, monkeypatch):
        """Indicators are added using pandas_ta helpers."""
        import types
        pta = types.ModuleType('pandas_ta')
        pta.vwap = lambda h,l,c,v: pd.Series((h+l+c)/3, index=sample_df.index)
        pta.macd = lambda c, **k: {
            'MACD_12_26_9': c * 0 + 1.0,
            'MACDs_12_26_9': c * 0 + 0.5,
        }
        pta.kc = lambda h,l,c,length=20: pd.DataFrame({0: c*0+1.0,1:c*0+2.0,2:c*0+3.0})
        pta.mfi = lambda h,l,c,v,length=14: pd.Series(c*0+5.0, index=sample_df.index)
        pta.adx = lambda h,l,c,length=14: {
            'ADX_14': pd.Series(c*0+7.0, index=sample_df.index),
            'DMP_14': pd.Series(c*0+1.0, index=sample_df.index),
            'DMN_14': pd.Series(c*0+1.0, index=sample_df.index),
        }
        pta.rsi = lambda *a, **k: pd.Series([50.0]*len(sample_df))
        pta.atr = lambda *a, **k: pd.Series([1.0]*len(sample_df))
        pta.bbands = lambda *a, **k: {
            'BBU_20_2.0': pd.Series([1.0]*len(sample_df)),
            'BBL_20_2.0': pd.Series([1.0]*len(sample_df)),
            'BBP_20_2.0': pd.Series([1.0]*len(sample_df)),
        }
        monkeypatch.setitem(sys.modules, 'pandas_ta', pta)
>       retrain = importlib.import_module('retrain')
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_signals.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap>:1204: in _gcd_import
    ???
<frozen importlib._bootstrap>:1176: in _find_and_load
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'retrain', import_ = <function _gcd_import at 0x7fa347c0fd80>

>   ???
E   ModuleNotFoundError: No module named 'retrain'

<frozen importlib._bootstrap>:1140: ModuleNotFoundError
__________________________ TestShortSellingImplementation.test_current_sell_logic_blocks_no_position ___________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_short_selling_implementation.TestShortSellingImplementation testMethod=test_current_sell_logic_blocks_no_position>

    def test_current_sell_logic_blocks_no_position(self):
        """Test that current logic blocks sell orders when no position exists."""
        # This test documents the current behavior that we need to fix
        from ai_trading.execution.engine import ExecutionEngine
    
        # Create mock context
        mock_ctx = Mock()
        mock_ctx.api = self.mock_api
    
        engine = ExecutionEngine(mock_ctx)
        engine.logger = Mock()
    
        # Mock _available_qty to return 0 (no existing position)
>       with patch.object(engine, '_available_qty', return_value=0):

tests/test_short_selling_implementation.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f44db1433d0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <ai_trading.execution.engine.ExecutionEngine object at 0x7f44db12b050> does not have the attribute '_available_qty'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.execution.engine:emit_once.py:21 Orde…ager initialized
INFO     ai_trading.execution.engine:emit_once.py:21 Exec…gine initialized
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 13:32:33,988", "level": "INFO", "name": "ai_trading.execution.engine", "msg": "Orde…ager initialized", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 13:32:33,989", "level": "INFO", "name": "ai_trading.execution.engine", "msg": "Exec…gine initialized", "bot_phase": "GENERAL"}
______________________________ TestShortSellingImplementation.test_order_status_monitoring_needed ______________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_short_selling_implementation.TestShortSellingImplementation testMethod=test_order_status_monitoring_needed>

    def test_order_status_monitoring_needed(self):
        """Test framework for order status monitoring."""
        from ai_trading.execution.engine import ExecutionEngine
    
        # Create mock context
        mock_ctx = Mock()
        mock_ctx.api = self.mock_api
    
        engine = ExecutionEngine(mock_ctx)
        engine.logger = Mock()
    
        # Test order tracking functionality
        mock_order = Mock()
        mock_order.id = "test_order_123"
        mock_order.status = "new"
    
        # Test _track_order method
>       engine._track_order(mock_order, "AAPL", "buy", 10)
        ^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'ExecutionEngine' object has no attribute '_track_order'

tests/test_short_selling_implementation.py:140: AttributeError
_________________________ TestShortSellingImplementation.test_sell_short_side_should_be_distinguished __________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_short_selling_implementation.TestShortSellingImplementation testMethod=test_sell_short_side_should_be_distinguished>

    def test_sell_short_side_should_be_distinguished(self):
        """Test that sell_short orders bypass position checks and validate short selling."""
        from ai_trading.execution.engine import ExecutionEngine
    
        # Create mock context
        mock_ctx = Mock()
        mock_ctx.api = self.mock_api
    
        engine = ExecutionEngine(mock_ctx)
        engine.logger = Mock()
    
        # Test the key distinction: sell vs sell_short in early validation
        # Mock everything to prevent execution from proceeding too far
>       with patch.object(engine, '_available_qty', return_value=0):

tests/test_short_selling_implementation.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f44ef2fe250>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <ai_trading.execution.engine.ExecutionEngine object at 0x7f44db12b310> does not have the attribute '_available_qty'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError
_______________________________ TestShortSellingImplementation.test_sell_short_validation_exists _______________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_short_selling_implementation.TestShortSellingImplementation testMethod=test_sell_short_validation_exists>

    def test_sell_short_validation_exists(self):
        """Test that _validate_short_selling method exists and works."""
        from ai_trading.execution.engine import ExecutionEngine
    
        # Create mock context
        mock_ctx = Mock()
        mock_ctx.api = self.mock_api
    
        engine = ExecutionEngine(mock_ctx)
        engine.logger = Mock()
    
        # Test that validation method exists
        self.assertTrue(hasattr(engine, '_validate_short_selling'))
    
        # Test validation logic
>       result = engine._validate_short_selling(self.mock_api, "AAPL", 10)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_short_selling_implementation.py:78: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.execution.engine.ExecutionEngine object at 0x7f44db78b290>
symbol = <Mock name='mock.api' id='139933724929296'>, qty = 'AAPL', price = 10

    def _validate_short_selling(self, symbol: str, qty: float, price: float) -> None:
>       from ai_trading.risk.short_selling import validate_short_selling
E       ModuleNotFoundError: No module named 'ai_trading.risk.short_selling'; 'ai_trading.risk' is not a package

ai_trading/execution/engine.py:708: ModuleNotFoundError
______________________________________ TestStalenessGuard.test_staleness_guard_stale_data ______________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f44db7a6dd0>

    def test_staleness_guard_stale_data(self):
        """Test staleness guard with stale data."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Create a mock fetcher that returns stale data
        now = datetime.datetime.now(datetime.timezone.utc)
        stale_timestamp = now - datetime.timedelta(seconds=600)  # 10 minutes old
    
        # Create test dataframe with stale timestamp
        df = pd.DataFrame({
            'open': [100.0],
            'high': [101.0],
            'low': [99.0],
            'close': [100.5],
            'volume': [1000],
            'timestamp': [stale_timestamp]
        })
    
        # Mock fetcher
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(return_value=df)
    
        # Should raise RuntimeError for stale data
        with pytest.raises(RuntimeError, match="Stale data for symbols"):
>           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:70: TypeError
_______________________________________ TestStalenessGuard.test_staleness_guard_no_data ________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f44db7a7610>

    def test_staleness_guard_no_data(self):
        """Test staleness guard with no data."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Mock fetcher that returns None/empty data
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(return_value=None)
    
        # Should raise RuntimeError for no data
        with pytest.raises(RuntimeError, match="Stale data for symbols"):
>           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:82: TypeError
___________________________________ TestStalenessGuard.test_staleness_guard_empty_dataframe ____________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f44db7a7910>

    def test_staleness_guard_empty_dataframe(self):
        """Test staleness guard with empty dataframe."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Mock fetcher that returns empty dataframe
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(return_value=pd.DataFrame())
    
        # Should raise RuntimeError for empty data
        with pytest.raises(RuntimeError, match="Stale data for symbols"):
>           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:94: TypeError
___________________________________ TestStalenessGuard.test_staleness_guard_multiple_symbols ___________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f44db7a7750>

    def test_staleness_guard_multiple_symbols(self):
        """Test staleness guard with multiple symbols."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        now = datetime.datetime.now(datetime.timezone.utc)
    
        # Create mock fetcher that returns different data for different symbols
        def mock_get_minute_df(symbol, start, end):
            if symbol == "AAPL":
                # Fresh data for AAPL
                fresh_ts = now - datetime.timedelta(seconds=30)
                return pd.DataFrame({
                    'timestamp': [fresh_ts],
                    'close': [150.0]
                })
            elif symbol == "MSFT":
                # Stale data for MSFT
                stale_ts = now - datetime.timedelta(seconds=600)
                return pd.DataFrame({
                    'timestamp': [stale_ts],
                    'close': [300.0]
                })
            else:
                # No data for other symbols
                return None
    
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(side_effect=mock_get_minute_df)
    
        # Should raise RuntimeError mentioning the stale symbol
        with pytest.raises(RuntimeError) as exc_info:
>           _ensure_data_fresh(mock_fetcher, ["AAPL", "MSFT", "GOOGL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:127: TypeError
_____________________________________ TestStalenessGuard.test_staleness_guard_utc_logging ______________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f44db7b74d0>

    def test_staleness_guard_utc_logging(self):
        """Test that staleness guard logs UTC timestamps."""
        from unittest.mock import patch
    
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Mock logger to capture log messages
        with patch('ai_trading.core.bot_engine.logger') as mock_logger:
            now = datetime.datetime.now(datetime.timezone.utc)
            fresh_timestamp = now - datetime.timedelta(seconds=30)
    
            df = pd.DataFrame({
                'timestamp': [fresh_timestamp],
                'close': [100.0]
            })
    
            mock_fetcher = Mock()
            mock_fetcher.get_minute_df = Mock(return_value=df)
    
            # Call the function
>           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:153: TypeError
__________________________________ TestStalenessGuard.test_staleness_guard_timezone_handling ___________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f44db7b76d0>

    def test_staleness_guard_timezone_handling(self):
        """Test staleness guard handles timezone-aware and naive timestamps."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        now = datetime.datetime.now(datetime.timezone.utc)
    
        # Test with timezone-naive timestamp (should be treated as UTC)
        naive_timestamp = datetime.datetime.now(datetime.timezone.utc).replace(tzinfo=None) - datetime.timedelta(seconds=30)  # AI-AGENT-REF: Create naive datetime from UTC
        df_naive = pd.DataFrame({
            'timestamp': [naive_timestamp],
            'close': [100.0]
        })
    
        # Test with timezone-aware timestamp
        aware_timestamp = (now - datetime.timedelta(seconds=30)).replace(tzinfo=datetime.timezone.utc)
        df_aware = pd.DataFrame({
            'timestamp': [aware_timestamp],
            'close': [100.0]
        })
    
        mock_fetcher = Mock()
    
        # Test both cases should work without error
        for df in [df_naive, df_aware]:
            mock_fetcher.get_minute_df = Mock(return_value=df)
            try:
                _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
                success = True
            except Exception:
                success = False
>           assert success, "Should handle both timezone-aware and naive timestamps"
E           AssertionError: Should handle both timezone-aware and naive timestamps
E           assert False

tests/test_staleness_guard.py:193: AssertionError
____________________________________ TestStalenessGuard.test_staleness_guard_error_handling ____________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f44db7b44d0>

    def test_staleness_guard_error_handling(self):
        """Test staleness guard handles fetcher errors gracefully."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Mock fetcher that raises an exception
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(side_effect=Exception("Network error"))
    
        # Should raise RuntimeError with error details
        with pytest.raises(RuntimeError) as exc_info:
>           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:205: TypeError
_________________________________________________ test_strategy_generate_base __________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_strategy_generate_base():
        """Base Strategy.generate returns empty list."""
>       assert Strategy().generate(None) == []
               ^^^^^^^^^^
E       TypeError: Can't instantiate abstract class BaseStrategy with abstract methods calculate_position_size, generate_signals

tests/test_strategies_base_extra.py:12: TypeError
____________________________________________________ test_exit_confirmation ____________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

ensure_real_strategy_allocator = <module 'ai_trading.strategy_allocator' from '/workspace/ai-trading-bot/ai_trading/strategy_allocator.py'>

    def test_exit_confirmation(ensure_real_strategy_allocator):
        strategy_allocator = ensure_real_strategy_allocator
        alloc = strategy_allocator.StrategyAllocator()
        # Explicitly set configuration to ensure test isolation
        alloc.config.delta_threshold = 0.0  # Allow repeated signals with same confidence
        alloc.config.signal_confirmation_bars = 2  # Ensure we have expected confirmation bars
    
>       buy = TradeSignal(symbol="A", side="buy", confidence=1.0, strategy="s")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_exit.py:46: TypeError
______________________ TestStrategyAllocatorRegression.test_signal_confirmation_with_zero_min_confidence _______________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f44db640050>

    def test_signal_confirmation_with_zero_min_confidence(self):
        """
        Regression test for the original failing scenario.
    
        The original issue was that with min_confidence=0.0, the second call
        to allocate() was returning an empty list instead of confirmed signals.
        """
        alloc = strategy_allocator.StrategyAllocator()
    
        # Set exact configuration from original failing test
        alloc.config.delta_threshold = 0.0
        alloc.config.signal_confirmation_bars = 2
        alloc.config.min_confidence = 0.0
    
>       sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:30: TypeError
_________________________ TestStrategyAllocatorRegression.test_config_missing_min_confidence_attribute _________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f44db640850>

    def test_config_missing_min_confidence_attribute(self):
        """
        Regression test for missing min_confidence attribute in config.
    
        Previously, if min_confidence was missing from config, it could cause
        AttributeError or incorrect behavior.
        """
        alloc = strategy_allocator.StrategyAllocator()
    
        # Remove min_confidence attribute to simulate missing config
        if hasattr(alloc.config, 'min_confidence'):
            delattr(alloc.config, 'min_confidence')
    
        alloc.config.delta_threshold = 0.0
        alloc.config.signal_confirmation_bars = 2
    
>       sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:58: TypeError
_______________________________ TestStrategyAllocatorRegression.test_config_none_min_confidence ________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f44db640f50>

    def test_config_none_min_confidence(self):
        """
        Regression test for None min_confidence value.
    
        Previously, if min_confidence was set to None, it could cause
        comparison errors or unexpected behavior.
        """
        alloc = strategy_allocator.StrategyAllocator()
    
        alloc.config.min_confidence = None
        alloc.config.delta_threshold = 0.0
        alloc.config.signal_confirmation_bars = 2
    
>       sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:81: TypeError
_________________________ TestStrategyAllocatorRegression.test_signal_confirmation_boundary_conditions _________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f44db6415d0>

    def test_signal_confirmation_boundary_conditions(self):
        """
        Test signal confirmation at various boundary conditions.
    
        Ensures that the confirmation logic works correctly at edge cases
        that could have caused the original failure.
        """
        test_cases = [
            # (min_confidence, signal_confidence, should_confirm)
            (0.0, 0.0, True),    # Zero threshold, zero confidence
            (0.0, 1.0, True),    # Zero threshold, high confidence
            (0.6, 0.6, True),    # Exact threshold match
            (0.8, 0.5, False),   # Below threshold
            (0.5, 0.8, True),    # Above threshold
        ]
    
        for min_conf, sig_conf, should_confirm in test_cases:
            alloc = strategy_allocator.StrategyAllocator()
            alloc.config.delta_threshold = 0.0
            alloc.config.signal_confirmation_bars = 2
            alloc.config.min_confidence = min_conf
    
>           sig = TradeSignal(symbol="AAPL", side="buy", confidence=sig_conf, strategy="s1")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:113: TypeError
___________________________ TestStrategyAllocatorRegression.test_invalid_signal_confidence_handling ____________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f44db6418d0>

    def test_invalid_signal_confidence_handling(self):
        """
        Test handling of invalid signal confidence values.
    
        Ensures that out-of-range confidence values are properly normalized
        and don't cause the confirmation logic to fail.
        """
        alloc = strategy_allocator.StrategyAllocator()
        alloc.config.delta_threshold = 0.0
        alloc.config.signal_confirmation_bars = 2
        alloc.config.min_confidence = 0.0
    
        # Test high confidence (> 1.0)
>       sig_high = TradeSignal(symbol="AAPL", side="buy", confidence=2.0, strategy="s1")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:137: TypeError
___________________________ TestStrategyAllocatorRegression.test_multiple_instances_no_shared_state ____________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f44db642250>

    def test_multiple_instances_no_shared_state(self):
        """
        Test that multiple allocator instances don't share state.
    
        Ensures that the signal confirmation works consistently across
        different allocator instances.
        """
        for i in range(3):
            alloc = strategy_allocator.StrategyAllocator()
            alloc.config.delta_threshold = 0.0
            alloc.config.signal_confirmation_bars = 2
            alloc.config.min_confidence = 0.0
    
>           sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:174: TypeError
________________________________________________________ test_allocator ________________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    @pytest.mark.smoke
    def test_allocator():
        alloc = strategy_allocator.StrategyAllocator()
    
        # Configuration that properly tests signal confirmation workflow
        alloc.config.delta_threshold = 0.0        # Allow repeated signals
        alloc.config.signal_confirmation_bars = 2  # Require 2 bars for proper confirmation testing
        alloc.config.min_confidence = 0.0         # Ensure confidence threshold is met
    
        # AI-AGENT-REF: Add defensive verification to ensure config is applied correctly
        assert alloc.config.signal_confirmation_bars == 2, f"Expected signal_confirmation_bars=2, got {alloc.config.signal_confirmation_bars}"
        assert alloc.config.min_confidence == 0.0, f"Expected min_confidence=0.0, got {alloc.config.min_confidence}"
        assert alloc.config.delta_threshold == 0.0, f"Expected delta_threshold=0.0, got {alloc.config.delta_threshold}"
    
>       sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_smoke.py:30: TypeError
_______________________________________________ test_composite_signal_confidence _______________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fa31414d590>

    def test_composite_signal_confidence(monkeypatch):
        """SignalManager combines weights into final score."""
        from ai_trading.core import bot_engine as bot
        sm = bot.SignalManager()
        monkeypatch.setattr(sm, 'load_signal_weights', lambda: {})
        monkeypatch.setattr(bot, 'load_global_signal_performance', lambda: [])
        monkeypatch.setattr(sm, 'signal_momentum', lambda df, model=None: (1, 0.4, 'momentum'))
        monkeypatch.setattr(sm, 'signal_mean_reversion', lambda df, model=None: (-1, 0.2, 'mean_reversion'))
        monkeypatch.setattr(sm, 'signal_ml', lambda df, model=None, symbol=None: (1, 0.6, 'ml'))
        monkeypatch.setattr(sm, 'signal_sentiment', lambda ctx, ticker, df=None, model=None: (1, 0.1, 'sentiment'))
        monkeypatch.setattr(sm, 'signal_regime', lambda state, df, model=None: (1, 1.0, 'regime'))
        monkeypatch.setattr(sm, 'signal_stochrsi', lambda df, model=None: (1, 0.1, 'stochrsi'))
        monkeypatch.setattr(sm, 'signal_obv', lambda df, model=None: (1, 0.1, 'obv'))
        monkeypatch.setattr(sm, 'signal_vsa', lambda df, model=None: (1, 0.1, 'vsa'))
        df = pd.DataFrame({'close': np.linspace(1,2,60)})
        ctx = types.SimpleNamespace()
        state = types.SimpleNamespace(current_regime='trending', no_signal_events=0)
        model = types.SimpleNamespace(predict=lambda x: [1], predict_proba=lambda x: [[0.4,0.6]], feature_names_in_=['rsi','macd','atr','vwap','sma_50','sma_200'])
>       final, conf, label = sm.evaluate(ctx, state, df, 'TST', model)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_signals.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.core.bot_engine.SignalManager object at 0x7fa3176d6c10>, ctx = namespace()
state = namespace(current_regime='trending', no_signal_events=0)
df =        close
0   1.000000
1   1.016949
2   1.033898
3   1.050847
4   1.067797
5   1.084746
6   1.101695
7   1.118644
8...58
51  1.864407
52  1.881356
53  1.898305
54  1.915254
55  1.932203
56  1.949153
57  1.966102
58  1.983051
59  2.000000
ticker = 'TST'
model = namespace(predict=<function test_composite_signal_confidence.<locals>.<lambda> at 0x7fa314158cc0>, predict_proba=<func...confidence.<locals>.<lambda> at 0x7fa314158d60>, feature_names_in_=['rsi', 'macd', 'atr', 'vwap', 'sma_50', 'sma_200'])

    def evaluate(
        self,
        ctx: BotContext,
        state: BotState,
        df: pd.DataFrame,
        ticker: str,
        model: Any,
    ) -> tuple[int, float, str]:
        """Evaluate all active signals and return a combined decision.
    
        Parameters
        ----------
        ctx : BotContext
            Global bot context with API clients and configuration.
        state : BotState
            Current mutable bot state used by some signals.
        df : pandas.DataFrame
            DataFrame containing indicator columns for ``ticker``.
        ticker : str
            Symbol being evaluated.
        model : Any
            Optional machine learning model for ``signal_ml``.
    
        Returns
        -------
        tuple[int, float, str]
            ``(signal, confidence, label)`` where ``signal`` is -1, 0 or 1.
        """
        signals: list[tuple[int, float, str]] = []
        performance_data = load_global_signal_performance()
    
        # AI-AGENT-REF: Graceful degradation when no meta-learning data exists
        if performance_data is None:
            # For new deployments, allow all signal types with warning
            _log.info(
                "METALEARN_FALLBACK | No trade history - allowing all signals for new deployment"
            )
            allowed_tags = None  # None means allow all tags
        else:
>           allowed_tags = set(performance_data.keys())
                               ^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'list' object has no attribute 'keys'

ai_trading/core/bot_engine.py:4961: AttributeError
_______________________________________________________ test_skip_logic ________________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fa317ae6ad0>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7fa3136f0450>

    def test_skip_logic(monkeypatch, caplog):
        state = bot_engine.BotState()
        state.position_cache = {"MSFT": 10, "TSLA": -10}
        bot_engine.state = state
        caplog.set_level("INFO")
    
        orders = []
        monkeypatch.setattr(bot_engine, "submit_order", lambda ctx, symbol, qty, side: orders.append((symbol, qty, side)))
        monkeypatch.setattr(bot_engine, "is_market_open", lambda: True)
        monkeypatch.setattr(bot_engine, "fetch_minute_df_safe", lambda s: pd.DataFrame({"close": [1]}, index=[pd.Timestamp("2023-01-01")]))
        monkeypatch.setattr(bot_engine, "_safe_trade", lambda *a, **k: None)
>       monkeypatch.setattr(bot_engine.prediction_executor, "submit", lambda fn, s: types.SimpleNamespace(result=lambda: fn(s)))
E       AttributeError: None has no attribute 'submit'

tests/test_skip_logic.py:19: AttributeError
_________________________________________________ test_run_all_trades_overlap __________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb3e597650>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7fdb40646f10>

    def test_run_all_trades_overlap(monkeypatch, caplog):
        state = bot_engine.BotState()
        runtime = bot_engine.get_ctx()
        caplog.set_level("INFO")
    
        monkeypatch.setattr(bot_engine, "is_market_open", lambda: True)
        monkeypatch.setattr(bot_engine, "check_pdt_rule", lambda ctx: False)
        monkeypatch.setattr(bot_engine, "_prepare_run", lambda ctx, st: (0.0, True, []))
        monkeypatch.setattr(bot_engine, "_process_symbols", lambda *a, **k: ([], {}))
        monkeypatch.setattr(bot_engine, "_send_heartbeat", lambda: None)
>       monkeypatch.setattr(runtime.api, "get_account", lambda: types.SimpleNamespace(cash=0, equity=0))
                            ^^^^^^^^^^^

tests/test_run_overlap.py:18: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:5483: in api
    self._ensure_initialized()
ai_trading/core/bot_engine.py:5453: in _ensure_initialized
    self._context.model = _load_required_model()
                          ^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _load_required_model() -> Any:
        """Load ML model from path or module; fail fast if missing."""  # AI-AGENT-REF: strict model loader
        path = os.getenv("AI_TRADER_MODEL_PATH")
        modname = os.getenv("AI_TRADER_MODEL_MODULE")
    
        if path and os.path.isfile(path):
            mdl = joblib.load(path)
            try:
                digest = _sha256_file(path)
            except OSError:  # hashing is best-effort; missing/perm issues shouldn't crash
                digest = "unknown"
            _log.info("MODEL_LOADED", extra={"source": "file", "path": path, "sha": digest})
            return mdl
    
        if modname:
            try:
                mod = importlib.import_module(modname)
            except COMMON_EXC as e:  # noqa: BLE001
                raise RuntimeError(
                    f"Failed to import AI_TRADER_MODEL_MODULE='{modname}': {e}"
                ) from e
            factory = getattr(mod, "get_model", None) or getattr(mod, "Model", None)
            if not factory:
                raise RuntimeError(
                    f"Module '{modname}' missing get_model()/Model() factory."
                )
            mdl = factory() if callable(factory) else factory
            _log.info(
                "MODEL_LOADED",
                extra={
                    "source": "module",
                    "model_module": modname,
                },  # AI-AGENT-REF: avoid reserved key
            )
            return mdl
    
        msg = (
            "Model required but not configured. "
            "Set one of: "
            "AI_TRADER_MODEL_PATH=<abs path to .joblib/.pkl> "
            "or AI_TRADER_MODEL_MODULE=<import.path with get_model()/Model()>."
        )
        _log.error(
            "MODEL_CONFIG_MISSING",
            extra={
                "hint_paths": ["AI_TRADER_MODEL_PATH", "TradingConfig.ml_model_path"],
                "hint_modules": ["AI_TRADER_MODEL_MODULE", "TradingConfig.ml_model_module"],
            },
        )
>       raise RuntimeError(msg)
E       RuntimeError: Model required but not configured. Set one of: AI_TRADER_MODEL_PATH=<abs path to .joblib/.pkl> or AI_TRADER_MODEL_MODULE=<import.path with get_model()/Model()>.

ai_trading/core/bot_engine.py:538: RuntimeError
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.core.bot_engine:bot_engine.py:550 Risk engine: ai_trading.risk.engine.RiskEngine
INFO     ai_trading.logging:performance_allocator.py:115 Perf…ator initialized with 20 day window
INFO     ai_trading.logging:__init__.py:293 Loaded strategies: Mome…tegy
INFO     ai_trading.logging:emit_once.py:21 Draw…aker initialized
ERROR    ai_trading.core.bot_engine:bot_engine.py:531 MODE…SING
_______________________________________________ test_handle_signal_sets_shutdown _______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb40254550>

    def test_handle_signal_sets_shutdown(monkeypatch):
        mod = load_runner(monkeypatch)
        mod._shutdown = False
>       mod._handle_signal(15, None)
        ^^^^^^^^^^^^^^^^^^
E       AttributeError: module 'ai_trading.runner' has no attribute '_handle_signal'

tests/test_runner.py:14: AttributeError
____________________________________________________ test_run_forever_exit _____________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb400b81d0>

    def test_run_forever_exit(monkeypatch):
        mod = load_runner(monkeypatch)
        monkeypatch.setattr(mod, "main", lambda: (_ for _ in ()).throw(SystemExit(0)))
>       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
                            ^^^^^^^^
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:21: AttributeError
_____________________________________________________ test_slippage_limits _____________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_slippage_limits():
>       df = pd.read_csv("logs/slippage.csv")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_slippage.py:5: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026: in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620: in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620: in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880: in _make_engine
    self.handles = get_handle(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path_or_buf = 'logs/slippage.csv', mode = 'r'

    @doc(compression_options=_shared_docs["compression_options"] % "path_or_buf")
    def get_handle(
        path_or_buf: FilePath | BaseBuffer,
        mode: str,
        *,
        encoding: str | None = None,
        compression: CompressionOptions | None = None,
        memory_map: bool = False,
        is_text: bool = True,
        errors: str | None = None,
        storage_options: StorageOptions | None = None,
    ) -> IOHandles[str] | IOHandles[bytes]:
        """
        Get file handle for given path/buffer and mode.
    
        Parameters
        ----------
        path_or_buf : str or file handle
            File path or object.
        mode : str
            Mode to open path_or_buf with.
        encoding : str or None
            Encoding to use.
        {compression_options}
    
               May be a dict with key 'method' as compression mode
               and other keys as compression options if compression
               mode is 'zip'.
    
               Passing compression options as keys in dict is
               supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.
    
            .. versionchanged:: 1.4.0 Zstandard support.
    
        memory_map : bool, default False
            See parsers._parser_params for more information. Only used by read_csv.
        is_text : bool, default True
            Whether the type of the content passed to the file/buffer is string or
            bytes. This is not the same as `"b" not in mode`. If a string content is
            passed to a binary file/buffer, a wrapper is inserted.
        errors : str, default 'strict'
            Specifies how encoding and decoding errors are to be handled.
            See the errors argument for :func:`open` for a full list
            of options.
        storage_options: StorageOptions = None
            Passed to _get_filepath_or_buffer
    
        Returns the dataclass IOHandles
        """
        # Windows does not default to utf-8. Set to utf-8 for a consistent behavior
        encoding = encoding or "utf-8"
    
        errors = errors or "strict"
    
        # read_csv does not know whether the buffer is opened in binary/text mode
        if _is_binary_mode(path_or_buf, mode) and "b" not in mode:
            mode += "b"
    
        # validate encoding and errors
        codecs.lookup(encoding)
        if isinstance(errors, str):
            codecs.lookup_error(errors)
    
        # open URLs
        ioargs = _get_filepath_or_buffer(
            path_or_buf,
            encoding=encoding,
            compression=compression,
            mode=mode,
            storage_options=storage_options,
        )
    
        handle = ioargs.filepath_or_buffer
        handles: list[BaseBuffer]
    
        # memory mapping needs to be the first step
        # only used for read_csv
        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)
    
        is_path = isinstance(handle, str)
        compression_args = dict(ioargs.compression)
        compression = compression_args.pop("method")
    
        # Only for write methods
        if "r" not in mode and is_path:
            check_parent_directory(str(handle))
    
        if compression:
            if compression != "zstd":
                # compression libraries do not like an explicit text-mode
                ioargs.mode = ioargs.mode.replace("t", "")
            elif compression == "zstd" and "b" not in ioargs.mode:
                # python-zstandard defaults to text mode, but we always expect
                # compression libraries to use binary mode.
                ioargs.mode += "b"
    
            # GZ Compression
            if compression == "gzip":
                if isinstance(handle, str):
                    # error: Incompatible types in assignment (expression has type
                    # "GzipFile", variable has type "Union[str, BaseBuffer]")
                    handle = gzip.GzipFile(  # type: ignore[assignment]
                        filename=handle,
                        mode=ioargs.mode,
                        **compression_args,
                    )
                else:
                    handle = gzip.GzipFile(
                        # No overload variant of "GzipFile" matches argument types
                        # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                        fileobj=handle,  # type: ignore[call-overload]
                        mode=ioargs.mode,
                        **compression_args,
                    )
    
            # BZ Compression
            elif compression == "bz2":
                # Overload of "BZ2File" to handle pickle protocol 5
                # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                handle = get_bz2_file()(  # type: ignore[call-overload]
                    handle,
                    mode=ioargs.mode,
                    **compression_args,
                )
    
            # ZIP Compression
            elif compression == "zip":
                # error: Argument 1 to "_BytesZipFile" has incompatible type
                # "Union[str, BaseBuffer]"; expected "Union[Union[str, PathLike[str]],
                # ReadBuffer[bytes], WriteBuffer[bytes]]"
                handle = _BytesZipFile(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
                if handle.buffer.mode == "r":
                    handles.append(handle)
                    zip_names = handle.buffer.namelist()
                    if len(zip_names) == 1:
                        handle = handle.buffer.open(zip_names.pop())
                    elif not zip_names:
                        raise ValueError(f"Zero files found in ZIP file {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in ZIP file. "
                            f"Only one file per ZIP: {zip_names}"
                        )
    
            # TAR Encoding
            elif compression == "tar":
                compression_args.setdefault("mode", ioargs.mode)
                if isinstance(handle, str):
                    handle = _BytesTarFile(name=handle, **compression_args)
                else:
                    # error: Argument "fileobj" to "_BytesTarFile" has incompatible
                    # type "BaseBuffer"; expected "Union[ReadBuffer[bytes],
                    # WriteBuffer[bytes], None]"
                    handle = _BytesTarFile(
                        fileobj=handle, **compression_args  # type: ignore[arg-type]
                    )
                assert isinstance(handle, _BytesTarFile)
                if "r" in handle.buffer.mode:
                    handles.append(handle)
                    files = handle.buffer.getnames()
                    if len(files) == 1:
                        file = handle.buffer.extractfile(files[0])
                        assert file is not None
                        handle = file
                    elif not files:
                        raise ValueError(f"Zero files found in TAR archive {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in TAR archive. "
                            f"Only one file per TAR archive: {files}"
                        )
    
            # XZ Compression
            elif compression == "xz":
                # error: Argument 1 to "LZMAFile" has incompatible type "Union[str,
                # BaseBuffer]"; expected "Optional[Union[Union[str, bytes, PathLike[str],
                # PathLike[bytes]], IO[bytes]], None]"
                handle = get_lzma_file()(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
    
            # Zstd Compression
            elif compression == "zstd":
                zstd = import_optional_dependency("zstandard")
                if "r" in ioargs.mode:
                    open_args = {"dctx": zstd.ZstdDecompressor(**compression_args)}
                else:
                    open_args = {"cctx": zstd.ZstdCompressor(**compression_args)}
                handle = zstd.open(
                    handle,
                    mode=ioargs.mode,
                    **open_args,
                )
    
            # Unrecognized Compression
            else:
                msg = f"Unrecognized compression type: {compression}"
                raise ValueError(msg)
    
            assert not isinstance(handle, str)
            handles.append(handle)
    
        elif isinstance(handle, str):
            # Check whether the filename is to be opened in binary mode.
            # Binary mode does not support 'encoding' and 'newline'.
            if ioargs.encoding and "b" not in ioargs.mode:
                # Encoding
>               handle = open(
                    handle,
                    ioargs.mode,
                    encoding=ioargs.encoding,
                    errors=errors,
                    newline="",
                )
E               FileNotFoundError: [Errno 2] No such file or directory: 'logs/slippage.csv'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/common.py:873: FileNotFoundError
__________________________________________________ test_run_forever_exception __________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb70839b50>

    def test_run_forever_exception(monkeypatch):
        mod = load_runner(monkeypatch)
        monkeypatch.setattr(mod, "main", lambda: (_ for _ in ()).throw(ValueError("bad")))
>       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
                            ^^^^^^^^
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:29: AttributeError
___________________________________ test_fetch_sentiment_graceful_when_requests_unavailable ____________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fa3136e0710>

    def test_fetch_sentiment_graceful_when_requests_unavailable(monkeypatch):
        from ai_trading.core import bot_engine as be
    
        # Force a stub that raises RequestException on .get()
        class _ReqStub:
            class exceptions:
                class RequestException(Exception):
                    pass
    
            def get(self, *a, **k):
                raise self.exceptions.RequestException("no network")
    
        be.requests = _ReqStub()
        be.RequestException = _ReqStub.exceptions.RequestException
    
        # Ensure it won't bail early for missing key
        monkeypatch.setenv("SENTIMENT_API_KEY", "dummy")
        be.SENTIMENT_API_URL = "http://127.0.0.1:1"
        be._SENTIMENT_FAILURES = 0
        out = be.fetch_sentiment("AAPL")
        assert isinstance(out, float) and out == 0.0
>       assert be._SENTIMENT_FAILURES >= 1
E       AssertionError: assert 0 >= 1
E        +  where 0 = <module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'>._SENTIMENT_FAILURES

tests/test_stage1_1.py:35: AssertionError
______________________________________________ test_run_forever_request_exception ______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb40112f90>

    def test_run_forever_request_exception(monkeypatch):
        mod = load_runner(monkeypatch)
        monkeypatch.setattr(mod, "main", lambda: (_ for _ in ()).throw(requests.exceptions.RequestException("boom")))
>       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
                            ^^^^^^^^
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:38: AttributeError
_______________________________________________ test_audit_file_multiple_trades ________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw1/test_audit_file_multiple_trade0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44d8374bd0>

    def test_audit_file_multiple_trades(tmp_path, monkeypatch):
        """Test that multiple trades are appended correctly without duplicate headers."""
        import sys
    
        trade_log_path = tmp_path / "trades.csv"
    
        original_config = sys.modules.get("config")
        sys.modules["config"] = MockConfig()
    
        try:
            if "audit" in sys.modules:
                del sys.modules["audit"]
            import ai_trading.audit as audit  # AI-AGENT-REF: canonical import
    
            # Log first trade
            audit.log_trade("AAPL", 5, "buy", 150.0, "2024-01-01T10:00:00Z", "TEST_MODE")
    
            # Log second trade
            audit.log_trade("MSFT", 3, "sell", 250.0, "2024-01-01T11:00:00Z", "TEST_MODE")
    
            # Verify both trades are in file
>           with open(trade_log_path) as f:
                 ^^^^^^^^^^^^^^^^^^^^
E           FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pytest-of-root/pytest-0/popen-gw1/test_audit_file_multiple_trade0/trades.csv'

tests/test_talib_enforcement.py:153: FileNotFoundError
____________________________________________________ test_nyse_session_dst _____________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_nyse_session_dst():
        # July 15, 2024 (DST)
        s, e = nyse_session_utc(date(2024, 7, 15))
>       assert s.hour == 13 and s.tzinfo == ZoneInfo("UTC")
E       AssertionError: assert (13 == 13 and datetime.timezone.utc == zoneinfo.ZoneInfo(key='UTC'))
E        +  where 13 = datetime.datetime(2024, 7, 15, 13, 30, tzinfo=datetime.timezone.utc).hour
E        +  and   datetime.timezone.utc = datetime.datetime(2024, 7, 15, 13, 30, tzinfo=datetime.timezone.utc).tzinfo
E        +  and   zoneinfo.ZoneInfo(key='UTC') = ZoneInfo('UTC')

tests/test_timeutils.py:10: AssertionError
________________________________________ test_validate_trading_parameters_no_name_error ________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_validate_trading_parameters_no_name_error():
        """Test that validate_trading_parameters function references only defined parameters.
    
        This test parses the bot_engine.py source code and validates that all parameters
        referenced in validate_trading_parameters() are defined before the function call.
        """
    
        # Read the bot_engine.py source code
        src_path = Path(__file__).resolve().parents[1] / 'bot_engine.py'
>       source = src_path.read_text()
                 ^^^^^^^^^^^^^^^^^^^^

tests/test_trading_parameter_validation.py:15: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/pathlib.py:1058: in read_text
    with self.open(mode='r', encoding=encoding, errors=errors) as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = PosixPath('/workspace/ai-trading-bot/bot_engine.py'), mode = 'r', buffering = -1, encoding = 'locale', errors = None
newline = None

    def open(self, mode='r', buffering=-1, encoding=None,
             errors=None, newline=None):
        """
        Open the file pointed by this path and return a file object, as
        the built-in open() function does.
        """
        if "b" not in mode:
            encoding = io.text_encoding(encoding)
>       return io.open(self, mode, buffering, encoding, errors, newline)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       FileNotFoundError: [Errno 2] No such file or directory: '/workspace/ai-trading-bot/bot_engine.py'

/root/.pyenv/versions/3.11.12/lib/python3.11/pathlib.py:1044: FileNotFoundError
_____________________________________________ test_buy_threshold_definition_order ______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_buy_threshold_definition_order():
        """Specific test to ensure BUY_THRESHOLD is defined before validate_trading_parameters call."""
    
        src_path = Path(__file__).resolve().parents[1] / 'bot_engine.py'
>       source = src_path.read_text()
                 ^^^^^^^^^^^^^^^^^^^^

tests/test_trading_parameter_validation.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/pathlib.py:1058: in read_text
    with self.open(mode='r', encoding=encoding, errors=errors) as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = PosixPath('/workspace/ai-trading-bot/bot_engine.py'), mode = 'r', buffering = -1, encoding = 'locale', errors = None
newline = None

    def open(self, mode='r', buffering=-1, encoding=None,
             errors=None, newline=None):
        """
        Open the file pointed by this path and return a file object, as
        the built-in open() function does.
        """
        if "b" not in mode:
            encoding = io.text_encoding(encoding)
>       return io.open(self, mode, buffering, encoding, errors, newline)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       FileNotFoundError: [Errno 2] No such file or directory: '/workspace/ai-trading-bot/bot_engine.py'

/root/.pyenv/versions/3.11.12/lib/python3.11/pathlib.py:1044: FileNotFoundError
________________________________ TestSystemdStartupCompatibility.test_utc_timestamp_no_double_z ________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_systemd_startup.TestSystemdStartupCompatibility object at 0x7fdb40219d10>

        def test_utc_timestamp_no_double_z(self):
            """Test that UTC timestamps don't have double Z suffix."""
            test_script = '''
    from ai_trading.utils.timefmt import utc_now_iso, format_datetime_utc, ensure_utc_format
    from datetime import datetime, timezone
    
    # Test utc_now_iso
    timestamp = utc_now_iso()
    assert timestamp.endswith('Z')
    assert timestamp.count('Z') == 1
    print(f"✓ utc_now_iso: {timestamp}")
    
    # Test format_datetime_utc
    dt = datetime(2024, 1, 1, 12, 0, 0, tzinfo=timezone.utc)
    formatted = format_datetime_utc(dt)
    assert formatted == "2024-01-01T12:00:00Z"
    assert formatted.count('Z') == 1
    print(f"✓ format_datetime_utc: {formatted}")
    
    # Test ensure_utc_format fixes double Z
    fixed = ensure_utc_format("2024-01-01T12:00:00ZZ")
    assert fixed == "2024-01-01T12:00:00Z"
    assert fixed.count('Z') == 1
    print(f"✓ ensure_utc_format: {fixed}")
    
    print("✓ All UTC timestamp functions work correctly")
    '''
    
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(test_script)
                script_path = f.name
    
            try:
>               result = subprocess.run([sys.executable, script_path], capture_output=True, text=True, timeout=30, check=True)  # AI-AGENT-REF: Added timeout and check for security
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_systemd_startup.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 30, check = True
popenargs = (['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmpfk8wimhv.py'],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}
process = <Popen: returncode: 1 args: ['/root/.pyenv/versions/3.11.12/bin/python3.11',...>, stdout = ''
stderr = 'Traceback (most recent call last):\n  File "/tmp/tmpfk8wimhv.py", line 2, in <module>\n    from ai_trading.utils.timefmt import utc_now_iso, format_datetime_utc, ensure_utc_format\nModuleNotFoundError: No module named \'ai_trading\'\n'
retcode = 1

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired as exc:
                process.kill()
                if _mswindows:
                    # Windows accumulates the output in a single blocking
                    # read() call run on child threads, with the timeout
                    # being done in a join() on those threads.  communicate()
                    # _after_ kill() is required to collect that and add it
                    # to the exception.
                    exc.stdout, exc.stderr = process.communicate()
                else:
                    # POSIX _communicate already populated the output so
                    # far into the TimeoutExpired exception.
                    process.wait()
                raise
            except:  # Including KeyboardInterrupt, communicate handled that.
                process.kill()
                # We don't call process.wait() as .__exit__ does that for us.
                raise
            retcode = process.poll()
            if check and retcode:
>               raise CalledProcessError(retcode, process.args,
                                         output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmpfk8wimhv.py']' returned non-zero exit status 1.

/root/.pyenv/versions/3.11.12/lib/python3.11/subprocess.py:571: CalledProcessError
____________________________________ test_trigger_meta_learning_conversion_pure_meta_format ____________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trigger_meta_learning_conversion_pure_meta_format():
        """Test trigger function with pure meta-learning format - should return True immediately."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            # Write meta-learning format data
            f.write("symbol,entry_time,entry_price,exit_time,exit_price,qty,side,strategy,classification,signal_tags,confidence,reward\n")
            f.write("TEST,2025-08-05T23:17:35Z,100.0,2025-08-05T23:18:35Z,105.0,10,buy,test_strategy,test,signal1+signal2,0.8,5.0\n")
            f.write("AAPL,2025-08-05T23:19:35Z,150.0,2025-08-05T23:20:35Z,155.0,5,buy,test_strategy,test,signal3,0.7,25.0\n")
            f.write("MSFT,2025-08-05T23:21:35Z,300.0,2025-08-05T23:22:35Z,295.0,2,sell,test_strategy,test,signal4,0.6,-10.0\n")
            test_file = f.name
    
        try:
            # Set the trade log file path
            MockConfig.TRADE_LOG_FILE = test_file
    
            # Test trade data
            test_trade = {
                'symbol': 'TEST',
                'qty': 10,
                'side': 'buy',
                'price': 100.0,
                'timestamp': '2025-08-05T23:17:35Z',
                'order_id': 'test-001',
                'status': 'filled'
            }
    
            # Verify quality report shows pure meta format
            quality_report = meta_learning.validate_trade_data_quality(test_file)
            assert quality_report['mixed_format_detected'] is False
            assert quality_report['audit_format_rows'] == 0
            assert quality_report['meta_format_rows'] > 0
    
            # Test the trigger function - should return True immediately (no conversion needed)
>           result = meta_learning.trigger_meta_learning_conversion(test_trade)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_trigger_meta_learning_conversion.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -> bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
>           if config is not None:
               ^^^^^^
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:34,717", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "META…GGER | symbol=TEST", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.meta_learning:meta_learning.py:312 Invalid price in meta format row: could not convert string to float: 'entry_price'
INFO     ai_trading.meta_learning:meta_learning.py:1806 META…GGER | symbol=TEST
__________________________________ TestSystemdStartupCompatibility.test_lazy_import_behavior ___________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_systemd_startup.TestSystemdStartupCompatibility object at 0x7fdb4021a410>

        def test_lazy_import_behavior(self):
            """Test that lazy imports work correctly."""
            test_script = '''
    import os
    
    # Clear credentials
    for key in ["ALPACA_API_KEY", "APCA_API_KEY_ID", "ALPACA_SECRET_KEY", "APCA_API_SECRET_KEY"]:
        os.environ.pop(key, None)
    
    # Import runner (should work without credentials)
    from ai_trading import runner
    
    # Verify lazy loading variables exist
    assert hasattr(runner, '_load_engine')
    assert hasattr(runner, '_bot_engine')
    assert hasattr(runner, '_bot_state_class')
    
    # Verify initial state is None (not loaded)
    assert runner._bot_engine is None
    assert runner._bot_state_class is None
    
    print("✓ Lazy import mechanism working correctly")
    '''
    
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(test_script)
                script_path = f.name
    
            try:
>               result = subprocess.run([sys.executable, script_path], capture_output=True, text=True, timeout=30, check=True)  # AI-AGENT-REF: Added timeout and check for security
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_systemd_startup.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 30, check = True
popenargs = (['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmpfw0t7f65.py'],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}
process = <Popen: returncode: 1 args: ['/root/.pyenv/versions/3.11.12/bin/python3.11',...>, stdout = ''
stderr = 'Traceback (most recent call last):\n  File "/tmp/tmpfw0t7f65.py", line 9, in <module>\n    from ai_trading import runner\nModuleNotFoundError: No module named \'ai_trading\'\n'
retcode = 1

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired as exc:
                process.kill()
                if _mswindows:
                    # Windows accumulates the output in a single blocking
                    # read() call run on child threads, with the timeout
                    # being done in a join() on those threads.  communicate()
                    # _after_ kill() is required to collect that and add it
                    # to the exception.
                    exc.stdout, exc.stderr = process.communicate()
                else:
                    # POSIX _communicate already populated the output so
                    # far into the TimeoutExpired exception.
                    process.wait()
                raise
            except:  # Including KeyboardInterrupt, communicate handled that.
                process.kill()
                # We don't call process.wait() as .__exit__ does that for us.
                raise
            retcode = process.poll()
            if check and retcode:
>               raise CalledProcessError(retcode, process.args,
                                         output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmpfw0t7f65.py']' returned non-zero exit status 1.

/root/.pyenv/versions/3.11.12/lib/python3.11/subprocess.py:571: CalledProcessError
________________________________________________ test_talib_import_enforcement _________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_talib_import_enforcement():
        """Test that TA library import gracefully handles missing dependency."""
        # Read the imports file to test the TA library section
        imports_file = (
            Path(__file__).parent.parent / "ai_trading" / "strategies" / "imports.py"
        )
    
        with open(imports_file) as f:
            content = f.read()
    
        # Find the TA library section
        lines = content.split("\n")
        ta_start = None
        ta_end = None
    
        for i, line in enumerate(lines):
            if "# TA library for optimized technical analysis" in line:
                ta_start = i
            elif ta_start is not None and "ta = MockTa()" in line:
                ta_end = i + 1
                break
    
        assert ta_start is not None, "Could not find TA library section"
>       assert ta_end is not None, "Could not find end of TA library section"
E       AssertionError: Could not find end of TA library section
E       assert None is not None

tests/test_talib_enforcement.py:34: AssertionError
___________________________________________ test_audit_file_creation_and_permissions ___________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw3/test_audit_file_creation_and_p0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb6eab6c90>

    def test_audit_file_creation_and_permissions(tmp_path, monkeypatch):
        """Test that audit.py creates trade log file with proper permissions."""
        import sys
    
        # Mock config to use temporary path
        trade_log_path = tmp_path / "data" / "trades.csv"
    
        # Create mock config module
        # Temporarily replace config module
        original_config = sys.modules.get("config")
        sys.modules["config"] = MockConfig()
    
        try:
            # Import audit after mocking config
            if "audit" in sys.modules:
                del sys.modules["audit"]
            import ai_trading.audit as audit  # AI-AGENT-REF: canonical import
    
            # Ensure the file doesn't exist initially
            assert not trade_log_path.exists()
            assert not trade_log_path.parent.exists()
    
            # Call log_trade which should create the directory and file
>           audit.log_trade(
                symbol="TEST",
                qty=10,
                side="buy",
                fill_price=100.0,
                timestamp="2024-01-01T10:00:00Z",
                extra_info="TEST_MODE",
                exposure=0.1,
            )
E           TypeError: log_trade() got an unexpected keyword argument 'exposure'

tests/test_talib_enforcement.py:81: TypeError
___________________________________ test_trigger_meta_learning_conversion_pure_audit_format ____________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trigger_meta_learning_conversion_pure_audit_format():
        """Test trigger function with pure audit format - should attempt conversion."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            # Write audit format data
            f.write("order_id,timestamp,symbol,side,qty,price,mode,status\n")
            f.write("123e4567-e89b-12d3-a456-426614174000,2025-08-05T23:17:35Z,TEST,buy,10,100.0,live,filled\n")
            f.write("234e5678-e89b-12d3-a456-426614174001,2025-08-05T23:18:35Z,TEST,sell,10,105.0,live,filled\n")
            f.write("345e6789-e89b-12d3-a456-426614174002,2025-08-05T23:19:35Z,AAPL,buy,5,150.0,live,filled\n")
            test_file = f.name
    
        try:
            # Set the trade log file path
            MockConfig.TRADE_LOG_FILE = test_file
    
            # Test trade data
            test_trade = {
                'symbol': 'TEST',
                'qty': 10,
                'side': 'buy',
                'price': 100.0,
                'timestamp': '2025-08-05T23:17:35Z',
                'order_id': 'test-001',
                'status': 'filled'
            }
    
            # Verify quality report shows pure audit format
            quality_report = meta_learning.validate_trade_data_quality(test_file)
            assert quality_report['mixed_format_detected'] is False
            assert quality_report['audit_format_rows'] > 0
            assert quality_report['meta_format_rows'] == 0
    
            # Test the trigger function - should attempt conversion and return True if successful
>           result = meta_learning.trigger_meta_learning_conversion(test_trade)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_trigger_meta_learning_conversion.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -> bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
>           if config is not None:
               ^^^^^^
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:34,859", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "META…GGER | symbol=TEST", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.meta_learning:meta_learning.py:1806 META…GGER | symbol=TEST
______________________________________ test_trigger_meta_learning_conversion_mixed_format ______________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trigger_meta_learning_conversion_mixed_format():
        """Test trigger function with mixed format - should attempt conversion."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            # Write mixed format data (meta headers with audit data)
            f.write("symbol,entry_time,entry_price,exit_time,exit_price,qty,side,strategy,classification,signal_tags,confidence,reward\n")
            f.write("123e4567-e89b-12d3-a456-426614174000,2025-08-05T23:17:35Z,TEST,buy,10,100.0,live,filled\n")
            f.write("234e5678-e89b-12d3-a456-426614174001,2025-08-05T23:18:35Z,TEST,sell,10,105.0,live,filled\n")
            test_file = f.name
    
        try:
            # Set the trade log file path
            MockConfig.TRADE_LOG_FILE = test_file
    
            # Test trade data
            test_trade = {
                'symbol': 'TEST',
                'qty': 10,
                'side': 'buy',
                'price': 100.0,
                'timestamp': '2025-08-05T23:17:35Z',
                'order_id': 'test-001',
                'status': 'filled'
            }
    
            # Verify quality report shows mixed format
            quality_report = meta_learning.validate_trade_data_quality(test_file)
            assert quality_report['mixed_format_detected'] is True
    
            # Test the trigger function - should attempt conversion and return True if successful
>           result = meta_learning.trigger_meta_learning_conversion(test_trade)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_trigger_meta_learning_conversion.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -> bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
>           if config is not None:
               ^^^^^^
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:34,892", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "META…GGER | symbol=TEST", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.meta_learning:meta_learning.py:312 Invalid price in meta format row: could not convert string to float: 'entry_price'
INFO     ai_trading.meta_learning:meta_learning.py:1806 META…GGER | symbol=TEST
________________________________ test_trigger_meta_learning_conversion_problem_statement_exact _________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trigger_meta_learning_conversion_problem_statement_exact():
        """Test the exact scenario from the problem statement."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            # Create exactly the scenario: mixed_format_detected=False, audit_format_rows=0, meta_format_rows=4
            f.write("symbol,entry_time,entry_price,exit_time,exit_price,qty,side,strategy,classification,signal_tags,confidence,reward\n")
            f.write("TEST,2025-08-05T23:17:35Z,100.0,2025-08-05T23:18:35Z,105.0,10,buy,test_strategy,test,signal1+signal2,0.8,5.0\n")
            f.write("AAPL,2025-08-05T23:19:35Z,150.0,2025-08-05T23:20:35Z,155.0,5,buy,test_strategy,test,signal3,0.7,25.0\n")
            f.write("MSFT,2025-08-05T23:21:35Z,300.0,2025-08-05T23:22:35Z,295.0,2,sell,test_strategy,test,signal4,0.6,-10.0\n")
            f.write("GOOGL,2025-08-05T23:23:35Z,2500.0,2025-08-05T23:24:35Z,2505.0,1,buy,test_strategy,test,signal5,0.9,5.0\n")
            test_file = f.name
    
        try:
            MockConfig.TRADE_LOG_FILE = test_file
    
            test_trade = {
                'symbol': 'TEST',
                'qty': 10,
                'side': 'buy',
                'price': 100.0,
                'timestamp': '2025-08-05T23:17:35Z',
                'order_id': 'test-001',
                'status': 'filled'
            }
    
            # Verify we have the exact scenario from problem statement
            quality_report = meta_learning.validate_trade_data_quality(test_file)
            assert quality_report['mixed_format_detected'] is False
            assert quality_report['audit_format_rows'] == 0
            assert quality_report['meta_format_rows'] > 0  # Should be 5 (4 data + 1 header)
    
            # This should return True immediately (no conversion needed)
>           result = meta_learning.trigger_meta_learning_conversion(test_trade)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_trigger_meta_learning_conversion.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -> bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
>           if config is not None:
               ^^^^^^
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.meta_learning:meta_learning.py:312 Invalid price in meta format row: could not convert string to float: 'entry_price'
INFO     ai_trading.meta_learning:meta_learning.py:1806 META…GGER | symbol=TEST
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 13:32:34,886", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "META…GGER | symbol=TEST", "bot_phase": "GENERAL"}
______________________________________ test_trigger_meta_learning_conversion_missing_file ______________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trigger_meta_learning_conversion_missing_file():
        """Test trigger function with missing file - should return False."""
        # Set a non-existent file path
        MockConfig.TRADE_LOG_FILE = '/tmp/non_existent_file.csv'
    
        test_trade = {
            'symbol': 'TEST',
            'qty': 10,
            'side': 'buy',
            'price': 100.0,
            'timestamp': '2025-08-05T23:17:35Z',
            'order_id': 'test-001',
            'status': 'filled'
        }
    
        # Test the trigger function - should return False for missing file
>       result = meta_learning.trigger_meta_learning_conversion(test_trade)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_trigger_meta_learning_conversion.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -> bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
>           if config is not None:
               ^^^^^^
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:32:34,927", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "META…GGER | symbol=TEST", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.meta_learning:meta_learning.py:1806 META…GGER | symbol=TEST
_________________________________________________ test_universe_fetch_pooling __________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db267fd0>

    def test_universe_fetch_pooling(monkeypatch):
        calls = {}
    
        def fake_map_get(urls, timeout=None, headers=None):
            calls['count'] = calls.get('count', 0) + 1
            calls['len'] = len(urls)
            return [((u, 200, f"BODY{i}".encode()), None) for i, u in enumerate(urls)]
    
        monkeypatch.setattr(http, "map_get", fake_map_get)
>       monkeypatch.setattr(data_fetcher, "_parse_bars", lambda s, c, b: b.decode())
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute '_parse_bars'

tests/test_universe_fetch_pooling.py:14: AttributeError
_____________________________________________ test_yfinance_auto_adjust_and_cache ______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db205f10>

    def test_yfinance_auto_adjust_and_cache(monkeypatch):
        calls = {"auto_adjust": None, "cache_called": False}
    
        fake = types.SimpleNamespace()
    
        def set_tz_cache_location(path):  # AI-AGENT-REF: track tz cache invocation
            calls["cache_called"] = True
    
        def download(*args, auto_adjust=None, **kwargs):  # AI-AGENT-REF: capture auto_adjust
            calls["auto_adjust"] = auto_adjust
            import pandas as pd
    
            return pd.DataFrame(
                {"Open": [1.0], "High": [1.0], "Low": [1.0], "Close": [1.0], "Volume": [100]},
                index=pd.date_range(datetime(2025, 8, 1, tzinfo=UTC), periods=1, name="Date"),
            )
    
        fake.set_tz_cache_location = set_tz_cache_location
        fake.download = download
        monkeypatch.setitem(sys.modules, "yfinance", fake)
    
>       from ai_trading.data_fetcher import _yahoo_get_bars
E       ImportError: cannot import name '_yahoo_get_bars' from 'ai_trading.data_fetcher' (unknown location)

tests/test_yf_auto_adjust_and_cache.py:29: ImportError
______________________________________ TestStalenessGuard.test_staleness_guard_fresh_data ______________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7fa317778150>

    def test_staleness_guard_fresh_data(self):
        """Test staleness guard with fresh data."""
        # Import the function we're testing
>       from ai_trading.core.bot_engine import _ensure_data_fresh

tests/test_staleness_guard.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    # ruff: noqa
    # fmt: off
    from __future__ import annotations
    
    import importlib
    import importlib.util
    import os
    import sys
    from typing import Dict, Iterable
    from zoneinfo import ZoneInfo  # AI-AGENT-REF: timezone conversions
    
    from json import JSONDecodeError
    # Safe 'requests' import with stub + RequestException binding
    try:  # pragma: no cover
        import requests  # type: ignore
        RequestException = requests.exceptions.RequestException  # type: ignore[attr-defined]
    except ImportError:  # pragma: no cover  # AI-AGENT-REF: narrow import handling
        class RequestException(Exception):
            pass
    
        # Minimal stub so runtime calls fail gracefully into COMMON_EXC
        class _RequestsStub:
            class exceptions:
                RequestException = RequestException
    
            def get(self, *a, **k):
                raise RequestException("requests not installed")
    
        requests = _RequestsStub()  # type: ignore
    
    from threading import Lock
    import warnings
    
    from ai_trading.data_fetcher import (
        get_bars,
        get_bars_batch,
        get_minute_df,
    )
>   from ai_trading.market.calendars import last_market_session
E   ImportError: cannot import name 'last_market_session' from 'ai_trading.market.calendars' (unknown location)

ai_trading/core/bot_engine.py:39: ImportError
____________________________________________ test_submit_order_successful_execution ____________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_submit_order_successful_execution():
        """Test that submit_order works correctly when properly initialized."""
        # Import after setting environment
        from unittest.mock import Mock
    
        from ai_trading.core import bot_engine
>       from ai_trading.core.bot_engine import BotContext, submit_order

tests/test_submit_order_fix.py:72: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    # ruff: noqa
    # fmt: off
    from __future__ import annotations
    
    import importlib
    import importlib.util
    import os
    import sys
    from typing import Dict, Iterable
    from zoneinfo import ZoneInfo  # AI-AGENT-REF: timezone conversions
    
    from json import JSONDecodeError
    # Safe 'requests' import with stub + RequestException binding
    try:  # pragma: no cover
        import requests  # type: ignore
        RequestException = requests.exceptions.RequestException  # type: ignore[attr-defined]
    except ImportError:  # pragma: no cover  # AI-AGENT-REF: narrow import handling
        class RequestException(Exception):
            pass
    
        # Minimal stub so runtime calls fail gracefully into COMMON_EXC
        class _RequestsStub:
            class exceptions:
                RequestException = RequestException
    
            def get(self, *a, **k):
                raise RequestException("requests not installed")
    
        requests = _RequestsStub()  # type: ignore
    
    from threading import Lock
    import warnings
    
    from ai_trading.data_fetcher import (
        get_bars,
        get_bars_batch,
        get_minute_df,
    )
>   from ai_trading.market.calendars import last_market_session
E   ImportError: cannot import name 'last_market_session' from 'ai_trading.market.calendars' (unknown location)

ai_trading/core/bot_engine.py:39: ImportError
________________________________________ test_submit_order_execution_error_propagation _________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_submit_order_execution_error_propagation():
        """Test that submit_order properly propagates execution errors."""
        # Import after setting environment
        from unittest.mock import Mock
    
        from ai_trading.core import bot_engine
>       from ai_trading.core.bot_engine import BotContext, submit_order

tests/test_submit_order_fix.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    # ruff: noqa
    # fmt: off
    from __future__ import annotations
    
    import importlib
    import importlib.util
    import os
    import sys
    from typing import Dict, Iterable
    from zoneinfo import ZoneInfo  # AI-AGENT-REF: timezone conversions
    
    from json import JSONDecodeError
    # Safe 'requests' import with stub + RequestException binding
    try:  # pragma: no cover
        import requests  # type: ignore
        RequestException = requests.exceptions.RequestException  # type: ignore[attr-defined]
    except ImportError:  # pragma: no cover  # AI-AGENT-REF: narrow import handling
        class RequestException(Exception):
            pass
    
        # Minimal stub so runtime calls fail gracefully into COMMON_EXC
        class _RequestsStub:
            class exceptions:
                RequestException = RequestException
    
            def get(self, *a, **k):
                raise RequestException("requests not installed")
    
        requests = _RequestsStub()  # type: ignore
    
    from threading import Lock
    import warnings
    
    from ai_trading.data_fetcher import (
        get_bars,
        get_bars_batch,
        get_minute_df,
    )
>   from ai_trading.market.calendars import last_market_session
E   ImportError: cannot import name 'last_market_session' from 'ai_trading.market.calendars' (unknown location)

ai_trading/core/bot_engine.py:39: ImportError
___________________________ TestSystemdStartupCompatibility.test_import_no_crash_without_credentials ___________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_systemd_startup.TestSystemdStartupCompatibility object at 0x7fa3176f3150>

        def test_import_no_crash_without_credentials(self):
            """Test that imports don't crash without credentials."""
            # Create a test script that imports key modules
            test_script = '''
    import os
    import sys
    
    # Clear all credential environment variables
    for key in ["ALPACA_API_KEY", "APCA_API_KEY_ID", "ALPACA_SECRET_KEY", "APCA_API_SECRET_KEY"]:
        os.environ.pop(key, None)
    
    try:
        # Test importing key modules without credentials
        from ai_trading.config.management import _resolve_alpaca_env
        print("✓ Config management imported")
    
        from ai_trading import runner
        print("✓ Runner imported")
    
        from ai_trading.utils.timefmt import utc_now_iso
        print("✓ Time utilities imported")
    
        # Test that credential resolution works
        api_key, secret_key, base_url = _resolve_alpaca_env()
        assert api_key is None
        assert secret_key is None
        assert base_url == "https://paper-api.alpaca.markets"
        print("✓ Credential resolution works with missing creds")
    
        # Test UTC timestamp doesn't have double Z
        timestamp = utc_now_iso()
        assert timestamp.endswith('Z')
        assert timestamp.count('Z') == 1
        print("✓ UTC timestamp has single Z")
    
        print("SUCCESS: No import-time crashes!")
    
    except SystemExit as e:
        print(f"FAIL: SystemExit called: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"FAIL: Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    '''
    
            # Write test script to temporary file
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(test_script)
                script_path = f.name
    
            try:
                # Run the test script in a clean subprocess
>               result = subprocess.run(
                    [sys.executable, script_path],
                    capture_output=True,
                    text=True,
                    timeout=30,
                    check=True
                )

tests/test_systemd_startup.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 30, check = True
popenargs = (['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmpd93dzpqg.py'],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}
process = <Popen: returncode: 1 args: ['/root/.pyenv/versions/3.11.12/bin/python3.11',...>
stdout = "FAIL: Unexpected error: No module named 'ai_trading'\n"
stderr = 'Traceback (most recent call last):\n  File "/tmp/tmpd93dzpqg.py", line 11, in <module>\n    from ai_trading.config.management import _resolve_alpaca_env\nModuleNotFoundError: No module named \'ai_trading\'\n'
retcode = 1

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired as exc:
                process.kill()
                if _mswindows:
                    # Windows accumulates the output in a single blocking
                    # read() call run on child threads, with the timeout
                    # being done in a join() on those threads.  communicate()
                    # _after_ kill() is required to collect that and add it
                    # to the exception.
                    exc.stdout, exc.stderr = process.communicate()
                else:
                    # POSIX _communicate already populated the output so
                    # far into the TimeoutExpired exception.
                    process.wait()
                raise
            except:  # Including KeyboardInterrupt, communicate handled that.
                process.kill()
                # We don't call process.wait() as .__exit__ does that for us.
                raise
            retcode = process.poll()
            if check and retcode:
>               raise CalledProcessError(retcode, process.args,
                                         output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmpd93dzpqg.py']' returned non-zero exit status 1.

/root/.pyenv/versions/3.11.12/lib/python3.11/subprocess.py:571: CalledProcessError
__________________________ TestSystemdStartupCompatibility.test_dual_credential_schema_with_env_file ___________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_systemd_startup.TestSystemdStartupCompatibility object at 0x7fa3176f0450>

        def test_dual_credential_schema_with_env_file(self):
            """Test that both credential schemas work with .env files."""
            # Test ALPACA_* schema
            alpaca_env_content = """
    ALPACA_API_KEY=test_alpaca_key_from_env
    ALPACA_SECRET_KEY=test_alpaca_secret_from_env
    ALPACA_BASE_URL=https://paper-api.alpaca.markets
    """
    
            with tempfile.NamedTemporaryFile(mode='w', suffix='.env', delete=False) as f:
                f.write(alpaca_env_content)
                alpaca_env_path = f.name
    
            # Test APCA_* schema
            apca_env_content = """
    APCA_API_KEY_ID=test_apca_key_from_env
    APCA_API_SECRET_KEY=test_apca_secret_from_env
    APCA_API_BASE_URL=https://api.alpaca.markets
    """
    
            with tempfile.NamedTemporaryFile(mode='w', suffix='.env', delete=False) as f:
                f.write(apca_env_content)
                apca_env_path = f.name
    
            try:
                # Test ALPACA schema
                test_script = f'''
    import os
    from dotenv import load_dotenv
    load_dotenv("{alpaca_env_path}", override=True)
    
    from ai_trading.config.management import _resolve_alpaca_env
    api_key, secret_key, base_url = _resolve_alpaca_env()
    
    assert api_key == "test_alpaca_key_from_env"
    assert secret_key == "test_alpaca_secret_from_env"
    assert base_url == "https://paper-api.alpaca.markets"
    print("✓ ALPACA schema with .env file works")
    '''
    
                with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                    f.write(test_script)
                    script_path = f.name
    
>               result = subprocess.run([sys.executable, script_path], capture_output=True, text=True, timeout=30, check=True)  # AI-AGENT-REF: Added timeout and check for security
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_systemd_startup.py:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 30, check = True
popenargs = (['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp04usct6p.py'],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}
process = <Popen: returncode: 1 args: ['/root/.pyenv/versions/3.11.12/bin/python3.11',...>, stdout = ''
stderr = 'Traceback (most recent call last):\n  File "/tmp/tmp04usct6p.py", line 6, in <module>\n    from ai_trading.config.management import _resolve_alpaca_env\nModuleNotFoundError: No module named \'ai_trading\'\n'
retcode = 1

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired as exc:
                process.kill()
                if _mswindows:
                    # Windows accumulates the output in a single blocking
                    # read() call run on child threads, with the timeout
                    # being done in a join() on those threads.  communicate()
                    # _after_ kill() is required to collect that and add it
                    # to the exception.
                    exc.stdout, exc.stderr = process.communicate()
                else:
                    # POSIX _communicate already populated the output so
                    # far into the TimeoutExpired exception.
                    process.wait()
                raise
            except:  # Including KeyboardInterrupt, communicate handled that.
                process.kill()
                # We don't call process.wait() as .__exit__ does that for us.
                raise
            retcode = process.poll()
            if check and retcode:
>               raise CalledProcessError(retcode, process.args,
                                         output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp04usct6p.py']' returned non-zero exit status 1.

/root/.pyenv/versions/3.11.12/lib/python3.11/subprocess.py:571: CalledProcessError
__________________________________________ test_submit_order_uses_client_and_returns ___________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

dummy_alpaca_client = <tests.conftest.dummy_alpaca_client.<locals>.DummyClient object at 0x7f44d836d990>
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f44db284fd0>

    @pytest.mark.unit
    def test_submit_order_uses_client_and_returns(dummy_alpaca_client, monkeypatch):
        submit = getattr(alpaca_api, "submit_order", None)
        if submit is None:
            pytest.skip("submit_order not available")
    
        # Mock the DRY_RUN setting to False so the actual client is used
>       monkeypatch.setattr(alpaca_api, "DRY_RUN", False)
E       AttributeError: <module 'alpaca_api' from '/workspace/ai-trading-bot/tests/../ai_trading/alpaca_api.py'> has no attribute 'DRY_RUN'

tests/unit/test_alpaca_api.py:22: AttributeError
_________________________________________ test_pending_orders_lock_exists_and_is_lock __________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    @pytest.mark.unit
    def test_pending_orders_lock_exists_and_is_lock():
>       assert hasattr(alpaca_api, "_pending_orders_lock")
E       AssertionError: assert False
E        +  where False = hasattr(alpaca_api, '_pending_orders_lock')

tests/unit/test_alpaca_api.py:7: AssertionError
___________________________________ test_pre_trade_health_resolves_min_rows_without_ctx_attr ___________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

dummy_data_fetcher = <tests.conftest.dummy_data_fetcher.<locals>.DF object at 0x7fa3104c8090>

    @pytest.mark.unit
    def test_pre_trade_health_resolves_min_rows_without_ctx_attr(dummy_data_fetcher):
        """Test that pre_trade_health_check handles missing ctx.min_rows gracefully."""
        # Try to import the function, but skip if not available
>       from ai_trading.core.bot_engine import pre_trade_health_check

tests/unit/test_health_check.py:10: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    # ruff: noqa
    # fmt: off
    from __future__ import annotations
    
    import importlib
    import importlib.util
    import os
    import sys
    from typing import Dict, Iterable
    from zoneinfo import ZoneInfo  # AI-AGENT-REF: timezone conversions
    
    from json import JSONDecodeError
    # Safe 'requests' import with stub + RequestException binding
    try:  # pragma: no cover
        import requests  # type: ignore
        RequestException = requests.exceptions.RequestException  # type: ignore[attr-defined]
    except ImportError:  # pragma: no cover  # AI-AGENT-REF: narrow import handling
        class RequestException(Exception):
            pass
    
        # Minimal stub so runtime calls fail gracefully into COMMON_EXC
        class _RequestsStub:
            class exceptions:
                RequestException = RequestException
    
            def get(self, *a, **k):
                raise RequestException("requests not installed")
    
        requests = _RequestsStub()  # type: ignore
    
    from threading import Lock
    import warnings
    
    from ai_trading.data_fetcher import (
        get_bars,
        get_bars_batch,
        get_minute_df,
    )
>   from ai_trading.market.calendars import last_market_session
E   ImportError: cannot import name 'last_market_session' from 'ai_trading.market.calendars' (unknown location)

ai_trading/core/bot_engine.py:39: ImportError
_________________________________________________ test_fast_retry_skips_sleep __________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb40279d10>

    @pytest.mark.unit
    def test_fast_retry_skips_sleep(monkeypatch: pytest.MonkeyPatch) -> None:
        monkeypatch.setenv("FAST_RETRY_IN_TESTS", "1")
    
        calls = {"n": 0}
    
        def func() -> str:
            calls["n"] += 1
            if calls["n"] < 2:
                raise RuntimeError("boom")
            return "done"
    
        start = time.perf_counter()
        result = retry_call(func, exceptions=(RuntimeError,), retries=1, backoff=0.5)
        elapsed = time.perf_counter() - start
        assert result == "done"
        assert calls["n"] == 2
>       assert elapsed < 0.01
E       assert 0.5141302449992509 < 0.01

tests/unit/test_retry.py:65: AssertionError
________________________________________________ test_retry_eventually_succeeds ________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    @pytest.mark.unit
    def test_retry_eventually_succeeds() -> None:
        flaky = _Flaky()
        result = retry_call(flaky, exceptions=(RuntimeError,), retries=2)
        assert result == "ok"
>       assert flaky.calls == 2
E       assert 3 == 2
E        +  where 3 = <tests.unit.test_retry._Flaky object at 0x7f44d82a70d0>.calls

tests/unit/test_retry.py:37: AssertionError
________________________________________________ test_retry_succeeds_and_sleeps ________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fa317955bd0>

    def test_retry_succeeds_and_sleeps(monkeypatch: pytest.MonkeyPatch) -> None:
        sleeps: list[float] = []
        monkeypatch.setattr(time, "sleep", lambda s: sleeps.append(s))
        fn = Flaky(2)
        assert retry_call(fn, exceptions=(TimeoutError,), retries=3) == "ok"
        assert fn.calls == 3
>       assert len(sleeps) == 2
E       assert 0 == 2
E        +  where 0 = len([])

tests/utils/test_retry.py:31: AssertionError
______________________________________________________ test_backoff_caps _______________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fdb3e5f2d90>

    def test_backoff_caps(monkeypatch: pytest.MonkeyPatch) -> None:
        sleeps: list[float] = []
        monkeypatch.setattr(time, "sleep", lambda s: sleeps.append(s))
        fn = Flaky(5)
        with pytest.raises(TimeoutError):
            retry_call(fn, exceptions=(TimeoutError,), retries=4, backoff=0.1, max_backoff=0.3, jitter=0)
>       assert sleeps[-1] <= 0.3
               ^^^^^^^^^^
E       IndexError: list index out of range

tests/utils/test_retry.py:46: IndexError
____________________________ TestOrderExecutionTracking.test_safe_submit_order_quantity_validation _____________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_trading_issues.TestOrderExecutionTracking testMethod=test_safe_submit_order_quantity_validation>

    def test_safe_submit_order_quantity_validation(self):
        """Test that safe_submit_order validates filled_qty matches intended qty."""
    
        # Mock order request
        mock_req = Mock()
        mock_req.symbol = "AAPL"
        mock_req.qty = 100
    
        # Mock order with partial fill
        partial_order = Mock()
        partial_order.status = "partially_filled"
        partial_order.filled_qty = "50"  # Only half filled
        partial_order.qty = "100"
    
        with patch.object(self.mock_ctx.api, 'submit_order', return_value=partial_order), \
             patch.object(self.mock_ctx.api, 'get_order_by_id', return_value=partial_order):
    
            if hasattr(bot_engine, 'safe_submit_order'):
                result = bot_engine.safe_submit_order(self.mock_ctx.api, mock_req)
    
                # The issue: function returns the order but doesn't validate
                # that filled_qty (50) matches intended qty (100)
>               self.assertEqual(result.filled_qty, "50")
                                 ^^^^^^^^^^^^^^^^^
E               AttributeError: 'NoneType' object has no attribute 'filled_qty'

tests/test_critical_trading_issues.py:143: AttributeError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 13:34:24,284", "level": "WARNING", "name": "ai_trading.core.bot_engine", "msg": "MARK…SKIP", "symbol": "AAPL", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.core.bot_engine:bot_engine.py:7539 MARK…SKIP
__________________________________ TestLiquidityManagement.test_conservative_spread_threshold __________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_trading_issues.TestLiquidityManagement testMethod=test_conservative_spread_threshold>

    def test_conservative_spread_threshold(self):
        """Test that 0.05 spread threshold is too conservative."""
    
        symbol = "AAPL"
    
        # Mock quote with moderate spread
        mock_quote = Mock()
        mock_quote.ask_price = 150.05
        mock_quote.bid_price = 150.00
        mock_quote.spread = 0.05  # Exactly at threshold
    
        # Mock volume data
        avg_vol = 500000  # Good volume
    
        with patch.object(self.mock_ctx.data_client, 'get_stock_latest_quote', return_value=mock_quote):
            if hasattr(bot_engine, 'liquidity_factor'):
>               factor = bot_engine.liquidity_factor(self.mock_ctx, symbol)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_critical_trading_issues.py:266: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:7169: in liquidity_factor
    df = fetch_minute_df_safe(symbol)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ai_trading/core/bot_engine.py:2047: in fetch_minute_df_safe
    df = get_minute_df(symbol, start_dt, now_utc)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ai_trading/data_fetcher.py:531: in get_minute_df
    fh_fetcher.fetch(symbol, start_dt, end_dt, resolution="1")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.data_fetcher._FinnhubFetcherStub object at 0x7f4716e2f050>
args = ('AAPL', datetime.datetime(2025, 8, 21, 13, 34, 24, 303157, tzinfo=datetime.timezone.utc), datetime.datetime(2025, 8, 22, 13, 34, 24, 303157, tzinfo=datetime.timezone.utc))
kwargs = {'resolution': '1'}

    def fetch(self, *args, **kwargs):
>       raise NotImplementedError
E       NotImplementedError

ai_trading/data_fetcher.py:149: NotImplementedError
____________________________________________________ test_disk_cache_basic _____________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_disk_cache_basic0')

    def test_disk_cache_basic(tmp_path):
        """Test disk cache functionality"""
        cache_dir = str(tmp_path / "cache")
        df = pd.DataFrame({"timestamp":[1], "open":[2], "high":[3], "low":[1], "close":[2.5], "volume":[1000]})
    
        # Put data in disk cache
        mcache.put_disk(cache_dir, "TSLA", "1H", "2024-01-01", "2024-01-02", df)
    
        # Retrieve from disk cache
        retrieved = mcache.get_disk(cache_dir, "TSLA", "1H", "2024-01-01", "2024-01-02")
>       assert retrieved is not None
E       assert None is not None

tests/test_data_cache.py:26: AssertionError
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.market.cache:cache.py:81 Failed to write cache file /tmp/pytest-of-root/pytest-0/popen-gw0/test_disk_cache_basic0/cache/TSLA_1H_2024-01-01_2024-01-02.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
___________________________________________________ test_get_bars_df_spy_day ___________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    @pytest.mark.requires_credentials
    def test_get_bars_df_spy_day():
        if not (os.getenv("ALPACA_API_KEY") and os.getenv("ALPACA_SECRET_KEY")):
            pytest.skip("missing Alpaca credentials")
>       df = get_bars_df("SPY", TimeFrame.Day)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_data_fetch.py:21: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:184: in get_bars_df
    df = rest.get_bars(
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:735: in get_bars
    bars = list(self.get_bars_iter(symbol,
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:718: in get_bars_iter
    for bar in bars:
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:594: in _data_get
    resp = self.data_get(path, data=data, feed=feed,
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:274: in data_get
    return self._request(
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:222: in _request
    return self._one_request(method, url, opts, retry)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:248: in _one_request
    raise_api_error(resp, http_error)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:81: in raise_api_error
    raise http_error from None
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:243: in _one_request
    resp.raise_for_status()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Response [403]>

    def raise_for_status(self):
        """Raises :class:`HTTPError`, if one occurred."""
    
        http_error_msg = ""
        if isinstance(self.reason, bytes):
            # We attempt to decode utf-8 first because some servers
            # choose to localize their reason strings. If the string
            # isn't utf-8, we fall back to iso-8859-1 for all other
            # encodings. (See PR #3538)
            try:
                reason = self.reason.decode("utf-8")
            except UnicodeDecodeError:
                reason = self.reason.decode("iso-8859-1")
        else:
            reason = self.reason
    
        if 400 <= self.status_code < 500:
            http_error_msg = (
                f"{self.status_code} Client Error: {reason} for url: {self.url}"
            )
    
        elif 500 <= self.status_code < 600:
            http_error_msg = (
                f"{self.status_code} Server Error: {reason} for url: {self.url}"
            )
    
        if http_error_msg:
>           raise HTTPError(http_error_msg, response=self)
E           requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://data.alpaca.markets/v2/stocks/SPY/bars?timeframe=1Day&adjustment=all&start=2025-02-03&end=2025-08-22&feed=iex

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/requests/models.py:1026: HTTPError
______________________________________________________ test_get_minute_df ______________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f4715161b10>

    def test_get_minute_df(monkeypatch):
        df = pd.DataFrame(
            {"open": [1.0], "high": [2.0], "low": [0.5], "close": [1.5], "volume": [100]},
            index=[pd.Timestamp("2023-01-01T09:30")],
        )
    
        monkeypatch.setattr(data_fetcher, "_fetch_bars", lambda *a, **k: df.reset_index().rename(columns={"index": "timestamp"}))
        monkeypatch.setattr(data_fetcher, "is_market_open", lambda: True)
>       result = data_fetcher.get_minute_df("AAPL", datetime.date(2023, 1, 1), datetime.date(2023, 1, 2))
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_data_fetcher.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/data_fetcher.py:531: in get_minute_df
    fh_fetcher.fetch(symbol, start_dt, end_dt, resolution="1")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.data_fetcher._FinnhubFetcherStub object at 0x7f4716e2f050>
args = ('AAPL', datetime.datetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2023, 1, 2, 0, 0, tzinfo=datetime.timezone.utc))
kwargs = {'resolution': '1'}

    def fetch(self, *args, **kwargs):
>       raise NotImplementedError
E       NotImplementedError

ai_trading/data_fetcher.py:149: NotImplementedError
________________________________________________ test_subscription_error_logged ________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f471504fe90>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7f471504df50>

    def test_subscription_error_logged(monkeypatch, caplog):
        df = pd.DataFrame(
            {"open": [1.0], "high": [2.0], "low": [0.5], "close": [1.5], "volume": [100]},
            index=[pd.Timestamp("2023-01-01T09:30")],
        )
    
        class DummyClient:
            def get_stock_bars(self, req):
                if getattr(req, "feed", None) == "iex":
                    return FakeBars(df)
                raise data_fetcher.APIError("subscription does not permit querying recent SIP data")
    
>       monkeypatch.setattr(data_fetcher, "client", DummyClient())
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute 'client'

tests/test_data_fetcher.py:118: AttributeError
______________________________________________ test_fetch_bars_retry_invalid_feed ______________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f4714da9790>

    def test_fetch_bars_retry_invalid_feed(monkeypatch):
        calls = []
    
        class Resp:
            def __init__(self, status, text, data=None):
                self.status_code = status
                self.text = text
                self._data = data or {}
    
            def json(self):
                return self._data
    
        def fake_get(url, params=None, headers=None, timeout=10):
            calls.append(params["feed"])
            if len(calls) == 1:
                return Resp(400, "invalid feed")
            return Resp(200, "", {"bars": [{"t": "2023-01-01T00:00:00Z", "o": 1, "h": 1, "l": 1, "c": 1, "v": 1}]})
    
        monkeypatch.setattr(data_fetcher.requests, "get", fake_get)
    
        start = pd.Timestamp("2023-01-01", tz="UTC")
        end = start + pd.Timedelta(minutes=1)
>       df = data_fetcher._fetch_bars("AAPL", start, end, "1Min", "iex")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: _fetch_bars() takes 4 positional arguments but 5 were given

tests/test_data_fetcher.py:162: TypeError
__________________________________________________ test_finnhub_403_yfinance ___________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f4713094a10>

    def test_finnhub_403_yfinance(monkeypatch):
        def raise_fetch(*a, **k):
            raise data_fetcher.DataFetchException("AAPL", "alpaca", "", "err")
    
        def raise_finnhub(*a, **k):
            raise data_fetcher.FinnhubAPIException(status_code=403)
    
        called = []
    
        def fake_yf(symbol, *args, **kwargs):
            called.append(symbol)
            return pd.DataFrame(
                {"open": [1], "high": [1], "low": [1], "close": [1], "volume": [1]},
                index=[pd.Timestamp("2023-01-01", tz="UTC")],
            )
    
        monkeypatch.setattr(data_fetcher, "_fetch_bars", raise_fetch)
        monkeypatch.setattr(data_fetcher.fh_fetcher, "fetch", raise_finnhub)
>       monkeypatch.setattr(data_fetcher.yf, "download", fake_yf)
E       AttributeError: None has no attribute 'download'

tests/test_data_fetcher.py:185: AttributeError
_________________________________________________ test_fetch_bars_empty_raises _________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f4714ea5450>

    def test_fetch_bars_empty_raises(monkeypatch):
        """_fetch_bars propagates empty results for Yahoo fallback."""  # AI-AGENT-REF
    
        class Resp:
            status_code = 200
            text = ""
    
            def json(self):
                return {"bars": []}
    
        monkeypatch.setattr(data_fetcher.requests, "get", lambda *a, **k: Resp())
    
        with pytest.raises(ValueError):
>           data_fetcher._fetch_bars(
                "AAPL",
                pd.Timestamp("2023-01-02", tz="UTC"),
                pd.Timestamp("2023-01-02", tz="UTC"),
                "1Day",
                "iex",
            )
E           TypeError: _fetch_bars() takes 4 positional arguments but 5 were given

tests/test_data_fetcher.py:224: TypeError
___________________________________________ test_fetch_minute_df_safe_handles_empty ____________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f4714f7a350>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7f4714f7be50>

    def test_fetch_minute_df_safe_handles_empty(monkeypatch, caplog):
        """fetch_minute_df_safe returns empty DataFrame without error."""  # AI-AGENT-REF
        monkeypatch.setattr("ai_trading.core.bot_engine.get_minute_df", lambda *a, **k: pd.DataFrame())
        caplog.set_level("INFO")
>       result = fetch_minute_df_safe("AAPL")
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_data_fetcher.py:253: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

symbol = 'AAPL'

    def fetch_minute_df_safe(symbol: str) -> pd.DataFrame:
        """Fetch the last day of minute bars and raise on empty."""
        # AI-AGENT-REF: raise on empty DataFrame
        now_utc = datetime.now(UTC)
        start_dt = now_utc - timedelta(days=1)
    
        # AI-AGENT-REF: Cache wrapper (optional around fetch)
        if hasattr(CFG, "market_cache_enabled") and CFG.market_cache_enabled:
            try:
                from ai_trading.market.cache import get_or_load as _get_or_load
    
                cache_key = f"minute:{symbol}:{start_dt.isoformat()}"
                df = _get_or_load(
                    key=cache_key,
                    loader=lambda: get_minute_df(symbol, start_dt, now_utc),
                    ttl=getattr(S, "market_cache_ttl", 900),
                )
            except (
                FileNotFoundError,
                PermissionError,
                IsADirectoryError,
                JSONDecodeError,
                ValueError,
                KeyError,
                TypeError,
                OSError,
            ) as e:  # AI-AGENT-REF: narrow exception
                _log.debug("Cache layer unavailable/failed: %s", e)
                df = get_minute_df(symbol, start_dt, now_utc)
        else:
            df = get_minute_df(symbol, start_dt, now_utc)
    
        if df.empty:
            msg = "Minute bars DataFrame is empty after fallbacks; market likely closed"  # AI-AGENT-REF
            _log.warning(
                "FETCH_MINUTE_EMPTY",
                extra={"reason": "empty", "context": "market_closed"},
            )
>           raise DataFetchError(msg)
E           ai_trading.core.bot_engine.DataFetchError: Minute bars DataFrame is empty after fallbacks; market likely closed

ai_trading/core/bot_engine.py:2055: DataFetchError
---------------------------------------------------- Captured stdout setup -----------------------------------------------------
{"ts": "2025-08-22 13:34:25,079", "level": "WARNING", "name": "ai_trading.core.bot_engine", "msg": "Data freshness check unavailable; skipping\nTraceback (most recent call last):\n  File \"/workspace/ai-t…-bot/ai_trading/core/bot_engine.py\", line 5792, in _ens…resh\n    from ai_trading.data…cher import last…onds\nImportError: cannot import name 'last…onds' from 'ai_trading.data…cher' (unknown location)", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.core.bot_engine:bot_engine.py:2051 FETC…MPTY
=================================================== short test summary info ====================================================
FAILED tests/test_broker_alpaca_adapter.py::test_positions_and_account_old - AssertionError: assert [] == ['pos-old']
FAILED tests/test_additional_coverage.py::test_validate_env_main - ImportError: Error while finding module specification for ...
FAILED tests/test_advanced_features.py::test_submit_order_shadow - TypeError: 'types.SimpleNamespace' object is not subscript...
FAILED tests/test_critical_datetime_fixes.py::TestDatetimeTimezoneAwareness::test_alpaca_api_format_compatibility - ImportErr...
FAILED tests/test_critical_datetime_fixes.py::TestDatetimeTimezoneAwareness::test_ensure_datetime_returns_timezone_aware - Im...
FAILED tests/test_alpaca_import.py::test_ai_trading_import_without_alpaca - AssertionError: assert True is False
FAILED tests/test_alpaca_init_contract.py::test_no_import_time_initialization - AssertionError: assert <ai_trading.broker.alp...
FAILED tests/test_broker_unavailable_paths.py::test_safe_account_none - AttributeError: '_TClient' object has no attribute 'g...
FAILED tests/test_broker_unavailable_paths.py::test_pdt_rule_skips_without_false_fail - assert namespace(api=None) is False
FAILED tests/test_critical_datetime_fixes.py::TestSentimentCaching::test_sentiment_cache_rate_limit_handling - AttributeError...
FAILED tests/runtime/test_exception_narrowing_df_main.py::test_data_fetcher_json_decode_is_valueerror_only - assert None
FAILED tests/runtime/test_http_wrapped.py::test_wrapped_get_retries_and_parses - Exception: boom
FAILED tests/test_critical_fixes_implementation.py::test_dependency_injection - NameError: name 'MockConfigManager' is not de...
FAILED tests/test_critical_fixes_implementation.py::test_performance_optimizations - AttributeError: 'IndicatorManager' objec...
FAILED tests/test_alpaca_time_params.py::test_daily_uses_date_only - requests.exceptions.HTTPError: 403 Client Error: Forbidd...
FAILED tests/test_critical_fixes_validation.py::TestCriticalFixes::test_data_staleness_detection_improvement - AssertionError...
FAILED tests/test_critical_fixes_validation.py::TestCriticalFixes::test_meta_learning_price_validation - AssertionError: 3 !=...
FAILED tests/test_critical_fixes_validation.py::TestCriticalFixes::test_systemd_service_configuration - AssertionError: 'NoNe...
FAILED tests/test_alpaca_time_params.py::test_intraday_uses_rfc3339z - requests.exceptions.HTTPError: 403 Client Error: Forbi...
FAILED tests/test_alpaca_timeframe_mapping.py::test_day_timeframe_normalized - requests.exceptions.HTTPError: 403 Client Erro...
FAILED tests/runtime/test_no_broad_except_in_hotpaths.py::test_no_broad_except_in_hotpaths - AssertionError: broad except pre...
FAILED tests/test_critical_trading_fixes.py::TestMetaLearningSystemFixes::test_reduced_minimum_trade_requirement - TypeError:...
FAILED tests/test_critical_trading_fixes.py::TestSystemMonitoringAndAlerting::test_meta_learning_configuration - AssertionErr...
FAILED tests/test_critical_trading_fixes.py::TestSystemMonitoringAndAlerting::test_sentiment_success_rate_monitoring - Assert...
FAILED tests/test_alpaca_timeframe_mapping.py::test_tf_object_normalized - requests.exceptions.HTTPError: 403 Client Error: F...
FAILED tests/test_env_flags.py::test_disable_daily_retrain_env_parsing - AttributeError: DISABLE_DAILY_RETRAIN
FAILED tests/test_env_flags.py::test_disable_daily_retrain_unset - AttributeError: DISABLE_DAILY_RETRAIN
FAILED tests/test_env_flags.py::test_disable_daily_retrain_fallback_settings - AttributeError: _FallbackSettings
FAILED tests/test_env_order_and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_dotenv_loaded_before_settings_construction
FAILED tests/test_env_order_and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_lazy_engine_loading_caches_components
FAILED tests/test_additional_coverage.py::test_main_starts_api_thread - ValueError: "Settings" object has no field "max_posit...
FAILED tests/test_env_order_and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_run_cycle_uses_lazy_loading - Asserti...
FAILED tests/test_data_fetcher_datetime.py::test_ensure_datetime_none - TypeError: Invalid datetime input: Invalid datetime i...
FAILED tests/test_alpaca_timeframe_mapping.py::test_minute_normalized - requests.exceptions.HTTPError: 403 Client Error: Forb...
FAILED tests/test_data_fetcher_datetime.py::test_ensure_datetime_empty_str - TypeError: Invalid datetime input: Invalid datet...
FAILED tests/test_env_order_and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_main_loads_dotenv_before_runner_import
FAILED tests/test_env_order_and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_env_loaded_multiple_times_safely - As...
FAILED tests/test_env_order_and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_lazy_import_error_handling - Failed: ...
FAILED tests/test_data_fetcher_datetime.py::test_ensure_datetime_invalid_str - TypeError: Invalid datetime input: Invalid dat...
FAILED tests/test_data_fetcher_datetime.py::test_ensure_datetime_nat - Failed: DID NOT RAISE <class 'ValueError'>
FAILED tests/test_data_fetcher_extended.py::test_get_historical_data - AttributeError: <module 'ai_trading.data_fetcher' from...
FAILED tests/test_data_fetcher_extended.py::test_get_historical_data_bad_timeframe - AttributeError: <module 'ai_trading.data...
FAILED tests/test_data_fetcher_extended.py::test_get_minute_df_market_closed - NotImplementedError
FAILED tests/test_data_fetcher_extended.py::test_get_minute_df_missing_columns - AttributeError: <module 'ai_trading.data_fet...
FAILED tests/test_data_fetcher_extended.py::test_get_minute_df_invalid_inputs - TypeError: Invalid datetime input: Invalid da...
FAILED tests/test_equity_curve.py::test_equity_curve_monotonic - FileNotFoundError: [Errno 2] No such file or directory: 'dat...
FAILED tests/test_data_fetcher_fallbacks.py::test_minute_fallback_on_empty - AttributeError: None has no attribute 'download'
FAILED tests/test_data_fetcher_fallbacks.py::test_minute_fallback_on_exception - AttributeError: None has no attribute 'downl...
FAILED tests/test_data_fetcher_fallbacks.py::test_daily_fallback_on_empty - AttributeError: None has no attribute 'download'
FAILED tests/test_data_fetcher_timezone.py::test_yahoo_get_bars_accepts_various_datetime_types - ImportError: cannot import n...
FAILED tests/test_data_pipeline.py::test_position_none_safe - AttributeError: module 'ai_trading.core.bot_engine' has no attr...
FAILED tests/test_deprecation_warnings.py::test_bot_engine_deprecation_warning - assert False
FAILED tests/test_deprecation_warnings.py::test_data_fetcher_deprecation_warning - assert 0 >= 1
FAILED tests/test_deprecation_warnings.py::test_runner_deprecation_warning - assert 0 >= 1
FAILED tests/test_executors_sizing.py::test_executor_env_validation - ValueError: invalid literal for int() with base 10: 'in...
FAILED tests/test_fallback_concurrency.py::test_daily_fallback_parallel - AssertionError: assert set() == {'A', 'B', 'C', 'D'}
FAILED tests/test_fallback_concurrency.py::test_parallel_execution_timing - assert 0 == 4
FAILED tests/test_fallback_concurrency.py::test_bounded_concurrency_respects_limit - assert 0 == 6
FAILED tests/test_drawdown_integration.py::TestDrawdownIntegration::test_bot_context_integration - AttributeError: <module 'a...
FAILED tests/test_drawdown_integration.py::TestDrawdownIntegration::test_configuration_values - AssertionError: 0.08 != 0.15
FAILED tests/test_institutional_enhancements.py::TestEnhancedRebalancer::test_enhanced_rebalancer_fallback - ImportError: can...
FAILED tests/test_import_fallbacks.py::test_bot_engine_import_fallbacks - AssertionError: Expected import pattern not found: ...
FAILED tests/test_import_fallbacks.py::test_runner_import_fallbacks - AssertionError: Expected import pattern not found in ru...
FAILED tests/test_import_fallbacks.py::test_backtester_import_fallbacks - AssertionError: Expected import pattern not found i...
FAILED tests/test_import_fallbacks.py::test_profile_indicators_import_fallbacks - ModuleNotFoundError: No module named 'profi...
FAILED tests/test_import_fallbacks.py::test_data_fetcher_helpers_available - ImportError: cannot import name 'clear_cached_mi...
FAILED tests/test_institutional_kelly.py::TestKellyIntegration::test_kelly_with_risk_levels - AttributeError: 'NoneType' obje...
FAILED tests/test_institutional_kelly.py::TestKellyIntegration::test_kelly_logging - AttributeError: 'NoneType' object has no...
FAILED tests/test_critical_trading_fixes.py::test_meta_learning_price_validation - assert 4 == 3
FAILED tests/test_integration_robust.py::test_bot_main_normal - AttributeError: <module 'data_fetcher' from '/workspace/ai-tr...
FAILED tests/test_critical_trading_fixes.py::test_quantity_tracking_fix - AssertionError: assert 'FULL_FILL_SUCCESS' in ''
FAILED tests/test_integration_robust.py::test_bot_main_data_fetch_error - AttributeError: <module 'data_fetcher' from '/works...
FAILED tests/test_ellipsis_fix.py::TestEllipsisFix::test_get_runtime_context_or_none_error - Exception: Context unavailable
FAILED tests/test_integration_robust.py::test_bot_main_signal_nan - AttributeError: <module 'data_fetcher' from '/workspace/a...
FAILED tests/test_ellipsis_fix.py::TestEllipsisFix::test_update_risk_engine_exposure_error - AssertionError: Expected 'warnin...
FAILED tests/test_ellipsis_fix.py::TestEllipsisFix::test_update_risk_engine_exposure_no_risk_engine - AssertionError: 'No ris...
FAILED tests/test_integration_robust.py::test_trade_execution_api_timeout - AttributeError: <class 'ai_trading.broker.alpaca....
FAILED tests/test_integration_simple.py::test_integration - AttributeError: DAILY_LOSS_LIMIT
FAILED tests/test_ellipsis_fix.py::TestEllipsisFix::test_update_risk_engine_exposure_with_context - AssertionError: Expected ...
FAILED tests/test_intelligent_position_management.py::TestTrailingStopManager::test_stop_initialization - NameError: name 'Mo...
FAILED tests/test_fetch_and_screen.py::test_fetch_fallback_to_daily - AttributeError: <module 'ai_trading.data_fetcher' from ...
FAILED tests/test_fetch_contract.py::test_get_bars_never_none - AttributeError: <module 'ai_trading.data_fetcher' from '/work...
FAILED tests/test_intelligent_position_management.py::TestTrailingStopManager::test_stop_movement - NameError: name 'MockPosi...
FAILED tests/test_fetch_sample_universe_cli.py::test_run_success - AttributeError: 'module' object at ai_trading.data_fetcher...
FAILED tests/test_intelligent_position_management.py::TestTrailingStopManager::test_stop_trigger_detection - NameError: name ...
FAILED tests/test_intelligent_position_management.py::TestProfitTakingEngine::test_profit_plan_creation - NameError: name 'Mo...
FAILED tests/test_intelligent_position_management.py::TestProfitTakingEngine::test_target_triggering - NameError: name 'MockP...
FAILED tests/test_intelligent_position_management.py::TestPortfolioCorrelationAnalyzer::test_position_data_extraction - NameE...
FAILED tests/test_intelligent_position_management.py::TestPortfolioCorrelationAnalyzer::test_concentration_analysis - NameErr...
FAILED tests/test_intelligent_position_management.py::TestIntegrationScenarios::test_profitable_position_scenario - NameError...
FAILED tests/test_intelligent_position_management.py::TestIntegrationScenarios::test_loss_position_scenario - NameError: name...
FAILED tests/test_intelligent_position_management.py::TestIntegrationScenarios::test_portfolio_level_recommendations - NameEr...
FAILED tests/test_critical_trading_fixes.py::test_risk_management_sector_exposure_logging - TypeError: 'Mock' object is not i...
FAILED tests/test_json_formatter.py::test_json_formatter_custom_fields_and_masking - AssertionError: assert (False)
FAILED tests/test_kelly_confidence_fix.py::test_kelly_confidence_normalization - NameError: name 'MockBotContext' is not defined
FAILED tests/test_health.py::test_health_check_empty_dataframe - AssertionError: assert [('AAA', 'no_data')] == ['AAA']
FAILED tests/test_kelly_confidence_fix.py::test_kelly_input_validation - NameError: name 'MockBotContext' is not defined
FAILED tests/test_logger.py::test_setup_logging_idempotent - AssertionError: No rotating handler paths created. Captured: []
FAILED tests/test_logger.py::test_get_logger - AttributeError: 'SanitizingLoggerAdapter' object has no attribute 'handlers'
FAILED tests/test_http_pooling.py::test_host_semaphore_respects_env - assert 6 == 3
FAILED tests/test_logger_file.py::test_setup_logging_with_file - assert []
FAILED tests/test_logger_module.py::test_get_logger_singleton - AttributeError: 'SanitizingLoggerAdapter' object has no attri...
FAILED tests/test_http_timeouts.py::test_httpsession_sets_default_timeout - AttributeError: module 'ai_trading.utils.http' ha...
FAILED tests/test_critical_trading_fixes.py::test_emergency_data_validation - AssertionError: assert True is False
FAILED tests/test_meta_learning.py::test_update_signal_weights_norm_zero - AssertionError: assert 'Normalization factor zero'...
FAILED tests/test_meta_learning.py::test_portfolio_rl_trigger - ModuleNotFoundError: No module named 'portfolio_rl'
FAILED tests/test_logging_scrubbed.py::test_no_secrets_in_logs - AssertionError: assert 'TOPSECRETKEY' not in 'boot with key=...
FAILED tests/test_main_extended2.py::test_run_flask_app - TypeError: test_run_flask_app.<locals>.App.run() got an unexpected ...
FAILED tests/test_main_extended2.py::test_run_flask_app_port_in_use - AttributeError: module 'ai_trading.main' has no attribu...
FAILED tests/test_meta_learning_additional.py::test_load_weights_save_fail - OSError: fail
FAILED tests/test_main_extended2.py::test_run_bot_calls_cycle - assert 1 == 0
FAILED tests/test_main_extended2.py::test_validate_environment_missing - ValueError: "Settings" object has no field "WEBHOOK_...
FAILED tests/test_meta_learning_optional.py::test_optimize_signals_fallback - TypeError: optimize_signals() missing 1 require...
FAILED tests/test_main_extended2.py::test_main_runs_once - ValueError: "Settings" object has no field "max_position_size"
FAILED tests/test_mean_reversion_extra.py::test_generate_insufficient_data - AssertionError: assert 'insufficient' in 'WARNIN...
FAILED tests/test_mean_reversion_extra.py::test_generate_invalid_stats - AssertionError: assert 'invalid rolling' in 'WARNING...
FAILED tests/test_ml_model_extra.py::test_fit_and_predict - TypeError: '>=' not supported between instances of 'MLModel' and ...
FAILED tests/test_ml_model_loading.py::test_load_real_model - assert None is not None
FAILED tests/test_model_registry_roundtrip.py::test_model_registry_multiple_registrations - assert 2 == 1
FAILED tests/test_momentum_extra.py::test_generate_insufficient_data - AssertionError: assert 'Insufficient data' in 'INFO   ...
FAILED tests/test_moving_average_crossover_extra.py::test_generate_insufficient_data - TypeError: MovingAverageCrossoverStrat...
FAILED tests/test_moving_average_crossover_extra.py::test_generate_buy_signal - TypeError: MovingAverageCrossoverStrategy.__i...
FAILED tests/test_my_fixes.py::TestMyFixes::test_confidence_normalization_improved - FileNotFoundError: [Errno 2] No such fil...
FAILED tests/test_my_fixes.py::TestMyFixes::test_data_quality_handling_improved - FileNotFoundError: [Errno 2] No such file o...
FAILED tests/test_my_fixes.py::TestMyFixes::test_duplicate_logging_fix - AssertionError: 'elif phase in [ExecutionPhase.SIGNA...
FAILED tests/test_my_fixes.py::TestMyFixes::test_liquidity_thresholds_increased - FileNotFoundError: [Errno 2] No such file o...
FAILED tests/test_my_fixes.py::TestMyFixes::test_meta_learning_thresholds_reduced - FileNotFoundError: [Errno 2] No such file...
FAILED tests/test_my_fixes.py::TestMyFixes::test_position_limit_rebalancing - FileNotFoundError: [Errno 2] No such file or di...
FAILED tests/test_nameerror_integration.py::test_bot_engine_import_no_nameerror - AssertionError: Subprocess timeout - bot_en...
FAILED tests/test_net_http_timeout.py::test_timeoutsession_injects_default_timeout - AttributeError: module 'requests' has no...
FAILED tests/test_net_http_timeout.py::test_build_retrying_session_defaults - AttributeError: module 'requests' has no attrib...
FAILED tests/test_no_legacy_imports.py::test_legacy_modules_not_importable - AssertionError: assert ModuleSpec(name='metrics'...
FAILED tests/test_no_raw_requests.py::test_no_raw_requests_in_src - AssertionError: Raw requests.* found in: ['/workspace/ai-...
FAILED tests/test_no_root_imports.py::test_no_root_level_imports_of_migrated_modules - AssertionError: Root imports are no lo...
FAILED tests/test_package_first_smoke.py::test_ai_trading_module_imports - ModuleNotFoundError: No module named 'ai_trading.t...
FAILED tests/test_package_first_smoke.py::test_ai_trading_init_exports - AssertionError: assert False
FAILED tests/test_parameter_optimization.py::test_kelly_parameters_optimization - AssertionError: Expected 0.15, got 0.3
FAILED tests/test_parameter_optimization.py::test_adaptive_sizing_optimization - TypeError: object() takes no arguments
FAILED tests/test_parameter_optimization.py::test_execution_algorithm_optimization - NameError: name 'MockOrderManager' is no...
FAILED tests/test_peak_performance.py::test_adaptive_risk_controls - AttributeError: 'Settings' object has no attribute 'ENAB...
FAILED tests/test_peak_performance.py::test_determinism - NameError: name 'HAS_NUMPY' is not defined
FAILED tests/test_peak_performance.py::test_backtest_cost_enforcement - assert False
FAILED tests/test_performance_allocator_conf_gate.py::test_allocator_confidence_gate_filters_and_logs - assert 0 >= 2
FAILED tests/test_performance_fixes.py::test_meta_learning_mixed_format - AssertionError: Should detect mixed formats
FAILED tests/test_performance_fixes.py::test_cache_performance_monitoring - ImportError: cannot import name '_CACHE_STATS' fr...
FAILED tests/test_phase2_enhancements.py::TestConfigurationEnhancements::test_order_management_config - AssertionError: False...
FAILED tests/test_phase2_enhancements.py::TestConfigurationEnhancements::test_system_health_config - AssertionError: False is...
FAILED tests/test_portfolio.py::test_short_close_queued - AttributeError: None has no attribute 'submit'
FAILED tests/test_position_holding.py::test_meta_learning_trigger - AttributeError: <module 'ai_trading.meta_learning' from '...
FAILED tests/test_position_holding.py::test_position_manager_cleanup - AssertionError: assert 'GOOGL' not in {'AAPL': <Mock i...
FAILED tests/test_position_holding_simple.py::test_meta_learning_functions - AttributeError: <module 'ai_trading.meta_learnin...
FAILED tests/test_problem_statement_fixes.py::TestProblemStatementFixes::test_meta_learning_minimum_trades_requirement - Asse...
FAILED tests/test_problem_statement_fixes.py::TestProblemStatementFixes::test_order_quantity_tracking_clarity - AssertionErro...
FAILED tests/test_problem_statement_fixes.py::TestProblemStatementFixes::test_pltr_sector_classification - AssertionError: bo...
FAILED tests/test_problem_statement_validation.py::test_alpaca_availability_detection - ImportError: cannot import name '_alp...
FAILED tests/test_problem_statement_validation.py::test_alpaca_import_exception_handling - AttributeError: <module 'ai_tradin...
FAILED tests/test_problem_statement_validation.py::test_package_safe_imports - ImportError: cannot import name '_alpaca_avail...
FAILED tests/test_problem_statement_validation.py::test_python_version_requirements - AssertionError: Should use flexible Pyt...
FAILED tests/test_production_fixes.py::TestSentimentAPIConfiguration::test_sentiment_api_env_vars_in_config - AssertionError:...
FAILED tests/test_production_fixes.py::TestIntegration::test_all_modules_importable - AssertionError: Failed to import perfor...
FAILED tests/test_imports_smoke.py::test_submodules_import - ImportError: cannot import name 'DynamicPositionSizer' from 'ai_...
FAILED tests/test_initial_rebalance.py::test_partial_initial_rebalance_fill - AttributeError: 'DummyAPI' object has no attrib...
FAILED tests/test_prof_budget.py::test_soft_budget_elapsed_and_over - assert (False is True or 0.00957063700479921 == 0.0)
FAILED tests/test_regime_filters.py::test_regime_changes - FileNotFoundError: [Errno 2] No such file or directory: 'data/trad...
FAILED tests/test_risk_engine_additional.py::test_position_size_division_error - TypeError: StrategySignal.__init__() missing...
FAILED tests/test_risk_engine_additional.py::test_apply_weight_limits - TypeError: StrategySignal.__init__() missing 1 requir...
FAILED tests/test_resample_daily.py::test_get_daily_bars_resamples_minutes - TypeError: test_get_daily_bars_resamples_minutes...
FAILED tests/test_pydantic_v2_migration.py::test_pydantic_v2_migration_syntax - assert 'from pydantic import field_validator,...
FAILED tests/test_risk_engine_module.py::test_can_trade_limits - TypeError: StrategySignal.__init__() missing 1 required posi...
FAILED tests/test_retrain_smoke.py::test_retrain_detect_regime_and_dump - ModuleNotFoundError: No module named 'retrain'
FAILED tests/test_risk_engine_module.py::test_register_and_position_size - TypeError: StrategySignal.__init__() missing 1 req...
FAILED tests/test_retry_idempotency_integration.py::test_retry_idempotency_integration - NameError: name 'MockBrokerAPI' is n...
FAILED tests/test_retry_idempotency_integration.py::test_reconciliation_heals_state - NameError: name 'MockBrokerAPI' is not ...
FAILED tests/test_risk_engine_module.py::test_hard_stop_blocks_trading - TypeError: StrategySignal.__init__() missing 1 requi...
FAILED tests/test_risk_engine_package.py::TestRiskEnginePackage::test_risk_engine_import_from_package - ImportError: cannot i...
FAILED tests/test_retry_idempotency_integration.py::test_retry_exhaustion_with_idempotency - NameError: name 'MockBrokerAPI' ...
FAILED tests/test_risk_engine_package.py::TestRiskEnginePackage::test_update_exposure_requires_context - ImportError: cannot ...
FAILED tests/test_risk_engine_package.py::TestRiskEnginePackage::test_update_exposure_works_with_context - ImportError: canno...
FAILED tests/test_runtime_fixes.py::test_top_level_shims - FileNotFoundError: [Errno 2] No such file or directory: 'bot_engin...
FAILED tests/test_rl_module.py::test_rl_train_and_infer - AttributeError: module 'ai_trading.rl_trading.train' has no attribu...
FAILED tests/test_runner.py::test_run_forever_system_exit_nonzero - AttributeError: module 'ai_trading.runner' has no attribu...
FAILED tests/test_runtime_params_hydration.py::test_trading_config_has_required_parameters - assert 0.25 == 0.04
FAILED tests/test_runner.py::test_runner_as_main - AttributeError: module 'ai_trading.runner' has no attribute 'time'
FAILED tests/test_runtime_params_hydration.py::test_trading_config_from_env_loads_parameters - AssertionError: assert 8000.0 ...
FAILED tests/test_runner.py::test_runner_import_fallback - AssertionError: assert <function main at 0x7fa3140cd1c0> is <funct...
FAILED tests/test_runtime_params_hydration.py::test_build_runtime_hydrates_all_parameters - assert 0.25 == 0.04
FAILED tests/test_runner_additional.py::test_runner_starts - AttributeError: module 'ai_trading.core.bot_engine' has no attri...
FAILED tests/test_runtime_params_hydration.py::test_build_runtime_uses_config_values - pydantic_core._pydantic_core.Validatio...
FAILED tests/test_runtime_paths.py::test_http_utilities_available - AssertionError: assert False
FAILED tests/test_settings_config.py::test_settings_invalid_risk - Failed: DID NOT RAISE <class 'pydantic_core._pydantic_core...
FAILED tests/test_signals.py::test_prepare_indicators_calculates - ModuleNotFoundError: No module named 'retrain'
FAILED tests/test_short_selling_implementation.py::TestShortSellingImplementation::test_current_sell_logic_blocks_no_position
FAILED tests/test_short_selling_implementation.py::TestShortSellingImplementation::test_order_status_monitoring_needed - Attr...
FAILED tests/test_short_selling_implementation.py::TestShortSellingImplementation::test_sell_short_side_should_be_distinguished
FAILED tests/test_short_selling_implementation.py::TestShortSellingImplementation::test_sell_short_validation_exists - Module...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_stale_data - TypeError: _ensure_data_fresh() g...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_no_data - TypeError: _ensure_data_fresh() got ...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_empty_dataframe - TypeError: _ensure_data_fres...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_multiple_symbols - TypeError: _ensure_data_fre...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_utc_logging - TypeError: _ensure_data_fresh() ...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_timezone_handling - AssertionError: Should han...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_error_handling - TypeError: _ensure_data_fresh...
FAILED tests/test_strategies_base_extra.py::test_strategy_generate_base - TypeError: Can't instantiate abstract class BaseStr...
FAILED tests/test_strategy_allocator_exit.py::test_exit_confirmation - TypeError: StrategySignal.__init__() missing 1 require...
FAILED tests/test_strategy_allocator_regression.py::TestStrategyAllocatorRegression::test_signal_confirmation_with_zero_min_confidence
FAILED tests/test_strategy_allocator_regression.py::TestStrategyAllocatorRegression::test_config_missing_min_confidence_attribute
FAILED tests/test_strategy_allocator_regression.py::TestStrategyAllocatorRegression::test_config_none_min_confidence - TypeEr...
FAILED tests/test_strategy_allocator_regression.py::TestStrategyAllocatorRegression::test_signal_confirmation_boundary_conditions
FAILED tests/test_strategy_allocator_regression.py::TestStrategyAllocatorRegression::test_invalid_signal_confidence_handling
FAILED tests/test_strategy_allocator_regression.py::TestStrategyAllocatorRegression::test_multiple_instances_no_shared_state
FAILED tests/test_strategy_allocator_smoke.py::test_allocator - TypeError: StrategySignal.__init__() missing 1 required posit...
FAILED tests/test_signals.py::test_composite_signal_confidence - AttributeError: 'list' object has no attribute 'keys'
FAILED tests/test_skip_logic.py::test_skip_logic - AttributeError: None has no attribute 'submit'
FAILED tests/test_run_overlap.py::test_run_all_trades_overlap - RuntimeError: Model required but not configured. Set one of: ...
FAILED tests/test_runner.py::test_handle_signal_sets_shutdown - AttributeError: module 'ai_trading.runner' has no attribute '...
FAILED tests/test_runner.py::test_run_forever_exit - AttributeError: module 'ai_trading.runner' has no attribute 'time'
FAILED tests/test_slippage.py::test_slippage_limits - FileNotFoundError: [Errno 2] No such file or directory: 'logs/slippage....
FAILED tests/test_runner.py::test_run_forever_exception - AttributeError: module 'ai_trading.runner' has no attribute 'time'
FAILED tests/test_stage1_1.py::test_fetch_sentiment_graceful_when_requests_unavailable - AssertionError: assert 0 >= 1
FAILED tests/test_runner.py::test_run_forever_request_exception - AttributeError: module 'ai_trading.runner' has no attribute...
FAILED tests/test_talib_enforcement.py::test_audit_file_multiple_trades - FileNotFoundError: [Errno 2] No such file or direct...
FAILED tests/test_timeutils.py::test_nyse_session_dst - AssertionError: assert (13 == 13 and datetime.timezone.utc == zoneinf...
FAILED tests/test_trading_parameter_validation.py::test_validate_trading_parameters_no_name_error - FileNotFoundError: [Errno...
FAILED tests/test_trading_parameter_validation.py::test_buy_threshold_definition_order - FileNotFoundError: [Errno 2] No such...
FAILED tests/test_systemd_startup.py::TestSystemdStartupCompatibility::test_utc_timestamp_no_double_z - subprocess.CalledProc...
FAILED tests/test_trigger_meta_learning_conversion.py::test_trigger_meta_learning_conversion_pure_meta_format - NameError: na...
FAILED tests/test_systemd_startup.py::TestSystemdStartupCompatibility::test_lazy_import_behavior - subprocess.CalledProcessEr...
FAILED tests/test_talib_enforcement.py::test_talib_import_enforcement - AssertionError: Could not find end of TA library section
FAILED tests/test_talib_enforcement.py::test_audit_file_creation_and_permissions - TypeError: log_trade() got an unexpected k...
FAILED tests/test_trigger_meta_learning_conversion.py::test_trigger_meta_learning_conversion_pure_audit_format - NameError: n...
FAILED tests/test_trigger_meta_learning_conversion.py::test_trigger_meta_learning_conversion_mixed_format - NameError: name '...
FAILED tests/test_trigger_meta_learning_conversion.py::test_trigger_meta_learning_conversion_problem_statement_exact - NameEr...
FAILED tests/test_trigger_meta_learning_conversion.py::test_trigger_meta_learning_conversion_missing_file - NameError: name '...
FAILED tests/test_universe_fetch_pooling.py::test_universe_fetch_pooling - AttributeError: <module 'ai_trading.data_fetcher' ...
FAILED tests/test_yf_auto_adjust_and_cache.py::test_yfinance_auto_adjust_and_cache - ImportError: cannot import name '_yahoo_...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_fresh_data - ImportError: cannot import name '...
FAILED tests/test_submit_order_fix.py::test_submit_order_successful_execution - ImportError: cannot import name 'last_market_...
FAILED tests/test_submit_order_fix.py::test_submit_order_execution_error_propagation - ImportError: cannot import name 'last_...
FAILED tests/test_systemd_startup.py::TestSystemdStartupCompatibility::test_import_no_crash_without_credentials - subprocess....
FAILED tests/test_systemd_startup.py::TestSystemdStartupCompatibility::test_dual_credential_schema_with_env_file - subprocess...
FAILED tests/unit/test_alpaca_api.py::test_submit_order_uses_client_and_returns - AttributeError: <module 'alpaca_api' from '...
FAILED tests/unit/test_alpaca_api.py::test_pending_orders_lock_exists_and_is_lock - AssertionError: assert False
FAILED tests/unit/test_health_check.py::test_pre_trade_health_resolves_min_rows_without_ctx_attr - ImportError: cannot import...
FAILED tests/unit/test_retry.py::test_fast_retry_skips_sleep - assert 0.5141302449992509 < 0.01
FAILED tests/unit/test_retry.py::test_retry_eventually_succeeds - assert 3 == 2
FAILED tests/utils/test_retry.py::test_retry_succeeds_and_sleeps - assert 0 == 2
FAILED tests/utils/test_retry.py::test_backoff_caps - IndexError: list index out of range
FAILED tests/test_critical_trading_issues.py::TestOrderExecutionTracking::test_safe_submit_order_quantity_validation - Attrib...
FAILED tests/test_critical_trading_issues.py::TestLiquidityManagement::test_conservative_spread_threshold - NotImplementedError
FAILED tests/test_data_cache.py::test_disk_cache_basic - assert None is not None
FAILED tests/test_data_fetch.py::test_get_bars_df_spy_day - requests.exceptions.HTTPError: 403 Client Error: Forbidden for ur...{"ts": "2025-08-22 13:32:15,527", "level": "INFO", "name": "ai_trading.logging", "msg": "Logging configured succ…ully - no duplicates possible", "bot_phase": "GENERAL"}

FAILED tests/test_data_fetcher.py::test_get_minute_df - NotImplementedError
FAILED tests/test_data_fetcher.py::test_subscription_error_logged - AttributeError: <module 'ai_trading.data_fetcher' from '/...
FAILED tests/test_data_fetcher.py::test_fetch_bars_retry_invalid_feed - TypeError: _fetch_bars() takes 4 positional arguments...
FAILED tests/test_data_fetcher.py::test_finnhub_403_yfinance - AttributeError: None has no attribute 'download'
FAILED tests/test_data_fetcher.py::test_fetch_bars_empty_raises - TypeError: _fetch_bars() takes 4 positional arguments but 5...
FAILED tests/test_data_fetcher.py::test_fetch_minute_df_safe_handles_empty - ai_trading.core.bot_engine.DataFetchError: Minut...
ERROR tests/test_portfolio_integration.py
ERROR tests/test_institutional_kelly.py::TestKellyCalculator::test_kelly_calculator_initialization - AttributeError: 'NoneTyp...
ERROR tests/test_institutional_kelly.py::TestKellyCalculator::test_portfolio_kelly_calculation - AttributeError: 'NoneType' o...
ERROR tests/test_institutional_kelly.py::TestKellyCalculator::test_dynamic_kelly_adjustment - AttributeError: 'NoneType' obje...
ERROR tests/test_institutional_kelly.py::TestKellyCalculator::test_kelly_with_correlation - AttributeError: 'NoneType' object...
ERROR tests/test_institutional_kelly.py::TestKellyCalculator::test_calculation_history_recording - AttributeError: 'NoneType'...
ERROR tests/test_main_extended2.py::test_validate_environment_missing - AttributeError: 'Settings' object has no attribute 'W...
ERROR tests/test_portfolio_optimization.py::TestPortfolioOptimizer::test_portfolio_kelly_efficiency_calculation - AttributeEr...
ERROR tests/test_portfolio_optimization.py::TestPortfolioOptimizer::test_correlation_impact_calculation - AttributeError: 'No...
ERROR tests/test_portfolio_optimization.py::TestPortfolioOptimizer::test_trade_impact_evaluation - AttributeError: 'NoneType'...
ERROR tests/test_portfolio_optimization.py::TestPortfolioOptimizer::test_portfolio_decision_making - AttributeError: 'NoneTyp...
ERROR tests/test_portfolio_optimization.py::TestPortfolioOptimizer::test_rebalance_trigger_logic - AttributeError: 'NoneType'...
ERROR tests/test_portfolio_optimization.py::TestIntegration::test_integrated_portfolio_decision_workflow - AttributeError: 'N...
ERROR tests/test_portfolio_optimization.py::TestIntegration::test_churn_reduction_validation - AttributeError: 'NoneType' obj...
