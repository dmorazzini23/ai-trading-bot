<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="37" failures="263" skipped="49" tests="947" time="132.892" timestamp="2025-08-22T17:37:11.522744+00:00" hostname="eb0d9d0b5d89"><testcase classname="" name="tests.institutional.test_live_trading" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/institutional/test_live_trading.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/institutional/test_live_trading.py:21: in &lt;module&gt;
    from ai_trading.execution.live_trading import AlpacaExecutionEngine
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_advanced_features" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_advanced_features.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_advanced_features.py:31: in &lt;module&gt;
    from ai_trading.execution import slippage  # AI-AGENT-REF: use prod slippage module
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_batch_and_warmup" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_batch_and_warmup.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_batch_and_warmup.py:6: in &lt;module&gt;
    from ai_trading.data_fetcher import get_bars_batch, warmup_cache
E   ImportError: cannot import name 'warmup_cache' from 'ai_trading.data_fetcher' (/workspace/ai-trading-bot/ai_trading/data_fetcher.py)</error></testcase><testcase classname="" name="tests.test_benchmarks" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_benchmarks.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_benchmarks.py:6: in &lt;module&gt;
    from ai_trading import indicators, signals
ai_trading/signals.py:114: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_critical_trading_fixes" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_critical_trading_fixes.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_critical_trading_fixes.py:32: in &lt;module&gt;
    from ai_trading.execution.engine import ExecutionEngine
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_enhanced_signals" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_enhanced_signals.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_enhanced_signals.py:10: in &lt;module&gt;
    from ai_trading import signals
ai_trading/signals.py:114: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_execution_classes" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_execution_classes.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_execution_classes.py:10: in &lt;module&gt;
    from ai_trading.execution import ExecutionResult, OrderRequest
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_execution_engine_check_stops" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_execution_engine_check_stops.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_execution_engine_check_stops.py:1: in &lt;module&gt;
    from ai_trading.execution.engine import ExecutionEngine
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_execution_methods" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_execution_methods.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_execution_methods.py:1: in &lt;module&gt;
    from ai_trading.execution import ExecutionEngine
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_fill_rate_calculation_fix" time="0.000"><skipped message="collection skipped">('/workspace/ai-trading-bot/tests/test_fill_rate_calculation_fix.py', 21, 'Skipped: ExecutionEngine not available')</skipped></testcase><testcase classname="" name="tests.test_logger_rotator_smoke" time="0.000"><skipped message="collection skipped">('/workspace/ai-trading-bot/tests/test_logger_rotator_smoke.py', 10, 'Skipped: logger_rotator not available')</skipped></testcase><testcase classname="" name="tests.test_logging_behavior" time="0.000"><skipped message="collection skipped">('/workspace/ai-trading-bot/tests/test_logging_behavior.py', 15, 'Skipped: TradeSignal unavailable')</skipped></testcase><testcase classname="" name="tests.test_main_smoke" time="0.000"><skipped message="collection skipped">('/workspace/ai-trading-bot/tests/test_main_smoke.py', 9, 'Skipped: run module not available')</skipped></testcase><testcase classname="" name="tests.test_ml_model_loading" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_ml_model_loading.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_ml_model_loading.py:9: in &lt;module&gt;
    from sklearn.dummy import DummyClassifier
E   ModuleNotFoundError: No module named 'sklearn.dummy'; 'sklearn' is not a package</error></testcase><testcase classname="" name="tests.test_model_registry_roundtrip" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_model_registry_roundtrip.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_model_registry_roundtrip.py:8: in &lt;module&gt;
    from sklearn.linear_model import LinearRegression
E   ImportError: cannot import name 'LinearRegression' from 'sklearn.linear_model' (unknown location)</error></testcase><testcase classname="" name="tests.test_parallel_speed" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_parallel_speed.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_parallel_speed.py:4: in &lt;module&gt;
    from ai_trading import signals
ai_trading/signals.py:114: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_portfolio_integration" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_portfolio_integration.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_portfolio_integration.py:28: in &lt;module&gt;
    from ai_trading.signals import filter_signals_with_portfolio_optimization
ai_trading/signals.py:114: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_portfolio_optimization" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_portfolio_optimization.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_portfolio_optimization.py:13: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (  # AI-AGENT-REF: normalized import
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_property_based" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_property_based.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_property_based.py:13: in &lt;module&gt;
    from ai_trading import signals, utils
ai_trading/signals.py:114: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_signals" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_signals.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_signals.py:11: in &lt;module&gt;
    from ai_trading.signals import GaussianHMM, detect_market_regime_hmm
ai_trading/signals.py:114: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_signals_extended" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_signals_extended.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_signals_extended.py:1: in &lt;module&gt;
    from ai_trading import signals
ai_trading/signals.py:114: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.test_signals_scoring" time="0.000"><error message="collection failure">ImportError while importing test module '/workspace/ai-trading-bot/tests/test_signals_scoring.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_signals_scoring.py:3: in &lt;module&gt;
    from ai_trading import signals
ai_trading/signals.py:114: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in &lt;module&gt;
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'</error></testcase><testcase classname="" name="tests.unit.test_alpaca_api" time="0.000"><skipped message="collection skipped">('/workspace/ai-trading-bot/tests/unit/test_alpaca_api.py', 3, 'Skipped: alpaca_api module not found')</skipped></testcase><testcase classname="tests.allocators.test_confidence_gate_env" name="test_conf_gate_env_and_log" time="0.006" /><testcase classname="tests.test_alpaca_import_handling.TestAlpacaImportHandling" name="test_check_alpaca_available_function" time="0.003" /><testcase classname="tests.test_critical_fixes" name="test_risk_engine_missing_methods" time="0.004" /><testcase classname="tests.test_bot_engine_imports.TestBotEngineImports" name="test_import_types_annotation" time="0.004" /><testcase classname="tests.test_cfg_required_fields" name="test_cfg_required_fields_exist" time="0.003" /><testcase classname="tests.test_critical_fixes" name="test_bot_context_alpaca_client_compatibility" time="0.004" /><testcase classname="tests.test_bot_engine_unit" name="test_initialize_bot_returns_ctx_and_state" time="0.002" /><testcase classname="tests.config.test_mode_aliases" name="test_precedence" time="0.004" /><testcase classname="tests.test_bot_engine_unit" name="test_generate_signals_basic[prices0-expected0]" time="0.005" /><testcase classname="tests.test_cli_smoke" name="test_ai_trade_dry_run_exits_zero" time="0.856" /><testcase classname="tests.test_critical_fixes" name="test_process_manager_lock_mechanism" time="0.003" /><testcase classname="tests.config.test_mode_aliases" name="test_conflict_prefers_canonical" time="0.003" /><testcase classname="tests.test_alpaca_import_handling.TestAlpacaImportHandling" name="test_import_error_types" time="0.006" /><testcase classname="tests.config.test_mode_aliases" name="test_deprecation_logged_once" time="0.002" /><testcase classname="tests.test_alpaca_import_handling.TestAlpacaImportHandling" name="test_mock_classes_functionality" time="0.003" /><testcase classname="tests.test_critical_fixes" name="test_data_validation_freshness" time="0.007" /><testcase classname="tests.test_bot_engine_unit" name="test_generate_signals_basic[prices1-expected1]" time="0.004" /><testcase classname="tests.test_bot_engine_unit" name="test_generate_signals_basic[prices2-expected2]" time="0.004" /><testcase classname="tests.data_fetcher.test_datetime_narrow_exceptions" name="test_dt_invalid_raises_typeerror" time="0.004" /><testcase classname="tests.test_bot_engine_unit" name="test_generate_signals_missing_column_raises" time="0.003" /><testcase classname="tests.test_critical_fixes" name="test_data_validation_emergency_check" time="0.005" /><testcase classname="tests.test_alpaca_import_handling.TestAlpacaImportHandling" name="test_safe_submit_order_with_unavailable_alpaca" time="0.006" /><testcase classname="tests.data_fetcher.test_datetime_narrow_exceptions" name="test_dt_oob_raises_typeerror" time="0.003" /><testcase classname="tests.test_bot_engine_unit" name="test_execute_trades_sends_orders" time="0.002" /><testcase classname="tests.execution.test_fetch_minute_df_safe_empty" name="test_empty_minute_raises" time="0.004" /><testcase classname="tests.test_bot_engine_unit" name="test_run_trading_cycle_integration" time="0.004" /><testcase classname="tests.test_critical_fixes" name="test_risk_engine_exposure_tracking" time="0.003" /><testcase classname="tests.test_alpaca_import_handling.TestAlpacaImportHandling" name="test_service_startup_simulation" time="0.006" /><testcase classname="tests.runtime.test_alpaca_stub_no_typeerror" name="test_alpaca_stub_accepts_args_and_noops" time="0.002" /><testcase classname="tests.test_alpaca_init_contract" name="test_no_import_time_initialization" time="0.003" /><testcase classname="tests.test_critical_fixes" name="test_process_manager_multiple_instances_check" time="0.002" /><testcase classname="tests.test_bot_engine_unit" name="test_load_model_single" time="0.003" /><testcase classname="tests.runtime.test_alpaca_wrapped" name="test_submit_order_retries" time="0.110" /><testcase classname="tests.test_critical_fixes" name="test_audit_permission_handling" time="0.007" /><testcase classname="tests.test_bot_engine_unit" name="test_load_model_missing" time="0.003" /><testcase classname="tests.test_bot_engine_unit" name="test_load_model_ensemble" time="0.003" /><testcase classname="tests.test_alpaca_init_contract" name="test_ensure_returns_tuple_and_skips_in_shadow" time="0.006" /><testcase classname="tests.test_bot_engine_unit" name="test_health_check_various[0-False]" time="0.003" /><testcase classname="tests.test_critical_fixes" name="test_integration_risk_engine_methods" time="0.004" /><testcase classname="tests.test_bot_engine_unit" name="test_health_check_various[150-True]" time="0.002" /><testcase classname="tests.test_alpaca_init_contract" name="test_initialize_skips_in_shadow_mode" time="0.011" /><testcase classname="tests.test_bot_engine_unit" name="test_run_trading_cycle_empty_df_returns_no_orders" time="0.002" /><testcase classname="tests.test_critical_fixes_focused.TestCriticalFixes" name="test_confidence_normalization_exists" time="0.003" /><testcase classname="tests.test_bot_extended" name="test_compute_time_range" time="0.001" /><testcase classname="tests.test_bot_extended" name="test_get_latest_close_edge_cases" time="0.009" /><testcase classname="tests.test_critical_fixes_focused.TestCriticalFixes" name="test_sector_classification_fallback" time="0.005" /><testcase classname="tests.test_alpaca_init_contract" name="test_initialize_raises_when_missing_creds_and_not_shadow" time="0.004" /><testcase classname="tests.test_bot_extended" name="test_fetch_minute_df_safe_market_closed" time="0.002" /><testcase classname="tests.test_alpaca_time_params" name="test_daily_uses_date_only" time="0.005"><failure message="AttributeError: type object '_TFUnit' has no attribute 'Week'">mock_rest_cls = &lt;MagicMock name='TradeApiREST' id='140245807055184'&gt;

    @patch("ai_trading.alpaca_api.TradeApiREST")
    def test_daily_uses_date_only(mock_rest_cls):
        mock_rest = MagicMock()
        mock_rest.get_bars.return_value = _Resp(pd.DataFrame({"open": [1.0], "close": [1.1]}))
        mock_rest_cls.return_value = mock_rest
    
&gt;       df = get_bars_df("SPY", "Day", feed="iex", adjustment="all")

tests/test_alpaca_time_params.py:21: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:174: in get_bars_df
    base_tf = tf_raw if isinstance(tf_raw, TimeFrame) else TimeFrame(1, TimeFrameUnit.Day)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:40: in __init__
    self.validate_timeframe(amount, unit)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amount = 1, unit = &lt;TimeFrameUnit.Day: 'Day'&gt;

    @staticmethod
    def validate_timeframe(amount: int, unit: TimeFrameUnit):
        """Validates the amount value against the TimeFrameUnit value for consistency
    
        Args:
            amount (int): The number of multiples of unit
            unit (TimeFrameUnit): The base unit of time interval the TimeFrame is measured by
    
        Raises:
            ValueError: Raised if the values of amount and unit are not consistent with each other
        """
        if amount &lt;= 0:
            raise ValueError("Amount must be a positive integer value.")
    
        if unit == TimeFrameUnit.Minute and amount &gt; 59:
            raise ValueError(
                "Second or Minute units can only be "
                + "used with amounts between 1-59."
            )
    
        if unit == TimeFrameUnit.Hour and amount &gt; 23:
            raise ValueError("Hour units can only be used with amounts 1-23")
    
&gt;       if unit in (TimeFrameUnit.Day, TimeFrameUnit.Week) and amount != 1:
E       AttributeError: type object '_TFUnit' has no attribute 'Week'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:94: AttributeError</failure></testcase><testcase classname="tests.test_bot_extended" name="test_fetch_minute_df_safe_open" time="0.003"><failure message="ImportError: cannot import name 'last_minute_bar_age_seconds' from 'ai_trading.data_fetcher' (unknown location)">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f3d458f6250&gt;

    def test_fetch_minute_df_safe_open(monkeypatch):
        """DataFrame is returned when the market is open."""
        df = pd.DataFrame({"close": [1]}, index=[pd.Timestamp("2024-01-01")])
        monkeypatch.setattr(bot, "get_minute_df", lambda symbol, start_date, end_date: df)
&gt;       result = bot.fetch_minute_df_safe("AAPL")

tests/test_bot_extended.py:229: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:2060: in fetch_minute_df_safe
    _ensure_data_fresh(symbols=[symbol], max_age_seconds=600)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

symbols = ['AAPL'], max_age_seconds = 600

    def _ensure_data_fresh(symbols, max_age_seconds: int) -&gt; None:
        """
        Validate that the cached minute data for each symbol is recent enough.
        Logs UTC timestamps and fails fast if any symbol is stale.
        """
        try:
&gt;           from ai_trading.data_fetcher import last_minute_bar_age_seconds
E           ImportError: cannot import name 'last_minute_bar_age_seconds' from 'ai_trading.data_fetcher' (unknown location)

ai_trading/core/bot_engine.py:5792: ImportError</failure></testcase><testcase classname="tests.test_critical_fixes_focused.TestCriticalFixes" name="test_sentiment_circuit_breaker_thresholds" time="0.010" /><testcase classname="tests.test_critical_fixes_focused.TestCriticalFixes" name="test_short_selling_validation_exists" time="0.007"><failure message="ModuleNotFoundError: No module named 'cachetools'">self = &lt;tests.test_critical_fixes_focused.TestCriticalFixes testMethod=test_short_selling_validation_exists&gt;

    def test_short_selling_validation_exists(self):
        """Test that short selling validation method exists."""
        # P2 Fix: Short selling validation
&gt;       from ai_trading.execution.engine import ExecutionEngine

tests/test_critical_fixes_focused.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_alpaca_time_params" name="test_intraday_uses_rfc3339z" time="0.007" /><testcase classname="tests.test_alpaca_timeframe_mapping" name="test_day_timeframe_normalized" time="0.005"><failure message="AttributeError: type object '_TFUnit' has no attribute 'Week'">mock_rest_cls = &lt;MagicMock name='TradeApiREST' id='140245799324304'&gt;

    @patch("ai_trading.alpaca_api.TradeApiREST")
    def test_day_timeframe_normalized(mock_rest_cls):
        mock_rest = MagicMock()
        mock_rest.get_bars.return_value = _Resp(pd.DataFrame({"open": [1.0], "close": [1.1]}))
        mock_rest_cls.return_value = mock_rest
    
&gt;       df = get_bars_df("SPY", "Day", feed="iex", adjustment="all")

tests/test_alpaca_timeframe_mapping.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:174: in get_bars_df
    base_tf = tf_raw if isinstance(tf_raw, TimeFrame) else TimeFrame(1, TimeFrameUnit.Day)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:40: in __init__
    self.validate_timeframe(amount, unit)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amount = 1, unit = &lt;TimeFrameUnit.Day: 'Day'&gt;

    @staticmethod
    def validate_timeframe(amount: int, unit: TimeFrameUnit):
        """Validates the amount value against the TimeFrameUnit value for consistency
    
        Args:
            amount (int): The number of multiples of unit
            unit (TimeFrameUnit): The base unit of time interval the TimeFrame is measured by
    
        Raises:
            ValueError: Raised if the values of amount and unit are not consistent with each other
        """
        if amount &lt;= 0:
            raise ValueError("Amount must be a positive integer value.")
    
        if unit == TimeFrameUnit.Minute and amount &gt; 59:
            raise ValueError(
                "Second or Minute units can only be "
                + "used with amounts between 1-59."
            )
    
        if unit == TimeFrameUnit.Hour and amount &gt; 23:
            raise ValueError("Hour units can only be used with amounts 1-23")
    
&gt;       if unit in (TimeFrameUnit.Day, TimeFrameUnit.Week) and amount != 1:
E       AttributeError: type object '_TFUnit' has no attribute 'Week'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:94: AttributeError</failure></testcase><testcase classname="tests.test_alpaca_timeframe_mapping" name="test_tf_object_normalized" time="0.006"><failure message="AttributeError: type object '_TFUnit' has no attribute 'Week'">mock_rest_cls = &lt;MagicMock name='TradeApiREST' id='140245798861584'&gt;

    @patch("ai_trading.alpaca_api.TradeApiREST")
    def test_tf_object_normalized(mock_rest_cls):
        mock_rest = MagicMock()
        mock_rest.get_bars.return_value = _Resp(pd.DataFrame({"open": [1.0], "close": [1.1]}))
        mock_rest_cls.return_value = mock_rest
    
&gt;       df = get_bars_df("SPY", TimeFrame(1, TimeFrameUnit.Day), feed="iex", adjustment="all")

tests/test_alpaca_timeframe_mapping.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:40: in __init__
    self.validate_timeframe(amount, unit)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amount = 1, unit = &lt;TimeFrameUnit.Day: 'Day'&gt;

    @staticmethod
    def validate_timeframe(amount: int, unit: TimeFrameUnit):
        """Validates the amount value against the TimeFrameUnit value for consistency
    
        Args:
            amount (int): The number of multiples of unit
            unit (TimeFrameUnit): The base unit of time interval the TimeFrame is measured by
    
        Raises:
            ValueError: Raised if the values of amount and unit are not consistent with each other
        """
        if amount &lt;= 0:
            raise ValueError("Amount must be a positive integer value.")
    
        if unit == TimeFrameUnit.Minute and amount &gt; 59:
            raise ValueError(
                "Second or Minute units can only be "
                + "used with amounts between 1-59."
            )
    
        if unit == TimeFrameUnit.Hour and amount &gt; 23:
            raise ValueError("Hour units can only be used with amounts 1-23")
    
&gt;       if unit in (TimeFrameUnit.Day, TimeFrameUnit.Week) and amount != 1:
E       AttributeError: type object '_TFUnit' has no attribute 'Week'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:94: AttributeError</failure></testcase><testcase classname="tests.test_critical_fixes_focused.TestCriticalFixes" name="test_trade_execution_quantity_fix_exists" time="0.005"><failure message="ModuleNotFoundError: No module named 'cachetools'">self = &lt;tests.test_critical_fixes_focused.TestCriticalFixes testMethod=test_trade_execution_quantity_fix_exists&gt;

    def test_trade_execution_quantity_fix_exists(self):
        """Test that trade execution has the quantity calculation fix."""
        # P0 Fix: Quantity calculation bug
        # We can't easily test the actual fix without mocking orders, but we can verify
        # the _reconcile_partial_fills method exists and has been updated
    
&gt;       from ai_trading.execution.engine import ExecutionEngine

tests/test_critical_fixes_focused.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_alpaca_timeframe_mapping" name="test_minute_normalized" time="0.006"><failure message="AttributeError: type object '_TFUnit' has no attribute 'Week'">mock_rest_cls = &lt;MagicMock name='TradeApiREST' id='140245803049232'&gt;

    @patch("ai_trading.alpaca_api.TradeApiREST")
    def test_minute_normalized(mock_rest_cls):
        mock_rest = MagicMock()
        mock_rest.get_bars.return_value = _Resp(pd.DataFrame({"open": [1.0], "close": [1.1]}))
        mock_rest_cls.return_value = mock_rest
    
&gt;       df = get_bars_df("SPY", "Minute", feed="iex", adjustment="all")

tests/test_alpaca_timeframe_mapping.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:174: in get_bars_df
    base_tf = tf_raw if isinstance(tf_raw, TimeFrame) else TimeFrame(1, TimeFrameUnit.Day)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:40: in __init__
    self.validate_timeframe(amount, unit)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amount = 1, unit = &lt;TimeFrameUnit.Day: 'Day'&gt;

    @staticmethod
    def validate_timeframe(amount: int, unit: TimeFrameUnit):
        """Validates the amount value against the TimeFrameUnit value for consistency
    
        Args:
            amount (int): The number of multiples of unit
            unit (TimeFrameUnit): The base unit of time interval the TimeFrame is measured by
    
        Raises:
            ValueError: Raised if the values of amount and unit are not consistent with each other
        """
        if amount &lt;= 0:
            raise ValueError("Amount must be a positive integer value.")
    
        if unit == TimeFrameUnit.Minute and amount &gt; 59:
            raise ValueError(
                "Second or Minute units can only be "
                + "used with amounts between 1-59."
            )
    
        if unit == TimeFrameUnit.Hour and amount &gt; 23:
            raise ValueError("Hour units can only be used with amounts 1-23")
    
&gt;       if unit in (TimeFrameUnit.Day, TimeFrameUnit.Week) and amount != 1:
E       AttributeError: type object '_TFUnit' has no attribute 'Week'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:94: AttributeError</failure></testcase><testcase classname="tests.runtime.test_exception_narrowing_df_main" name="test_data_fetcher_has_importerror_for_optional_imports" time="0.006" /><testcase classname="tests.runtime.test_exception_narrowing_df_main" name="test_data_fetcher_json_decode_is_valueerror_only" time="0.003"><failure message="assert None&#10; +  where None = &lt;function search at 0x7ff8f111a200&gt;('resp\\.json\\(\\)\\n\\s*except ValueError:\\n\\s*payload\\s*=\\s*\\{\\}', 'from __future__ import annotations\n\nimport datetime as _dt\nimport os\nimport warnings  # AI-AGENT-REF: control yfi..._minute_yfinance&quot;,\n    &quot;is_market_open&quot;,\n    &quot;get_last_available_bar&quot;,\n    &quot;fh_fetcher&quot;,\n    &quot;get_minute_df&quot;,\n]\n')&#10; +    where &lt;function search at 0x7ff8f111a200&gt; = re.search">def test_data_fetcher_json_decode_is_valueerror_only():
        src = _source(df_mod)
        # The JSON decode guard around resp.json() should not be broad
&gt;       assert re.search(r"resp\.json\(\)\n\s*except ValueError:\n\s*payload\s*=\s*\{\}", src)
E       assert None
E        +  where None = &lt;function search at 0x7ff8f111a200&gt;('resp\\.json\\(\\)\\n\\s*except ValueError:\\n\\s*payload\\s*=\\s*\\{\\}', 'from __future__ import annotations\n\nimport datetime as _dt\nimport os\nimport warnings  # AI-AGENT-REF: control yfi..._minute_yfinance",\n    "is_market_open",\n    "get_last_available_bar",\n    "fh_fetcher",\n    "get_minute_df",\n]\n')
E        +    where &lt;function search at 0x7ff8f111a200&gt; = re.search

tests/runtime/test_exception_narrowing_df_main.py:23: AssertionError</failure></testcase><testcase classname="tests.runtime.test_exception_narrowing_df_main" name="test_main_get_int_env_narrows_to_valueerror" time="0.002" /><testcase classname="tests.runtime.test_exception_narrowing_df_main" name="test_main_validate_runtime_config_wrapper_is_valueerror" time="0.002" /><testcase classname="tests.runtime.test_exception_narrowing_df_main" name="test_start_api_with_signal_uses_specific_errors" time="0.002" /><testcase classname="tests.test_alpha_quality" name="test_fixed_horizon_return" time="0.015" /><testcase classname="tests.runtime.test_http_wrapped" name="test_wrapped_get_retries_and_parses" time="0.002"><failure message="Exception: boom">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3d471d0&gt;

    def test_wrapped_get_retries_and_parses(monkeypatch):
        calls = []
    
        def fake_request(self, method, url, **kwargs):
            calls.append(kwargs)
            assert kwargs["timeout"] == clamp_timeout(None, default_non_test=HTTP_TIMEOUT)
            if len(calls) == 1:
                raise requests.exceptions.RequestException("boom")
            return DummyResp({"ok": True})
    
        # Patch session.request used by wrapper
        monkeypatch.setattr(requests.Session, "request", fake_request)
        # Patch requests.get per requirement, though wrapper uses session
        monkeypatch.setattr(requests, "get", lambda url, **kw: fake_request(None, "GET", url, **kw))
    
&gt;       resp = http.get("https://example.com")

tests/runtime/test_http_wrapped.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/utils/http.py:196: in get
    return request("GET", url, **kwargs)
ai_trading/utils/http.py:131: in request
    resp = retry_call(
ai_trading/utils/retry.py:31: in retry_call
    return func(*args, **kwargs)
ai_trading/utils/http.py:119: in _do_request
    return sess.request(method, url, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;requests.sessions.Session object at 0x7ff8d80b4710&gt;, method = 'GET', url = 'https://example.com'
kwargs = {'timeout': 0.25}, @py_assert0 = None, @py_assert4 = None, @py_assert7 = None, @py_assert2 = None

    def fake_request(self, method, url, **kwargs):
        calls.append(kwargs)
        assert kwargs["timeout"] == clamp_timeout(None, default_non_test=HTTP_TIMEOUT)
        if len(calls) == 1:
&gt;           raise requests.exceptions.RequestException("boom")
E           Exception: boom

tests/runtime/test_http_wrapped.py:21: Exception</failure></testcase><testcase classname="tests.test_alpha_quality" name="test_no_leakage_validation" time="0.025" /><testcase classname="tests.runtime.test_import_contract_cli" name="test_import_contract_ok" time="0.206" /><testcase classname="tests.test_alpha_quality" name="test_slippage_calculation" time="0.010" /><testcase classname="tests.test_critical_fixes_focused" name="test_position_sizing_minimum_viable" time="0.002" /><testcase classname="tests.test_alpha_quality" name="test_rl_reward_penalties" time="0.004" /><testcase classname="tests.test_critical_fixes_focused" name="test_meta_learning_price_conversion" time="0.010" /><testcase classname="tests.test_alpha_quality" name="test_model_registry" time="0.006"><failure message="_pickle.PicklingError: Can't pickle &lt;class 'unittest.mock.Mock'&gt;: it's not the same object as unittest.mock.Mock">def test_model_registry():
        """Test model registry functionality."""
        try:
            import os
            import tempfile
    
            from ai_trading.model_registry import ModelRegistry
    
            # Create temporary directory for testing
            with tempfile.TemporaryDirectory() as temp_dir:
                registry = ModelRegistry(temp_dir)
    
                # Create a mock model
                mock_model = Mock()
                mock_model.__class__.__name__ = "MockModel"
    
                metadata = {
                    "training_date": "2024-01-01",
                    "cv_score": 0.85,
                    "feature_count": 10
                }
    
                # Register model
&gt;               model_id = registry.register_model(
                    model=mock_model,
                    strategy="test_strategy",
                    model_type="mock",
                    metadata=metadata
                )

tests/test_alpha_quality.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;ai_trading.model_registry.ModelRegistry object at 0x7f8d853fd990&gt;, model = &lt;MockModel id='140245802133392'&gt;
strategy = 'test_strategy', model_type = 'mock'
metadata = {'cv_score': 0.85, 'feature_count': 10, 'training_date': '2024-01-01'}, dataset_fingerprint = None, tags = None

    def register_model(
        self,
        model: Any,
        strategy: str,
        model_type: str,
        metadata: dict[str, Any] | None = None,
        dataset_fingerprint: str | None = None,
        tags: list[str] | None = None,
    ) -&gt; str:
        """Store model + metadata and return deterministic ID."""
        try:
&gt;           blob = pickle.dumps(model)
E           _pickle.PicklingError: Can't pickle &lt;class 'unittest.mock.Mock'&gt;: it's not the same object as unittest.mock.Mock

ai_trading/model_registry.py:65: PicklingError</failure></testcase><testcase classname="tests.test_critical_fixes_focused" name="test_liquidity_minimum_position" time="0.003" /><testcase classname="tests.test_critical_fixes_focused" name="test_stale_data_bypass_startup" time="0.003" /><testcase classname="tests.test_alpha_quality" name="test_walk_forward_monotone_timeline" time="0.003" /><testcase classname="tests.test_critical_fixes_focused" name="test_rfc3339_timestamp_api_format" time="0.002" /><testcase classname="tests.test_critical_fixes_implementation" name="test_metrics_division_by_zero_protection" time="0.008" /><testcase classname="tests.test_alpha_quality" name="test_feature_pipeline_no_leakage" time="0.007" /><testcase classname="tests.test_api_settings" name="test_api_host_port_defaults_present" time="0.003" /><testcase classname="tests.test_critical_fixes_implementation" name="test_algorithm_optimizer_thread_safety" time="0.013" /><testcase classname="tests.test_artifacts_directories" name="test_walkforward_artifacts_directory" time="0.010"><failure message="ModuleNotFoundError: No module named 'sklearn.model_selection'; 'sklearn' is not a package">def test_walkforward_artifacts_directory():
        """Test that walkforward creates artifacts directory with env override."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Set custom artifacts directory
            custom_artifacts = os.path.join(temp_dir, "custom_artifacts")
            os.environ["ARTIFACTS_DIR"] = custom_artifacts
    
            try:
                # Import and create evaluator
&gt;               from ai_trading.evaluation.walkforward import WalkForwardEvaluator

tests/test_artifacts_directories.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/evaluation/walkforward.py:41: in &lt;module&gt;
    from ..data.splits import walkforward_splits
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Time series cross-validation splits with purging and embargo.
    
    Provides leak-proof data splitting for financial time series,
    including purged group time series splits and walk-forward analysis.
    """
    
    from collections.abc import Iterator
    from datetime import datetime, timedelta
    
    import numpy as np
    import pandas as pd
    
    # sklearn is a hard dependency
&gt;   from sklearn.model_selection import BaseCrossValidator
E   ModuleNotFoundError: No module named 'sklearn.model_selection'; 'sklearn' is not a package

ai_trading/data/splits.py:15: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_critical_fixes_implementation" name="test_sentiment_cache_memory_leak_prevention" time="0.005"><failure message="NameError: name 'requests' is not defined">from __future__ import annotations
    
    from functools import lru_cache
    
    try:  # AI-AGENT-REF: optional cachetools TTL cache
&gt;       from cachetools import TTLCache
E       ModuleNotFoundError: No module named 'cachetools'

ai_trading/predict.py:6: ModuleNotFoundError

During handling of the above exception, another exception occurred:

    def test_sentiment_cache_memory_leak_prevention():
        """Test sentiment cache prevents memory leaks."""
        # Mock the imports to avoid external dependencies
&gt;       from ai_trading import predict

tests/test_critical_fixes_implementation.py:99: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    from __future__ import annotations
    
    from functools import lru_cache
    
    try:  # AI-AGENT-REF: optional cachetools TTL cache
        from cachetools import TTLCache
    
        _CACHETOOLS_AVAILABLE = True
        _sentiment_cache = TTLCache(maxsize=1000, ttl=3600)
&gt;   except (requests.RequestException, TimeoutError):
E   NameError: name 'requests' is not defined

ai_trading/predict.py:10: NameError</failure></testcase><testcase classname="tests.test_critical_fixes_implementation" name="test_circular_buffer_memory_efficiency" time="0.002" /><testcase classname="tests.test_critical_fixes_implementation" name="test_incremental_indicators" time="0.002" /><testcase classname="tests.test_critical_fixes_implementation" name="test_market_data_validation" time="0.014" /><testcase classname="tests.test_artifacts_directories" name="test_model_registry_directory" time="0.005" /><testcase classname="tests.test_audit_column_fix" name="test_log_trade" time="0.005" /><testcase classname="tests.test_critical_fixes_implementation" name="test_security_manager" time="0.014"><failure message="ModuleNotFoundError: No module named 'cryptography'">def test_security_manager():
        """Test security manager functionality."""
        sys.path.append('ai_trading')
&gt;       from security import mask_sensitive_data

tests/test_critical_fixes_implementation.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """Security enhancements for production trading platform.
    
    Provides secure configuration with encryption for API keys,
    comprehensive audit logging for compliance, and prevents
    API key exposure in logs and error messages.
    
    AI-AGENT-REF: Security enhancements for institutional-grade trading
    """
    
    from __future__ import annotations
    
    import base64
    import json
    import logging
    import os
    import secrets
    from dataclasses import dataclass
    from datetime import UTC, datetime
    from enum import Enum
    from pathlib import Path
    from typing import Any
    
    # Optional cryptography import; tests may run without the package
    try:  # AI-AGENT-REF: handle missing cryptography gracefully
&gt;       from cryptography.fernet import Fernet
E       ModuleNotFoundError: No module named 'cryptography'

ai_trading/security.py:25: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_audit_column_fix" name="test_csv_column_alignment" time="0.003" /><testcase classname="tests.test_audit_column_fix" name="test_no_uuid_corruption" time="0.003" /><testcase classname="tests.test_audit_smoke" name="test_log_trade" time="0.003" /><testcase classname="tests.test_backtest_smoke" name="test_backtester_engine_basic" time="0.017"><skipped type="pytest.xfail" message="minimal data may produce no trades" /></testcase><testcase classname="tests.runtime.test_import_contract_cli" name="test_import_contract_timeout_simulated" time="0.225"><failure message="AssertionError: assert 'TIMEOUT' in (('' or ''))&#10; +  where '' = CompletedProcess(args=['/root/.pyenv/versions/3.11.12/bin/python3.11', '/workspace/ai-trading-bot/tools/import_contract.py', '--ci', '--timeout', '0.1', '--modules', 'sys'], returncode=124, stdout='', stderr='').stderr">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3d46010&gt;

    def test_import_contract_timeout_simulated(monkeypatch):
        env = os.environ.copy()
        env["IMPORT_CONTRACT_SIMULATE_HANG"] = "1"
        cp = subprocess.run(
            [sys.executable, _script_path(), "--ci", "--timeout", "0.1", "--modules", "sys"],
            capture_output=True,
            text=True,
            env=env,
            check=False,
        )
        assert cp.returncode != 0
&gt;       assert "TIMEOUT" in (cp.stderr or "")
E       AssertionError: assert 'TIMEOUT' in (('' or ''))
E        +  where '' = CompletedProcess(args=['/root/.pyenv/versions/3.11.12/bin/python3.11', '/workspace/ai-trading-bot/tools/import_contract.py', '--ci', '--timeout', '0.1', '--modules', 'sys'], returncode=124, stdout='', stderr='').stderr

tests/runtime/test_import_contract_cli.py:32: AssertionError</failure></testcase><testcase classname="tests.test_critical_fixes_implementation" name="test_configuration_validation" time="0.004" /><testcase classname="tests.test_critical_fixes_implementation" name="test_dependency_injection" time="0.011"><failure message="NameError: name 'MockConfigManager' is not defined">def test_dependency_injection():
        """Test dependency injection container."""
        sys.path.append('ai_trading')
        from core.interfaces import IConfigManager, SimpleDependencyContainer
    
        container = SimpleDependencyContainer()
    
        # Mock implementation
        # Register implementation
&gt;       container.register(IConfigManager, MockConfigManager)
E       NameError: name 'MockConfigManager' is not defined

tests/test_critical_fixes_implementation.py:260: NameError</failure></testcase><testcase classname="tests.test_critical_fixes_implementation" name="test_performance_optimizations" time="0.004"><failure message="AttributeError: 'IndicatorManager' object has no attribute 'create_indicator'">def test_performance_optimizations():
        """Test performance optimizations work correctly."""
        sys.path.append('ai_trading')
        from indicator_manager import IndicatorManager, IndicatorType
    
        manager = IndicatorManager()
    
        # Create indicators
&gt;       sma_id = manager.create_indicator(IndicatorType.SIMPLE_MOVING_AVERAGE, "TEST", 5)
E       AttributeError: 'IndicatorManager' object has no attribute 'create_indicator'

tests/test_critical_fixes_implementation.py:282: AttributeError</failure></testcase><testcase classname="tests.test_critical_fixes_simple" name="test_timestamp_format_includes_timezone" time="0.003" /><testcase classname="tests.test_critical_fixes_simple" name="test_position_sizing_minimum_viable" time="0.002" /><testcase classname="tests.test_critical_fixes_simple" name="test_meta_learning_price_conversion" time="0.002" /><testcase classname="tests.test_critical_fixes_simple" name="test_liquidity_minimum_position" time="0.002" /><testcase classname="tests.test_critical_fixes_simple" name="test_stale_data_bypass_startup" time="0.002" /><testcase classname="tests.test_critical_fixes_simple" name="test_rfc3339_timestamp_api_format" time="0.001" /><testcase classname="tests.test_critical_fixes_validation.TestCriticalFixes" name="test_cache_behavior" time="0.002" /><testcase classname="tests.test_critical_fixes_validation.TestCriticalFixes" name="test_data_staleness_detection_improvement" time="0.004"><failure message="AssertionError: True is not false : Regular day should not be detected as holiday">self = &lt;tests.test_critical_fixes_validation.TestCriticalFixes testMethod=test_data_staleness_detection_improvement&gt;

    def test_data_staleness_detection_improvement(self):
        """Test 4: Data Staleness Detection - Weekend/holiday awareness."""
        from ai_trading.utils.base import is_market_holiday, is_weekend
    
        # Test weekend detection
        saturday = datetime(2024, 1, 6, 12, 0, tzinfo=UTC)  # Saturday
        sunday = datetime(2024, 1, 7, 12, 0, tzinfo=UTC)  # Sunday
        monday = datetime(2024, 1, 8, 12, 0, tzinfo=UTC)  # Monday
    
        self.assertTrue(is_weekend(saturday), "Saturday should be detected as weekend")
        self.assertTrue(is_weekend(sunday), "Sunday should be detected as weekend")
        self.assertFalse(is_weekend(monday), "Monday should not be detected as weekend")
    
        # Test holiday detection
        new_years = date(2024, 1, 1)  # New Year's Day
        christmas = date(2024, 12, 25)  # Christmas
        regular_day = date(2024, 3, 15)  # Regular Friday
    
        self.assertTrue(
            is_market_holiday(new_years), "New Year's should be detected as holiday"
        )
        self.assertTrue(
            is_market_holiday(christmas), "Christmas should be detected as holiday"
        )
&gt;       self.assertFalse(
            is_market_holiday(regular_day),
            "Regular day should not be detected as holiday",
        )
E       AssertionError: True is not false : Regular day should not be detected as holiday

tests/test_critical_fixes_validation.py:72: AssertionError</failure></testcase><testcase classname="tests.test_critical_fixes_validation.TestCriticalFixes" name="test_error_handling_robustness" time="0.003" /><testcase classname="tests.test_critical_fixes_validation.TestCriticalFixes" name="test_meta_learning_price_validation" time="0.006"><failure message="AssertionError: 3 != 2 : Should have 2 rows with valid positive prices">self = &lt;tests.test_critical_fixes_validation.TestCriticalFixes testMethod=test_meta_learning_price_validation&gt;

    def test_meta_learning_price_validation(self):
        """Test 2: MetaLearning Data Validation - Price validation logic."""
        # Mock pandas for testing
        try:
            import pandas as pd
    
            # Test data with mixed price types
            test_data = {
                "entry_price": ["100.50", "200", "invalid", "50.25"],
                "exit_price": ["105.75", "195", "0", "55.00"],
                "side": ["buy", "sell", "buy", "sell"],
                "signal_tags": ["momentum", "mean_revert", "momentum", "trend"],
            }
            df = pd.DataFrame(test_data)
    
            # Apply the validation logic from meta_learning.py
            df["entry_price"] = pd.to_numeric(df["entry_price"], errors="coerce")
            df["exit_price"] = pd.to_numeric(df["exit_price"], errors="coerce")
            df = df.dropna(subset=["entry_price", "exit_price"])
    
            # Filter out non-positive prices
            df = df[(df["entry_price"] &gt; 0) &amp; (df["exit_price"] &gt; 0)]
    
            # Should have 2 valid rows (first and last)
&gt;           self.assertEqual(
                len(df), 2, "Should have 2 rows with valid positive prices"
            )
E           AssertionError: 3 != 2 : Should have 2 rows with valid positive prices

tests/test_critical_fixes_validation.py:101: AssertionError</failure></testcase><testcase classname="tests.test_critical_fixes_validation.TestCriticalFixes" name="test_sentiment_circuit_breaker_constants" time="0.002" /><testcase classname="tests.test_critical_fixes_validation.TestCriticalFixes" name="test_systemd_service_configuration" time="0.002"><failure message="AssertionError: 'NoNewPrivileges=true' not found in '[Unit]\nDescription=AI Trading Bot\nAfter=network.target\n\n[Service]\nType=simple\nUser=aiuser\nGroup=aiuser\nWorkingDirectory=/home/aiuser/ai-trading-bot\nEnvironment=PATH=/home/aiuser/ai-trading-bot/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin\nEnvironment=AI_TRADER_MODEL_MODULE=ai_trading.models.baseline\nEnvironmentFile=-/home/aiuser/ai-trading-bot/.env\nExecStart=/home/aiuser/ai-trading-bot/venv/bin/python -m ai_trading.main\nRestart=always\nRestartSec=10\nStandardOutput=journal\nStandardError=journal\n\n[Install]\nWantedBy=multi-user.target\n' : Should have security restrictions">self = &lt;tests.test_critical_fixes_validation.TestCriticalFixes testMethod=test_systemd_service_configuration&gt;

    def test_systemd_service_configuration(self):
        """Test 3: Service Configuration - systemd service file."""
        service_file = os.path.join(
            os.getcwd(), "packaging", "systemd", "ai-trading.service"
        )
        self.assertTrue(os.path.exists(service_file), "service file should exist")
    
        # Legacy service files should be absent
        self.assertFalse(os.path.exists("ai-trading-bot.service"))
        self.assertFalse(os.path.exists(os.path.join("deploy", "ai-trading.service")))
    
        with open(service_file) as f:
            content = f.read()
    
        # Check key configuration elements
        self.assertIn("User=aiuser", content, "Service should run as aiuser")
        self.assertIn("Group=aiuser", content, "Service should run as aiuser group")
        self.assertIn(
            "WorkingDirectory=/home/aiuser/ai-trading-bot",
            content,
            "Should have correct working directory",
        )
&gt;       self.assertIn(
            "NoNewPrivileges=true", content, "Should have security restrictions"
        )
E       AssertionError: 'NoNewPrivileges=true' not found in '[Unit]\nDescription=AI Trading Bot\nAfter=network.target\n\n[Service]\nType=simple\nUser=aiuser\nGroup=aiuser\nWorkingDirectory=/home/aiuser/ai-trading-bot\nEnvironment=PATH=/home/aiuser/ai-trading-bot/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin\nEnvironment=AI_TRADER_MODEL_MODULE=ai_trading.models.baseline\nEnvironmentFile=-/home/aiuser/ai-trading-bot/.env\nExecStart=/home/aiuser/ai-trading-bot/venv/bin/python -m ai_trading.main\nRestart=always\nRestartSec=10\nStandardOutput=journal\nStandardError=journal\n\n[Install]\nWantedBy=multi-user.target\n' : Should have security restrictions

tests/test_critical_fixes_validation.py:137: AssertionError</failure></testcase><testcase classname="tests.test_critical_issue_fixes.TestCriticalIssueFixes" name="test_issue_1_meta_learning_trigger_exists" time="0.002" /><testcase classname="tests.test_critical_issue_fixes.TestCriticalIssueFixes" name="test_issue_2_sentiment_circuit_breaker_thresholds" time="0.003" /><testcase classname="tests.test_bars_fallback" name="test_resample_minute_to_daily_basic" time="0.048" /><testcase classname="tests.test_critical_issue_fixes.TestCriticalIssueFixes" name="test_issue_3_quantity_tracking_logging" time="0.002" /><testcase classname="tests.test_critical_issue_fixes.TestCriticalIssueFixes" name="test_issue_4_position_limit_increase" time="0.002" /><testcase classname="tests.test_critical_issues_resolution.TestCriticalIssuesResolution" name="test_market_data_validation_logic" time="0.002" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_apca_schema_only" time="0.002" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_alpaca_precedence_over_apca" time="0.003" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_mixed_schema_alpaca_key_apca_secret" time="0.002" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_mixed_schema_apca_key_alpaca_secret" time="0.002" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_default_base_url_when_missing" time="0.002" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_missing_credentials" time="0.002" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_partial_credentials_api_key_only" time="0.012" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_partial_credentials_secret_key_only" time="0.003" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_warn_duplicate_env_keys_conflicting" time="0.005" /><testcase classname="tests.test_bars_timeframe_feed_canonicalization" name="test_canonicalizers_map_weird_values_to_safe_defaults" time="0.002" /><testcase classname="tests.test_bars_timeframe_feed_canonicalization" name="test_safe_get_stock_bars_uses_canonicalized_values" time="0.354" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_warn_duplicate_env_keys_no_conflict" time="0.004" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_validate_alpaca_credentials_skip_in_testing" time="0.002" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_validate_alpaca_credentials_missing_production" time="0.003" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_validate_alpaca_credentials_success_alpaca_schema" time="0.003" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_validate_alpaca_credentials_success_apca_schema" time="0.004" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_validate_alpaca_credentials_partial_key_only" time="0.002" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_validate_alpaca_credentials_partial_secret_only" time="0.003" /><testcase classname="tests.test_dynamic_position_sizing" name="test_auto_mode_resolves_from_equity_and_capital_cap" time="0.002" /><testcase classname="tests.runtime.test_no_broad_except_in_hotpaths" name="test_no_broad_except_in_hotpaths" time="1.079" /><testcase classname="tests.test_dynamic_position_sizing" name="test_auto_mode_fallback_on_error" time="0.002" /><testcase classname="tests.test_ellipsis_fix.TestEllipsisFix" name="test_get_runtime_context_or_none" time="0.005" /><testcase classname="tests.test_ellipsis_fix.TestEllipsisFix" name="test_get_runtime_context_or_none_error" time="0.003"><failure message="Exception: Context unavailable">self = &lt;tests.test_ellipsis_fix.TestEllipsisFix testMethod=test_get_runtime_context_or_none_error&gt;

    def test_get_runtime_context_or_none_error(self):
        """Test runtime context accessor handles errors gracefully."""
        with patch('ai_trading.core.bot_engine.get_ctx') as mock_get_ctx:
            with patch('ai_trading.core.bot_engine._log') as mock_log:
                # Test error handling
                mock_get_ctx.side_effect = Exception("Context unavailable")
    
&gt;               result = _get_runtime_context_or_none()

tests/test_ellipsis_fix.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:5596: in _get_runtime_context_or_none
    lbc = get_ctx()
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1124: in __call__
    return self._mock_call(*args, **kwargs)
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1128: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;MagicMock name='get_ctx' id='140684882813392'&gt;, args = (), kwargs = {}, effect = Exception('Context unavailable')

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
&gt;               raise effect
E               Exception: Context unavailable

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1183: Exception</failure></testcase><testcase classname="tests.test_cli_smoke" name="test_ai_backtest_dry_run_exits_zero" time="0.832" /><testcase classname="tests.test_batch_paths" name="test_regime_batch" time="0.009" /><testcase classname="tests.test_batch_paths" name="test_pretrade_batch" time="0.005" /><testcase classname="tests.test_batch_paths" name="test_intraday_entries_and_exits" time="0.005" /><testcase classname="tests.test_bot" name="test_screen_candidates_empty" time="0.006" /><testcase classname="tests.test_bot_engine" name="test_prepare_indicators_creates_required_columns" time="0.009" /><testcase classname="tests.test_bot_engine" name="test_prepare_indicators_insufficient_data" time="0.009" /><testcase classname="tests.test_bot_engine" name="test_prepare_indicators_all_nan_columns" time="0.007" /><testcase classname="tests.test_bot_engine_edge_cases" name="test_prepare_indicators_missing_close_column" time="0.002" /><testcase classname="tests.test_bot_engine_edge_cases" name="test_prepare_indicators_non_numeric_close" time="0.002" /><testcase classname="tests.test_bot_engine_edge_cases" name="test_prepare_indicators_empty_dataframe" time="0.002" /><testcase classname="tests.test_bot_engine_edge_cases" name="test_prepare_indicators_single_row" time="0.008" /><testcase classname="tests.test_bot_engine_imports.TestBotEngineImports" name="test_model_pipeline_import_fallback" time="0.003" /><testcase classname="tests.test_bot_engine_imports.TestBotEngineImports" name="test_model_pipeline_import_fallback_to_legacy" time="0.003" /><testcase classname="tests.test_bot_engine_imports.TestBotEngineImports" name="test_import_robustness_when_both_fail" time="0.010" /><testcase classname="tests.test_data_fetcher" name="test_fetch_minute_df_safe_no_retry" time="0.003"><failure message="ImportError: cannot import name 'last_minute_bar_age_seconds' from 'ai_trading.data_fetcher' (unknown location)">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d854d9dd0&gt;

    def test_fetch_minute_df_safe_no_retry(monkeypatch):
        calls = []
    
        def fake_get(sym, start, end):
            calls.append(1)
            return pd.DataFrame({"close": [1]}, index=[pd.Timestamp("2023-01-01")])
    
        monkeypatch.setattr("ai_trading.core.bot_engine.get_minute_df", fake_get)
&gt;       result = fetch_minute_df_safe("AAPL")

tests/test_data_fetcher.py:246: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:2060: in fetch_minute_df_safe
    _ensure_data_fresh(symbols=[symbol], max_age_seconds=600)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

symbols = ['AAPL'], max_age_seconds = 600

    def _ensure_data_fresh(symbols, max_age_seconds: int) -&gt; None:
        """
        Validate that the cached minute data for each symbol is recent enough.
        Logs UTC timestamps and fails fast if any symbol is stale.
        """
        try:
&gt;           from ai_trading.data_fetcher import last_minute_bar_age_seconds
E           ImportError: cannot import name 'last_minute_bar_age_seconds' from 'ai_trading.data_fetcher' (unknown location)

ai_trading/core/bot_engine.py:5792: ImportError</failure></testcase><testcase classname="tests.test_broker_alpaca" name="test_list_open_positions_returns_objects" time="0.002" /><testcase classname="tests.test_broker_alpaca" name="test_get_open_position_uses_sdk_then_falls_back" time="0.002" /><testcase classname="tests.test_broker_alpaca_adapter" name="test_adapter_orders_new" time="0.002" /><testcase classname="tests.test_broker_alpaca_adapter" name="test_adapter_orders_old" time="0.002" /><testcase classname="tests.test_broker_alpaca_adapter" name="test_positions_and_account_old" time="0.002"><failure message="AssertionError: assert [] == ['pos-old']&#10;  &#10;  Right contains one more item: 'pos-old'&#10;  Use -v to get more diff">def test_positions_and_account_old():
        fake = FakeOld()
        b = AlpacaBroker(fake)
&gt;       assert b.list_open_positions() == ["pos-old"]
E       AssertionError: assert [] == ['pos-old']
E         
E         Right contains one more item: 'pos-old'
E         Use -v to get more diff

tests/test_broker_alpaca_adapter.py:86: AssertionError</failure></testcase><testcase classname="tests.test_broker_unavailable_paths" name="test_safe_account_none" time="0.004"><failure message="AttributeError: '_TClient' object has no attribute 'get_account'">def test_safe_account_none():
        # AI-AGENT-REF: ensure None is returned when Alpaca client missing
        ctx = SimpleNamespace(api=None)
&gt;       assert safe_alpaca_get_account(ctx) is None

tests/test_broker_unavailable_paths.py:10: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:1617: in _wrapped
    return func(*a, **kw)
ai_trading/core/bot_engine.py:3288: in safe_alpaca_get_account
    return ctx.api.get_account()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;ai_trading.broker.alpaca.AlpacaBroker object at 0x7f3d4530bcd0&gt;

    def get_account(self) -&gt; Any:
        if self._is_new:
            return self._call_with_retry("get_account", self._api.get_account)
&gt;       return self._call_with_retry("get_account", self._api.get_account)
E       AttributeError: '_TClient' object has no attribute 'get_account'

ai_trading/broker/alpaca.py:281: AttributeError</failure></testcase><testcase classname="tests.test_cli_smoke" name="test_ai_health_dry_run_exits_zero" time="0.812" /><testcase classname="tests.runtime.test_no_broad_except_stage2" name="test_stage2_modules_have_no_broad_except" time="0.244" /><testcase classname="tests.test_ellipsis_fix.TestEllipsisFix" name="test_json_formatter_log_trading_event_unicode" time="0.004" /><testcase classname="tests.test_ellipsis_fix.TestEllipsisFix" name="test_json_formatter_unicode_ensure_ascii_false" time="0.002" /><testcase classname="tests.test_ellipsis_fix.TestEllipsisFix" name="test_update_risk_engine_exposure_error" time="0.004"><failure message="AssertionError: Expected 'warning' to have been called once. Called 0 times.">self = &lt;tests.test_ellipsis_fix.TestEllipsisFix testMethod=test_update_risk_engine_exposure_error&gt;

    def test_update_risk_engine_exposure_error(self):
        """Test risk exposure update handles errors gracefully."""
        with patch('ai_trading.core.bot_engine._get_runtime_context_or_none') as mock_get_ctx:
            with patch('ai_trading.core.bot_engine._log') as mock_log:
                # Setup mock context with failing risk engine
                mock_context = Mock()
                mock_risk_engine = Mock()
                mock_risk_engine.update_exposure.side_effect = Exception("Update failed")
                mock_context.risk_engine = mock_risk_engine
                mock_get_ctx.return_value = mock_context
    
                _update_risk_engine_exposure()
    
                # Should log warning about failure
&gt;               mock_log.warning.assert_called_once()

tests/test_ellipsis_fix.py:154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;MagicMock name='_log.warning' id='140684884164048'&gt;

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
&gt;           raise AssertionError(msg)
E           AssertionError: Expected 'warning' to have been called once. Called 0 times.

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:918: AssertionError</failure></testcase><testcase classname="tests.test_additional_coverage" name="test_config_missing_vars" time="0.002" /><testcase classname="tests.test_additional_coverage" name="test_get_env_reload" time="0.002" /><testcase classname="tests.test_additional_coverage" name="test_create_flask_routes" time="0.029" /><testcase classname="tests.test_additional_coverage" name="test_main_starts_api_thread" time="0.005"><failure message="ValueError: &quot;Settings&quot; object has no field &quot;max_position_size&quot;">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d37b6a10&gt;

    def test_main_starts_api_thread(monkeypatch):
        """main launches the API thread and runs a cycle."""
        monkeypatch.setenv("SCHEDULER_ITERATIONS", "1")
        # AI-AGENT-REF: Mock required environment variables for validation
        monkeypatch.setenv("WEBHOOK_SECRET", "test_secret")
        monkeypatch.setenv("ALPACA_API_KEY", "test_key")
        # AI-AGENT-REF: Use environment variables to avoid hardcoded secrets
        monkeypatch.setenv("TEST_ALPACA_SECRET_KEY", "test_secret_key")
    
        # AI-AGENT-REF: Mock the config object directly to ensure environment validation passes
        monkeypatch.setattr(main, "config", MockConfig())
    
        called = {}
    
        class DummyThread:
            def __init__(self, target, args=(), daemon=None):
                called["created"] = True
                self.target = target
                self.args = args
    
            def start(self):
                called["started"] = True
                self.target(*self.args)
    
            def is_alive(self):
                # AI-AGENT-REF: Add missing is_alive method to prevent AttributeError
                return True
    
        monkeypatch.setattr(main, "Thread", DummyThread)
        # AI-AGENT-REF: Fix lambda signature to accept ready_signal parameter
        monkeypatch.setattr(
            main, "start_api", lambda ready_signal=None: called.setdefault("api", True)
        )
        monkeypatch.setattr(
            main,
            "run_cycle",
            lambda: called.setdefault("cycle", 0)
            or called.update(cycle=called.get("cycle", 0) + 1),
        )
        monkeypatch.setattr(main.time, "sleep", lambda s: None)
    
&gt;       main.main()

tests/test_additional_coverage.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/main.py:341: in main
    _validate_runtime_config(config, S)
ai_trading/main.py:166: in _validate_runtime_config
    setattr(tcfg, "max_position_size", float(fallback))
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:997: in __setattr__
    elif (setattr_handler := self._setattr_handler(name, value)) is not None:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
name = 'max_position_size', value = 8000.0

    def _setattr_handler(self, name: str, value: Any) -&gt; Callable[[BaseModel, str, Any], None] | None:
        """Get a handler for setting an attribute on the model instance.
    
        Returns:
            A handler for setting an attribute on the model instance. Used for memoization of the handler.
            Memoizing the handlers leads to a dramatic performance improvement in `__setattr__`
            Returns `None` when memoization is not safe, then the attribute is set directly.
        """
        cls = self.__class__
        if name in cls.__class_vars__:
            raise AttributeError(
                f'{name!r} is a ClassVar of `{cls.__name__}` and cannot be set on an instance. '
                f'If you want to set a value on the class, use `{cls.__name__}.{name} = value`.'
            )
        elif not _fields.is_valid_field_name(name):
            if (attribute := cls.__private_attributes__.get(name)) is not None:
                if hasattr(attribute, '__set__'):
                    return lambda model, _name, val: attribute.__set__(model, val)
                else:
                    return _SIMPLE_SETATTR_HANDLERS['private']
            else:
                _object_setattr(self, name, value)
                return None  # Can not return memoized handler with possibly freeform attr names
    
        attr = getattr(cls, name, None)
        # NOTE: We currently special case properties and `cached_property`, but we might need
        # to generalize this to all data/non-data descriptors at some point. For non-data descriptors
        # (such as `cached_property`), it isn't obvious though. `cached_property` caches the value
        # to the instance's `__dict__`, but other non-data descriptors might do things differently.
        if isinstance(attr, cached_property):
            return _SIMPLE_SETATTR_HANDLERS['cached_property']
    
        _check_frozen(cls, name, value)
    
        # We allow properties to be set only on non frozen models for now (to match dataclasses).
        # This can be changed if it ever gets requested.
        if isinstance(attr, property):
            return lambda model, _name, val: attr.__set__(model, val)
        elif cls.model_config.get('validate_assignment'):
            return _SIMPLE_SETATTR_HANDLERS['validate_assignment']
        elif name not in cls.__pydantic_fields__:
            if cls.model_config.get('extra') != 'allow':
                # TODO - matching error
&gt;               raise ValueError(f'"{cls.__name__}" object has no field "{name}"')
E               ValueError: "Settings" object has no field "max_position_size"

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1044: ValueError</failure></testcase><testcase classname="tests.test_broker_unavailable_paths" name="test_pdt_rule_skips_without_false_fail" time="0.003"><failure message="assert namespace(api=None) is False&#10; +  where namespace(api=None) = check_pdt_rule(namespace(api=None))">caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7f3d45f0f250&gt;

    def test_pdt_rule_skips_without_false_fail(caplog):
        # AI-AGENT-REF: verify PDT check logs skip and not failure
        ctx = SimpleNamespace(api=None)
        with caplog.at_level(logging.INFO):
&gt;           assert check_pdt_rule(ctx) is False
E           assert namespace(api=None) is False
E            +  where namespace(api=None) = check_pdt_rule(namespace(api=None))

tests/test_broker_unavailable_paths.py:17: AssertionError</failure></testcase><testcase classname="tests.test_capital_scaling_smoke" name="test_capital_scaler_basic" time="0.002" /><testcase classname="tests.test_additional_coverage" name="test_meta_update_signal_weights" time="0.002" /><testcase classname="tests.test_centralized_config.TestCentralizedConfig" name="test_trading_config_initialization" time="0.004" /><testcase classname="tests.test_additional_coverage" name="test_meta_load_checkpoint_missing" time="0.009" /><testcase classname="tests.test_centralized_config.TestCentralizedConfig" name="test_trading_config_from_env" time="0.002" /><testcase classname="tests.test_centralized_config.TestCentralizedConfig" name="test_mode_specific_configurations" time="0.002" /><testcase classname="tests.test_centralized_config.TestCentralizedConfig" name="test_conservative_mode_parameters" time="0.002" /><testcase classname="tests.test_centralized_config.TestCentralizedConfig" name="test_balanced_mode_parameters" time="0.002" /><testcase classname="tests.test_additional_coverage" name="test_meta_retrain_missing_file" time="0.010" /><testcase classname="tests.test_centralized_config.TestCentralizedConfig" name="test_aggressive_mode_parameters" time="0.002" /><testcase classname="tests.test_centralized_config.TestCentralizedConfig" name="test_legacy_parameter_interface" time="0.002" /><testcase classname="tests.test_centralized_config.TestCentralizedConfig" name="test_bot_mode_integration" time="0.003" /><testcase classname="tests.test_centralized_config.TestCentralizedConfig" name="test_parameter_completeness" time="0.002" /><testcase classname="tests.test_centralized_config.TestCentralizedConfig" name="test_to_dict_conversion" time="0.002" /><testcase classname="tests.test_additional_coverage" name="test_meta_retrain_insufficient" time="0.023" /><testcase classname="tests.test_centralized_config.TestCentralizedConfig" name="test_from_optimization_method" time="0.002" /><testcase classname="tests.test_centralized_config.TestCentralizedConfig" name="test_environment_variable_override" time="0.002" /><testcase classname="tests.test_centralized_config.TestCentralizedConfig" name="test_parameter_ranges" time="0.002" /><testcase classname="tests.test_centralized_config" name="test_trading_config_has_max_drawdown_threshold" time="0.002" /><testcase classname="tests.test_centralized_config" name="test_trading_config_to_dict_includes_capital_and_drawdown" time="0.002" /><testcase classname="tests.test_centralized_config" name="test_trading_config_legacy_params_keys" time="0.002" /><testcase classname="tests.test_additional_coverage" name="test_meta_update_weights_error" time="0.005" /><testcase classname="tests.test_centralized_config" name="test_botmode_init_uses_fallback_when_method_missing" time="0.009" /><testcase classname="tests.test_ellipsis_fix.TestEllipsisFix" name="test_update_risk_engine_exposure_no_context" time="0.022" /><testcase classname="tests.test_centralized_logging_no_duplicates" name="test_centralized_logging_prevents_duplicates" time="0.006" /><testcase classname="tests.test_additional_coverage" name="test_mlmodel_validation_errors" time="0.033" /><testcase classname="tests.test_ellipsis_fix.TestEllipsisFix" name="test_update_risk_engine_exposure_no_risk_engine" time="0.004"><failure message="AssertionError: 'No risk_engine' not found in &quot;call('Skipping exposure update: runtime not ready')&quot;">self = &lt;tests.test_ellipsis_fix.TestEllipsisFix testMethod=test_update_risk_engine_exposure_no_risk_engine&gt;

    def test_update_risk_engine_exposure_no_risk_engine(self):
        """Test risk exposure update handles missing risk engine gracefully."""
        with patch('ai_trading.core.bot_engine._get_runtime_context_or_none') as mock_get_ctx:
            with patch('ai_trading.core.bot_engine._log') as mock_log:
                # Setup mock context without risk engine
                mock_context = Mock()
                mock_context.risk_engine = None
                mock_get_ctx.return_value = mock_context
    
                _update_risk_engine_exposure()
    
                # Should log debug message about missing risk engine
                mock_log.debug.assert_called_once()
&gt;               self.assertIn("No risk_engine", str(mock_log.debug.call_args))
E               AssertionError: 'No risk_engine' not found in "call('Skipping exposure update: runtime not ready')"

tests/test_ellipsis_fix.py:138: AssertionError</failure></testcase><testcase classname="tests.test_centralized_logging_no_duplicates" name="test_deprecated_modules_removed" time="0.003" /><testcase classname="tests.test_ellipsis_fix.TestEllipsisFix" name="test_update_risk_engine_exposure_with_context" time="0.006"><failure message="AssertionError: Expected 'update_exposure' to be called once. Called 0 times.">self = &lt;tests.test_ellipsis_fix.TestEllipsisFix testMethod=test_update_risk_engine_exposure_with_context&gt;

    def test_update_risk_engine_exposure_with_context(self):
        """Test risk exposure update works with valid context."""
        with patch('ai_trading.core.bot_engine._get_runtime_context_or_none') as mock_get_ctx:
            with patch('ai_trading.core.bot_engine._log'):
                # Setup mock context with risk engine
                mock_context = Mock()
                mock_risk_engine = Mock()
                mock_context.risk_engine = mock_risk_engine
                mock_get_ctx.return_value = mock_context
    
                _update_risk_engine_exposure()
    
                # Verify risk engine update_exposure was called
&gt;               mock_risk_engine.update_exposure.assert_called_once_with(mock_context)

tests/test_ellipsis_fix.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;Mock name='_get_runtime_context_or_none().risk_engine.update_exposure' id='140684883619472'&gt;
args = (&lt;Mock name='_get_runtime_context_or_none()' id='140684888641104'&gt;,), kwargs = {}
msg = "Expected 'update_exposure' to be called once. Called 0 times."

    def assert_called_once_with(self, /, *args, **kwargs):
        """assert that the mock was called exactly once and that that call was
        with the specified arguments."""
        if not self.call_count == 1:
            msg = ("Expected '%s' to be called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
&gt;           raise AssertionError(msg)
E           AssertionError: Expected 'update_exposure' to be called once. Called 0 times.

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:950: AssertionError</failure></testcase><testcase classname="tests.test_centralized_logging_no_duplicates" name="test_centralized_logging_thread_safety" time="0.021" /><testcase classname="tests.test_additional_coverage" name="test_mlmodel_fit_predict_exceptions" time="0.006" /><testcase classname="tests.test_additional_coverage" name="test_mlmodel_save_load_fail" time="0.004" /><testcase classname="tests.test_additional_coverage" name="test_train_and_predict_helpers" time="0.004" /><testcase classname="tests.test_additional_coverage" name="test_risk_engine_branches" time="0.006" /><testcase classname="tests.test_critical_issues_resolution.TestCriticalIssuesResolution" name="test_meta_learning_fallback_logic" time="0.002" /><testcase classname="tests.test_critical_issues_resolution.TestCriticalIssuesResolution" name="test_order_fill_tracking_reconciliation" time="0.002"><skipped type="pytest.skip" message="Required modules not available">/workspace/ai-trading-bot/tests/test_critical_issues_resolution.py:35: Required modules not available</skipped></testcase><testcase classname="tests.test_additional_coverage" name="test_runner_main_loop" time="0.029" /><testcase classname="tests.test_critical_issues_resolution.TestCriticalIssuesResolution" name="test_overtrading_prevention_cooldown_logic" time="0.002" /><testcase classname="tests.test_critical_issues_resolution.TestCriticalIssuesResolution" name="test_position_reconciliation_logic" time="0.002" /><testcase classname="tests.test_critical_issues_resolution.TestCriticalIssuesResolution" name="test_sentiment_rate_limiting_logic" time="0.011" /><testcase classname="tests.test_critical_issues_resolution.TestOrderSpacingConfiguration" name="test_risk_engine_order_spacing" time="0.003"><skipped type="pytest.skip" message="Required modules not available">/workspace/ai-trading-bot/tests/test_critical_issues_resolution.py:154: Required modules not available</skipped></testcase><testcase classname="tests.test_critical_issues_resolution.TestOrderSpacingConfiguration" name="test_trade_frequency_limits_logic" time="0.002" /><testcase classname="tests.test_critical_trading_issues.TestOrderExecutionTracking" name="test_order_slicing_quantity_mismatch" time="111.960" /><testcase classname="tests.test_additional_coverage" name="test_mean_reversion_nan_and_short" time="0.007" /><testcase classname="tests.test_additional_coverage" name="test_utils_edge_cases" time="0.005"><failure message="IndexError: single positional indexer is out-of-bounds">tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_utils_edge_cases0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3944f10&gt;

    def test_utils_edge_cases(tmp_path, monkeypatch):
        """Cover utility helper edge cases."""
        # AI-AGENT-REF: Ensure FORCE_MARKET_OPEN doesn't interfere with market hours test
        monkeypatch.setenv("FORCE_MARKET_OPEN", "false")
    
        assert utils.get_latest_close(pd.DataFrame()) == 0.0
        df = pd.DataFrame({"close": [np.nan]})
&gt;       assert utils.get_latest_close(df) == 0.0

tests/test_additional_coverage.py:318: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/utils/__init__.py:118: in get_latest_close
    val = float(df["close"].dropna().iloc[-1])
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/core/indexing.py:1191: in __getitem__
    return self._getitem_axis(maybe_callable, axis=axis)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/core/indexing.py:1752: in _getitem_axis
    self._validate_integer(key, axis)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;pandas.core.indexing._iLocIndexer object at 0x7ff8d353c5f0&gt;, key = -1, axis = 0

    def _validate_integer(self, key: int | np.integer, axis: AxisInt) -&gt; None:
        """
        Check that 'key' is a valid position in the desired axis.
    
        Parameters
        ----------
        key : int
            Requested position.
        axis : int
            Desired axis.
    
        Raises
        ------
        IndexError
            If 'key' is not a valid position in axis 'axis'.
        """
        len_axis = len(self.obj._get_axis(axis))
        if key &gt;= len_axis or key &lt; -len_axis:
&gt;           raise IndexError("single positional indexer is out-of-bounds")
E           IndexError: single positional indexer is out-of-bounds

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/core/indexing.py:1685: IndexError</failure></testcase><testcase classname="tests.test_emit_once" name="test_emit_once_emits_only_first_time" time="0.003" /><testcase classname="tests.test_emit_once_logger" name="test_emit_once_info_prevents_duplicates" time="0.002" /><testcase classname="tests.test_emit_once_logger" name="test_emit_once_with_custom_key" time="0.002" /><testcase classname="tests.test_emit_once_logger" name="test_emit_once_different_levels" time="0.003" /><testcase classname="tests.test_emit_once_logger" name="test_emit_once_thread_safe" time="0.124" /><testcase classname="tests.test_data_fetcher" name="test_fetch_minute_df_safe_handles_empty" time="0.005"><failure message="ai_trading.core.bot_engine.DataFetchError: Minute bars DataFrame is empty after fallbacks; market likely closed">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85397750&gt;
caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7f8d859fd990&gt;

    def test_fetch_minute_df_safe_handles_empty(monkeypatch, caplog):
        """fetch_minute_df_safe returns empty DataFrame without error."""  # AI-AGENT-REF
        monkeypatch.setattr("ai_trading.core.bot_engine.get_minute_df", lambda *a, **k: pd.DataFrame())
        caplog.set_level("INFO")
&gt;       result = fetch_minute_df_safe("AAPL")

tests/test_data_fetcher.py:255: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

symbol = 'AAPL'

    def fetch_minute_df_safe(symbol: str) -&gt; pd.DataFrame:
        """Fetch the last day of minute bars and raise on empty."""
        # AI-AGENT-REF: raise on empty DataFrame
        now_utc = datetime.now(UTC)
        start_dt = now_utc - timedelta(days=1)
    
        # AI-AGENT-REF: Cache wrapper (optional around fetch)
        if hasattr(CFG, "market_cache_enabled") and CFG.market_cache_enabled:
            try:
                from ai_trading.market.cache import get_or_load as _get_or_load
    
                cache_key = f"minute:{symbol}:{start_dt.isoformat()}"
                df = _get_or_load(
                    key=cache_key,
                    loader=lambda: get_minute_df(symbol, start_dt, now_utc),
                    ttl=getattr(S, "market_cache_ttl", 900),
                )
            except (
                FileNotFoundError,
                PermissionError,
                IsADirectoryError,
                JSONDecodeError,
                ValueError,
                KeyError,
                TypeError,
                OSError,
            ) as e:  # AI-AGENT-REF: narrow exception
                _log.debug("Cache layer unavailable/failed: %s", e)
                df = get_minute_df(symbol, start_dt, now_utc)
        else:
            df = get_minute_df(symbol, start_dt, now_utc)
    
        if df.empty:
            msg = "Minute bars DataFrame is empty after fallbacks; market likely closed"  # AI-AGENT-REF
            _log.warning(
                "FETCH_MINUTE_EMPTY",
                extra={"reason": "empty", "context": "market_closed"},
            )
&gt;           raise DataFetchError(msg)
E           ai_trading.core.bot_engine.DataFetchError: Minute bars DataFrame is empty after fallbacks; market likely closed

ai_trading/core/bot_engine.py:2055: DataFetchError</failure></testcase><testcase classname="tests.test_additional_coverage" name="test_validate_env_main" time="0.002"><failure message="ImportError: Error while finding module specification for 'validate_env' (ValueError: validate_env.__spec__ is None)">mod_name = 'validate_env', error = &lt;class 'ImportError'&gt;

&gt;   ???

&lt;frozen runpy&gt;:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'validate_env', package = None

&gt;   ???
E   ValueError: validate_env.__spec__ is None

&lt;frozen importlib.util&gt;:115: ValueError

The above exception was the direct cause of the following exception:

monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d39255d0&gt;

    def test_validate_env_main(monkeypatch):
        """Running validate_env as script calls _main."""
        # AI-AGENT-REF: Mock environment variables to ensure validation passes
        monkeypatch.setenv(
            "WEBHOOK_SECRET",
            "fake_test_webhook_secret_that_is_at_least_32_characters_long_for_security_not_real",
        )
        monkeypatch.setenv(
            "ALPACA_API_KEY", "FAKE_TEST_API_KEY_NOT_REAL_123456789012345"
        )  # Realistic length
        monkeypatch.setenv(
            "ALPACA_SECRET_KEY",
            "FAKE_TEST_SECRET_KEY_NOT_REAL_123456789012345678901234567890ABCDEFGHIJKLMN",
        )  # Realistic length
        monkeypatch.setenv("ALPACA_BASE_URL", "https://paper-api.alpaca.markets")
    
        # AI-AGENT-REF: Clear sys.argv to prevent pytest args from interfering with validate_env argument parsing
        original_argv = sys.argv[:]
        try:
            sys.argv = ["validate_env"]  # Simulate clean module execution
&gt;           runpy.run_module("validate_env", run_name="__main__")

tests/test_additional_coverage.py:350: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
&lt;frozen runpy&gt;:222: in run_module
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

mod_name = 'validate_env', error = &lt;class 'ImportError'&gt;

&gt;   ???
E   ImportError: Error while finding module specification for 'validate_env' (ValueError: validate_env.__spec__ is None)

&lt;frozen runpy&gt;:140: ImportError</failure></testcase><testcase classname="tests.test_allocator_size_bias" name="test_allocator_prefers_higher_conf_when_boost_enabled" time="0.006" /><testcase classname="tests.test_alpaca_api_extended" name="test_submit_order_http_error" time="0.002"><failure message="tests.test_alpaca_api_extended.HTTPError: 500">def test_submit_order_http_error():
        def submit_order(**_):
            raise HTTPError(500)
    
        api = types.SimpleNamespace(submit_order=submit_order)
&gt;       res = alpaca_api.submit_order(api, symbol="AAPL", qty=1, side="buy")

tests/test_alpaca_api_extended.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:301: in submit_order
    resp = submit_fn(**payload)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

_ = {'client_order_id': 'ai-1755884247437-5aedfbc4', 'qty': 1, 'side': 'buy', 'symbol': 'AAPL', ...}

    def submit_order(**_):
&gt;       raise HTTPError(500)
E       tests.test_alpaca_api_extended.HTTPError: 500

tests/test_alpaca_api_extended.py:13: HTTPError</failure></testcase><testcase classname="tests.test_empty_policy" name="test_classify_levels" time="0.002" /><testcase classname="tests.test_empty_policy" name="test_rate_limit_window" time="0.002" /><testcase classname="tests.test_enhanced_execution_debugging.TestExecutionDebugging" name="test_correlation_id_generation" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:48: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_enhanced_execution_debugging.TestExecutionDebugging" name="test_execution_statistics" time="0.003"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:181: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_alpaca_api_extended" name="test_submit_order_generic_error" time="0.002"><failure message="Exception: boom">def test_submit_order_generic_error():
        def submit_order(**_):
            raise Exception("boom")
    
        api = types.SimpleNamespace(submit_order=submit_order)
&gt;       res = alpaca_api.submit_order(api, symbol="AAPL", qty=1, side="buy")

tests/test_alpaca_api_extended.py:27: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:301: in submit_order
    resp = submit_fn(**payload)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

_ = {'client_order_id': 'ai-1755884247458-6848049c', 'qty': 1, 'side': 'buy', 'symbol': 'AAPL', ...}

    def submit_order(**_):
&gt;       raise Exception("boom")
E       Exception: boom

tests/test_alpaca_api_extended.py:24: Exception</failure></testcase><testcase classname="tests.test_enhanced_execution_debugging.TestExecutionDebugging" name="test_execution_tracking_lifecycle" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:65: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_enhanced_execution_debugging.TestExecutionDebugging" name="test_failed_execution_tracking" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:131: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_enhanced_execution_debugging.TestExecutionDebugging" name="test_position_update_tracking" time="0.003"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:160: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_enhanced_execution_debugging.TestPositionReconciliation" name="test_auto_resolution" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:292: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_enhanced_execution_debugging.TestPositionReconciliation" name="test_bot_position_tracking" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:215: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_alpaca_api_module" name="test_submit_order_shadow" time="0.003" /><testcase classname="tests.test_enhanced_execution_debugging.TestPositionReconciliation" name="test_discrepancy_classification" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:257: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_enhanced_execution_debugging.TestPositionReconciliation" name="test_discrepancy_detection" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:231: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_enhanced_execution_debugging.TestPositionReconciliation" name="test_severity_determination" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:276: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_alpaca_api_module" name="test_submit_order_missing_submit" time="0.002" /><testcase classname="tests.test_alpaca_api_module" name="test_submit_order_rate_limit" time="0.002"><failure message="Exception: fail">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d81be550&gt;

    def test_submit_order_rate_limit(monkeypatch):
        monkeypatch.setattr(alpaca_api, "SHADOW_MODE", False)
        api = DummyAPI(fail_status=429)
&gt;       res = alpaca_api.submit_order(api, symbol="AAPL", qty=1, side="buy")

tests/test_alpaca_api_module.py:40: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:301: in submit_order
    resp = submit_fn(**payload)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;tests.test_alpaca_api_module.DummyAPI object at 0x7ff8d39546d0&gt;
order_data = {'client_order_id': 'ai-1755884247482-82f63bc8', 'qty': 1, 'side': 'buy', 'symbol': 'AAPL', ...}
err = Exception('fail')

    def submit_order(self, **order_data):
        self.calls += 1
        if self.fail_status and self.calls == 1:
            err = Exception("fail")
            err.status = self.fail_status
&gt;           raise err
E           Exception: fail

tests/test_alpaca_api_module.py:16: Exception</failure></testcase><testcase classname="tests.test_enhanced_execution_debugging.TestPnLAttribution" name="test_dividend_pnl_recording" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:425: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_enhanced_execution_debugging.TestPnLAttribution" name="test_pnl_explanation" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:409: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_enhanced_execution_debugging.TestPnLAttribution" name="test_pnl_summary_and_breakdown" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:385: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_client_order_id" name="test_unique_client_order_id" time="0.002" /><testcase classname="tests.test_conf_size_curve" name="test_monotonic_and_bounds[0.7-1.15-1.0]" time="0.002" /><testcase classname="tests.test_conf_size_curve" name="test_monotonic_and_bounds[0.7-1.25-0.5]" time="0.004" /><testcase classname="tests.test_enhanced_execution_debugging.TestPnLAttribution" name="test_position_snapshot_pnl_attribution" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:358: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_conf_size_curve" name="test_monotonic_and_bounds[0.7-1.1-2.0]" time="0.003" /><testcase classname="tests.test_enhanced_execution_debugging.TestPnLAttribution" name="test_trade_pnl_recording" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:324: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_enhanced_execution_debugging.TestIntegratedExecutionDebugging" name="test_complete_trade_lifecycle_debugging" time="0.002"><skipped type="pytest.skip" message="Enhanced debugging modules not available">/workspace/ai-trading-bot/tests/test_enhanced_execution_debugging.py:459: Enhanced debugging modules not available</skipped></testcase><testcase classname="tests.test_confidence_gate" name="test_conf_gate_basic" time="0.002" /><testcase classname="tests.test_alpaca_contract" name="test_submit_order_contract" time="0.002" /><testcase classname="tests.test_alpaca_import" name="test_ai_trading_import_without_alpaca" time="0.004"><failure message="AssertionError: assert True is False&#10; +  where True = &lt;module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'&gt;.ALPACA_AVAILABLE&#10; +    where &lt;module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'&gt; = &lt;module 'ai_trading.core' from '/workspace/ai-trading-bot/ai_trading/core/__init__.py'&gt;.bot_engine&#10; +      where &lt;module 'ai_trading.core' from '/workspace/ai-trading-bot/ai_trading/core/__init__.py'&gt; = &lt;module 'ai_trading' from '/workspace/ai-trading-bot/ai_trading/__init__.py'&gt;.core">def test_ai_trading_import_without_alpaca():
        """Test that ai_trading can be imported even when alpaca packages are missing."""
        # Remove alpaca modules from sys.modules to simulate missing packages
        alpaca_modules = [module for module in sys.modules.keys() if 'alpaca' in module.lower()]
        for module in alpaca_modules:
            sys.modules.pop(module, None)
    
        # Simulate missing alpaca packages by setting them to None
        sys.modules['alpaca_trade_api'] = None
        sys.modules['alpaca.trading'] = None
        sys.modules['alpaca.data'] = None
        sys.modules['alpaca'] = None
    
        # Set testing mode
        import os
        os.environ['TESTING'] = 'true'
    
        try:
            # This should not raise an exception
            import ai_trading
            import ai_trading.core.bot_engine
    
            # Check that ALPACA_AVAILABLE is False
            assert hasattr(ai_trading.core.bot_engine, 'ALPACA_AVAILABLE')
&gt;           assert ai_trading.core.bot_engine.ALPACA_AVAILABLE is False
E           AssertionError: assert True is False
E            +  where True = &lt;module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'&gt;.ALPACA_AVAILABLE
E            +    where &lt;module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'&gt; = &lt;module 'ai_trading.core' from '/workspace/ai-trading-bot/ai_trading/core/__init__.py'&gt;.bot_engine
E            +      where &lt;module 'ai_trading.core' from '/workspace/ai-trading-bot/ai_trading/core/__init__.py'&gt; = &lt;module 'ai_trading' from '/workspace/ai-trading-bot/ai_trading/__init__.py'&gt;.core

tests/test_alpaca_import.py:30: AssertionError</failure></testcase><testcase classname="tests.test_ensure_utc" name="test_reject_callable" time="0.002" /><testcase classname="tests.test_ensure_utc" name="test_datetime_naive_to_utc" time="0.002" /><testcase classname="tests.test_config_additional" name="test_get_env_required_missing" time="0.002" /><testcase classname="tests.test_config_additional" name="test_require_env_vars_failure" time="0.003" /><testcase classname="tests.test_ensure_utc" name="test_date_to_utc_midnight" time="0.002" /><testcase classname="tests.test_ensure_utc_datetime_callables" name="test_callable_rejected" time="0.002" /><testcase classname="tests.test_alpaca_import_handling.TestAlpacaImportHandling" name="test_alpaca_import_failure_graceful_handling" time="0.004" /><testcase classname="tests.test_config_additional" name="test_validate_environment_failure" time="0.002" /><testcase classname="tests.test_ensure_utc_datetime_callables" name="test_callable_allowed" time="0.002" /><testcase classname="tests.test_env_flags" name="test_disable_daily_retrain_env_parsing" time="0.002"><failure message="AttributeError: DISABLE_DAILY_RETRAIN">def test_disable_daily_retrain_env_parsing():
        """Test DISABLE_DAILY_RETRAIN parsing for various values."""
        test_cases = [
            ("true", True),
            ("True", True),
            ("TRUE", True),
            ("1", True),
            ("false", False),
            ("False", False),
            ("FALSE", False),
            ("0", False),
            ("", False),  # empty string should default to False
            ("invalid", False),  # invalid values should default to False
        ]
    
        for env_value, expected in test_cases:
            # Set the environment variable
            os.environ["DISABLE_DAILY_RETRAIN"] = env_value
            os.environ["TESTING"] = "1"  # Enable testing mode
    
            # Clear module cache to force re-import
            if 'config' in os.sys.modules:
                del os.sys.modules['config']
    
            # Import config module
            from ai_trading import config
    
            # Test the result
&gt;           actual = config.DISABLE_DAILY_RETRAIN

tests/test_env_flags.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'DISABLE_DAILY_RETRAIN'

    def __getattr__(name: str):  # AI-AGENT-REF: lazy export for TradingConfig
        if name == "TradingConfig":
            from .management import TradingConfig as _TC
            return _TC
&gt;       raise AttributeError(name)
E       AttributeError: DISABLE_DAILY_RETRAIN

ai_trading/config/__init__.py:46: AttributeError</failure></testcase><testcase classname="tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport" name="test_env_loaded_multiple_times_safely" time="0.003"><failure message="AssertionError: assert None == 'safe_value'&#10; +  where None = get('MULTI_LOAD_TEST')&#10; +    where get = environ({'COREPACK_ENABLE_AUTO_PIN': '0', 'PYENV_HOOK_PATH': '/root/.pyenv/pyenv.d:/usr/etc/pyenv.d:/usr/local/etc/pye...stEnvironmentOrderAndLazyImport::test_env_loaded_multiple_times_safely (call)', 'AI_TRADER_OFFLINE': '1', 'TZ': 'UTC'}).get&#10; +      where environ({'COREPACK_ENABLE_AUTO_PIN': '0', 'PYENV_HOOK_PATH': '/root/.pyenv/pyenv.d:/usr/etc/pyenv.d:/usr/local/etc/pye...stEnvironmentOrderAndLazyImport::test_env_loaded_multiple_times_safely (call)', 'AI_TRADER_OFFLINE': '1', 'TZ': 'UTC'}) = os.environ">self = &lt;tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7ff8d818c7d0&gt;

    def test_env_loaded_multiple_times_safely(self):
        """Test that loading .env multiple times is safe."""
        # Create temp .env with test values
        with tempfile.NamedTemporaryFile(mode='w', suffix='.env', delete=False) as f:
            f.write("MULTI_LOAD_TEST=safe_value\n")
            temp_env_path = f.name
    
        try:
            # Clear environment
            os.environ.pop('MULTI_LOAD_TEST', None)
    
            # Mock load_dotenv to use our temp file
            def mock_load_side_effect(*args, **kwargs):
                with open(temp_env_path) as env_file:
                    for line in env_file:
                        if '=' in line and not line.startswith('#'):
                            key, value = line.strip().split('=', 1)
                            os.environ[key] = value
    
            with patch('dotenv.load_dotenv', side_effect=mock_load_side_effect):
                # Load multiple times (simulating multiple imports)
                from ai_trading.main import load_dotenv
                load_dotenv(override=True)  # First load
                load_dotenv(override=True)  # Second load
                load_dotenv(override=True)  # Third load
    
                # Should still have the correct value
&gt;               assert os.environ.get('MULTI_LOAD_TEST') == 'safe_value'
E               AssertionError: assert None == 'safe_value'
E                +  where None = get('MULTI_LOAD_TEST')
E                +    where get = environ({'COREPACK_ENABLE_AUTO_PIN': '0', 'PYENV_HOOK_PATH': '/root/.pyenv/pyenv.d:/usr/etc/pyenv.d:/usr/local/etc/pye...stEnvironmentOrderAndLazyImport::test_env_loaded_multiple_times_safely (call)', 'AI_TRADER_OFFLINE': '1', 'TZ': 'UTC'}).get
E                +      where environ({'COREPACK_ENABLE_AUTO_PIN': '0', 'PYENV_HOOK_PATH': '/root/.pyenv/pyenv.d:/usr/etc/pyenv.d:/usr/local/etc/pye...stEnvironmentOrderAndLazyImport::test_env_loaded_multiple_times_safely (call)', 'AI_TRADER_OFFLINE': '1', 'TZ': 'UTC'}) = os.environ

tests/test_env_order_and_lazy_import.py:210: AssertionError</failure></testcase><testcase classname="tests.test_config_additional" name="test_validate_alpaca_credentials_missing" time="0.002" /><testcase classname="tests.test_config_additional" name="test_log_config_does_not_log" time="0.003" /><testcase classname="tests.test_config_deadlock_fix" name="test_no_hang_on_basic_validation" time="0.001" /><testcase classname="tests.test_config_deadlock_fix" name="test_no_hang_on_comprehensive_validation" time="0.002" /><testcase classname="tests.test_env_flags" name="test_disable_daily_retrain_unset" time="0.002"><failure message="AttributeError: DISABLE_DAILY_RETRAIN">def test_disable_daily_retrain_unset():
        """Test DISABLE_DAILY_RETRAIN when environment variable is unset."""
        # Remove the environment variable if it exists
        if "DISABLE_DAILY_RETRAIN" in os.environ:
            del os.environ["DISABLE_DAILY_RETRAIN"]
    
        os.environ["TESTING"] = "1"  # Enable testing mode
    
        # Clear module cache
        if 'config' in os.sys.modules:
            del os.sys.modules['config']
    
        # Import config module
        from ai_trading import config
    
        # Should default to False
&gt;       assert config.DISABLE_DAILY_RETRAIN is False

tests/test_env_flags.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'DISABLE_DAILY_RETRAIN'

    def __getattr__(name: str):  # AI-AGENT-REF: lazy export for TradingConfig
        if name == "TradingConfig":
            from .management import TradingConfig as _TC
            return _TC
&gt;       raise AttributeError(name)
E       AttributeError: DISABLE_DAILY_RETRAIN

ai_trading/config/__init__.py:46: AttributeError</failure></testcase><testcase classname="tests.test_config_deadlock_fix" name="test_nested_validation_calls_no_deadlock" time="0.004" /><testcase classname="tests.test_config_deadlock_fix" name="test_concurrent_validation_no_hang" time="0.009" /><testcase classname="tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport" name="test_missing_env_file_handled_gracefully" time="0.003" /><testcase classname="tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport" name="test_lazy_import_error_handling" time="0.003"><failure message="Failed: DID NOT RAISE &lt;class 'RuntimeError'&gt;">self = &lt;tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7ff8d8062d90&gt;

    def test_lazy_import_error_handling(self):
        """Test that lazy import handles import errors gracefully."""
        from ai_trading import runner
    
        # Reset cache
        runner._bot_engine = None
        runner._bot_state_class = None
    
        with patch('ai_trading.core.bot_engine.run_all_trades_worker', side_effect=ImportError("Mock import error")):
&gt;           with pytest.raises(RuntimeError) as exc_info:
E           Failed: DID NOT RAISE &lt;class 'RuntimeError'&gt;

tests/test_env_order_and_lazy_import.py:239: Failed</failure></testcase><testcase classname="tests.test_env_flags" name="test_disable_daily_retrain_fallback_settings" time="0.002"><failure message="AttributeError: _FallbackSettings">def test_disable_daily_retrain_fallback_settings():
        """Test DISABLE_DAILY_RETRAIN through fallback settings."""
        # Test the fallback _FallbackSettings class directly
        if 'config' in os.sys.modules:
            del os.sys.modules['config']
    
        os.environ["TESTING"] = "1"
        os.environ["DISABLE_DAILY_RETRAIN"] = "true"
    
        from ai_trading import config
    
        # Check that fallback settings work
&gt;       fallback = config._FallbackSettings()

tests/test_env_flags.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = '_FallbackSettings'

    def __getattr__(name: str):  # AI-AGENT-REF: lazy export for TradingConfig
        if name == "TradingConfig":
            from .management import TradingConfig as _TC
            return _TC
&gt;       raise AttributeError(name)
E       AttributeError: _FallbackSettings

ai_trading/config/__init__.py:46: AttributeError</failure></testcase><testcase classname="tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport" name="test_import_time_no_credential_validation" time="0.003" /><testcase classname="tests.test_config_deadlock_fix" name="test_lock_timeout_functionality" time="0.002" /><testcase classname="tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport" name="test_dotenv_loaded_before_settings_construction" time="0.003"><failure message="AssertionError: Expected 'load_dotenv' to have been called.">self = &lt;tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7ff3c0ede550&gt;

    def test_dotenv_loaded_before_settings_construction(self):
        """Test that .env is loaded before Settings is constructed."""
        # Create a temporary .env file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.env', delete=False) as f:
            f.write("TEST_DOTENV_ORDER=loaded_early\n")
            f.write("ALPACA_API_KEY=test_from_dotenv\n")
            temp_env_path = f.name
    
        try:
            # Clear any existing env var
            if 'TEST_DOTENV_ORDER' in os.environ:
                del os.environ['TEST_DOTENV_ORDER']
            if 'ALPACA_API_KEY' in os.environ:
                del os.environ['ALPACA_API_KEY']
    
            # Mock dotenv.load_dotenv to load our temp file
            with patch('dotenv.load_dotenv') as mock_load_dotenv:
                def side_effect(*args, **kwargs):
                    # Simulate loading the .env file
                    with open(temp_env_path) as env_file:
                        for line in env_file:
                            if '=' in line and not line.startswith('#'):
                                key, value = line.strip().split('=', 1)
                                os.environ[key] = value
    
                mock_load_dotenv.side_effect = side_effect
    
                # Import main module (this should load .env before Settings)
    
                # Verify .env was loaded before Settings construction
&gt;               mock_load_dotenv.assert_called()

tests/test_env_order_and_lazy_import.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;MagicMock name='load_dotenv' id='140684884540048'&gt;

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
&gt;           raise AssertionError(msg)
E           AssertionError: Expected 'load_dotenv' to have been called.

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:908: AssertionError</failure></testcase><testcase classname="tests.test_equity_curve" name="test_equity_curve_monotonic" time="0.002"><failure message="FileNotFoundError: [Errno 2] No such file or directory: 'data/last_equity.txt'">def test_equity_curve_monotonic():
&gt;       df = pd.read_csv("data/last_equity.txt", names=["equity"])

tests/test_equity_curve.py:5: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026: in read_csv
    return _read(filepath_or_buffer, kwds)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620: in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620: in __init__
    self._engine = self._make_engine(f, self.engine)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880: in _make_engine
    self.handles = get_handle(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path_or_buf = 'data/last_equity.txt', mode = 'r'

    @doc(compression_options=_shared_docs["compression_options"] % "path_or_buf")
    def get_handle(
        path_or_buf: FilePath | BaseBuffer,
        mode: str,
        *,
        encoding: str | None = None,
        compression: CompressionOptions | None = None,
        memory_map: bool = False,
        is_text: bool = True,
        errors: str | None = None,
        storage_options: StorageOptions | None = None,
    ) -&gt; IOHandles[str] | IOHandles[bytes]:
        """
        Get file handle for given path/buffer and mode.
    
        Parameters
        ----------
        path_or_buf : str or file handle
            File path or object.
        mode : str
            Mode to open path_or_buf with.
        encoding : str or None
            Encoding to use.
        {compression_options}
    
               May be a dict with key 'method' as compression mode
               and other keys as compression options if compression
               mode is 'zip'.
    
               Passing compression options as keys in dict is
               supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.
    
            .. versionchanged:: 1.4.0 Zstandard support.
    
        memory_map : bool, default False
            See parsers._parser_params for more information. Only used by read_csv.
        is_text : bool, default True
            Whether the type of the content passed to the file/buffer is string or
            bytes. This is not the same as `"b" not in mode`. If a string content is
            passed to a binary file/buffer, a wrapper is inserted.
        errors : str, default 'strict'
            Specifies how encoding and decoding errors are to be handled.
            See the errors argument for :func:`open` for a full list
            of options.
        storage_options: StorageOptions = None
            Passed to _get_filepath_or_buffer
    
        Returns the dataclass IOHandles
        """
        # Windows does not default to utf-8. Set to utf-8 for a consistent behavior
        encoding = encoding or "utf-8"
    
        errors = errors or "strict"
    
        # read_csv does not know whether the buffer is opened in binary/text mode
        if _is_binary_mode(path_or_buf, mode) and "b" not in mode:
            mode += "b"
    
        # validate encoding and errors
        codecs.lookup(encoding)
        if isinstance(errors, str):
            codecs.lookup_error(errors)
    
        # open URLs
        ioargs = _get_filepath_or_buffer(
            path_or_buf,
            encoding=encoding,
            compression=compression,
            mode=mode,
            storage_options=storage_options,
        )
    
        handle = ioargs.filepath_or_buffer
        handles: list[BaseBuffer]
    
        # memory mapping needs to be the first step
        # only used for read_csv
        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)
    
        is_path = isinstance(handle, str)
        compression_args = dict(ioargs.compression)
        compression = compression_args.pop("method")
    
        # Only for write methods
        if "r" not in mode and is_path:
            check_parent_directory(str(handle))
    
        if compression:
            if compression != "zstd":
                # compression libraries do not like an explicit text-mode
                ioargs.mode = ioargs.mode.replace("t", "")
            elif compression == "zstd" and "b" not in ioargs.mode:
                # python-zstandard defaults to text mode, but we always expect
                # compression libraries to use binary mode.
                ioargs.mode += "b"
    
            # GZ Compression
            if compression == "gzip":
                if isinstance(handle, str):
                    # error: Incompatible types in assignment (expression has type
                    # "GzipFile", variable has type "Union[str, BaseBuffer]")
                    handle = gzip.GzipFile(  # type: ignore[assignment]
                        filename=handle,
                        mode=ioargs.mode,
                        **compression_args,
                    )
                else:
                    handle = gzip.GzipFile(
                        # No overload variant of "GzipFile" matches argument types
                        # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                        fileobj=handle,  # type: ignore[call-overload]
                        mode=ioargs.mode,
                        **compression_args,
                    )
    
            # BZ Compression
            elif compression == "bz2":
                # Overload of "BZ2File" to handle pickle protocol 5
                # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                handle = get_bz2_file()(  # type: ignore[call-overload]
                    handle,
                    mode=ioargs.mode,
                    **compression_args,
                )
    
            # ZIP Compression
            elif compression == "zip":
                # error: Argument 1 to "_BytesZipFile" has incompatible type
                # "Union[str, BaseBuffer]"; expected "Union[Union[str, PathLike[str]],
                # ReadBuffer[bytes], WriteBuffer[bytes]]"
                handle = _BytesZipFile(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
                if handle.buffer.mode == "r":
                    handles.append(handle)
                    zip_names = handle.buffer.namelist()
                    if len(zip_names) == 1:
                        handle = handle.buffer.open(zip_names.pop())
                    elif not zip_names:
                        raise ValueError(f"Zero files found in ZIP file {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in ZIP file. "
                            f"Only one file per ZIP: {zip_names}"
                        )
    
            # TAR Encoding
            elif compression == "tar":
                compression_args.setdefault("mode", ioargs.mode)
                if isinstance(handle, str):
                    handle = _BytesTarFile(name=handle, **compression_args)
                else:
                    # error: Argument "fileobj" to "_BytesTarFile" has incompatible
                    # type "BaseBuffer"; expected "Union[ReadBuffer[bytes],
                    # WriteBuffer[bytes], None]"
                    handle = _BytesTarFile(
                        fileobj=handle, **compression_args  # type: ignore[arg-type]
                    )
                assert isinstance(handle, _BytesTarFile)
                if "r" in handle.buffer.mode:
                    handles.append(handle)
                    files = handle.buffer.getnames()
                    if len(files) == 1:
                        file = handle.buffer.extractfile(files[0])
                        assert file is not None
                        handle = file
                    elif not files:
                        raise ValueError(f"Zero files found in TAR archive {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in TAR archive. "
                            f"Only one file per TAR archive: {files}"
                        )
    
            # XZ Compression
            elif compression == "xz":
                # error: Argument 1 to "LZMAFile" has incompatible type "Union[str,
                # BaseBuffer]"; expected "Optional[Union[Union[str, bytes, PathLike[str],
                # PathLike[bytes]], IO[bytes]], None]"
                handle = get_lzma_file()(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
    
            # Zstd Compression
            elif compression == "zstd":
                zstd = import_optional_dependency("zstandard")
                if "r" in ioargs.mode:
                    open_args = {"dctx": zstd.ZstdDecompressor(**compression_args)}
                else:
                    open_args = {"cctx": zstd.ZstdCompressor(**compression_args)}
                handle = zstd.open(
                    handle,
                    mode=ioargs.mode,
                    **open_args,
                )
    
            # Unrecognized Compression
            else:
                msg = f"Unrecognized compression type: {compression}"
                raise ValueError(msg)
    
            assert not isinstance(handle, str)
            handles.append(handle)
    
        elif isinstance(handle, str):
            # Check whether the filename is to be opened in binary mode.
            # Binary mode does not support 'encoding' and 'newline'.
            if ioargs.encoding and "b" not in ioargs.mode:
                # Encoding
&gt;               handle = open(
                    handle,
                    ioargs.mode,
                    encoding=ioargs.encoding,
                    errors=errors,
                    newline="",
                )
E               FileNotFoundError: [Errno 2] No such file or directory: 'data/last_equity.txt'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/common.py:873: FileNotFoundError</failure></testcase><testcase classname="tests.test_config_deadlock_fix" name="test_validation_with_proper_env_vars" time="0.005" /><testcase classname="tests.test_config_deadlock_fix" name="test_main_import_no_hang" time="0.002" /><testcase classname="tests.test_config_deadlock_fix" name="test_deadlock_scenario_resolved" time="0.002" /><testcase classname="tests.test_config_env.TestConfigEnvParsing" name="test_disable_daily_retrain_default" time="0.004" /><testcase classname="tests.test_config_env.TestConfigEnvParsing" name="test_disable_daily_retrain_true_string" time="0.002" /><testcase classname="tests.test_config_env.TestConfigEnvParsing" name="test_disable_daily_retrain_one_string" time="0.003" /><testcase classname="tests.test_config_env.TestConfigEnvParsing" name="test_disable_daily_retrain_false_string" time="0.002" /><testcase classname="tests.test_config_env.TestConfigEnvParsing" name="test_disable_daily_retrain_zero_string" time="0.002" /><testcase classname="tests.test_config_env.TestConfigEnvParsing" name="test_disable_daily_retrain_case_insensitive" time="0.002" /><testcase classname="tests.test_config_env.TestConfigEnvParsing" name="test_disable_daily_retrain_invalid_value" time="0.002" /><testcase classname="tests.test_config_env.TestConfigEnvParsing" name="test_config_import" time="0.002" /><testcase classname="tests.test_config_exports" name="test_lazy_exports_resolve" time="0.002" /><testcase classname="tests.test_config_validation_max_position_size" name="test_static_mode_nonpositive_is_autofixed" time="0.003" /><testcase classname="tests.test_config_validation_max_position_size" name="test_auto_mode_nonpositive_is_permitted" time="0.002" /><testcase classname="tests.test_core_init_fix.TestCoreModuleInit" name="test_core_module_import" time="0.001" /><testcase classname="tests.test_core_init_fix.TestCoreModuleInit" name="test_core_exports_available" time="0.001" /><testcase classname="tests.test_core_init_fix.TestCoreModuleInit" name="test_specific_imports_from_core" time="0.002" /><testcase classname="tests.test_core_init_fix.TestCoreModuleInit" name="test_enum_functionality" time="0.002" /><testcase classname="tests.test_core_init_fix.TestCoreModuleInit" name="test_trading_constants_structure" time="0.001" /><testcase classname="tests.test_core_init_fix.TestCoreModuleInit" name="test_all_exports_list" time="0.001" /><testcase classname="tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport" name="test_lazy_import_prevents_import_time_crash" time="0.003" /><testcase classname="tests.test_coverage_hack" name="test_force_full_coverage" time="0.004" /><testcase classname="tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport" name="test_lazy_engine_loading_defers_heavy_imports" time="0.004" /><testcase classname="tests.test_coverage_hack" name="test_critical_imports" time="0.013"><failure message="ImportError: Failed to import critical modules: data_fetcher (cannot import name 'ConnectionError' from 'requests.exceptions' (unknown location)), signals (No module named 'cachetools')">def test_critical_imports():
        """Test that all critical modules can be imported without errors."""
        critical_modules = ["bot_engine", "data_fetcher", "signals", "risk_engine", "trade_execution"]
        failed_imports = []
    
        for module_name in critical_modules:
            try:
                __import__(module_name)
            except ImportError as e:
                failed_imports.append((module_name, str(e)))
    
        if failed_imports:
            fail_msg = "Failed to import critical modules: " + ", ".join(f"{mod} ({err})" for mod, err in failed_imports)
            logger.error(fail_msg)
&gt;           raise ImportError(fail_msg)
E           ImportError: Failed to import critical modules: data_fetcher (cannot import name 'ConnectionError' from 'requests.exceptions' (unknown location)), signals (No module named 'cachetools')

tests/test_coverage_hack.py:40: ImportError</failure></testcase><testcase classname="tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport" name="test_lazy_engine_loading_caches_components" time="0.005"><failure message="AssertionError: assert &lt;MagicMock name='run_all_trades_worker' id='140684884148176'&gt; == 'cached_worker'">self = &lt;tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7ff3c0eddf10&gt;

    def test_lazy_engine_loading_caches_components(self):
        """Test that engine components are cached after first load."""
        from ai_trading import runner
    
        # Reset the lazy import cache
        runner._bot_engine = None
        runner._bot_state_class = None
    
        with patch('ai_trading.core.bot_engine.run_all_trades_worker') as mock_worker:
            with patch('ai_trading.core.bot_engine.BotState') as mock_state:
                mock_worker.return_value = "cached_worker"
                mock_state.return_value = "cached_state"
    
                # First call should import
                worker1, state1 = runner._load_engine()
    
                # Second call should use cached values
                worker2, state2 = runner._load_engine()
    
                # Should be the same objects
&gt;               assert worker1 == worker2 == "cached_worker"
E               AssertionError: assert &lt;MagicMock name='run_all_trades_worker' id='140684884148176'&gt; == 'cached_worker'

tests/test_env_order_and_lazy_import.py:130: AssertionError</failure></testcase><testcase classname="tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport" name="test_run_cycle_uses_lazy_loading" time="0.016"><failure message="AssertionError: Expected 'mock' to be called once. Called 0 times.">self = &lt;tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7ff3c0eddd50&gt;

    def test_run_cycle_uses_lazy_loading(self):
        """Test that run_cycle uses lazy loading for bot engine."""
        from ai_trading import runner
    
        # Reset lazy import cache
        runner._bot_engine = None
        runner._bot_state_class = None
    
        # Mock the components
        mock_worker = MagicMock()
        mock_state_class = MagicMock()
        mock_state_instance = MagicMock()
        mock_state_class.return_value = mock_state_instance
    
        with patch.object(runner, '_load_engine') as mock_load:
            mock_load.return_value = (mock_worker, mock_state_class)
    
            # Call run_cycle
            runner.run_cycle()
    
            # Verify lazy loading was called
            mock_load.assert_called_once()
    
            # Verify worker was called with state instance
&gt;           mock_worker.assert_called_once_with(mock_state_instance, None)

tests/test_env_order_and_lazy_import.py:161: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;MagicMock id='140684884132112'&gt;, args = (&lt;MagicMock name='mock()' id='140684883775888'&gt;, None), kwargs = {}
msg = "Expected 'mock' to be called once. Called 0 times."

    def assert_called_once_with(self, /, *args, **kwargs):
        """assert that the mock was called exactly once and that that call was
        with the specified arguments."""
        if not self.call_count == 1:
            msg = ("Expected '%s' to be called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
&gt;           raise AssertionError(msg)
E           AssertionError: Expected 'mock' to be called once. Called 0 times.

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:950: AssertionError</failure></testcase><testcase classname="tests.test_critical_datetime_fixes.TestDatetimeTimezoneAwareness" name="test_alpaca_api_format_compatibility" time="0.002"><failure message="ImportError: cannot import name 'ensure_datetime' from 'ai_trading.data_fetcher' (unknown location)">self = &lt;tests.test_critical_datetime_fixes.TestDatetimeTimezoneAwareness testMethod=test_alpaca_api_format_compatibility&gt;

    def test_alpaca_api_format_compatibility(self):
        """Test that datetime format is compatible with Alpaca API RFC3339 requirements."""
&gt;       from ai_trading.data_fetcher import ensure_datetime
E       ImportError: cannot import name 'ensure_datetime' from 'ai_trading.data_fetcher' (unknown location)

tests/test_critical_datetime_fixes.py:34: ImportError</failure></testcase><testcase classname="tests.test_critical_datetime_fixes.TestDatetimeTimezoneAwareness" name="test_ensure_datetime_returns_timezone_aware" time="0.004"><failure message="ImportError: cannot import name 'ensure_datetime' from 'ai_trading.data_fetcher' (unknown location)">self = &lt;tests.test_critical_datetime_fixes.TestDatetimeTimezoneAwareness testMethod=test_ensure_datetime_returns_timezone_aware&gt;

    def test_ensure_datetime_returns_timezone_aware(self):
        """Test that ensure_datetime returns timezone-aware datetime objects."""
&gt;       from ai_trading.data_fetcher import ensure_datetime
E       ImportError: cannot import name 'ensure_datetime' from 'ai_trading.data_fetcher' (unknown location)

tests/test_critical_datetime_fixes.py:23: ImportError</failure></testcase><testcase classname="tests.test_critical_datetime_fixes.TestDatetimeTimezoneAwareness" name="test_get_bars_datetime_parameters" time="0.002" /><testcase classname="tests.test_critical_datetime_fixes.TestMetaLearningDataFetching" name="test_metalearn_invalid_prices_prevention" time="0.024" /><testcase classname="tests.test_critical_datetime_fixes.TestSentimentCaching" name="test_sentiment_cache_rate_limit_handling" time="0.005"><failure message="AttributeError: 'NoneType' object has no attribute 'status_code'">self = &lt;tests.test_critical_datetime_fixes.TestSentimentCaching testMethod=test_sentiment_cache_rate_limit_handling&gt;

    def test_sentiment_cache_rate_limit_handling(self):
        """Test that sentiment caching properly handles rate limits."""
        try:
            import time
    
            from ai_trading.core.bot_engine import _SENTIMENT_CACHE, fetch_sentiment
            from requests.exceptions import HTTPError
    
            # Clear cache
            _SENTIMENT_CACHE.clear()
    
            # Mock the API key variables in bot_engine module
            with patch("ai_trading.core.bot_engine.SENTIMENT_API_KEY", "test_key"):
                with patch("ai_trading.core.bot_engine.NEWS_API_KEY", "test_key"):
                    # Mock the requests to simulate rate limiting
                    with patch("requests.get") as mock_get:
                        # First call - simulate rate limit (429)
                        mock_response = MagicMock()
                        mock_response.status_code = 429
                        mock_response.raise_for_status.side_effect = HTTPError(
                            "429 Too Many Requests"
                        )
                        mock_get.return_value = mock_response
    
                        # Mock context for fetch_sentiment
                        mock_ctx = MagicMock()
    
                        # This should handle the rate limit gracefully and cache neutral score
&gt;                       score = fetch_sentiment(mock_ctx, "AAPL")

tests/test_critical_datetime_fixes.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

symbol_or_ctx = &lt;MagicMock id='140215586815184'&gt;, symbol = 'AAPL'

    def fetch_sentiment(
        symbol_or_ctx, symbol: str | None = None, *, ttl_s: int = 300
    ) -&gt; float:
        global _SENTIMENT_FAILURES
        """Fetch sentiment score with basic caching and failure tracking."""
        if symbol is None:
            symbol = symbol_or_ctx  # backward compat: first arg was context
        now = time.time()
        cached = _SENTIMENT_CACHE.get(symbol)
        if cached and now - cached[0] &lt; ttl_s:
            return cached[1]
        if _SENTIMENT_FAILURES &gt;= SENTIMENT_FAILURE_THRESHOLD or not SENTIMENT_API_KEY:
            return 0.0
        params = {"symbol": symbol, "apikey": SENTIMENT_API_KEY}
        try:
            # fmt: off
            resp = requests.get(SENTIMENT_API_URL, params=params, timeout=HTTP_TIMEOUT)
            # fmt: on
&gt;           if resp.status_code in {429, 500, 502, 503, 504}:
E           AttributeError: 'NoneType' object has no attribute 'status_code'

ai_trading/core/bot_engine.py:462: AttributeError</failure></testcase><testcase classname="tests.test_executors_sizing" name="test_executor_auto_sizing" time="0.003" /><testcase classname="tests.test_executors_sizing" name="test_executor_env_overrides" time="0.002" /><testcase classname="tests.test_executors_sizing" name="test_executor_bounds" time="0.005" /><testcase classname="tests.test_executors_sizing" name="test_executor_fallback_behavior" time="0.003" /><testcase classname="tests.test_executors_sizing" name="test_executor_env_validation" time="0.002"><failure message="ValueError: invalid literal for int() with base 10: 'invalid'">def test_executor_env_validation():
        """Test that environment variable parsing handles edge cases."""
        test_cases = [
            ("", 0),      # Empty string
            ("0", 0),     # Zero
            ("1", 1),     # Valid number
            ("10", 10),   # Valid number
            ("invalid", 0),  # Invalid should default to 0 (fallback to auto-size)
        ]
    
        for env_val, expected in test_cases:
            os.environ["EXECUTOR_WORKERS"] = env_val
    
&gt;           _exec_env = int(os.getenv("EXECUTOR_WORKERS", "0") or "0")
E           ValueError: invalid literal for int() with base 10: 'invalid'

tests/test_executors_sizing.py:119: ValueError</failure></testcase><testcase classname="tests.test_executors_sizing" name="test_executor_cleanup_available" time="0.002" /><testcase classname="tests.test_fallback_concurrency" name="test_daily_fallback_parallel" time="0.002"><failure message="AssertionError: assert set() == {'A', 'B', 'C', 'D'}&#10;  &#10;  Extra items in the right set:&#10;  'A'&#10;  'C'&#10;  'D'&#10;  'B'&#10;  Use -v to get more diff">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3761910&gt;

    def test_daily_fallback_parallel(monkeypatch):
        # Force batch to return empty so we hit fallback path for all.
        ctx = types.SimpleNamespace()
        calls = {"single": []}
        monkeypatch.setattr(be, "get_bars_batch", lambda *a, **k: {})
        def fake_single(sym, *a, **k):
            calls["single"].append(sym)
            return _mk_df()
        monkeypatch.setattr(be, "get_bars", fake_single)
        out = be._fetch_universe_bars(ctx, ["A","B","C","D"], "1D", "2024-01-01", "2024-02-01", None)
&gt;       assert set(out.keys()) == {"A","B","C","D"}
E       AssertionError: assert set() == {'A', 'B', 'C', 'D'}
E         
E         Extra items in the right set:
E         'A'
E         'C'
E         'D'
E         'B'
E         Use -v to get more diff

tests/test_fallback_concurrency.py:27: AssertionError</failure></testcase><testcase classname="tests.test_fallback_concurrency" name="test_intraday_fallback_parallel" time="0.012" /><testcase classname="tests.test_fallback_concurrency" name="test_parallel_execution_timing" time="0.003"><failure message="assert 0 == 4&#10; +  where 0 = len({})">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d857cf10&gt;

    def test_parallel_execution_timing(monkeypatch):
        """Test that parallel execution provides performance benefit."""
        ctx = types.SimpleNamespace()
        call_times = []
    
        monkeypatch.setattr(be, "get_bars_batch", lambda *a, **k: {})
    
        def slow_single(sym, *a, **k):
            # Simulate slow API call
            time.sleep(0.1)
            call_times.append((sym, time.time()))
            return _mk_df()
    
        monkeypatch.setattr(be, "get_bars", slow_single)
    
        # Test with 4 symbols that should run in parallel
        start_time = time.time()
        out = be._fetch_universe_bars(ctx, ["A","B","C","D"], "1D", "2024-01-01", "2024-02-01", None)
        end_time = time.time()
    
        # Should complete faster than sequential (0.4s) due to parallelism
        # Allow some overhead but should be significantly faster than sequential
        assert end_time - start_time &lt; 0.3, f"Parallel execution took {end_time - start_time:.2f}s, expected &lt; 0.3s"
&gt;       assert len(out) == 4
E       assert 0 == 4
E        +  where 0 = len({})

tests/test_fallback_concurrency.py:66: AssertionError</failure></testcase><testcase classname="tests.test_fallback_concurrency" name="test_bounded_concurrency_respects_limit" time="0.002"><failure message="assert 0 == 6&#10; +  where 0 = len({})">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3f15d90&gt;

    def test_bounded_concurrency_respects_limit(monkeypatch):
        """Test that the worker limit is respected."""
        ctx = types.SimpleNamespace()
        active_workers = []
        max_concurrent = 0
    
        # Mock settings to use only 2 workers
        def mock_get_settings():
            settings = types.SimpleNamespace()
            settings.batch_fallback_workers = 2
            return settings
    
        monkeypatch.setattr(be, "get_settings", mock_get_settings)
        monkeypatch.setattr(be, "get_bars_batch", lambda *a, **k: {})
    
        def track_concurrent(sym, *a, **k):
            thread_id = threading.current_thread().ident
            active_workers.append(thread_id)
    
            nonlocal max_concurrent
            current_count = len(set(active_workers))
            max_concurrent = max(max_concurrent, current_count)
    
            time.sleep(0.1)  # Simulate work
            return _mk_df()
    
        monkeypatch.setattr(be, "get_bars", track_concurrent)
    
        # Test with 6 symbols but limit to 2 workers
        out = be._fetch_universe_bars(ctx, ["A","B","C","D","E","F"], "1D", "2024-01-01", "2024-02-01", None)
    
&gt;       assert len(out) == 6
E       assert 0 == 6
E        +  where 0 = len({})

tests/test_fallback_concurrency.py:108: AssertionError</failure></testcase><testcase classname="tests.test_fallback_logging_payload" name="test_fallback_payload_is_canonical" time="0.002" /><testcase classname="tests.test_features" name="test_features_pipeline" time="0.018" /><testcase classname="tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport" name="test_main_loads_dotenv_before_runner_import" time="0.006"><failure message="AttributeError: 'Settings' object has no attribute 'alpaca_secret_key_plain'">self = &lt;tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7ff3c0ede990&gt;

    def test_main_loads_dotenv_before_runner_import(self):
        """Test that main.py loads .env before importing runner."""
        # Mock load_dotenv to track when it's called
        with patch('dotenv.load_dotenv') as mock_load_dotenv:
            with patch('ai_trading.runner.run_cycle') as mock_run_cycle:
                # Import and call run_bot from main
                from ai_trading.main import run_bot
    
                # Call run_bot
&gt;               result = run_bot()

tests/test_env_order_and_lazy_import.py:172: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/main.py:245: in run_bot
    validate_environment()
ai_trading/main.py:201: in validate_environment
    if not cfg.alpaca_api_key or not cfg.alpaca_secret_key_plain:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
item = 'alpaca_secret_key_plain'

    def __getattr__(self, item: str) -&gt; Any:
        private_attributes = object.__getattribute__(self, '__private_attributes__')
        if item in private_attributes:
            attribute = private_attributes[item]
            if hasattr(attribute, '__get__'):
                return attribute.__get__(self, type(self))  # type: ignore
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                return self.__pydantic_private__[item]  # type: ignore
            except KeyError as exc:
                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
        else:
            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.
            # See `BaseModel.__repr_args__` for more details
            try:
                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')
            except AttributeError:
                pydantic_extra = None
    
            if pydantic_extra:
                try:
                    return pydantic_extra[item]
                except KeyError as exc:
                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
            else:
                if hasattr(self.__class__, item):
                    return super().__getattribute__(item)  # Raises AttributeError if appropriate
                else:
                    # this is the current error
&gt;                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E                   AttributeError: 'Settings' object has no attribute 'alpaca_secret_key_plain'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:991: AttributeError</failure></testcase><testcase classname="tests.test_fetch_and_screen" name="test_fetch_fallback_to_daily" time="0.014"><failure message="AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute 'get_daily_df'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8eb3a7850&gt;

    def test_fetch_fallback_to_daily(monkeypatch):
        df = _stub_df()
        monkeypatch.setattr(data_fetcher, "get_minute_df", lambda *a, **k: None)
&gt;       monkeypatch.setattr(data_fetcher, "get_daily_df", lambda *a, **k: df)
E       AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute 'get_daily_df'

tests/test_fetch_and_screen.py:24: AttributeError</failure></testcase><testcase classname="tests.test_fetch_and_screen" name="test_fetch_minute_success" time="0.003" /><testcase classname="tests.test_fetch_contract" name="test_get_bars_never_none" time="0.002"><failure message="AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute '_alpaca_get_bars'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3b85e10&gt;

    def test_get_bars_never_none(monkeypatch):
        now = pd.Timestamp("2024-01-01", tz="UTC")
        df = pd.DataFrame(
            {
                "timestamp": [now],
                "open": [1.0],
                "high": [2.0],
                "low": [0.5],
                "close": [1.5],
                "volume": [100],
            }
        )
&gt;       monkeypatch.setattr(
            data_fetcher,
            "_alpaca_get_bars",
            lambda client, symbol, start, end, timeframe="1Day": df,
        )
E       AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute '_alpaca_get_bars'

tests/test_fetch_contract.py:34: AttributeError</failure></testcase><testcase classname="tests.test_fetch_sample_universe_cli" name="test_run_success" time="0.002"><failure message="AttributeError: 'module' object at ai_trading.data_fetcher has no attribute '_build_daily_url'">obj = &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt;, name = '_build_daily_url'
ann = 'ai_trading.data_fetcher'

    def annotated_getattr(obj: object, name: str, ann: str) -&gt; object:
        try:
&gt;           obj = getattr(obj, name)
E           AttributeError: module 'ai_trading.data_fetcher' has no attribute '_build_daily_url'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/_pytest/monkeypatch.py:90: AttributeError

The above exception was the direct cause of the following exception:

monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3718790&gt;

    def test_run_success(monkeypatch):
        urls_captured = []
        logged = []
    
        def fake_build(symbol, start, end):
            return f"https://example.com/{symbol}"
    
        def fake_map_get(urls, timeout=None):
            urls_captured.extend(urls)
            return [(u, 200, b"OK") for u in urls]
    
        def fake_info(msg, *args, **kwargs):
            logged.append((msg, kwargs.get("extra", {})))
    
&gt;       monkeypatch.setattr("ai_trading.data_fetcher._build_daily_url", fake_build)

tests/test_fetch_sample_universe_cli.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/_pytest/monkeypatch.py:104: in derive_importpath
    annotated_getattr(target, attr, ann=module)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt;, name = '_build_daily_url'
ann = 'ai_trading.data_fetcher'

    def annotated_getattr(obj: object, name: str, ann: str) -&gt; object:
        try:
            obj = getattr(obj, name)
        except AttributeError as e:
&gt;           raise AttributeError(
                f"{type(obj).__name__!r} object at {ann} has no attribute {name!r}"
            ) from e
E           AttributeError: 'module' object at ai_trading.data_fetcher has no attribute '_build_daily_url'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/_pytest/monkeypatch.py:92: AttributeError</failure></testcase><testcase classname="tests.test_fixes" name="test_tickers_csv" time="0.002" /><testcase classname="tests.test_data_fetcher_canonicalization" name="test_canonical_helpers" time="0.002" /><testcase classname="tests.test_fixes" name="test_talib_imports" time="0.003" /><testcase classname="tests.test_data_fetcher_canonicalization" name="test_fallback_payload_is_canonical_df" time="0.002" /><testcase classname="tests.test_fixes" name="test_screen_universe_logging" time="0.002" /><testcase classname="tests.test_data_fetcher_datetime" name="test_ensure_datetime_valid[value0-expected0]" time="0.002" /><testcase classname="tests.test_fixes_minimal" name="test_risk_engine_methods_exist" time="0.002" /><testcase classname="tests.test_data_fetcher_datetime" name="test_ensure_datetime_valid[2024-01-01-expected1]" time="0.002" /><testcase classname="tests.test_fixes_minimal" name="test_bot_context_alpaca_client" time="0.003" /><testcase classname="tests.test_data_fetcher_datetime" name="test_ensure_datetime_valid[2024-01-01 05:30:00-expected2]" time="0.002" /><testcase classname="tests.test_grid_runner" name="test_persist_artifacts" time="0.003" /><testcase classname="tests.test_fixes_minimal" name="test_process_manager_enhancements" time="0.002" /><testcase classname="tests.test_grid_runner" name="test_grid_search_empty_grid" time="0.002" /><testcase classname="tests.test_data_fetcher_datetime" name="test_ensure_datetime_valid[20240101-expected3]" time="0.002" /><testcase classname="tests.test_data_fetcher_datetime" name="test_ensure_datetime_valid[2024-01-01T12:00:00Z-expected4]" time="0.002" /><testcase classname="tests.test_fixes_minimal" name="test_data_validation_module" time="0.002"><failure message="AssertionError: should_halt_trading function missing&#10;assert False&#10; +  where False = hasattr(&lt;module 'ai_trading.data_validation' from '/workspace/ai-trading-bot/ai_trading/data_validation.py'&gt;, 'should_halt_trading')">def test_data_validation_module():
        """Test data validation module exists and has required functions."""
    
        try:
            from ai_trading import data_validation
    
            # Test required functions exist
            required_functions = [
                'check_data_freshness',
                'validate_trading_data',
                'get_stale_symbols',
                'should_halt_trading',
                'emergency_data_check'
            ]
    
            for func_name in required_functions:
&gt;               assert hasattr(data_validation, func_name), f"{func_name} function missing"
E               AssertionError: should_halt_trading function missing
E               assert False
E                +  where False = hasattr(&lt;module 'ai_trading.data_validation' from '/workspace/ai-trading-bot/ai_trading/data_validation.py'&gt;, 'should_halt_trading')

tests/test_fixes_minimal.py:127: AssertionError</failure></testcase><testcase classname="tests.test_grid_runner" name="test_grid_search_single_param" time="0.002" /><testcase classname="tests.test_grid_sanity" name="test_grid_search_results" time="0.004" /><testcase classname="tests.test_data_fetcher_datetime" name="test_ensure_datetime_none" time="0.002"><failure message="TypeError: Invalid datetime input: Invalid datetime input: None">value = None

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -&gt; datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
&gt;               raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
E               TypeError: Unsupported datetime type: NoneType

ai_trading/data/timeutils.py:45: TypeError

The above exception was the direct cause of the following exception:

value = None

    def ensure_datetime(value: Any) -&gt; _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
&gt;           return ensure_utc_datetime(value, allow_callables=False)

ai_trading/data_fetcher.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -&gt; datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
                raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
        except (ValueError, TypeError) as e:
            if default is not None:
                return ensure_utc_datetime(default, allow_callables=allow_callables, clamp_to=clamp_to)
&gt;           raise ValueError(f"Invalid datetime input: {value!r}") from e
E           ValueError: Invalid datetime input: None

ai_trading/data/timeutils.py:49: ValueError

The above exception was the direct cause of the following exception:

    def test_ensure_datetime_none():
        with pytest.raises(ValueError):
&gt;           data_fetcher.ensure_datetime(None)

tests/test_data_fetcher_datetime.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None

    def ensure_datetime(value: Any) -&gt; _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
            return ensure_utc_datetime(value, allow_callables=False)
        except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
&gt;           raise TypeError(f"Invalid datetime input: {e}") from e
E           TypeError: Invalid datetime input: Invalid datetime input: None

ai_trading/data_fetcher.py:205: TypeError</failure></testcase><testcase classname="tests.test_fixes_minimal" name="test_audit_permission_handling" time="0.003" /><testcase classname="tests.test_health" name="test_health_check_empty_dataframe" time="0.003"><failure message="AssertionError: assert [('AAA', 'no_data')] == ['AAA']&#10;  &#10;  At index 0 diff: ('AAA', 'no_data') != 'AAA'&#10;  Use -v to get more diff">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c0772550&gt;

    def test_health_check_empty_dataframe(monkeypatch):
        monkeypatch.setenv("HEALTH_MIN_ROWS", "30")
        ctx = DummyCtx(pd.DataFrame())
        summary = pre_trade_health_check(ctx, ["AAA"])
&gt;       assert summary["failures"] == ["AAA"]
E       AssertionError: assert [('AAA', 'no_data')] == ['AAA']
E         
E         At index 0 diff: ('AAA', 'no_data') != 'AAA'
E         Use -v to get more diff

tests/test_health.py:254: AssertionError</failure></testcase><testcase classname="tests.test_grid_runner" name="test_grid_search_basic" time="0.002" /><testcase classname="tests.test_institutional_enhancements.TestPreTradeValidation" name="test_comprehensive_validation" time="0.003"><skipped type="pytest.skip" message="Pre-trade validation modules not available">/workspace/ai-trading-bot/tests/test_institutional_enhancements.py:178: Pre-trade validation modules not available</skipped></testcase><testcase classname="tests.test_health" name="test_health_check_succeeds" time="0.003" /><testcase classname="tests.test_institutional_enhancements.TestPreTradeValidation" name="test_liquidity_validator" time="0.002"><skipped type="pytest.skip" message="Pre-trade validation modules not available">/workspace/ai-trading-bot/tests/test_institutional_enhancements.py:142: Pre-trade validation modules not available</skipped></testcase><testcase classname="tests.test_institutional_enhancements.TestPreTradeValidation" name="test_market_hours_validator" time="0.002"><skipped type="pytest.skip" message="Pre-trade validation modules not available">/workspace/ai-trading-bot/tests/test_institutional_enhancements.py:129: Pre-trade validation modules not available</skipped></testcase><testcase classname="tests.test_institutional_enhancements.TestPreTradeValidation" name="test_risk_validator" time="0.003"><skipped type="pytest.skip" message="Pre-trade validation modules not available">/workspace/ai-trading-bot/tests/test_institutional_enhancements.py:162: Pre-trade validation modules not available</skipped></testcase><testcase classname="tests.test_healthcheck_minute_fallback" name="test_minute_fallback_uses_http_yahoo" time="0.016" /><testcase classname="tests.test_institutional_enhancements.TestMarketMicrostructure" name="test_microstructure_engine" time="0.010"><failure message="AttributeError: module 'requests' has no attribute 'Response'">self = &lt;tests.test_institutional_enhancements.TestMarketMicrostructure testMethod=test_microstructure_engine&gt;

    def setUp(self):
        """Set up test fixtures."""
        try:
&gt;           from ai_trading.execution.microstructure import (
                BidAskSpreadAnalyzer,
                MarketMicrostructureEngine,
                MarketRegimeFeature,
                OrderFlowAnalyzer,
            )

tests/test_institutional_enhancements.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:35: in &lt;module&gt;
    _alpaca_rest = _optional_import("alpaca_trade_api.rest")
ai_trading/execution/engine.py:29: in _optional_import
    return importlib.import_module(name)
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/__init__.py:3: in &lt;module&gt;
    from .rest import REST, TimeFrame, TimeFrameUnit  # noqa
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import logging
    import os
    from typing import Iterator, List, Optional, Union
    import requests
    from requests.exceptions import HTTPError
    import time
    from enum import Enum
    from alpaca_trade_api import __version__
    from .common import (
        get_base_url,
        get_data_url,
        get_credentials,
        get_api_version, URL, FLOAT,
    )
    from .entity import (
        Bar, Entity, Account, AccountConfigurations, AccountActivity,
        Asset, Order, Position, Clock, Calendar,
        Trade, Quote, Watchlist, PortfolioHistory
    )
    from .entity_v2 import (
        BarV2, BarsV2, LatestBarsV2, LatestQuotesV2, LatestTradesV2,
        SnapshotV2, SnapshotsV2, TradesV2, TradeV2, QuotesV2, QuoteV2,
        NewsV2, NewsListV2, OrderbookV2, OrderbooksV2
    )
    
    logger = logging.getLogger(__name__)
    Positions = List[Position]
    Orders = List[Order]
    Assets = List[Asset]
    AccountActivities = List[AccountActivity]
    Calendars = List[Calendar]
    Watchlists = List[Watchlist]
    TradeIterator = Iterator[Union[Trade, dict]]
    QuoteIterator = Iterator[Union[Quote, dict]]
    BarIterator = Iterator[Union[Bar, dict]]
    NewsIterator = Iterator[Union[NewsV2, dict]]
    
    DATA_V2_MAX_LIMIT = 10000  # max items per api call
    NEWS_MAX_LIMIT = 50  # max items per api call
    
    
    class RetryException(Exception):
        pass
    
    
    class APIError(Exception):
        """
        Represent API related error.
        error.status_code will have http status code.
        """
    
        def __init__(self, error, http_error=None):
            super().__init__(error['message'])
            self._error = error
            self._http_error = http_error
    
        @property
        def code(self):
            return self._error.get('code', self.status_code)
    
        @property
        def status_code(self):
            http_error = self._http_error
            if http_error is not None and hasattr(http_error, 'response'):
                return http_error.response.status_code
    
        @property
        def request(self):
            if self._http_error is not None:
                return self._http_error.request
    
        @property
        def response(self):
            if self._http_error is not None:
                return self._http_error.response
    
&gt;   def raise_api_error(resp: requests.Response, http_error: requests.HTTPError):
E   AttributeError: module 'requests' has no attribute 'Response'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:77: AttributeError</failure></testcase><testcase classname="tests.test_healthcheck_minute_fallback_handles_none" name="test_ensure_df_none_and_dict" time="0.002" /><testcase classname="tests.test_http_pooling" name="test_pool_config_defaults" time="0.002" /><testcase classname="tests.test_http_pooling" name="test_host_semaphore_respects_env" time="0.003"><failure message="assert 6 == 3">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c0c42890&gt;

    def test_host_semaphore_respects_env(monkeypatch):
        def fake_get(url, timeout=None, headers=None):
            return DummyResp()
    
        monkeypatch.setattr(H, "get", fake_get)
        monkeypatch.setenv("HTTP_MAX_PER_HOST", "3")
        _ = H.map_get(["https://example.com"])
&gt;       assert H.pool_stats()["per_host"] == 3
E       assert 6 == 3

tests/test_http_pooling.py:25: AssertionError</failure></testcase><testcase classname="tests.test_http_timeouts" name="test_httpsession_sets_default_timeout" time="0.003"><failure message="AttributeError: module 'ai_trading.utils.http' has no attribute 'HTTPSession'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c0c43690&gt;

    def test_httpsession_sets_default_timeout(monkeypatch):
&gt;       s = http.HTTPSession(timeout=7)
E       AttributeError: module 'ai_trading.utils.http' has no attribute 'HTTPSession'

tests/test_http_timeouts.py:25: AttributeError</failure></testcase><testcase classname="tests.test_http_timeouts" name="test_bot_engine_uses_http_abstraction" time="0.003" /><testcase classname="tests.test_data_fetcher_datetime" name="test_ensure_datetime_empty_str" time="0.003"><failure message="TypeError: Invalid datetime input: Invalid datetime input: ''">value = ''

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -&gt; datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
&gt;               tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
E               ValueError: Invalid isoformat string: ''

ai_trading/data/timeutils.py:42: ValueError

The above exception was the direct cause of the following exception:

value = ''

    def ensure_datetime(value: Any) -&gt; _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
&gt;           return ensure_utc_datetime(value, allow_callables=False)

ai_trading/data_fetcher.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = ''

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -&gt; datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
                raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
        except (ValueError, TypeError) as e:
            if default is not None:
                return ensure_utc_datetime(default, allow_callables=allow_callables, clamp_to=clamp_to)
&gt;           raise ValueError(f"Invalid datetime input: {value!r}") from e
E           ValueError: Invalid datetime input: ''

ai_trading/data/timeutils.py:49: ValueError

The above exception was the direct cause of the following exception:

    def test_ensure_datetime_empty_str():
        with pytest.raises(ValueError):
&gt;           data_fetcher.ensure_datetime("")

tests/test_data_fetcher_datetime.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = ''

    def ensure_datetime(value: Any) -&gt; _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
            return ensure_utc_datetime(value, allow_callables=False)
        except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
&gt;           raise TypeError(f"Invalid datetime input: {e}") from e
E           TypeError: Invalid datetime input: Invalid datetime input: ''

ai_trading/data_fetcher.py:205: TypeError</failure></testcase><testcase classname="tests.test_http_timeouts" name="test_requests_can_still_be_patched_via_session" time="0.003" /><testcase classname="tests.test_http_timeouts_enforced" name="test_all_requests_have_timeout" time="0.051" /><testcase classname="tests.test_data_fetcher_datetime" name="test_ensure_datetime_invalid_str" time="0.002"><failure message="TypeError: Invalid datetime input: Invalid datetime input: 'notadate'">value = 'notadate'

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -&gt; datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
&gt;               tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
E               ValueError: Invalid isoformat string: 'notadate'

ai_trading/data/timeutils.py:42: ValueError

The above exception was the direct cause of the following exception:

value = 'notadate'

    def ensure_datetime(value: Any) -&gt; _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
&gt;           return ensure_utc_datetime(value, allow_callables=False)

ai_trading/data_fetcher.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = 'notadate'

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -&gt; datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
                raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
        except (ValueError, TypeError) as e:
            if default is not None:
                return ensure_utc_datetime(default, allow_callables=allow_callables, clamp_to=clamp_to)
&gt;           raise ValueError(f"Invalid datetime input: {value!r}") from e
E           ValueError: Invalid datetime input: 'notadate'

ai_trading/data/timeutils.py:49: ValueError

The above exception was the direct cause of the following exception:

    def test_ensure_datetime_invalid_str():
        with pytest.raises(ValueError):
&gt;           data_fetcher.ensure_datetime("notadate")

tests/test_data_fetcher_datetime.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = 'notadate'

    def ensure_datetime(value: Any) -&gt; _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
            return ensure_utc_datetime(value, allow_callables=False)
        except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
&gt;           raise TypeError(f"Invalid datetime input: {e}") from e
E           TypeError: Invalid datetime input: Invalid datetime input: 'notadate'

ai_trading/data_fetcher.py:205: TypeError</failure></testcase><testcase classname="tests.test_hyperparams" name="test_best_hyperparams_sensible" time="0.002" /><testcase classname="tests.test_import_fallbacks" name="test_model_registry_import_fallback" time="0.010" /><testcase classname="tests.test_import_fallbacks" name="test_bot_engine_import_fallbacks" time="0.005"><failure message="AssertionError: Expected import pattern not found: from meta_learning import optimize_signals&#10;assert 'from meta_learning import optimize_signals' in '# ruff: noqa\n# fmt: off\nfrom __future__ import annotations\n\nimport importlib\nimport importlib.util\nimport os\ni...eption\n            _log.exception(&quot;Scheduler loop error: %s&quot;, exc)\n        time.sleep(CFG.scheduler_sleep_seconds)\n'">def test_bot_engine_import_fallbacks():
        """Test that bot_engine import fallbacks work correctly."""
        # Test that the import patterns are present in the code
        # Check that the file contains the expected try/except patterns
        import inspect
    
        from ai_trading.core import bot_engine
    
        source = inspect.getsource(bot_engine)
    
        # Look for the expected import patterns
        expected_patterns = [
            "from ai_trading.meta_learning import optimize_signals",
            "from meta_learning import optimize_signals",
            "from ai_trading.pipeline import model_pipeline",
            "from pipeline import model_pipeline",
            "from ai_trading.data_fetcher import",
            "from data_fetcher import",
            "from ai_trading.indicators import rsi",
            "from indicators import rsi",
            "from ai_trading.signals import generate_position_hold_signals",
            "from signals import generate_position_hold_signals",
            "from ai_trading import portfolio",
            "import portfolio",
            "from ai_trading.alpaca_api import alpaca_get",
            "from alpaca_api import alpaca_get",
        ]
    
        for pattern in expected_patterns:
&gt;           assert pattern in source, f"Expected import pattern not found: {pattern}"
E           AssertionError: Expected import pattern not found: from meta_learning import optimize_signals
E           assert 'from meta_learning import optimize_signals' in '# ruff: noqa\n# fmt: off\nfrom __future__ import annotations\n\nimport importlib\nimport importlib.util\nimport os\ni...eption\n            _log.exception("Scheduler loop error: %s", exc)\n        time.sleep(CFG.scheduler_sleep_seconds)\n'

tests/test_import_fallbacks.py:53: AssertionError</failure></testcase><testcase classname="tests.test_institutional_enhancements.TestMarketMicrostructure" name="test_order_flow_analyzer" time="0.008"><failure message="AttributeError: module 'requests' has no attribute 'Response'">self = &lt;tests.test_institutional_enhancements.TestMarketMicrostructure testMethod=test_order_flow_analyzer&gt;

    def setUp(self):
        """Set up test fixtures."""
        try:
&gt;           from ai_trading.execution.microstructure import (
                BidAskSpreadAnalyzer,
                MarketMicrostructureEngine,
                MarketRegimeFeature,
                OrderFlowAnalyzer,
            )

tests/test_institutional_enhancements.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:35: in &lt;module&gt;
    _alpaca_rest = _optional_import("alpaca_trade_api.rest")
ai_trading/execution/engine.py:29: in _optional_import
    return importlib.import_module(name)
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/__init__.py:3: in &lt;module&gt;
    from .rest import REST, TimeFrame, TimeFrameUnit  # noqa
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import logging
    import os
    from typing import Iterator, List, Optional, Union
    import requests
    from requests.exceptions import HTTPError
    import time
    from enum import Enum
    from alpaca_trade_api import __version__
    from .common import (
        get_base_url,
        get_data_url,
        get_credentials,
        get_api_version, URL, FLOAT,
    )
    from .entity import (
        Bar, Entity, Account, AccountConfigurations, AccountActivity,
        Asset, Order, Position, Clock, Calendar,
        Trade, Quote, Watchlist, PortfolioHistory
    )
    from .entity_v2 import (
        BarV2, BarsV2, LatestBarsV2, LatestQuotesV2, LatestTradesV2,
        SnapshotV2, SnapshotsV2, TradesV2, TradeV2, QuotesV2, QuoteV2,
        NewsV2, NewsListV2, OrderbookV2, OrderbooksV2
    )
    
    logger = logging.getLogger(__name__)
    Positions = List[Position]
    Orders = List[Order]
    Assets = List[Asset]
    AccountActivities = List[AccountActivity]
    Calendars = List[Calendar]
    Watchlists = List[Watchlist]
    TradeIterator = Iterator[Union[Trade, dict]]
    QuoteIterator = Iterator[Union[Quote, dict]]
    BarIterator = Iterator[Union[Bar, dict]]
    NewsIterator = Iterator[Union[NewsV2, dict]]
    
    DATA_V2_MAX_LIMIT = 10000  # max items per api call
    NEWS_MAX_LIMIT = 50  # max items per api call
    
    
    class RetryException(Exception):
        pass
    
    
    class APIError(Exception):
        """
        Represent API related error.
        error.status_code will have http status code.
        """
    
        def __init__(self, error, http_error=None):
            super().__init__(error['message'])
            self._error = error
            self._http_error = http_error
    
        @property
        def code(self):
            return self._error.get('code', self.status_code)
    
        @property
        def status_code(self):
            http_error = self._http_error
            if http_error is not None and hasattr(http_error, 'response'):
                return http_error.response.status_code
    
        @property
        def request(self):
            if self._http_error is not None:
                return self._http_error.request
    
        @property
        def response(self):
            if self._http_error is not None:
                return self._http_error.response
    
&gt;   def raise_api_error(resp: requests.Response, http_error: requests.HTTPError):
E   AttributeError: module 'requests' has no attribute 'Response'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:77: AttributeError</failure></testcase><testcase classname="tests.test_import_fallbacks" name="test_runner_import_fallbacks" time="0.003"><failure message="AssertionError: Expected import pattern not found in runner.py: from ai_trading.indicators import&#10;assert 'from ai_trading.indicators import' in 'from __future__ import annotations\n\n# ruff: noqa\nimport os\nimport time as _time\nfrom threading import RLock\nimp...and-line invocation.&quot;&quot;&quot;\n    run_cycle()\n\n\nif __name__ == &quot;__main__&quot;:\n    _preflight_import_health()\n    main()\n'">def test_runner_import_fallbacks():
        """Test that runner.py import fallbacks are correctly implemented."""
        import inspect
    
        from ai_trading import runner
    
        source = inspect.getsource(runner)
    
        # Check for expected fallback patterns
        expected_patterns = [
            "from ai_trading.indicators import",
            "from indicators import",
        ]
    
        for pattern in expected_patterns:
&gt;           assert pattern in source, f"Expected import pattern not found in runner.py: {pattern}"
E           AssertionError: Expected import pattern not found in runner.py: from ai_trading.indicators import
E           assert 'from ai_trading.indicators import' in 'from __future__ import annotations\n\n# ruff: noqa\nimport os\nimport time as _time\nfrom threading import RLock\nimp...and-line invocation."""\n    run_cycle()\n\n\nif __name__ == "__main__":\n    _preflight_import_health()\n    main()\n'

tests/test_import_fallbacks.py:71: AssertionError</failure></testcase><testcase classname="tests.test_import_fallbacks" name="test_backtester_import_fallbacks" time="0.008"><failure message="ModuleNotFoundError: No module named 'cachetools'">def test_backtester_import_fallbacks():
        """Test that backtester.py import fallbacks are correctly implemented."""
        import inspect
    
&gt;       from ai_trading.strategies import backtester

tests/test_import_fallbacks.py:78: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/strategies/backtester.py:20: in &lt;module&gt;
    from ai_trading import (
ai_trading/signals.py:114: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_data_fetcher_datetime" name="test_ensure_datetime_pandas_timestamp" time="0.003" /><testcase classname="tests.test_data_fetcher_datetime" name="test_ensure_datetime_nat" time="0.002"><failure message="Failed: DID NOT RAISE &lt;class 'ValueError'&gt;">def test_ensure_datetime_nat():
&gt;       with pytest.raises(ValueError):
E       Failed: DID NOT RAISE &lt;class 'ValueError'&gt;

tests/test_data_fetcher_datetime.py:49: Failed</failure></testcase><testcase classname="tests.test_data_fetcher_datetime" name="test_ensure_datetime_bad_type" time="0.002" /><testcase classname="tests.test_data_fetcher_extended" name="test_get_historical_data" time="0.003"><failure message="AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute 'TimeFrame'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85444a50&gt;

    def test_get_historical_data(monkeypatch):
        df = make_df()
&gt;       setup_tf(monkeypatch)

tests/test_data_fetcher_extended.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85444a50&gt;

    def setup_tf(monkeypatch):
&gt;       monkeypatch.setattr(data_fetcher, "TimeFrame", TF)
E       AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute 'TimeFrame'

tests/test_data_fetcher_extended.py:36: AttributeError</failure></testcase><testcase classname="tests.test_data_fetcher_extended" name="test_get_historical_data_bad_timeframe" time="0.002"><failure message="AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute 'TimeFrame'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85445610&gt;

    def test_get_historical_data_bad_timeframe(monkeypatch):
&gt;       setup_tf(monkeypatch)

tests/test_data_fetcher_extended.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85445610&gt;

    def setup_tf(monkeypatch):
&gt;       monkeypatch.setattr(data_fetcher, "TimeFrame", TF)
E       AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute 'TimeFrame'

tests/test_data_fetcher_extended.py:36: AttributeError</failure></testcase><testcase classname="tests.test_data_fetcher_extended" name="test_get_minute_df_market_closed" time="0.002"><failure message="NotImplementedError">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85444f90&gt;

    def test_get_minute_df_market_closed(monkeypatch):
        monkeypatch.setattr(data_fetcher, "is_market_open", lambda: False)
        today = datetime.date.today()
&gt;       result = data_fetcher.get_minute_df("AAPL", today, today)

tests/test_data_fetcher_extended.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/data_fetcher.py:531: in get_minute_df
    fh_fetcher.fetch(symbol, start_dt, end_dt, resolution="1")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;ai_trading.data_fetcher._FinnhubFetcherStub object at 0x7f8d86253cd0&gt;
args = ('AAPL', datetime.datetime(2025, 8, 22, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2025, 8, 22, 0, 0, tzinfo=datetime.timezone.utc))
kwargs = {'resolution': '1'}

    def fetch(self, *args, **kwargs):
&gt;       raise NotImplementedError
E       NotImplementedError

ai_trading/data_fetcher.py:149: NotImplementedError</failure></testcase><testcase classname="tests.test_institutional_enhancements.TestMarketMicrostructure" name="test_spread_analyzer_initialization" time="0.005"><failure message="AttributeError: module 'requests' has no attribute 'Response'">self = &lt;tests.test_institutional_enhancements.TestMarketMicrostructure testMethod=test_spread_analyzer_initialization&gt;

    def setUp(self):
        """Set up test fixtures."""
        try:
&gt;           from ai_trading.execution.microstructure import (
                BidAskSpreadAnalyzer,
                MarketMicrostructureEngine,
                MarketRegimeFeature,
                OrderFlowAnalyzer,
            )

tests/test_institutional_enhancements.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:35: in &lt;module&gt;
    _alpaca_rest = _optional_import("alpaca_trade_api.rest")
ai_trading/execution/engine.py:29: in _optional_import
    return importlib.import_module(name)
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/__init__.py:3: in &lt;module&gt;
    from .rest import REST, TimeFrame, TimeFrameUnit  # noqa
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import logging
    import os
    from typing import Iterator, List, Optional, Union
    import requests
    from requests.exceptions import HTTPError
    import time
    from enum import Enum
    from alpaca_trade_api import __version__
    from .common import (
        get_base_url,
        get_data_url,
        get_credentials,
        get_api_version, URL, FLOAT,
    )
    from .entity import (
        Bar, Entity, Account, AccountConfigurations, AccountActivity,
        Asset, Order, Position, Clock, Calendar,
        Trade, Quote, Watchlist, PortfolioHistory
    )
    from .entity_v2 import (
        BarV2, BarsV2, LatestBarsV2, LatestQuotesV2, LatestTradesV2,
        SnapshotV2, SnapshotsV2, TradesV2, TradeV2, QuotesV2, QuoteV2,
        NewsV2, NewsListV2, OrderbookV2, OrderbooksV2
    )
    
    logger = logging.getLogger(__name__)
    Positions = List[Position]
    Orders = List[Order]
    Assets = List[Asset]
    AccountActivities = List[AccountActivity]
    Calendars = List[Calendar]
    Watchlists = List[Watchlist]
    TradeIterator = Iterator[Union[Trade, dict]]
    QuoteIterator = Iterator[Union[Quote, dict]]
    BarIterator = Iterator[Union[Bar, dict]]
    NewsIterator = Iterator[Union[NewsV2, dict]]
    
    DATA_V2_MAX_LIMIT = 10000  # max items per api call
    NEWS_MAX_LIMIT = 50  # max items per api call
    
    
    class RetryException(Exception):
        pass
    
    
    class APIError(Exception):
        """
        Represent API related error.
        error.status_code will have http status code.
        """
    
        def __init__(self, error, http_error=None):
            super().__init__(error['message'])
            self._error = error
            self._http_error = http_error
    
        @property
        def code(self):
            return self._error.get('code', self.status_code)
    
        @property
        def status_code(self):
            http_error = self._http_error
            if http_error is not None and hasattr(http_error, 'response'):
                return http_error.response.status_code
    
        @property
        def request(self):
            if self._http_error is not None:
                return self._http_error.request
    
        @property
        def response(self):
            if self._http_error is not None:
                return self._http_error.response
    
&gt;   def raise_api_error(resp: requests.Response, http_error: requests.HTTPError):
E   AttributeError: module 'requests' has no attribute 'Response'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:77: AttributeError</failure></testcase><testcase classname="tests.test_import_fallbacks" name="test_profile_indicators_import_fallbacks" time="0.003"><failure message="ModuleNotFoundError: No module named 'profile_indicators'">def test_profile_indicators_import_fallbacks():
        """Test that profile_indicators.py import fallbacks are correctly implemented."""
        import inspect
    
&gt;       import profile_indicators
E       ModuleNotFoundError: No module named 'profile_indicators'

tests/test_import_fallbacks.py:98: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_data_fetcher_extended" name="test_get_minute_df_missing_columns" time="0.003"><failure message="AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute 'TimeFrame'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d861c0910&gt;

    def test_get_minute_df_missing_columns(monkeypatch):
        df_bad = pd.DataFrame({"price": [1]}, index=[pd.Timestamp("2024-01-01")])
        df_good = make_df()
&gt;       setup_tf(monkeypatch)

tests/test_data_fetcher_extended.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d861c0910&gt;

    def setup_tf(monkeypatch):
&gt;       monkeypatch.setattr(data_fetcher, "TimeFrame", TF)
E       AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute 'TimeFrame'

tests/test_data_fetcher_extended.py:36: AttributeError</failure></testcase><testcase classname="tests.test_import_fallbacks" name="test_import_robustness" time="0.008" /><testcase classname="tests.test_data_fetcher_extended" name="test_get_minute_df_invalid_inputs" time="0.002"><failure message="TypeError: Invalid datetime input: Invalid datetime input: None">value = None

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -&gt; datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
&gt;               raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
E               TypeError: Unsupported datetime type: NoneType

ai_trading/data/timeutils.py:45: TypeError

The above exception was the direct cause of the following exception:

value = None

    def ensure_datetime(value: Any) -&gt; _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
&gt;           return ensure_utc_datetime(value, allow_callables=False)

ai_trading/data_fetcher.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -&gt; datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
                raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
        except (ValueError, TypeError) as e:
            if default is not None:
                return ensure_utc_datetime(default, allow_callables=allow_callables, clamp_to=clamp_to)
&gt;           raise ValueError(f"Invalid datetime input: {value!r}") from e
E           ValueError: Invalid datetime input: None

ai_trading/data/timeutils.py:49: ValueError

The above exception was the direct cause of the following exception:

monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d861c2ed0&gt;

    def test_get_minute_df_invalid_inputs(monkeypatch):
        monkeypatch.setattr(data_fetcher, "is_market_open", lambda: True)
        with pytest.raises(ValueError):
&gt;           data_fetcher.get_minute_df("AAPL", None, datetime.date.today())

tests/test_data_fetcher_extended.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/data_fetcher.py:524: in get_minute_df
    start_dt = ensure_datetime(start)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None

    def ensure_datetime(value: Any) -&gt; _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
            return ensure_utc_datetime(value, allow_callables=False)
        except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
&gt;           raise TypeError(f"Invalid datetime input: {e}") from e
E           TypeError: Invalid datetime input: Invalid datetime input: None

ai_trading/data_fetcher.py:205: TypeError</failure></testcase><testcase classname="tests.test_import_fallbacks" name="test_data_fetcher_helpers_available" time="0.002"><failure message="ImportError: cannot import name 'clear_cached_minute_cache' from 'ai_trading.data_fetcher' (unknown location)">def test_data_fetcher_helpers_available():
        """Test that the new data_fetcher helper functions are available."""
        try:
&gt;           from ai_trading.data_fetcher import (
                clear_cached_minute_cache,
                get_cached_age_seconds,
                get_cached_minute_timestamp,
                set_cached_minute_timestamp,
            )
E           ImportError: cannot import name 'clear_cached_minute_cache' from 'ai_trading.data_fetcher' (unknown location)

tests/test_import_fallbacks.py:143: ImportError

During handling of the above exception, another exception occurred:

    def test_data_fetcher_helpers_available():
        """Test that the new data_fetcher helper functions are available."""
        try:
            from ai_trading.data_fetcher import (
                clear_cached_minute_cache,
                get_cached_age_seconds,
                get_cached_minute_timestamp,
                set_cached_minute_timestamp,
            )
    
            assert callable(get_cached_minute_timestamp)
            assert callable(set_cached_minute_timestamp)
            assert callable(get_cached_age_seconds)
            assert callable(clear_cached_minute_cache)
        except ImportError:
&gt;           from ai_trading.data_fetcher import (
                clear_cached_minute_cache,
                get_cached_age_seconds,
                get_cached_minute_timestamp,
                set_cached_minute_timestamp,
            )
E           ImportError: cannot import name 'clear_cached_minute_cache' from 'ai_trading.data_fetcher' (unknown location)

tests/test_import_fallbacks.py:155: ImportError</failure></testcase><testcase classname="tests.test_import_wiring" name="test_import_contract" time="2.691"><failure message="AssertionError: Import contract failed:&#10;  &#10;assert 1 == 0">def test_import_contract() -&gt; None:
        code, out = run([sys.executable, "tools/import_contract.py"])
&gt;       assert code == 0, f"Import contract failed:\n{out}"
E       AssertionError: Import contract failed:
E         
E       assert 1 == 0

tests/test_import_wiring.py:24: AssertionError</failure></testcase><testcase classname="tests.test_data_fetcher_fallbacks" name="test_minute_fallback_on_empty" time="0.002"><failure message="AttributeError: None has no attribute 'download'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85a0bcd0&gt;

    def test_minute_fallback_on_empty(monkeypatch):
        """Minute bars fall back to Yahoo when Alpaca yields empty."""  # AI-AGENT-REF
        monkeypatch.setattr(dfetch, "_fetch_bars", lambda *a, **k: pd.DataFrame())
&gt;       monkeypatch.setattr(dfetch.yf, "download", _fake_yf)
E       AttributeError: None has no attribute 'download'

tests/test_data_fetcher_fallbacks.py:26: AttributeError</failure></testcase><testcase classname="tests.test_data_fetcher_fallbacks" name="test_minute_fallback_on_exception" time="0.002"><failure message="AttributeError: None has no attribute 'download'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d852ca750&gt;

    def test_minute_fallback_on_exception(monkeypatch):
        """Minute bars fall back to Yahoo when Alpaca errors."""  # AI-AGENT-REF
        def _boom(*_, **__):
            raise ValueError("json error")
    
        monkeypatch.setattr(dfetch, "_fetch_bars", _boom)
        monkeypatch.setattr(dfetch, "fh_fetcher", None)
&gt;       monkeypatch.setattr(dfetch.yf, "download", _fake_yf)
E       AttributeError: None has no attribute 'download'

tests/test_data_fetcher_fallbacks.py:40: AttributeError</failure></testcase><testcase classname="tests.test_data_fetcher_fallbacks" name="test_daily_fallback_on_empty" time="0.004"><failure message="AttributeError: None has no attribute 'download'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d857dbcd0&gt;

    def test_daily_fallback_on_empty(monkeypatch):
        """Daily bars fall back to Yahoo when Alpaca yields empty."""  # AI-AGENT-REF
        monkeypatch.setattr(dfetch, "get_bars", lambda *a, **k: pd.DataFrame())
&gt;       monkeypatch.setattr(dfetch.yf, "download", _fake_yf)
E       AttributeError: None has no attribute 'download'

tests/test_data_fetcher_fallbacks.py:49: AttributeError</failure></testcase><testcase classname="tests.test_data_fetcher_timezone" name="test_yahoo_get_bars_accepts_various_datetime_types" time="0.002"><failure message="ImportError: cannot import name '_yahoo_get_bars' from 'ai_trading.data_fetcher' (unknown location)">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d8540bd90&gt;

    def test_yahoo_get_bars_accepts_various_datetime_types(monkeypatch):
&gt;       from ai_trading.data_fetcher import _yahoo_get_bars
E       ImportError: cannot import name '_yahoo_get_bars' from 'ai_trading.data_fetcher' (unknown location)

tests/test_data_fetcher_timezone.py:38: ImportError</failure></testcase><testcase classname="tests.test_data_init_no_circular" name="test_import_timeutils_does_not_import_bars" time="0.003" /><testcase classname="tests.test_institutional_enhancements.TestMarketMicrostructure" name="test_spread_feature_analysis" time="0.005"><failure message="AttributeError: module 'requests' has no attribute 'Response'">self = &lt;tests.test_institutional_enhancements.TestMarketMicrostructure testMethod=test_spread_feature_analysis&gt;

    def setUp(self):
        """Set up test fixtures."""
        try:
&gt;           from ai_trading.execution.microstructure import (
                BidAskSpreadAnalyzer,
                MarketMicrostructureEngine,
                MarketRegimeFeature,
                OrderFlowAnalyzer,
            )

tests/test_institutional_enhancements.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:35: in &lt;module&gt;
    _alpaca_rest = _optional_import("alpaca_trade_api.rest")
ai_trading/execution/engine.py:29: in _optional_import
    return importlib.import_module(name)
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/__init__.py:3: in &lt;module&gt;
    from .rest import REST, TimeFrame, TimeFrameUnit  # noqa
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import logging
    import os
    from typing import Iterator, List, Optional, Union
    import requests
    from requests.exceptions import HTTPError
    import time
    from enum import Enum
    from alpaca_trade_api import __version__
    from .common import (
        get_base_url,
        get_data_url,
        get_credentials,
        get_api_version, URL, FLOAT,
    )
    from .entity import (
        Bar, Entity, Account, AccountConfigurations, AccountActivity,
        Asset, Order, Position, Clock, Calendar,
        Trade, Quote, Watchlist, PortfolioHistory
    )
    from .entity_v2 import (
        BarV2, BarsV2, LatestBarsV2, LatestQuotesV2, LatestTradesV2,
        SnapshotV2, SnapshotsV2, TradesV2, TradeV2, QuotesV2, QuoteV2,
        NewsV2, NewsListV2, OrderbookV2, OrderbooksV2
    )
    
    logger = logging.getLogger(__name__)
    Positions = List[Position]
    Orders = List[Order]
    Assets = List[Asset]
    AccountActivities = List[AccountActivity]
    Calendars = List[Calendar]
    Watchlists = List[Watchlist]
    TradeIterator = Iterator[Union[Trade, dict]]
    QuoteIterator = Iterator[Union[Quote, dict]]
    BarIterator = Iterator[Union[Bar, dict]]
    NewsIterator = Iterator[Union[NewsV2, dict]]
    
    DATA_V2_MAX_LIMIT = 10000  # max items per api call
    NEWS_MAX_LIMIT = 50  # max items per api call
    
    
    class RetryException(Exception):
        pass
    
    
    class APIError(Exception):
        """
        Represent API related error.
        error.status_code will have http status code.
        """
    
        def __init__(self, error, http_error=None):
            super().__init__(error['message'])
            self._error = error
            self._http_error = http_error
    
        @property
        def code(self):
            return self._error.get('code', self.status_code)
    
        @property
        def status_code(self):
            http_error = self._http_error
            if http_error is not None and hasattr(http_error, 'response'):
                return http_error.response.status_code
    
        @property
        def request(self):
            if self._http_error is not None:
                return self._http_error.request
    
        @property
        def response(self):
            if self._http_error is not None:
                return self._http_error.response
    
&gt;   def raise_api_error(resp: requests.Response, http_error: requests.HTTPError):
E   AttributeError: module 'requests' has no attribute 'Response'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:77: AttributeError</failure></testcase><testcase classname="tests.test_data_pipeline" name="test_macd_pipeline_produces_macds" time="0.007" /><testcase classname="tests.test_data_pipeline" name="test_position_none_safe" time="0.002"><failure message="AttributeError: module 'ai_trading.core.bot_engine' has no attribute '_current_position_qty'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d8540afd0&gt;

    def test_position_none_safe(monkeypatch):
        class Dummy:
            def get_open_position(self, symbol):
                return None
    
        class Ctx:
            pass
    
        ctx = Ctx()
        ctx.api = Dummy()
        from ai_trading.core import bot_engine as be
    
&gt;       assert be._current_position_qty(ctx, "SPY") == 0
E       AttributeError: module 'ai_trading.core.bot_engine' has no attribute '_current_position_qty'

tests/test_data_pipeline.py:34: AttributeError</failure></testcase><testcase classname="tests.test_datetime_wrappers" name="test_naive_et_is_converted_to_utc" time="0.002" /><testcase classname="tests.test_datetime_wrappers" name="test_callable_is_unwrapped" time="0.002" /><testcase classname="tests.test_deprecation_warnings" name="test_bot_engine_deprecation_warning" time="0.009"><failure message="ImportError: cannot import name 'last_market_session' from 'ai_trading.market.calendars' (unknown location)">def test_bot_engine_deprecation_warning():
        """Importing bot_engine emits DeprecationWarning."""  # AI-AGENT-REF
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")
&gt;           import ai_trading.core.bot_engine  # noqa: F401

tests/test_deprecation_warnings.py:11: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    # ruff: noqa
    # fmt: off
    from __future__ import annotations
    
    import importlib
    import importlib.util
    import os
    import sys
    from typing import Dict, Iterable
    from zoneinfo import ZoneInfo  # AI-AGENT-REF: timezone conversions
    
    from json import JSONDecodeError
    # Safe 'requests' import with stub + RequestException binding
    try:  # pragma: no cover
        import requests  # type: ignore
        RequestException = requests.exceptions.RequestException  # type: ignore[attr-defined]
    except ImportError:  # pragma: no cover  # AI-AGENT-REF: narrow import handling
        class RequestException(Exception):
            pass
    
        # Minimal stub so runtime calls fail gracefully into COMMON_EXC
        class _RequestsStub:
            class exceptions:
                RequestException = RequestException
    
            def get(self, *a, **k):
                raise RequestException("requests not installed")
    
        requests = _RequestsStub()  # type: ignore
    
    from threading import Lock
    import warnings
    
    from ai_trading.data_fetcher import (
        get_bars,
        get_bars_batch,
        get_minute_df,
    )
&gt;   from ai_trading.market.calendars import last_market_session
E   ImportError: cannot import name 'last_market_session' from 'ai_trading.market.calendars' (unknown location)

ai_trading/core/bot_engine.py:39: ImportError</failure></testcase><testcase classname="tests.test_indicators" name="test_ichimoku_indicator_returns_dataframe" time="0.004" /><testcase classname="tests.test_indicators" name="test_compute_ichimoku_returns_df_pair" time="0.003" /><testcase classname="tests.test_indicators" name="test_vwap_calculation" time="0.003" /><testcase classname="tests.test_initial_rebalance" name="test_partial_initial_rebalance_fill" time="0.004"><failure message="AttributeError: 'DummyAPI' object has no attribute 'list_open_positions'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f867cdb1c90&gt;

    def test_partial_initial_rebalance_fill(monkeypatch):
        ctx = types.SimpleNamespace(
            api=DummyAPI(),
            data_fetcher=DummyFetcher(),
            rebalance_ids={},
            rebalance_attempts={},
            rebalance_buys={},
        )
    
        class FakeDateTime(datetime.datetime):
            @classmethod
            def now(cls, tz=None):
                return datetime.datetime(2025, 7, 26, 0, 16, tzinfo=datetime.UTC)
    
        monkeypatch.setattr(bot_engine, "datetime", FakeDateTime)
    
        def fake_submit(ctx_, symbol, qty, side):
            ctx_.api.orders.append((symbol, qty, side))
            ctx_.api.positions[symbol] = ctx_.api.positions.get(symbol, 0) + qty // 2
            return object()
    
        monkeypatch.setattr(bot_engine, "submit_order", fake_submit)
    
&gt;       bot_engine.initial_rebalance(ctx, ["AAPL"])

tests/test_initial_rebalance.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ctx = namespace(api=&lt;tests.test_initial_rebalance.DummyAPI object at 0x7f8677fc1050&gt;, data_fetcher=&lt;tests.test_initial_rebalance.DummyFetcher object at 0x7f8677fc2850&gt;, rebalance_ids={}, rebalance_attempts={}, rebalance_buys={})
symbols = ['AAPL']

    def initial_rebalance(ctx: BotContext, symbols: list[str]) -&gt; None:
        """Initial portfolio rebalancing."""
    
        if ctx.api is None:
            _log.warning("ctx.api is None - cannot perform initial rebalance")
            return
    
        try:
            datetime.now(UTC).astimezone(PACIFIC)
            acct = ctx.api.get_account()
            float(acct.equity)
    
            cash = float(acct.cash)
            buying_power = float(getattr(acct, "buying_power", cash))
            n = len(symbols)
            if n == 0 or cash &lt;= 0 or buying_power &lt;= 0:
                _log.info("INITIAL_REBALANCE_NO_SYMBOLS_OR_NO_CASH")
                return
        except (
            APIError,
            TimeoutError,
            ConnectionError,
        ) as e:  # AI-AGENT-REF: tighten rebalance account fetch errors
            _log.warning(
                "INITIAL_REBALANCE_ACCOUNT_FAIL",
                extra={"cause": e.__class__.__name__, "detail": str(e)},
            )
            return
    
        # Determine current UTC time
        now_utc = datetime.now(UTC)
        # If it’s between 00:00 and 00:15 UTC, daily bars may not be published yet.
        if now_utc.hour == 0 and now_utc.minute &lt; 15:
            _log.info("INITIAL_REBALANCE: Too early—daily bars not live yet.")
        else:
            # Gather all symbols that have a valid, nonzero close
            valid_symbols = []
            valid_prices = {}
            for symbol in symbols:
                df_daily = ctx.data_fetcher.get_daily_df(ctx, symbol)
                price = get_latest_close(df_daily)
                if price &lt;= 0:
                    # skip symbols with no real close data
                    continue
                valid_symbols.append(symbol)
                valid_prices[symbol] = price
    
            if not valid_symbols:
                log_level = logging.ERROR if in_trading_hours(now_utc) else logging.WARNING
                _log.log(
                    log_level,
                    (
                        "INITIAL_REBALANCE: No valid prices for any symbol—skipping "
                        "rebalance. Possible data outage or market holiday. "
                        "Check data provider/API status."
                    ),
                )
            else:
                # Compute equal weights on valid symbols only
                total_capital = cash
                weight_per = 1.0 / len(valid_symbols)
    
&gt;               positions = {p.symbol: int(p.qty) for p in ctx.api.list_open_positions()}
E               AttributeError: 'DummyAPI' object has no attribute 'list_open_positions'

ai_trading/core/bot_engine.py:12988: AttributeError</failure></testcase><testcase classname="tests.test_institutional_enhancements.TestTaxAwareRebalancing" name="test_loss_harvesting_identification" time="0.002"><skipped type="pytest.skip" message="Tax-aware rebalancer not available">/workspace/ai-trading-bot/tests/test_institutional_enhancements.py:373: Tax-aware rebalancer not available</skipped></testcase><testcase classname="tests.test_institutional_enhancements.TestTaxAwareRebalancing" name="test_tax_impact_calculation" time="0.002"><skipped type="pytest.skip" message="Tax-aware rebalancer not available">/workspace/ai-trading-bot/tests/test_institutional_enhancements.py:351: Tax-aware rebalancer not available</skipped></testcase><testcase classname="tests.test_institutional_enhancements.TestTaxAwareRebalancing" name="test_tax_rebalancer_initialization" time="0.002"><skipped type="pytest.skip" message="Tax-aware rebalancer not available">/workspace/ai-trading-bot/tests/test_institutional_enhancements.py:342: Tax-aware rebalancer not available</skipped></testcase><testcase classname="tests.test_institutional_enhancements.TestEnhancedRebalancer" name="test_enhanced_rebalancer_fallback" time="0.002"><failure message="ImportError: cannot import name 'enhanced_maybe_rebalance' from 'ai_trading.rebalancer' (unknown location)">self = &lt;tests.test_institutional_enhancements.TestEnhancedRebalancer testMethod=test_enhanced_rebalancer_fallback&gt;

    def test_enhanced_rebalancer_fallback(self):
        """Test that enhanced rebalancer falls back gracefully."""
        import os
        import sys
        sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    
&gt;       from ai_trading.rebalancer import enhanced_maybe_rebalance, rebalance_portfolio
E       ImportError: cannot import name 'enhanced_maybe_rebalance' from 'ai_trading.rebalancer' (unknown location)

tests/test_institutional_enhancements.py:419: ImportError</failure></testcase><testcase classname="tests.test_institutional_kelly.TestKellyCriterion" name="test_kelly_initialization" time="0.003" /><testcase classname="tests.test_institutional_kelly.TestKellyCriterion" name="test_basic_kelly_calculation" time="0.003" /><testcase classname="tests.test_institutional_kelly.TestKellyCriterion" name="test_kelly_with_max_fraction_cap" time="0.002" /><testcase classname="tests.test_institutional_kelly.TestKellyCriterion" name="test_kelly_negative_expectancy" time="0.002" /><testcase classname="tests.test_institutional_kelly.TestKellyCriterion" name="test_kelly_invalid_inputs" time="0.008" /><testcase classname="tests.test_institutional_kelly.TestKellyCriterion" name="test_calculate_from_returns" time="0.002" /><testcase classname="tests.test_institutional_kelly.TestKellyCriterion" name="test_insufficient_sample_size" time="0.003" /><testcase classname="tests.test_institutional_kelly.TestKellyCriterion" name="test_no_wins_or_losses" time="0.003" /><testcase classname="tests.test_institutional_kelly.TestKellyCriterion" name="test_fractional_kelly" time="0.002" /><testcase classname="tests.test_institutional_kelly.TestKellyCriterion" name="test_kelly_with_confidence" time="0.003" /><testcase classname="tests.test_institutional_kelly.TestKellyCalculator" name="test_kelly_calculator_initialization" time="0.002"><error message="failed on setup with &quot;AttributeError: 'NoneType' object has no attribute 'min_sample_size'&quot;">self = &lt;tests.test_institutional_kelly.TestKellyCalculator object at 0x7ff8d81a0550&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       self.calculator = KellyCalculator()

tests/test_institutional_kelly.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d34431d0&gt;, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
&gt;           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError</error></testcase><testcase classname="tests.test_institutional_kelly.TestKellyCalculator" name="test_portfolio_kelly_calculation" time="0.002"><error message="failed on setup with &quot;AttributeError: 'NoneType' object has no attribute 'min_sample_size'&quot;">self = &lt;tests.test_institutional_kelly.TestKellyCalculator object at 0x7ff8d3e98990&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       self.calculator = KellyCalculator()

tests/test_institutional_kelly.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d334f490&gt;, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
&gt;           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError</error></testcase><testcase classname="tests.test_institutional_kelly.TestKellyCalculator" name="test_dynamic_kelly_adjustment" time="0.002"><error message="failed on setup with &quot;AttributeError: 'NoneType' object has no attribute 'min_sample_size'&quot;">self = &lt;tests.test_institutional_kelly.TestKellyCalculator object at 0x7ff8d3e98a50&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       self.calculator = KellyCalculator()

tests/test_institutional_kelly.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d3ad0c10&gt;, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
&gt;           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError</error></testcase><testcase classname="tests.test_institutional_kelly.TestKellyCalculator" name="test_kelly_with_correlation" time="0.002"><error message="failed on setup with &quot;AttributeError: 'NoneType' object has no attribute 'min_sample_size'&quot;">self = &lt;tests.test_institutional_kelly.TestKellyCalculator object at 0x7ff8d3e99790&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       self.calculator = KellyCalculator()

tests/test_institutional_kelly.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d3ad13d0&gt;, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
&gt;           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError</error></testcase><testcase classname="tests.test_institutional_kelly.TestKellyCalculator" name="test_calculation_history_recording" time="0.002"><error message="failed on setup with &quot;AttributeError: 'NoneType' object has no attribute 'min_sample_size'&quot;">self = &lt;tests.test_institutional_kelly.TestKellyCalculator object at 0x7ff8d3e9a190&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       self.calculator = KellyCalculator()

tests/test_institutional_kelly.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d39868d0&gt;, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
&gt;           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError</error></testcase><testcase classname="tests.test_institutional_kelly.TestKellyIntegration" name="test_kelly_with_risk_levels" time="0.003"><failure message="AttributeError: 'NoneType' object has no attribute 'min_sample_size'">self = &lt;tests.test_institutional_kelly.TestKellyIntegration object at 0x7ff8d3ebffd0&gt;

    def test_kelly_with_risk_levels(self):
        """Test Kelly integration with different risk levels."""
        # Conservative risk level
&gt;       conservative_kelly = KellyCriterion(max_fraction=RiskLevel.CONSERVATIVE.max_position_size)

tests/test_institutional_kelly.py:278: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d37fadd0&gt;, config = None, min_sample_size = None
max_fraction = 0.02, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
&gt;           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError</failure></testcase><testcase classname="tests.test_institutional_kelly.TestKellyIntegration" name="test_kelly_logging" time="0.009"><failure message="AttributeError: 'NoneType' object has no attribute 'min_sample_size'">self = &lt;tests.test_institutional_kelly.TestKellyIntegration object at 0x7ff8d3e9a0d0&gt;
mock_logger = &lt;MagicMock name='logger' id='140706683029648'&gt;

    @patch('ai_trading.risk.kelly.logger')
    def test_kelly_logging(self, mock_logger):
        """Test Kelly Criterion logging functionality."""
&gt;       kelly = KellyCriterion()

tests/test_institutional_kelly.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d8329110&gt;, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
&gt;           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError</failure></testcase><testcase classname="tests.test_intelligent_position_management.TestMarketRegimeDetector" name="test_regime_classification" time="0.003" /><testcase classname="tests.test_intelligent_position_management.TestMarketRegimeDetector" name="test_regime_parameters" time="0.002" /><testcase classname="tests.test_intelligent_position_management.TestMarketRegimeDetector" name="test_high_volatility_regime" time="0.003" /><testcase classname="tests.test_intelligent_position_management.TestTechnicalSignalAnalyzer" name="test_rsi_calculation" time="0.003" /><testcase classname="tests.test_intelligent_position_management.TestTechnicalSignalAnalyzer" name="test_divergence_detection" time="0.003" /><testcase classname="tests.test_intelligent_position_management.TestTrailingStopManager" name="test_stop_initialization" time="0.002"><failure message="NameError: name 'MockPosition' is not defined">self = &lt;tests.test_intelligent_position_management.TestTrailingStopManager object at 0x7ff8d81ce010&gt;

    def test_stop_initialization(self):
        """Test trailing stop initialization."""
&gt;       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:243: NameError</failure></testcase><testcase classname="tests.test_intelligent_position_management.TestTrailingStopManager" name="test_stop_movement" time="0.003"><failure message="NameError: name 'MockPosition' is not defined">self = &lt;tests.test_intelligent_position_management.TestTrailingStopManager object at 0x7ff8d3d05f90&gt;

    def test_stop_movement(self):
        """Test that stops move up with price for long positions."""
&gt;       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:259: NameError</failure></testcase><testcase classname="tests.test_intelligent_position_management.TestTrailingStopManager" name="test_stop_trigger_detection" time="0.003"><failure message="NameError: name 'MockPosition' is not defined">self = &lt;tests.test_intelligent_position_management.TestTrailingStopManager object at 0x7ff8d3d06390&gt;

    def test_stop_trigger_detection(self):
        """Test stop trigger detection."""
&gt;       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:279: NameError</failure></testcase><testcase classname="tests.test_intelligent_position_management.TestProfitTakingEngine" name="test_profit_plan_creation" time="0.003"><failure message="NameError: name 'MockPosition' is not defined">self = &lt;tests.test_intelligent_position_management.TestProfitTakingEngine object at 0x7ff8d3d065d0&gt;

    def test_profit_plan_creation(self):
        """Test profit plan creation."""
&gt;       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:306: NameError</failure></testcase><testcase classname="tests.test_intelligent_position_management.TestProfitTakingEngine" name="test_target_triggering" time="0.013"><failure message="NameError: name 'MockPosition' is not defined">self = &lt;tests.test_intelligent_position_management.TestProfitTakingEngine object at 0x7ff8d3d06e90&gt;

    def test_target_triggering(self):
        """Test profit target triggering."""
&gt;       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:326: NameError</failure></testcase><testcase classname="tests.test_intelligent_position_management.TestPortfolioCorrelationAnalyzer" name="test_position_data_extraction" time="0.003"><failure message="NameError: name 'MockPosition' is not defined">self = &lt;tests.test_intelligent_position_management.TestPortfolioCorrelationAnalyzer object at 0x7ff8d3d76e50&gt;

    def test_position_data_extraction(self):
        """Test position data extraction."""
        positions = [
&gt;           MockPosition('AAPL', 100, 100.0, 11000.0),
            MockPosition('MSFT', 50, 200.0, 10500.0),
            MockPosition('GOOGL', 25, 150.0, 3750.0)
        ]
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:355: NameError</failure></testcase><testcase classname="tests.test_intelligent_position_management.TestPortfolioCorrelationAnalyzer" name="test_sector_classification" time="0.003" /><testcase classname="tests.test_intelligent_position_management.TestPortfolioCorrelationAnalyzer" name="test_concentration_analysis" time="0.002"><failure message="NameError: name 'MockPosition' is not defined">self = &lt;tests.test_intelligent_position_management.TestPortfolioCorrelationAnalyzer object at 0x7ff8d8191510&gt;

    def test_concentration_analysis(self):
        """Test concentration level analysis."""
        positions = [
&gt;           MockPosition('AAPL', 100, 100.0, 50000.0),  # 50% of portfolio
            MockPosition('MSFT', 50, 200.0, 25000.0),   # 25% of portfolio
            MockPosition('GOOGL', 25, 150.0, 25000.0)   # 25% of portfolio
        ]
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:377: NameError</failure></testcase><testcase classname="tests.test_intelligent_position_management.TestIntegrationScenarios" name="test_profitable_position_scenario" time="0.003"><failure message="NameError: name 'MockPosition' is not defined">self = &lt;tests.test_intelligent_position_management.TestIntegrationScenarios object at 0x7ff8d8192890&gt;

    def test_profitable_position_scenario(self):
        """Test scenario with profitable position."""
&gt;       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=12000.0  # 20% gain
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:399: NameError</failure></testcase><testcase classname="tests.test_intelligent_position_management.TestIntegrationScenarios" name="test_loss_position_scenario" time="0.003"><failure message="NameError: name 'MockPosition' is not defined">self = &lt;tests.test_intelligent_position_management.TestIntegrationScenarios object at 0x7ff8d87a5dd0&gt;

    def test_loss_position_scenario(self):
        """Test scenario with losing position."""
&gt;       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=9000.0  # 10% loss
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:417: NameError</failure></testcase><testcase classname="tests.test_intelligent_position_management.TestIntegrationScenarios" name="test_portfolio_level_recommendations" time="0.003"><failure message="NameError: name 'MockPosition' is not defined">self = &lt;tests.test_intelligent_position_management.TestIntegrationScenarios object at 0x7ff8d81cef10&gt;

    def test_portfolio_level_recommendations(self):
        """Test portfolio-level analysis and recommendations."""
        positions = [
&gt;           MockPosition('AAPL', 100, 100.0, 11000.0),
            MockPosition('MSFT', 50, 200.0, 10500.0),
            MockPosition('TSLA', 30, 150.0, 4800.0)
        ]
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:434: NameError</failure></testcase><testcase classname="tests.test_intelligent_position_management" name="test_logging_configuration" time="0.002" /><testcase classname="tests.test_json_formatter" name="test_json_formatter_custom_fields_and_masking" time="0.003"><failure message="AssertionError: assert (False)&#10; +  where False = &lt;built-in method endswith of str object at 0x7ff8d33236b0&gt;('1234')&#10; +    where &lt;built-in method endswith of str object at 0x7ff8d33236b0&gt; = 'ab***34'.endswith">def test_json_formatter_custom_fields_and_masking():
        fmt = logger.JSONFormatter("%(asctime)sZ")
        rec = _make_record(symbol="AAPL", api_key="abcdef1234", pathname="skip")
        out = fmt.format(rec)
        data = json.loads(out)
        assert set(data) &gt;= {"ts", "level", "name", "msg", "symbol", "api_key"}
&gt;       assert data["api_key"].endswith("1234") and set(data["api_key"]) &lt;= set("*1234")
E       AssertionError: assert (False)
E        +  where False = &lt;built-in method endswith of str object at 0x7ff8d33236b0&gt;('1234')
E        +    where &lt;built-in method endswith of str object at 0x7ff8d33236b0&gt; = 'ab***34'.endswith

tests/test_json_formatter.py:28: AssertionError</failure></testcase><testcase classname="tests.test_json_formatter" name="test_json_formatter_exc_info" time="0.003" /><testcase classname="tests.test_json_formatter" name="test_json_formatter_serializes_nonstandard_types" time="0.003" /><testcase classname="tests.test_meta_learning" name="test_update_signal_weights_empty" time="0.003" /><testcase classname="tests.test_meta_learning" name="test_update_signal_weights_norm_zero" time="0.003"><failure message="AssertionError: assert 'Normalization factor zero' in 'WARNING  ai_trading.meta_learning:meta_learning.py:616 Norm…tion factor zero in weight update\n'&#10; +  where 'WARNING  ai_trading.meta_learning:meta_learning.py:616 Norm…tion factor zero in weight update\n' = &lt;_pytest.logging.LogCaptureFixture object at 0x7ff8d39d35d0&gt;.text">caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7ff8d39d35d0&gt;

    def test_update_signal_weights_norm_zero(caplog):
        caplog.set_level("WARNING")
        w = {"a": 0.0}
        perf = {"a": 1.0}
        res = meta_learning.update_signal_weights(w, perf)
        assert res == w
&gt;       assert "Normalization factor zero" in caplog.text
E       AssertionError: assert 'Normalization factor zero' in 'WARNING  ai_trading.meta_learning:meta_learning.py:616 Norm…tion factor zero in weight update\n'
E        +  where 'WARNING  ai_trading.meta_learning:meta_learning.py:616 Norm…tion factor zero in weight update\n' = &lt;_pytest.logging.LogCaptureFixture object at 0x7ff8d39d35d0&gt;.text

tests/test_meta_learning.py:154: AssertionError</failure></testcase><testcase classname="tests.test_meta_learning" name="test_portfolio_rl_trigger" time="0.004"><failure message="ModuleNotFoundError: No module named 'portfolio_rl'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d39dbd50&gt;

    def test_portfolio_rl_trigger(monkeypatch):
        torch = pytest.importorskip("torch")
        # AI-AGENT-REF: ensure real torch is loaded during tests
        # if not hasattr(torch, "nn") or not hasattr(torch.nn, "Parameter"):
        #     pytest.skip("torch stubs active")
        class FakeLinear(nn.Module):
            def __init__(self, *a, **k):
                super().__init__()
                self.weight = nn.Parameter(torch.tensor([0.0]))
    
            def forward(self, x):
                return x
    
        monkeypatch.setattr(nn, "Linear", lambda *a, **k: FakeLinear())
&gt;       import portfolio_rl
E       ModuleNotFoundError: No module named 'portfolio_rl'

tests/test_meta_learning.py:171: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_deprecation_warnings" name="test_data_fetcher_deprecation_warning" time="0.003"><failure message="assert 0 &gt;= 1&#10; +  where 0 = len([])">def test_data_fetcher_deprecation_warning():
        """Test that importing data_fetcher shows deprecation warning."""
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")
            import ai_trading.data_fetcher  # noqa: F401
    
            # Check that a deprecation warning was raised
&gt;           assert len(w) &gt;= 1
E           assert 0 &gt;= 1
E            +  where 0 = len([])

tests/test_deprecation_warnings.py:22: AssertionError</failure></testcase><testcase classname="tests.test_meta_learning_additional" name="test_load_weights_save_fail" time="0.004"><failure message="OSError: fail">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3996350&gt;
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_load_weights_save_fail0')
caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7ff8d334c950&gt;

    def test_load_weights_save_fail(monkeypatch, tmp_path, caplog):
        """Failure to write default weights is logged and default returned."""
        p = tmp_path / "w.csv"
        monkeypatch.setattr(meta_learning.Path, "exists", lambda self: False)
        def fail(*a, **k):
            raise OSError("fail")
        monkeypatch.setattr(meta_learning.np, "savetxt", fail)
        caplog.set_level("ERROR")
&gt;       arr = meta_learning.load_weights(str(p), default=np.array([1.0]))

/workspace/ai-trading-bot/tests/test_meta_learning_additional.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/ai-trading-bot/ai_trading/meta_learning.py:540: in load_weights
    np.savetxt(p, default, delimiter=",")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = (PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_load_weights_save_fail0/w.csv'), array([1.]))
k = {'delimiter': ','}

    def fail(*a, **k):
&gt;       raise OSError("fail")
E       OSError: fail

/workspace/ai-trading-bot/tests/test_meta_learning_additional.py:14: OSError</failure></testcase><testcase classname="tests.test_deprecation_warnings" name="test_runner_deprecation_warning" time="0.003"><failure message="assert 0 &gt;= 1&#10; +  where 0 = len([])">def test_runner_deprecation_warning():
        """Test that importing runner shows deprecation warning."""
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")
            import ai_trading.runner  # noqa: F401
    
            # Check that a deprecation warning was raised
&gt;           assert len(w) &gt;= 1
E           assert 0 &gt;= 1
E            +  where 0 = len([])

tests/test_deprecation_warnings.py:34: AssertionError</failure></testcase><testcase classname="tests.test_deprecation_warnings" name="test_alpaca_api_deprecation_warning" time="0.002" /><testcase classname="tests.test_institutional_core.TestOrderEnums" name="test_order_side_values" time="0.003" /><testcase classname="tests.test_dual_schema_credentials.TestDualSchemaCredentials" name="test_alpaca_schema_only" time="0.002" /><testcase classname="tests.test_institutional_core.TestOrderEnums" name="test_order_type_values" time="0.002" /><testcase classname="tests.test_market_calendar_wrapper" name="test_rth_dst_summer_standard_times" time="0.068" /><testcase classname="tests.test_institutional_core.TestOrderEnums" name="test_order_status_values" time="0.002" /><testcase classname="tests.test_institutional_core.TestOrderEnums" name="test_order_status_terminal" time="0.002" /><testcase classname="tests.test_institutional_core.TestRiskLevel" name="test_risk_level_values" time="0.003" /><testcase classname="tests.test_institutional_core.TestRiskLevel" name="test_max_position_size" time="0.002" /><testcase classname="tests.test_institutional_core.TestRiskLevel" name="test_max_drawdown_threshold" time="0.013" /><testcase classname="tests.test_institutional_core.TestTimeFrame" name="test_timeframe_values" time="0.002" /><testcase classname="tests.test_institutional_core.TestTimeFrame" name="test_timeframe_seconds" time="0.002" /><testcase classname="tests.test_institutional_core.TestAssetClass" name="test_asset_class_values" time="0.002" /><testcase classname="tests.test_institutional_core.TestTradingConstants" name="test_market_hours_exist" time="0.002" /><testcase classname="tests.test_institutional_core.TestTradingConstants" name="test_risk_parameters_exist" time="0.002" /><testcase classname="tests.test_institutional_core.TestTradingConstants" name="test_kelly_parameters_exist" time="0.002" /><testcase classname="tests.test_institutional_core.TestTradingConstants" name="test_execution_parameters_exist" time="0.002" /><testcase classname="tests.test_institutional_core.TestTradingConstants" name="test_parameter_value_ranges" time="0.002" /><testcase classname="tests.test_institutional_core.TestConstantsIntegration" name="test_all_constant_groups_present" time="0.002" /><testcase classname="tests.test_meta_learning_additional" name="test_update_signal_weights_edge_cases" time="0.003" /><testcase classname="tests.test_meta_learning_additional" name="test_save_and_load_checkpoint" time="0.004" /><testcase classname="tests.test_institutional_core.TestConstantsIntegration" name="test_constants_are_immutable_types" time="0.009" /><testcase classname="tests.test_institutional_core.TestConstantsIntegration" name="test_constants_consistency" time="0.002" /><testcase classname="tests.test_meta_learning_additional" name="test_retrain_meta_learner" time="0.025"><failure message="assert False">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d33d9310&gt;
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_retrain_meta_learner0')

    def test_retrain_meta_learner(monkeypatch, tmp_path):
        """Meta learner retrains with small dataset."""
        data = Path(tmp_path / "trades.csv")
        df = meta_learning.pd.DataFrame({
            "entry_price": [1, 2],
            "exit_price": [2, 3],
            "signal_tags": ["a", "b"],
            "side": ["buy", "sell"],
        })
        df.to_csv(data, index=False)
        monkeypatch.setattr(meta_learning, "save_model_checkpoint", lambda *a, **k: None)
        monkeypatch.setattr(meta_learning, "load_model_checkpoint", lambda *a, **k: [])
        monkeypatch.setattr(sklearn.linear_model, "Ridge", lambda *a, **k: types.SimpleNamespace(fit=lambda X,y, sample_weight=None: None, predict=lambda X:[0]*len(X)))
        ok = meta_learning.retrain_meta_learner(str(data), str(tmp_path/"m.pkl"), str(tmp_path/"hist.pkl"), min_samples=1)
&gt;       assert ok
E       assert False

tests/test_meta_learning_additional.py:52: AssertionError</failure></testcase><testcase classname="tests.test_market_calendar_wrapper" name="test_known_early_close_black_friday" time="0.032" /><testcase classname="tests.test_institutional_enhancements.TestAdaptivePositionSizing" name="test_adaptive_position_calculation" time="0.002"><skipped type="pytest.skip" message="Adaptive sizing modules not available">/workspace/ai-trading-bot/tests/test_institutional_enhancements.py:69: Adaptive sizing modules not available</skipped></testcase><testcase classname="tests.test_institutional_enhancements.TestAdaptivePositionSizing" name="test_adaptive_position_sizer_initialization" time="0.003"><skipped type="pytest.skip" message="Adaptive sizing modules not available">/workspace/ai-trading-bot/tests/test_institutional_enhancements.py:60: Adaptive sizing modules not available</skipped></testcase><testcase classname="tests.test_institutional_enhancements.TestAdaptivePositionSizing" name="test_market_condition_analyzer_initialization" time="0.002"><skipped type="pytest.skip" message="Adaptive sizing modules not available">/workspace/ai-trading-bot/tests/test_institutional_enhancements.py:36: Adaptive sizing modules not available</skipped></testcase><testcase classname="tests.test_institutional_enhancements.TestAdaptivePositionSizing" name="test_market_regime_classification" time="0.002"><skipped type="pytest.skip" message="Adaptive sizing modules not available">/workspace/ai-trading-bot/tests/test_institutional_enhancements.py:45: Adaptive sizing modules not available</skipped></testcase><testcase classname="tests.test_ml_model_extra" name="test_train_model_invalid_algorithm" time="0.002" /><testcase classname="tests.test_ml_model_extra" name="test_train_model_invalid_data" time="0.008" /><testcase classname="tests.test_ml_model_extra" name="test_predict_model_untrained" time="0.002" /><testcase classname="tests.test_market_calendar_wrapper" name="test_is_trading_day_true_black_friday" time="0.003" /><testcase classname="tests.test_ml_model_extra" name="test_predict_model_invalid_input" time="0.027" /><testcase classname="tests.test_mean_reversion_extra" name="test_generate_insufficient_data" time="0.021"><failure message="AssertionError: assert 'insufficient' in 'WARNING  ai_trading.logging:mean_reversion.py:27 mean…sion: insu…ient data\n'&#10; +  where 'WARNING  ai_trading.logging:mean_reversion.py:27 mean…sion: insu…ient data\n' = &lt;_pytest.logging.LogCaptureFixture object at 0x7f8d8503a710&gt;.text">caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7f8d8503a710&gt;

    def test_generate_insufficient_data(caplog):
        """Insufficient history skips generation."""
        df = pd.DataFrame({"close": [1, 2]})
        ctx = Ctx(df)
        strat = MeanReversionStrategy(lookback=5)
        caplog.set_level('WARNING')
        assert strat.generate(ctx) == []
&gt;       assert "insufficient" in caplog.text
E       AssertionError: assert 'insufficient' in 'WARNING  ai_trading.logging:mean_reversion.py:27 mean…sion: insu…ient data\n'
E        +  where 'WARNING  ai_trading.logging:mean_reversion.py:27 mean…sion: insu…ient data\n' = &lt;_pytest.logging.LogCaptureFixture object at 0x7f8d8503a710&gt;.text

tests/test_mean_reversion_extra.py:24: AssertionError</failure></testcase><testcase classname="tests.test_mean_reversion_extra" name="test_generate_invalid_stats" time="0.005"><failure message="AssertionError: assert 'invalid rolling' in 'WARNING  ai_trading.logging:mean_reversion.py:33 mean…sion: invalid stats\n'&#10; +  where 'WARNING  ai_trading.logging:mean_reversion.py:33 mean…sion: invalid stats\n' = &lt;_pytest.logging.LogCaptureFixture object at 0x7f8d859ba350&gt;.text">caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7f8d859ba350&gt;

    def test_generate_invalid_stats(caplog):
        """Invalid rolling statistics skip generation."""
        df = pd.DataFrame({"close": [1]*10})
        ctx = Ctx(df)
        strat = MeanReversionStrategy(lookback=3)
        caplog.set_level('WARNING')
        ctx.data_fetcher.df.loc[ctx.data_fetcher.df.index[-1], "close"] = float('nan')
        assert strat.generate(ctx) == []
&gt;       assert "invalid rolling" in caplog.text
E       AssertionError: assert 'invalid rolling' in 'WARNING  ai_trading.logging:mean_reversion.py:33 mean…sion: invalid stats\n'
E        +  where 'WARNING  ai_trading.logging:mean_reversion.py:33 mean…sion: invalid stats\n' = &lt;_pytest.logging.LogCaptureFixture object at 0x7f8d859ba350&gt;.text

tests/test_mean_reversion_extra.py:35: AssertionError</failure></testcase><testcase classname="tests.test_ml_model_extra" name="test_load_model_missing_file" time="0.007" /><testcase classname="tests.test_meta_learning" name="test_meta_learning_instantiation" time="0.002" /><testcase classname="tests.test_meta_learning" name="test_load_weights_creates_default" time="0.004" /><testcase classname="tests.test_ml_model_extra" name="test_save_and_load_model" time="0.006" /><testcase classname="tests.test_ml_model_validation" name="test_predict_validation" time="0.007" /><testcase classname="tests.test_meta_learning" name="test_update_weights_no_change" time="0.004" /><testcase classname="tests.test_meta_learning" name="test_update_signal_weights_normal" time="0.002" /><testcase classname="tests.test_meta_learning" name="test_save_and_load_checkpoint" time="0.003" /><testcase classname="tests.test_model_loading" name="test_load_model_from_path" time="0.010" /><testcase classname="tests.test_meta_learning" name="test_optimize_signals" time="0.002" /><testcase classname="tests.test_meta_learning" name="test_retrain_meta_missing" time="0.006" /><testcase classname="tests.test_model_loading" name="test_load_model_from_module" time="0.007" /><testcase classname="tests.test_meta_learning" name="test_update_weights_history_error" time="0.007" /><testcase classname="tests.test_model_loading" name="test_model_missing_raises" time="0.007" /><testcase classname="tests.test_meta_learning" name="test_load_weights_corrupted" time="0.005" /><testcase classname="tests.test_model_registry.TestModelRegistry" name="test_registry_roundtrip" time="0.010" /><testcase classname="tests.test_meta_learning" name="test_update_weights_success" time="0.005" /><testcase classname="tests.test_meta_learning" name="test_load_model_checkpoint_missing" time="0.003" /><testcase classname="tests.test_model_registry.TestModelRegistry" name="test_index_file_creation" time="0.004" /><testcase classname="tests.test_meta_learning" name="test_update_signal_weights_zero" time="0.002" /><testcase classname="tests.test_model_registry.TestModelRegistry" name="test_dataset_fingerprint_verification" time="0.026" /><testcase classname="tests.test_meta_learning" name="test_load_weights_existing" time="0.004" /><testcase classname="tests.test_meta_learning" name="test_optimize_signals_failure" time="0.019" /><testcase classname="tests.test_meta_learning" name="test_load_weights_default_zero" time="0.003" /><testcase classname="tests.test_model_registry.TestModelRegistry" name="test_latest_for_empty_registry" time="0.004" /><testcase classname="tests.test_meta_learning" name="test_update_weights_failure" time="0.005" /><testcase classname="tests.test_model_registry.TestModelRegistry" name="test_load_nonexistent_model" time="0.003" /><testcase classname="tests.test_model_registry.TestModelRegistry" name="test_model_not_picklable" time="0.004"><failure message="Exception: Cannot pickle this object">self = &lt;tests.test_model_registry.TestModelRegistry object at 0x7f867c093390&gt;

    def test_model_not_picklable(self):
        """Test that non-picklable models raise RuntimeError."""
        with tempfile.TemporaryDirectory() as temp_dir:
            registry = ModelRegistry(temp_dir)
    
            # Create a mock object that raises an exception when pickled
            mock_model = Mock()
    
            def pickle_side_effect(*args, **kwargs):
                raise Exception("Cannot pickle this object")
    
            with pytest.raises(RuntimeError, match="Model not picklable"):
                with tempfile.NamedTemporaryFile():
                    # Patch pickle.dumps to raise an exception
                    import pickle as pickle_module
                    original_dumps = pickle_module.dumps
                    pickle_module.dumps = pickle_side_effect
                    try:
&gt;                       registry.register_model(
                            model=mock_model,
                            strategy="test_strategy",
                            model_type="test_type"
                        )

tests/test_model_registry.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/model_registry.py:65: in register_model
    blob = pickle.dumps(model)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (&lt;Mock id='140215515290512'&gt;,), kwargs = {}

    def pickle_side_effect(*args, **kwargs):
&gt;       raise Exception("Cannot pickle this object")
E       Exception: Cannot pickle this object

tests/test_model_registry.py:139: Exception</failure></testcase><testcase classname="tests.test_no_runtime_mocks" name="test_no_mocks_in_production_tree" time="0.022" /><testcase classname="tests.test_momentum_extra" name="test_generate_insufficient_data" time="0.004"><failure message="AssertionError: assert 'Insufficient data' in 'INFO     ai_trading.logging:__init__.py:293 Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate\n'&#10; +  where 'INFO     ai_trading.logging:__init__.py:293 Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate\n' = &lt;_pytest.logging.LogCaptureFixture object at 0x7f8676b021d0&gt;.text">caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7f8676b021d0&gt;

    def test_generate_insufficient_data(caplog):
        df = pd.DataFrame({"close": [1]})
        ctx = Ctx(df)
        strat = MomentumStrategy(lookback=2)
        caplog.set_level('WARNING')
        assert strat.generate(ctx) == []
&gt;       assert "Insufficient data" in caplog.text
E       AssertionError: assert 'Insufficient data' in 'INFO     ai_trading.logging:__init__.py:293 Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate\n'
E        +  where 'INFO     ai_trading.logging:__init__.py:293 Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate\n' = &lt;_pytest.logging.LogCaptureFixture object at 0x7f8676b021d0&gt;.text

tests/test_momentum_extra.py:24: AssertionError</failure></testcase><testcase classname="tests.test_no_trade_bands" name="test_no_trade_bands_suppresses_small_moves" time="0.002" /><testcase classname="tests.test_momentum_extra" name="test_generate_ret_nan" time="0.003" /><testcase classname="tests.test_no_trade_bands" name="test_no_trade_bands_allows_large_moves" time="0.002" /><testcase classname="tests.test_momentum_extra" name="test_threshold_skip" time="0.002" /><testcase classname="tests.test_no_trade_bands" name="test_no_trade_bands_handles_missing_symbols" time="0.002" /><testcase classname="tests.test_moving_average_crossover_extra" name="test_generate_insufficient_data" time="0.002"><failure message="TypeError: MovingAverageCrossoverStrategy.__init__() got an unexpected keyword argument 'short'">caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7f8676b03050&gt;

    def test_generate_insufficient_data(caplog):
        df = pd.DataFrame({"close": [1, 2]})
        ctx = Ctx(df)
&gt;       strat = MovingAverageCrossoverStrategy(short=3, long=5)
E       TypeError: MovingAverageCrossoverStrategy.__init__() got an unexpected keyword argument 'short'

tests/test_moving_average_crossover_extra.py:26: TypeError</failure></testcase><testcase classname="tests.test_no_trade_bands" name="test_no_trade_bands_custom_threshold" time="0.002" /><testcase classname="tests.test_optional_ml_imports" name="test_optional_ml_imports" time="0.002"><failure message="ImportError">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d8505e410&gt;

    def test_optional_ml_imports(monkeypatch):
        for mod in ("bs4", "transformers"):
            sys.modules.pop(mod, None)
    
        real_import = builtins.__import__
    
        def fake_import(name, *args, **kwargs):
            if name.startswith("bs4") or name.startswith("transformers"):
                raise ImportError
            return real_import(name, *args, **kwargs)
    
        monkeypatch.setattr(builtins, "__import__", fake_import)
    
        from ai_trading.analysis import sentiment
    
&gt;       res = sentiment.analyze_text("hello")

tests/test_optional_ml_imports.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/analysis/sentiment.py:532: in analyze_text
    deps = _load_transformers(logger)
ai_trading/analysis/sentiment.py:70: in _load_transformers
    from transformers import AutoModelForSequenceClassification, AutoTokenizer  # type: ignore
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'transformers'
args = ({'DEVICE': 'cpu', 'HTTP_TIMEOUT': 10.0, 'Lock': &lt;built-in function allocate_lock&gt;, 'SENTIMENT_API_KEY': '', ...}, None, ('AutoModelForSequenceClassification', 'AutoTokenizer'), 0)
kwargs = {}

    def fake_import(name, *args, **kwargs):
        if name.startswith("bs4") or name.startswith("transformers"):
&gt;           raise ImportError
E           ImportError

tests/test_optional_ml_imports.py:13: ImportError</failure></testcase><testcase classname="tests.test_moving_average_crossover_extra" name="test_generate_buy_signal" time="0.002"><failure message="TypeError: MovingAverageCrossoverStrategy.__init__() got an unexpected keyword argument 'short'">def test_generate_buy_signal():
        df = pd.DataFrame({"close": [1, 2, 3, 4, 5, 6]})
        ctx = Ctx(df)
&gt;       strat = MovingAverageCrossoverStrategy(short=2, long=3)
E       TypeError: MovingAverageCrossoverStrategy.__init__() got an unexpected keyword argument 'short'

tests/test_moving_average_crossover_extra.py:35: TypeError</failure></testcase><testcase classname="tests.test_my_fixes.TestMyFixes" name="test_confidence_algorithm_correctness" time="0.002" /><testcase classname="tests.test_my_fixes.TestMyFixes" name="test_confidence_normalization_improved" time="0.002"><failure message="FileNotFoundError: [Errno 2] No such file or directory: 'strategy_allocator.py'">self = &lt;tests.test_my_fixes.TestMyFixes testMethod=test_confidence_normalization_improved&gt;

    def test_confidence_normalization_improved(self):
        """Test that confidence score normalization is improved."""
&gt;       with open("strategy_allocator.py") as f:
E       FileNotFoundError: [Errno 2] No such file or directory: 'strategy_allocator.py'

tests/test_my_fixes.py:41: FileNotFoundError</failure></testcase><testcase classname="tests.test_my_fixes.TestMyFixes" name="test_data_quality_handling_improved" time="0.002"><failure message="FileNotFoundError: [Errno 2] No such file or directory: 'trade_execution.py'">self = &lt;tests.test_my_fixes.TestMyFixes testMethod=test_data_quality_handling_improved&gt;

    def test_data_quality_handling_improved(self):
        """Test that data quality validation is improved."""
&gt;       with open("trade_execution.py") as f:
E       FileNotFoundError: [Errno 2] No such file or directory: 'trade_execution.py'

tests/test_my_fixes.py:81: FileNotFoundError</failure></testcase><testcase classname="tests.test_my_fixes.TestMyFixes" name="test_duplicate_logging_fix" time="0.003"><failure message="AssertionError: 'elif phase in [ExecutionPhase.SIGNAL_GENERATED' not found in '&quot;&quot;&quot;Enhanced trade execution debugging and tracking system.\n\nThis module provides comprehensive logging and tracking for the complete\nsignal-to-execution pipeline, including correlation IDs, order lifecycle\ntracking, and detailed execution logging.\n&quot;&quot;&quot;\n\nfrom __future__ import annotations\n\nimport logging\nimport time\nimport uuid\nfrom collections import defaultdict, deque\nfrom datetime import UTC, datetime\nfrom enum import Enum\nfrom threading import Lock\nfrom typing import Any\n\nfrom ai_trading.logging import get_logger\n\n\ndef get_phase_logger(name: str, phase: str) -&gt; logging.Logger:\n    &quot;&quot;&quot;Get a logger for a specific phase - fallback implementation.&quot;&quot;&quot;\n    logger_name = f&quot;{name}.{phase}&quot; if phase else name\n    return get_logger(logger_name)\n\n\nclass ExecutionPhase(Enum):\n    &quot;&quot;&quot;Phases of order execution lifecycle.&quot;&quot;&quot;\n\n    SIGNAL_GENERATED = &quot;signal_generated&quot;\n    RISK_CHECK = &quot;risk_check&quot;\n    ORDER_PREPARED = &quot;order_prepared&quot;\n    ORDER_SUBMITTED = &quot;order_submitted&quot;\n    ORDER_ACKNOWLEDGED = &quot;order_acknowledged&quot;\n    ORDER_FILLED = &quot;order_filled&quot;\n    ORDER_PARTIALLY_FILLED = &quot;order_partially_filled&quot;\n    ORDER_REJECTED = &quot;order_rejected&quot;\n    ORDER_CANCELLED = &quot;order_cancelled&quot;\n    POSITION_UPDATED = &quot;position_updated&quot;\n    PNL_CALCULATED = &quot;pnl_calculated&quot;\n\n\nclass OrderStatus(Enum):\n    &quot;&quot;&quot;Order execution status.&quot;&quot;&quot;\n\n    PENDING = &quot;pending&quot;\n    SUBMITTED = &quot;submitted&quot;\n    ACKNOWLEDGED = &quot;acknowledged&quot;\n    FILLED = &quot;filled&quot;\n    PARTIALLY_FILLED = &quot;partially_filled&quot;\n    REJECTED = &quot;rejected&quot;\n    CANCELLED = &quot;cancelled&quot;\n    FAILED = &quot;failed&quot;\n\n\nclass ExecutionDebugTracker:\n    &quot;&quot;&quot;Comprehensive execution debugging and correlation tracking.&quot;&quot;&quot;\n\n    def __init__(self):\n        self.logger = get_phase_logger(__name__, &quot;EXEC_DEBUG&quot;)\n        self._lock = Lock()\n\n        # Track active orders by correlation ID\n        self._active_orders: dict[str, dict[str, Any]] = {}\n\n        # Track execution timeline for each correlation ID\n        self._execution_timelines: dict[str, list[dict[str, Any]]] = defaultdict(list)\n\n        # Track order lifecycle events\n        self._order_events: dict[str, list[dict[str, Any]]] = defaultdict(list)\n\n        # Track recent execution statistics\n        self._recent_executions: deque = deque(maxlen=1000)\n\n        # Track failed executions for analysis\n        self._failed_executions: deque = deque(maxlen=500)\n\n        # Track position updates\n        self._position_updates: deque = deque(maxlen=500)\n\n        # Debug flags\n        self.verbose_logging = False\n        self.trace_mode = False\n\n    def generate_correlation_id(self, symbol: str, side: str) -&gt; str:\n        &quot;&quot;&quot;Generate unique correlation ID for tracking order lifecycle.&quot;&quot;&quot;\n        timestamp = int(time.time() * 1000)  # milliseconds\n        unique_id = str(uuid.uuid4())[:8]\n        return f&quot;{symbol}_{side}_{timestamp}_{unique_id}&quot;\n\n    def start_execution_tracking(\n        self,\n        correlation_id: str,\n        symbol: str,\n        qty: int,\n        side: str,\n        signal_data: dict | None = None,\n    ) -&gt; None:\n        &quot;&quot;&quot;Start tracking a new order execution.&quot;&quot;&quot;\n        execution_start = {\n            &quot;correlation_id&quot;: correlation_id,\n            &quot;symbol&quot;: symbol,\n            &quot;qty&quot;: qty,\n            &quot;side&quot;: side,\n            &quot;start_time&quot;: datetime.now(UTC).isoformat(),\n            &quot;signal_data&quot;: signal_data or {},\n            &quot;status&quot;: OrderStatus.PENDING.value,\n            &quot;phases&quot;: [],\n        }\n\n        # AI-AGENT-REF: Use timeout-based lock to prevent deadlock\n        lock_acquired = False\n        try:\n            lock_acquired = self._lock.acquire(timeout=5.0)\n            if lock_acquired:\n                self._active_orders[correlation_id] = execution_start\n        except (ValueError, TypeError) as e:\n            self.logger.error(\n                &quot;START_TRACKING_ERROR&quot;,\n                extra={&quot;correlation_id&quot;: correlation_id, &quot;error&quot;: str(e)},\n            )\n        finally:\n            if lock_acquired:\n                self._lock.release()\n\n        # AI-AGENT-REF: Call log_execution_event outside of lock to prevent recursive deadlock\n        self.log_execution_event(\n            correlation_id,\n            ExecutionPhase.SIGNAL_GENERATED,\n            {&quot;symbol&quot;: symbol, &quot;qty&quot;: qty, &quot;side&quot;: side, &quot;signal_data&quot;: signal_data},\n        )\n\n    def log_execution_event(\n        self,\n        correlation_id: str,\n        phase: ExecutionPhase,\n        data: dict[str, Any] | None = None,\n    ) -&gt; None:\n        &quot;&quot;&quot;Log an execution phase event with correlation ID.&quot;&quot;&quot;\n        timestamp = datetime.now(UTC).isoformat()\n\n        event = {\n            &quot;timestamp&quot;: timestamp,\n            &quot;correlation_id&quot;: correlation_id,\n            &quot;phase&quot;: phase.value,\n            &quot;data&quot;: data or {},\n        }\n\n        # AI-AGENT-REF: Use timeout-based lock acquisition to prevent deadlock\n        lock_acquired = False\n        try:\n            lock_acquired = self._lock.acquire(timeout=5.0)  # 5 second timeout\n            if not lock_acquired:\n                # Fallback: log without state update to prevent blocking\n                self.logger.warning(\n                    &quot;LOCK_TIMEOUT_EXECUTION_EVENT&quot;,\n                    extra={\n                        &quot;correlation_id&quot;: correlation_id,\n                        &quot;phase&quot;: phase.value,\n                        &quot;message&quot;: &quot;Failed to acquire lock within timeout, logging without state update&quot;,\n                    },\n                )\n                return\n\n            self._execution_timelines[correlation_id].append(event)\n\n            # Update active order status if relevant\n            if correlation_id in self._active_orders:\n                self._active_orders[correlation_id][&quot;phases&quot;].append(event)\n\n                # Update status based on phase\n                if phase == ExecutionPhase.ORDER_SUBMITTED:\n                    self._active_orders[correlation_id][\n                        &quot;status&quot;\n                    ] = OrderStatus.SUBMITTED.value\n                elif phase == ExecutionPhase.ORDER_ACKNOWLEDGED:\n                    self._active_orders[correlation_id][\n                        &quot;status&quot;\n                    ] = OrderStatus.ACKNOWLEDGED.value\n                elif phase == ExecutionPhase.ORDER_FILLED:\n                    self._active_orders[correlation_id][\n                        &quot;status&quot;\n                    ] = OrderStatus.FILLED.value\n                elif phase == ExecutionPhase.ORDER_PARTIALLY_FILLED:\n                    self._active_orders[correlation_id][\n                        &quot;status&quot;\n                    ] = OrderStatus.PARTIALLY_FILLED.value\n                elif phase == ExecutionPhase.ORDER_REJECTED:\n                    self._active_orders[correlation_id][\n                        &quot;status&quot;\n                    ] = OrderStatus.REJECTED.value\n                elif phase == ExecutionPhase.ORDER_CANCELLED:\n                    self._active_orders[correlation_id][\n                        &quot;status&quot;\n                    ] = OrderStatus.CANCELLED.value\n        except (ValueError, TypeError) as e:\n            # AI-AGENT-REF: Graceful error handling for lock operations\n            self.logger.error(\n                &quot;EXECUTION_EVENT_ERROR&quot;,\n                extra={\n                    &quot;correlation_id&quot;: correlation_id,\n                    &quot;phase&quot;: phase.value,\n                    &quot;error&quot;: str(e),\n                    &quot;message&quot;: &quot;Error updating execution event state&quot;,\n                },\n            )\n        finally:\n            if lock_acquired:\n                self._lock.release()\n\n        # Log the event (moved outside lock to prevent circular logging)\n        log_data = {\n            &quot;correlation_id&quot;: correlation_id,\n            &quot;phase&quot;: phase.value,\n            &quot;timestamp&quot;: timestamp,\n        }\n        log_data.update(data or {})\n\n        try:\n            if self.verbose_logging or self.trace_mode:\n                self.logger.info(f&quot;EXEC_EVENT_{phase.value.upper()}&quot;, extra=log_data)\n            elif phase in [\n                ExecutionPhase.SIGNAL_GENERATED,\n                ExecutionPhase.ORDER_SUBMITTED,\n                ExecutionPhase.ORDER_FILLED,\n                ExecutionPhase.ORDER_REJECTED,\n            ]:\n                # Log only key phases in normal mode (but not if already logged in verbose mode)\n                self.logger.info(f&quot;EXEC_EVENT_{phase.value.upper()}&quot;, extra=log_data)\n        except (ValueError, TypeError, AttributeError) as e:\n            # AI-AGENT-REF: Prevent logging errors from cascading\n            self.logger.exception(\n                &quot;debug_tracker: logging error during execution event&quot;, exc_info=e\n            )\n\n    def log_order_result(\n        self,\n        correlation_id: str,\n        success: bool,\n        order_data: dict | None = None,\n        error: str | None = None,\n    ) -&gt; None:\n        &quot;&quot;&quot;Log the final result of an order execution.&quot;&quot;&quot;\n        timestamp = datetime.now(UTC).isoformat()\n\n        result_data = {\n            &quot;correlation_id&quot;: correlation_id,\n            &quot;success&quot;: success,\n            &quot;timestamp&quot;: timestamp,\n            &quot;order_data&quot;: order_data or {},\n            &quot;error&quot;: error,\n        }\n\n        # AI-AGENT-REF: Use timeout-based lock to prevent deadlock\n        lock_acquired = False\n        order_info = None\n        found_order = False\n\n        try:\n            lock_acquired = self._lock.acquire(timeout=5.0)\n            if lock_acquired and correlation_id in self._active_orders:\n                order_info = self._active_orders[correlation_id].copy()\n                order_info.update(result_data)\n                found_order = True\n\n                if success:\n                    self._recent_executions.append(order_info)\n                else:\n                    self._failed_executions.append(order_info)\n\n                # Remove from active orders\n                del self._active_orders[correlation_id]\n        except (ValueError, TypeError) as e:\n            self.logger.error(\n                &quot;ORDER_RESULT_ERROR&quot;,\n                extra={&quot;correlation_id&quot;: correlation_id, &quot;error&quot;: str(e)},\n            )\n        finally:\n            if lock_acquired:\n                self._lock.release()\n\n        # AI-AGENT-REF: Log outside of lock to prevent circular logging deadlock\n        try:\n            if found_order:\n                if success:\n                    self.logger.info(&quot;ORDER_EXECUTION_SUCCESS&quot;, extra=result_data)\n                else:\n                    self.logger.error(&quot;ORDER_EXECUTION_FAILED&quot;, extra=result_data)\n            else:\n                self.logger.warning(\n                    &quot;UNKNOWN_CORRELATION_ID&quot;,\n                    extra={\n                        &quot;correlation_id&quot;: correlation_id,\n                        &quot;message&quot;: &quot;Attempted to log result for unknown correlation ID&quot;,\n                    },\n                )\n        except (ValueError, TypeError, AttributeError) as e:\n            # AI-AGENT-REF: Prevent logging errors from cascading\n            self.logger.exception(\n                &quot;debug_tracker: logging error during order result&quot;, exc_info=e\n            )\n\n    def log_position_update(\n        self,\n        symbol: str,\n        old_qty: float,\n        new_qty: float,\n        correlation_id: str | None = None,\n    ) -&gt; None:\n        &quot;&quot;&quot;Log position updates with optional correlation to order.&quot;&quot;&quot;\n        position_update = {\n            &quot;timestamp&quot;: datetime.now(UTC).isoformat(),\n            &quot;symbol&quot;: symbol,\n            &quot;old_qty&quot;: old_qty,\n            &quot;new_qty&quot;: new_qty,\n            &quot;qty_change&quot;: new_qty - old_qty,\n            &quot;correlation_id&quot;: correlation_id,\n        }\n\n        with self._lock:\n            self._position_updates.append(position_update)\n\n        if correlation_id:\n            self.log_execution_event(\n                correlation_id, ExecutionPhase.POSITION_UPDATED, position_update\n            )\n\n        self.logger.info(&quot;POSITION_UPDATE&quot;, extra=position_update)\n\n    def get_active_orders(self) -&gt; dict[str, dict[str, Any]]:\n        &quot;&quot;&quot;Get all currently active orders being tracked.&quot;&quot;&quot;\n        with self._lock:\n            return self._active_orders.copy()\n\n    def get_execution_timeline(self, correlation_id: str) -&gt; list[dict[str, Any]]:\n        &quot;&quot;&quot;Get the complete execution timeline for a correlation ID.&quot;&quot;&quot;\n        with self._lock:\n            return self._execution_timelines[correlation_id].copy()\n\n    def get_recent_executions(self, limit: int = 50) -&gt; list[dict[str, Any]]:\n        &quot;&quot;&quot;Get recent successful executions.&quot;&quot;&quot;\n        with self._lock:\n            return list(self._recent_executions)[-limit:]\n\n    def get_failed_executions(self, limit: int = 50) -&gt; list[dict[str, Any]]:\n        &quot;&quot;&quot;Get recent failed executions for analysis.&quot;&quot;&quot;\n        with self._lock:\n            return list(self._failed_executions)[-limit:]\n\n    def get_position_updates(\n        self, symbol: str | None = None, limit: int = 50\n    ) -&gt; list[dict[str, Any]]:\n        &quot;&quot;&quot;Get recent position updates, optionally filtered by symbol.&quot;&quot;&quot;\n        with self._lock:\n            updates = list(self._position_updates)[-limit:]\n            if symbol:\n                updates = [u for u in updates if u[&quot;symbol&quot;] == symbol]\n            return updates\n\n    def set_debug_mode(self, verbose: bool = True, trace: bool = False) -&gt; None:\n        &quot;&quot;&quot;Enable/disable debug logging modes.&quot;&quot;&quot;\n        self.verbose_logging = verbose\n        self.trace_mode = trace\n\n        mode = &quot;TRACE&quot; if trace else &quot;VERBOSE&quot; if verbose else &quot;NORMAL&quot;\n        self.logger.info(&quot;DEBUG_MODE_CHANGED&quot;, extra={&quot;mode&quot;: mode})\n\n    def get_execution_stats(self) -&gt; dict[str, Any]:\n        &quot;&quot;&quot;Get execution statistics for monitoring.&quot;&quot;&quot;\n        with self._lock:\n            active_count = len(self._active_orders)\n            recent_success_count = len(self._recent_executions)\n            recent_failure_count = len(self._failed_executions)\n\n            # Calculate success rate from recent executions\n            total_recent = recent_success_count + recent_failure_count\n            success_rate = (\n                recent_success_count / total_recent if total_recent &gt; 0 else 0\n            )\n\n            # Get status breakdown of active orders\n            status_breakdown = {}\n            for order in self._active_orders.values():\n                status = order.get(&quot;status&quot;, &quot;unknown&quot;)\n                status_breakdown[status] = status_breakdown.get(status, 0) + 1\n\n            return {\n                &quot;active_orders&quot;: active_count,\n                &quot;recent_successes&quot;: recent_success_count,\n                &quot;recent_failures&quot;: recent_failure_count,\n                &quot;success_rate&quot;: success_rate,\n                &quot;status_breakdown&quot;: status_breakdown,\n                &quot;position_updates_count&quot;: len(self._position_updates),\n            }\n\n\n# Global debug tracker instance\n_debug_tracker: ExecutionDebugTracker | None = None\n_tracker_lock = Lock()\n\n\ndef get_debug_tracker() -&gt; ExecutionDebugTracker:\n    &quot;&quot;&quot;Get or create the global debug tracker instance.&quot;&quot;&quot;\n    global _debug_tracker\n    with _tracker_lock:\n        if _debug_tracker is None:\n            _debug_tracker = ExecutionDebugTracker()\n        return _debug_tracker\n\n\ndef enable_debug_mode(verbose: bool = True, trace: bool = False) -&gt; None:\n    &quot;&quot;&quot;Enable debug mode for execution tracking.&quot;&quot;&quot;\n    tracker = get_debug_tracker()\n    tracker.set_debug_mode(verbose, trace)\n\n\ndef log_signal_to_execution(\n    symbol: str, side: str, qty: int, signal_data: dict | None = None\n) -&gt; str:\n    &quot;&quot;&quot;Start tracking a signal-to-execution flow and return correlation ID.&quot;&quot;&quot;\n    tracker = get_debug_tracker()\n    correlation_id = tracker.generate_correlation_id(symbol, side)\n    tracker.start_execution_tracking(correlation_id, symbol, qty, side, signal_data)\n    return correlation_id\n\n\ndef log_execution_phase(\n    correlation_id: str, phase: ExecutionPhase, data: dict | None = None\n) -&gt; None:\n    &quot;&quot;&quot;Log an execution phase with correlation ID.&quot;&quot;&quot;\n    tracker = get_debug_tracker()\n    tracker.log_execution_event(correlation_id, phase, data)\n\n\ndef log_order_outcome(\n    correlation_id: str,\n    success: bool,\n    order_data: dict | None = None,\n    error: str | None = None,\n) -&gt; None:\n    &quot;&quot;&quot;Log the final outcome of an order execution.&quot;&quot;&quot;\n    tracker = get_debug_tracker()\n    tracker.log_order_result(correlation_id, success, order_data, error)\n\n\ndef log_position_change(\n    symbol: str, old_qty: float, new_qty: float, correlation_id: str | None = None\n) -&gt; None:\n    &quot;&quot;&quot;Log a position change with optional correlation to order.&quot;&quot;&quot;\n    tracker = get_debug_tracker()\n    tracker.log_position_update(symbol, old_qty, new_qty, correlation_id)\n\n\ndef get_execution_statistics() -&gt; dict[str, Any]:\n    &quot;&quot;&quot;Get current execution statistics.&quot;&quot;&quot;\n    tracker = get_debug_tracker()\n    return tracker.get_execution_stats()\n'">self = &lt;tests.test_my_fixes.TestMyFixes testMethod=test_duplicate_logging_fix&gt;

    def test_duplicate_logging_fix(self):
        """Test that duplicate event logging is eliminated."""
        debug_tracker_path = "ai_trading/execution/debug_tracker.py"
        if os.path.exists(debug_tracker_path):
            with open(debug_tracker_path) as f:
                content = f.read()
    
            # Should use elif instead of else to prevent double logging
&gt;           self.assertIn('elif phase in [ExecutionPhase.SIGNAL_GENERATED', content)
E           AssertionError: 'elif phase in [ExecutionPhase.SIGNAL_GENERATED' not found in '"""Enhanced trade execution debugging and tracking system.\n\nThis module provides comprehensive logging and tracking for the complete\nsignal-to-execution pipeline, including correlation IDs, order lifecycle\ntracking, and detailed execution logging.\n"""\n\nfrom __future__ import annotations\n\nimport logging\nimport time\nimport uuid\nfrom collections import defaultdict, deque\nfrom datetime import UTC, datetime\nfrom enum import Enum\nfrom threading import Lock\nfrom typing import Any\n\nfrom ai_trading.logging import get_logger\n\n\ndef get_phase_logger(name: str, phase: str) -&gt; logging.Logger:\n    """Get a logger for a specific phase - fallback implementation."""\n    logger_name = f"{name}.{phase}" if phase else name\n    return get_logger(logger_name)\n\n\nclass ExecutionPhase(Enum):\n    """Phases of order execution lifecycle."""\n\n    SIGNAL_GENERATED = "signal_generated"\n    RISK_CHECK = "risk_check"\n    ORDER_PREPARED = "order_prepared"\n    ORDER_SUBMITTED = "order_submitted"\n    ORDER_ACKNOWLEDGED = "order_acknowledged"\n    ORDER_FILLED = "order_filled"\n    ORDER_PARTIALLY_FILLED = "order_partially_filled"\n    ORDER_REJECTED = "order_rejected"\n    ORDER_CANCELLED = "order_cancelled"\n    POSITION_UPDATED = "position_updated"\n    PNL_CALCULATED = "pnl_calculated"\n\n\nclass OrderStatus(Enum):\n    """Order execution status."""\n\n    PENDING = "pending"\n    SUBMITTED = "submitted"\n    ACKNOWLEDGED = "acknowledged"\n    FILLED = "filled"\n    PARTIALLY_FILLED = "partially_filled"\n    REJECTED = "rejected"\n    CANCELLED = "cancelled"\n    FAILED = "failed"\n\n\nclass ExecutionDebugTracker:\n    """Comprehensive execution debugging and correlation tracking."""\n\n    def __init__(self):\n        self.logger = get_phase_logger(__name__, "EXEC_DEBUG")\n        self._lock = Lock()\n\n        # Track active orders by correlation ID\n        self._active_orders: dict[str, dict[str, Any]] = {}\n\n        # Track execution timeline for each correlation ID\n        self._execution_timelines: dict[str, list[dict[str, Any]]] = defaultdict(list)\n\n        # Track order lifecycle events\n        self._order_events: dict[str, list[dict[str, Any]]] = defaultdict(list)\n\n        # Track recent execution statistics\n        self._recent_executions: deque = deque(maxlen=1000)\n\n        # Track failed executions for analysis\n        self._failed_executions: deque = deque(maxlen=500)\n\n        # Track position updates\n        self._position_updates: deque = deque(maxlen=500)\n\n        # Debug flags\n        self.verbose_logging = False\n        self.trace_mode = False\n\n    def generate_correlation_id(self, symbol: str, side: str) -&gt; str:\n        """Generate unique correlation ID for tracking order lifecycle."""\n        timestamp = int(time.time() * 1000)  # milliseconds\n        unique_id = str(uuid.uuid4())[:8]\n        return f"{symbol}_{side}_{timestamp}_{unique_id}"\n\n    def start_execution_tracking(\n        self,\n        correlation_id: str,\n        symbol: str,\n        qty: int,\n        side: str,\n        signal_data: dict | None = None,\n    ) -&gt; None:\n        """Start tracking a new order execution."""\n        execution_start = {\n            "correlation_id": correlation_id,\n            "symbol": symbol,\n            "qty": qty,\n            "side": side,\n            "start_time": datetime.now(UTC).isoformat(),\n            "signal_data": signal_data or {},\n            "status": OrderStatus.PENDING.value,\n            "phases": [],\n        }\n\n        # AI-AGENT-REF: Use timeout-based lock to prevent deadlock\n        lock_acquired = False\n        try:\n            lock_acquired = self._lock.acquire(timeout=5.0)\n            if lock_acquired:\n                self._active_orders[correlation_id] = execution_start\n        except (ValueError, TypeError) as e:\n            self.logger.error(\n                "START_TRACKING_ERROR",\n                extra={"correlation_id": correlation_id, "error": str(e)},\n            )\n        finally:\n            if lock_acquired:\n                self._lock.release()\n\n        # AI-AGENT-REF: Call log_execution_event outside of lock to prevent recursive deadlock\n        self.log_execution_event(\n            correlation_id,\n            ExecutionPhase.SIGNAL_GENERATED,\n            {"symbol": symbol, "qty": qty, "side": side, "signal_data": signal_data},\n        )\n\n    def log_execution_event(\n        self,\n        correlation_id: str,\n        phase: ExecutionPhase,\n        data: dict[str, Any] | None = None,\n    ) -&gt; None:\n        """Log an execution phase event with correlation ID."""\n        timestamp = datetime.now(UTC).isoformat()\n\n        event = {\n            "timestamp": timestamp,\n            "correlation_id": correlation_id,\n            "phase": phase.value,\n            "data": data or {},\n        }\n\n        # AI-AGENT-REF: Use timeout-based lock acquisition to prevent deadlock\n        lock_acquired = False\n        try:\n            lock_acquired = self._lock.acquire(timeout=5.0)  # 5 second timeout\n            if not lock_acquired:\n                # Fallback: log without state update to prevent blocking\n                self.logger.warning(\n                    "LOCK_TIMEOUT_EXECUTION_EVENT",\n                    extra={\n                        "correlation_id": correlation_id,\n                        "phase": phase.value,\n                        "message": "Failed to acquire lock within timeout, logging without state update",\n                    },\n                )\n                return\n\n            self._execution_timelines[correlation_id].append(event)\n\n            # Update active order status if relevant\n            if correlation_id in self._active_orders:\n                self._active_orders[correlation_id]["phases"].append(event)\n\n                # Update status based on phase\n                if phase == ExecutionPhase.ORDER_SUBMITTED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.SUBMITTED.value\n                elif phase == ExecutionPhase.ORDER_ACKNOWLEDGED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.ACKNOWLEDGED.value\n                elif phase == ExecutionPhase.ORDER_FILLED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.FILLED.value\n                elif phase == ExecutionPhase.ORDER_PARTIALLY_FILLED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.PARTIALLY_FILLED.value\n                elif phase == ExecutionPhase.ORDER_REJECTED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.REJECTED.value\n                elif phase == ExecutionPhase.ORDER_CANCELLED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.CANCELLED.value\n        except (ValueError, TypeError) as e:\n            # AI-AGENT-REF: Graceful error handling for lock operations\n            self.logger.error(\n                "EXECUTION_EVENT_ERROR",\n                extra={\n                    "correlation_id": correlation_id,\n                    "phase": phase.value,\n                    "error": str(e),\n                    "message": "Error updating execution event state",\n                },\n            )\n        finally:\n            if lock_acquired:\n                self._lock.release()\n\n        # Log the event (moved outside lock to prevent circular logging)\n        log_data = {\n            "correlation_id": correlation_id,\n            "phase": phase.value,\n            "timestamp": timestamp,\n        }\n        log_data.update(data or {})\n\n        try:\n            if self.verbose_logging or self.trace_mode:\n                self.logger.info(f"EXEC_EVENT_{phase.value.upper()}", extra=log_data)\n            elif phase in [\n                ExecutionPhase.SIGNAL_GENERATED,\n                ExecutionPhase.ORDER_SUBMITTED,\n                ExecutionPhase.ORDER_FILLED,\n                ExecutionPhase.ORDER_REJECTED,\n            ]:\n                # Log only key phases in normal mode (but not if already logged in verbose mode)\n                self.logger.info(f"EXEC_EVENT_{phase.value.upper()}", extra=log_data)\n        except (ValueError, TypeError, AttributeError) as e:\n            # AI-AGENT-REF: Prevent logging errors from cascading\n            self.logger.exception(\n                "debug_tracker: logging error during execution event", exc_info=e\n            )\n\n    def log_order_result(\n        self,\n        correlation_id: str,\n        success: bool,\n        order_data: dict | None = None,\n        error: str | None = None,\n    ) -&gt; None:\n        """Log the final result of an order execution."""\n        timestamp = datetime.now(UTC).isoformat()\n\n        result_data = {\n            "correlation_id": correlation_id,\n            "success": success,\n            "timestamp": timestamp,\n            "order_data": order_data or {},\n            "error": error,\n        }\n\n        # AI-AGENT-REF: Use timeout-based lock to prevent deadlock\n        lock_acquired = False\n        order_info = None\n        found_order = False\n\n        try:\n            lock_acquired = self._lock.acquire(timeout=5.0)\n            if lock_acquired and correlation_id in self._active_orders:\n                order_info = self._active_orders[correlation_id].copy()\n                order_info.update(result_data)\n                found_order = True\n\n                if success:\n                    self._recent_executions.append(order_info)\n                else:\n                    self._failed_executions.append(order_info)\n\n                # Remove from active orders\n                del self._active_orders[correlation_id]\n        except (ValueError, TypeError) as e:\n            self.logger.error(\n                "ORDER_RESULT_ERROR",\n                extra={"correlation_id": correlation_id, "error": str(e)},\n            )\n        finally:\n            if lock_acquired:\n                self._lock.release()\n\n        # AI-AGENT-REF: Log outside of lock to prevent circular logging deadlock\n        try:\n            if found_order:\n                if success:\n                    self.logger.info("ORDER_EXECUTION_SUCCESS", extra=result_data)\n                else:\n                    self.logger.error("ORDER_EXECUTION_FAILED", extra=result_data)\n            else:\n                self.logger.warning(\n                    "UNKNOWN_CORRELATION_ID",\n                    extra={\n                        "correlation_id": correlation_id,\n                        "message": "Attempted to log result for unknown correlation ID",\n                    },\n                )\n        except (ValueError, TypeError, AttributeError) as e:\n            # AI-AGENT-REF: Prevent logging errors from cascading\n            self.logger.exception(\n                "debug_tracker: logging error during order result", exc_info=e\n            )\n\n    def log_position_update(\n        self,\n        symbol: str,\n        old_qty: float,\n        new_qty: float,\n        correlation_id: str | None = None,\n    ) -&gt; None:\n        """Log position updates with optional correlation to order."""\n        position_update = {\n            "timestamp": datetime.now(UTC).isoformat(),\n            "symbol": symbol,\n            "old_qty": old_qty,\n            "new_qty": new_qty,\n            "qty_change": new_qty - old_qty,\n            "correlation_id": correlation_id,\n        }\n\n        with self._lock:\n            self._position_updates.append(position_update)\n\n        if correlation_id:\n            self.log_execution_event(\n                correlation_id, ExecutionPhase.POSITION_UPDATED, position_update\n            )\n\n        self.logger.info("POSITION_UPDATE", extra=position_update)\n\n    def get_active_orders(self) -&gt; dict[str, dict[str, Any]]:\n        """Get all currently active orders being tracked."""\n        with self._lock:\n            return self._active_orders.copy()\n\n    def get_execution_timeline(self, correlation_id: str) -&gt; list[dict[str, Any]]:\n        """Get the complete execution timeline for a correlation ID."""\n        with self._lock:\n            return self._execution_timelines[correlation_id].copy()\n\n    def get_recent_executions(self, limit: int = 50) -&gt; list[dict[str, Any]]:\n        """Get recent successful executions."""\n        with self._lock:\n            return list(self._recent_executions)[-limit:]\n\n    def get_failed_executions(self, limit: int = 50) -&gt; list[dict[str, Any]]:\n        """Get recent failed executions for analysis."""\n        with self._lock:\n            return list(self._failed_executions)[-limit:]\n\n    def get_position_updates(\n        self, symbol: str | None = None, limit: int = 50\n    ) -&gt; list[dict[str, Any]]:\n        """Get recent position updates, optionally filtered by symbol."""\n        with self._lock:\n            updates = list(self._position_updates)[-limit:]\n            if symbol:\n                updates = [u for u in updates if u["symbol"] == symbol]\n            return updates\n\n    def set_debug_mode(self, verbose: bool = True, trace: bool = False) -&gt; None:\n        """Enable/disable debug logging modes."""\n        self.verbose_logging = verbose\n        self.trace_mode = trace\n\n        mode = "TRACE" if trace else "VERBOSE" if verbose else "NORMAL"\n        self.logger.info("DEBUG_MODE_CHANGED", extra={"mode": mode})\n\n    def get_execution_stats(self) -&gt; dict[str, Any]:\n        """Get execution statistics for monitoring."""\n        with self._lock:\n            active_count = len(self._active_orders)\n            recent_success_count = len(self._recent_executions)\n            recent_failure_count = len(self._failed_executions)\n\n            # Calculate success rate from recent executions\n            total_recent = recent_success_count + recent_failure_count\n            success_rate = (\n                recent_success_count / total_recent if total_recent &gt; 0 else 0\n            )\n\n            # Get status breakdown of active orders\n            status_breakdown = {}\n            for order in self._active_orders.values():\n                status = order.get("status", "unknown")\n                status_breakdown[status] = status_breakdown.get(status, 0) + 1\n\n            return {\n                "active_orders": active_count,\n                "recent_successes": recent_success_count,\n                "recent_failures": recent_failure_count,\n                "success_rate": success_rate,\n                "status_breakdown": status_breakdown,\n                "position_updates_count": len(self._position_updates),\n            }\n\n\n# Global debug tracker instance\n_debug_tracker: ExecutionDebugTracker | None = None\n_tracker_lock = Lock()\n\n\ndef get_debug_tracker() -&gt; ExecutionDebugTracker:\n    """Get or create the global debug tracker instance."""\n    global _debug_tracker\n    with _tracker_lock:\n        if _debug_tracker is None:\n            _debug_tracker = ExecutionDebugTracker()\n        return _debug_tracker\n\n\ndef enable_debug_mode(verbose: bool = True, trace: bool = False) -&gt; None:\n    """Enable debug mode for execution tracking."""\n    tracker = get_debug_tracker()\n    tracker.set_debug_mode(verbose, trace)\n\n\ndef log_signal_to_execution(\n    symbol: str, side: str, qty: int, signal_data: dict | None = None\n) -&gt; str:\n    """Start tracking a signal-to-execution flow and return correlation ID."""\n    tracker = get_debug_tracker()\n    correlation_id = tracker.generate_correlation_id(symbol, side)\n    tracker.start_execution_tracking(correlation_id, symbol, qty, side, signal_data)\n    return correlation_id\n\n\ndef log_execution_phase(\n    correlation_id: str, phase: ExecutionPhase, data: dict | None = None\n) -&gt; None:\n    """Log an execution phase with correlation ID."""\n    tracker = get_debug_tracker()\n    tracker.log_execution_event(correlation_id, phase, data)\n\n\ndef log_order_outcome(\n    correlation_id: str,\n    success: bool,\n    order_data: dict | None = None,\n    error: str | None = None,\n) -&gt; None:\n    """Log the final outcome of an order execution."""\n    tracker = get_debug_tracker()\n    tracker.log_order_result(correlation_id, success, order_data, error)\n\n\ndef log_position_change(\n    symbol: str, old_qty: float, new_qty: float, correlation_id: str | None = None\n) -&gt; None:\n    """Log a position change with optional correlation to order."""\n    tracker = get_debug_tracker()\n    tracker.log_position_update(symbol, old_qty, new_qty, correlation_id)\n\n\ndef get_execution_statistics() -&gt; dict[str, Any]:\n    """Get current execution statistics."""\n    tracker = get_debug_tracker()\n    return tracker.get_execution_stats()\n'

tests/test_my_fixes.py:32: AssertionError</failure></testcase><testcase classname="tests.test_package_first_smoke" name="test_package_first_single_tick_smoke" time="0.002" /><testcase classname="tests.test_package_first_smoke" name="test_ai_trading_module_imports" time="0.007"><failure message="ModuleNotFoundError: No module named 'cachetools'">def test_ai_trading_module_imports():
        # Test that modules can be imported from the package
        import importlib
    
        # Test each moved module can be imported from ai_trading
        modules = ["signals", "data_fetcher", "trade_execution", "indicators", "pipeline", "portfolio", "rebalancer"]
        for module_name in modules:
&gt;           pkg_module = importlib.import_module(f"ai_trading.{module_name}")

tests/test_package_first_smoke.py:15: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
&lt;frozen importlib._bootstrap&gt;:1204: in _gcd_import
    ???
&lt;frozen importlib._bootstrap&gt;:1176: in _find_and_load
    ???
&lt;frozen importlib._bootstrap&gt;:1147: in _find_and_load_unlocked
    ???
&lt;frozen importlib._bootstrap&gt;:690: in _load_unlocked
    ???
&lt;frozen importlib._bootstrap_external&gt;:940: in exec_module
    ???
&lt;frozen importlib._bootstrap&gt;:241: in _call_with_frames_removed
    ???
ai_trading/signals.py:114: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_my_fixes.TestMyFixes" name="test_liquidity_thresholds_increased" time="0.003"><failure message="FileNotFoundError: [Errno 2] No such file or directory: 'config.py'">self = &lt;tests.test_my_fixes.TestMyFixes testMethod=test_liquidity_thresholds_increased&gt;

    def test_liquidity_thresholds_increased(self):
        """Test that liquidity thresholds are made less aggressive."""
&gt;       with open("config.py") as f:
E       FileNotFoundError: [Errno 2] No such file or directory: 'config.py'

tests/test_my_fixes.py:69: FileNotFoundError</failure></testcase><testcase classname="tests.test_my_fixes.TestMyFixes" name="test_meta_learning_thresholds_reduced" time="0.003"><failure message="FileNotFoundError: [Errno 2] No such file or directory: 'bot_engine.py'">self = &lt;tests.test_my_fixes.TestMyFixes testMethod=test_meta_learning_thresholds_reduced&gt;

    def test_meta_learning_thresholds_reduced(self):
        """Test that meta-learning thresholds are reduced to allow easier activation."""
&gt;       with open("bot_engine.py") as f:
E       FileNotFoundError: [Errno 2] No such file or directory: 'bot_engine.py'

tests/test_my_fixes.py:14: FileNotFoundError</failure></testcase><testcase classname="tests.test_meta_learning_additional" name="test_optimize_signals" time="0.002" /><testcase classname="tests.test_my_fixes.TestMyFixes" name="test_meta_learning_would_activate" time="0.003" /><testcase classname="tests.test_meta_learning_module" name="test_load_weights_missing" time="0.004" /><testcase classname="tests.test_my_fixes.TestMyFixes" name="test_position_limit_rebalancing" time="0.002"><failure message="FileNotFoundError: [Errno 2] No such file or directory: 'bot_engine.py'">self = &lt;tests.test_my_fixes.TestMyFixes testMethod=test_position_limit_rebalancing&gt;

    def test_position_limit_rebalancing(self):
        """Test that position limits allow rebalancing."""
&gt;       with open("bot_engine.py") as f:
E       FileNotFoundError: [Errno 2] No such file or directory: 'bot_engine.py'

tests/test_my_fixes.py:56: FileNotFoundError</failure></testcase><testcase classname="tests.test_meta_learning_module" name="test_update_weights" time="0.005" /><testcase classname="tests.test_net_http_timeout" name="test_timeoutsession_injects_default_timeout" time="0.003"><failure message="AttributeError: module 'requests' has no attribute 'Session'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8677eee510&gt;

    def test_timeoutsession_injects_default_timeout(monkeypatch):
        captured = {}
    
        def fake_request(self, method, url, **kwargs):  # AI-AGENT-REF: capture timeout
            captured.update(kwargs)
            return types.SimpleNamespace(ok=True)
    
&gt;       monkeypatch.setattr(requests.Session, "request", fake_request, raising=True)
E       AttributeError: module 'requests' has no attribute 'Session'

tests/test_net_http_timeout.py:16: AttributeError</failure></testcase><testcase classname="tests.test_meta_learning_module" name="test_update_weights_no_change" time="0.004" /><testcase classname="tests.test_meta_learning_module" name="test_load_weights_corrupted" time="0.004" /><testcase classname="tests.test_net_http_timeout" name="test_build_retrying_session_defaults" time="0.002"><failure message="AttributeError: module 'requests' has no attribute 'Session'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f867c24ed90&gt;

    def test_build_retrying_session_defaults(monkeypatch):
        captured = {}
    
        def fake_request(self, method, url, **kwargs):  # AI-AGENT-REF: capture timeout
            captured.update(kwargs)
            return types.SimpleNamespace(ok=True)
    
&gt;       monkeypatch.setattr(requests.Session, "request", fake_request, raising=True)
E       AttributeError: module 'requests' has no attribute 'Session'

tests/test_net_http_timeout.py:34: AttributeError</failure></testcase><testcase classname="tests.test_meta_learning_module" name="test_update_weights_history_error" time="0.006" /><testcase classname="tests.test_no_direct_getenv" name="test_no_direct_getenv_outside_settings" time="0.001"><skipped type="pytest.skip" message="Enable after config consolidation PR merges">/workspace/ai-trading-bot/tests/test_no_direct_getenv.py:9: Enable after config consolidation PR merges</skipped></testcase><testcase classname="tests.test_meta_learning_optional" name="test_engine_imports_without_meta_learning" time="0.002" /><testcase classname="tests.test_no_legacy_imports" name="test_legacy_modules_not_importable" time="0.004"><failure message="AssertionError: assert ModuleSpec(name='metrics', loader=&lt;_frozen_importlib_external.SourceFileLoader object at 0x7f8677eeeb10&gt;, origin='/wor.../ai_trading/metrics/__init__.py', submodule_search_locations=['/workspace/ai-trading-bot/tests/../ai_trading/metrics']) is None&#10; +  where ModuleSpec(name='metrics', loader=&lt;_frozen_importlib_external.SourceFileLoader object at 0x7f8677eeeb10&gt;, origin='/wor.../ai_trading/metrics/__init__.py', submodule_search_locations=['/workspace/ai-trading-bot/tests/../ai_trading/metrics']) = &lt;function find_spec at 0x7f86948498a0&gt;('metrics')&#10; +    where &lt;function find_spec at 0x7f86948498a0&gt; = &lt;module 'importlib.util' (frozen)&gt;.find_spec&#10; +      where &lt;module 'importlib.util' (frozen)&gt; = importlib.util">@pytest.mark.unit
    def test_legacy_modules_not_importable():  # AI-AGENT-REF
        for name in BANNED:
&gt;           assert importlib.util.find_spec(name) is None
E           AssertionError: assert ModuleSpec(name='metrics', loader=&lt;_frozen_importlib_external.SourceFileLoader object at 0x7f8677eeeb10&gt;, origin='/wor.../ai_trading/metrics/__init__.py', submodule_search_locations=['/workspace/ai-trading-bot/tests/../ai_trading/metrics']) is None
E            +  where ModuleSpec(name='metrics', loader=&lt;_frozen_importlib_external.SourceFileLoader object at 0x7f8677eeeb10&gt;, origin='/wor.../ai_trading/metrics/__init__.py', submodule_search_locations=['/workspace/ai-trading-bot/tests/../ai_trading/metrics']) = &lt;function find_spec at 0x7f86948498a0&gt;('metrics')
E            +    where &lt;function find_spec at 0x7f86948498a0&gt; = &lt;module 'importlib.util' (frozen)&gt;.find_spec
E            +      where &lt;module 'importlib.util' (frozen)&gt; = importlib.util

tests/test_no_legacy_imports.py:19: AssertionError</failure></testcase><testcase classname="tests.test_meta_learning_optional" name="test_optimize_signals_fallback" time="0.002"><failure message="TypeError: optimize_signals() missing 1 required positional argument: 'cfg'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d37eb9d0&gt;

    def test_optimize_signals_fallback(monkeypatch):
        # Force missing meta module -&gt; fallback should return input unchanged
        sys.modules.pop("ai_trading.meta_learning", None)
        import importlib
        eng = importlib.import_module("ai_trading.core.bot_engine")
        dummy = [{"sym":"AAPL","score":0.5}, {"sym":"MSFT","score":0.4}]
&gt;       out = eng.optimize_signals(dummy)  # type: ignore[attr-defined]
E       TypeError: optimize_signals() missing 1 required positional argument: 'cfg'

tests/test_meta_learning_optional.py:21: TypeError</failure></testcase><testcase classname="tests.test_no_raw_requests" name="test_no_raw_requests_in_src" time="0.117"><failure message="AssertionError: Raw requests.* found in: ['/workspace/ai-trading-bot/ai_trading/predict.py', '/workspace/ai-trading-bot/ai_trading/data_fetcher.py', '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py', '/workspace/ai-trading-bot/ai_trading/analysis/sentiment.py']&#10;assert not ['/workspace/ai-trading-bot/ai_trading/predict.py', '/workspace/ai-trading-bot/ai_trading/data_fetcher.py', '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py', '/workspace/ai-trading-bot/ai_trading/analysis/sentiment.py']">def test_no_raw_requests_in_src():
        root = pathlib.Path(__file__).resolve().parents[1] / "ai_trading"
        banned = []
        for p in root.rglob("*.py"):
            if "utils/http.py" in str(p):
                continue
            txt = p.read_text(encoding="utf-8", errors="ignore")
            if re.search(r"\brequests\.(get|post|put|delete|patch|head|options)\b", txt):
                banned.append(str(p))
&gt;       assert not banned, f"Raw requests.* found in: {banned}"
E       AssertionError: Raw requests.* found in: ['/workspace/ai-trading-bot/ai_trading/predict.py', '/workspace/ai-trading-bot/ai_trading/data_fetcher.py', '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py', '/workspace/ai-trading-bot/ai_trading/analysis/sentiment.py']
E       assert not ['/workspace/ai-trading-bot/ai_trading/predict.py', '/workspace/ai-trading-bot/ai_trading/data_fetcher.py', '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py', '/workspace/ai-trading-bot/ai_trading/analysis/sentiment.py']

tests/test_no_raw_requests.py:14: AssertionError</failure></testcase><testcase classname="tests.test_metalearning_strategy.TestMetaLearning" name="test_strategy_initialization" time="0.003"><error message="failed on setup with &quot;ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)&quot;">self = &lt;tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0c310&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</error></testcase><testcase classname="tests.test_metalearning_strategy.TestMetaLearning" name="test_extract_features" time="0.003"><error message="failed on setup with &quot;ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)&quot;">self = &lt;tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0c9d0&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</error></testcase><testcase classname="tests.test_no_root_imports" name="test_no_root_level_imports_of_migrated_modules" time="1.706"><failure message="AssertionError: Root imports are no longer supported. Offenders: ['/workspace/ai-trading-bot/scripts/system_health_checker.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-trading-bot/scripts/production_validator.py:^\\s*import\\s+indicators\\b', '/workspace/ai-trading-bot/scripts/demo_short_selling_implementation.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-trading-bot/scripts/health_check.py:^\\s*import\\s+trade_execution\\b', '/workspace/ai-trading-bot/scripts/integration_test.py:\\bfrom\\s+pipeline\\s+import\\b', '/workspace/ai-trading-bot/scripts/critical_fixes_validation.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py:\\bfrom\\s+pipeline\\s+import\\b', '/workspace/ai-trading-bot/tests/test_import_fallbacks.py:\\bfrom\\s+signals\\s+import\\b', '/workspace/ai-trading-bot/tests/test_bot_engine_imports.py:\\bfrom\\s+pipeline\\s+import\\b']&#10;assert not ['/workspace/ai-trading-bot/scripts/system_health_checker.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-...ort\\b', '/workspace/ai-trading-bot/scripts/critical_fixes_validation.py:\\bfrom\\s+trade_execution\\s+import\\b', ...]">def test_no_root_level_imports_of_migrated_modules():
        root = pathlib.Path(__file__).resolve().parents[1]
        banned = {
            r"\bfrom\s+signals\s+import\b",
            r"\bfrom\s+data_fetcher\s+import\b",
            r"\bfrom\s+trade_execution\s+import\b",
            r"\bfrom\s+pipeline\s+import\b",
            r"\bfrom\s+indicators\s+import\b",
            r"\bfrom\s+portfolio\s+import\b",
            r"\bfrom\s+rebalancer\s+import\b",
            r"^\s*import\s+signals\b",
            r"^\s*import\s+data_fetcher\b",
            r"^\s*import\s+trade_execution\b",
            r"^\s*import\s+pipeline\b",
            r"^\s*import\s+indicators\b",
            r"^\s*import\s+portfolio\b",
            r"^\s*import\s+rebalancer\b",
        }
        offenders = []
        for p in root.rglob("*.py"):
            text = p.read_text(encoding="utf-8", errors="ignore")
            for pat in banned:
                if re.search(pat, text, re.MULTILINE):
                    offenders.append(f"{p}:{pat}")
                    break
&gt;       assert not offenders, f"Root imports are no longer supported. Offenders: {offenders}"
E       AssertionError: Root imports are no longer supported. Offenders: ['/workspace/ai-trading-bot/scripts/system_health_checker.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-trading-bot/scripts/production_validator.py:^\\s*import\\s+indicators\\b', '/workspace/ai-trading-bot/scripts/demo_short_selling_implementation.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-trading-bot/scripts/health_check.py:^\\s*import\\s+trade_execution\\b', '/workspace/ai-trading-bot/scripts/integration_test.py:\\bfrom\\s+pipeline\\s+import\\b', '/workspace/ai-trading-bot/scripts/critical_fixes_validation.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py:\\bfrom\\s+pipeline\\s+import\\b', '/workspace/ai-trading-bot/tests/test_import_fallbacks.py:\\bfrom\\s+signals\\s+import\\b', '/workspace/ai-trading-bot/tests/test_bot_engine_imports.py:\\bfrom\\s+pipeline\\s+import\\b']
E       assert not ['/workspace/ai-trading-bot/scripts/system_health_checker.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-...ort\\b', '/workspace/ai-trading-bot/scripts/critical_fixes_validation.py:\\bfrom\\s+trade_execution\\s+import\\b', ...]

tests/test_no_root_imports.py:30: AssertionError</failure></testcase><testcase classname="tests.test_metalearning_strategy.TestMetaLearning" name="test_train_model" time="0.003"><error message="failed on setup with &quot;ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)&quot;">self = &lt;tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0d0d0&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</error></testcase><testcase classname="tests.test_metalearning_strategy.TestMetaLearning" name="test_train_model_insufficient_data" time="0.005"><error message="failed on setup with &quot;ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)&quot;">self = &lt;tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0d410&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</error></testcase><testcase classname="tests.test_package_first_smoke" name="test_ai_trading_init_exports" time="0.002"><failure message="AssertionError: assert False&#10; +  where False = hasattr(&lt;module 'ai_trading' from '/workspace/ai-trading-bot/ai_trading/__init__.py'&gt;, 'signals')">def test_ai_trading_init_exports():
        # Test that ai_trading.__init__ properly exports the modules
        import ai_trading
    
        modules = ["signals", "data_fetcher", "trade_execution", "indicators", "pipeline", "portfolio", "rebalancer"]
        for module_name in modules:
&gt;           assert hasattr(ai_trading, module_name)
E           AssertionError: assert False
E            +  where False = hasattr(&lt;module 'ai_trading' from '/workspace/ai-trading-bot/ai_trading/__init__.py'&gt;, 'signals')

tests/test_package_first_smoke.py:24: AssertionError</failure></testcase><testcase classname="tests.test_metalearning_strategy.TestMetaLearning" name="test_predict_price_movement" time="0.004"><error message="failed on setup with &quot;ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)&quot;">self = &lt;tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0da50&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</error></testcase><testcase classname="tests.test_parameter_optimization" name="test_kelly_parameters_optimization" time="0.002"><failure message="AssertionError: Expected 0.15, got 0.3&#10;assert 0.3 == 0.15">def test_kelly_parameters_optimization():
        """Test that Kelly parameters are optimized correctly."""
        from ai_trading.core.constants import KELLY_PARAMETERS
    
        # Verify optimized Kelly parameters
&gt;       assert KELLY_PARAMETERS["MAX_KELLY_FRACTION"] == 0.15, f"Expected 0.15, got {KELLY_PARAMETERS['MAX_KELLY_FRACTION']}"
E       AssertionError: Expected 0.15, got 0.3
E       assert 0.3 == 0.15

tests/test_parameter_optimization.py:21: AssertionError</failure></testcase><testcase classname="tests.test_parameter_optimization" name="test_risk_parameters_optimization" time="0.004" /><testcase classname="tests.test_parameter_optimization" name="test_execution_parameters_optimization" time="0.002" /><testcase classname="tests.test_parameter_optimization" name="test_performance_thresholds_optimization" time="0.002" /><testcase classname="tests.test_parameter_optimization" name="test_parameter_consistency" time="0.002" /><testcase classname="tests.test_parameter_optimization" name="test_adaptive_sizing_optimization" time="0.002"><failure message="TypeError: object() takes no arguments">def test_adaptive_sizing_optimization():
        """Test that adaptive sizing uses optimized parameters."""
        try:
            from ai_trading.core.enums import RiskLevel
            from ai_trading.risk.adaptive_sizing import AdaptivePositionSizer
    
            # Test that sizer can be instantiated with optimized parameters
&gt;           sizer = AdaptivePositionSizer(RiskLevel.MODERATE)
E           TypeError: object() takes no arguments

tests/test_parameter_optimization.py:101: TypeError</failure></testcase><testcase classname="tests.test_parameter_optimization" name="test_execution_algorithm_optimization" time="0.006"><skipped type="pytest.skip" message="Execution algorithm test skipped due to import error: No module named 'cachetools'">/workspace/ai-trading-bot/tests/test_parameter_optimization.py:131: Execution algorithm test skipped due to import error: No module named 'cachetools'</skipped></testcase><testcase classname="tests.test_parameter_optimization" name="test_constants_backward_compatibility" time="0.002" /><testcase classname="tests.test_parameter_validation" name="test_parameter_validator_initialization" time="0.009" /><testcase classname="tests.test_metalearning_strategy.TestMetaLearning" name="test_execute_strategy_with_data" time="0.004"><error message="failed on setup with &quot;ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)&quot;">self = &lt;tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0df90&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</error></testcase><testcase classname="tests.test_parameter_validation" name="test_validate_all_parameters" time="0.004" /><testcase classname="tests.test_parameter_validation" name="test_parameter_change_validation" time="0.003" /><testcase classname="tests.test_parameter_validation" name="test_change_impact_assessment" time="0.004" /><testcase classname="tests.test_parameter_validation" name="test_optimization_summary" time="0.002" /><testcase classname="tests.test_parameter_validation" name="test_parameter_logging" time="0.009" /><testcase classname="tests.test_parameter_validation" name="test_safety_bounds_consistency" time="0.002" /><testcase classname="tests.test_peak_performance" name="test_order_idempotency" time="0.006"><failure message="ModuleNotFoundError: No module named 'cachetools'">def test_order_idempotency():
        """Test order idempotency caching."""
        # Clear any existing cache
&gt;       from ai_trading.execution.idempotency import (
            get_idempotency_cache,
            is_duplicate_order,
            mark_order_submitted,
        )

tests/test_peak_performance.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_metalearning_strategy.TestMetaLearning" name="test_execute_strategy_no_data" time="0.003"><error message="failed on setup with &quot;ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)&quot;">self = &lt;tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0fe10&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</error></testcase><testcase classname="tests.test_metalearning_strategy.TestMetaLearning" name="test_generate_signals" time="0.003"><error message="failed on setup with &quot;ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)&quot;">self = &lt;tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0e1d0&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</error></testcase><testcase classname="tests.test_peak_performance" name="test_position_reconciliation" time="0.005"><failure message="ModuleNotFoundError: No module named 'cachetools'">def test_position_reconciliation():
        """Test position reconciliation logic."""
        from datetime import datetime
    
        from ai_trading.core.interfaces import Position
&gt;       from ai_trading.execution.reconcile import PositionReconciler

tests/test_peak_performance.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_peak_performance" name="test_aligned_clock" time="0.007"><failure message="AttributeError: 'types.SimpleNamespace' object has no attribute 'tz'">def test_aligned_clock():
        """Test exchange-aligned clock functionality."""
        from ai_trading.scheduler.aligned_clock import AlignedClock
    
        clock = AlignedClock(max_skew_ms=250.0)
    
        # Test skew checking
&gt;       skew = clock.check_skew()

tests/test_peak_performance.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/scheduler/aligned_clock.py:195: in check_skew
    exchange_time = self.get_exchange_time()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;ai_trading.scheduler.aligned_clock.AlignedClock object at 0x7f8d8522c3d0&gt;

    def get_exchange_time(self) -&gt; datetime:
        """
        Get current exchange time (EST/EDT for NYSE).
    
        Returns:
            Current time in exchange timezone
        """
        utc_now = datetime.now(UTC)
    
        if self.calendar:
            try:
                # Get exchange timezone from calendar
&gt;               exchange_tz = self.calendar.tz
E               AttributeError: 'types.SimpleNamespace' object has no attribute 'tz'

ai_trading/scheduler/aligned_clock.py:81: AttributeError</failure></testcase><testcase classname="tests.test_peak_performance" name="test_symbol_costs" time="0.005"><failure message="ModuleNotFoundError: No module named 'cachetools'">def test_symbol_costs():
        """Test symbol-aware cost model."""
&gt;       from ai_trading.execution.costs import SymbolCostModel, SymbolCosts

tests/test_peak_performance.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_peak_performance" name="test_adaptive_risk_controls" time="0.012"><failure message="AttributeError: 'Settings' object has no attribute 'ENABLE_PORTFOLIO_FEATURES'">def test_adaptive_risk_controls():
        """Test adaptive risk control system."""
        from ai_trading.portfolio.risk_controls import AdaptiveRiskController
    
        # Create test data
        np.random.seed(42)
        dates = pd.date_range('2023-01-01', periods=100, freq='D')
        symbols = ['AAPL', 'GOOGL', 'MSFT']
    
        returns_data = pd.DataFrame(
            np.random.normal(0, 0.02, (100, 3)),
            index=dates,
            columns=symbols
        )
    
        controller = AdaptiveRiskController()
    
        # Test volatility calculation
        vols = controller.calculate_volatilities(returns_data)
        assert len(vols) == 3
        for symbol in symbols:
            assert symbol in vols
            assert vols[symbol] &gt; 0
    
        # Test correlation clustering (skip if scipy not available)
        try:
&gt;           clusters = controller.calculate_correlation_clusters(returns_data)

tests/test_peak_performance.py:188: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/portfolio/risk_controls.py:185: in calculate_correlation_clusters
    fcluster, linkage, squareform, clustering_available = _import_clustering()
ai_trading/portfolio/risk_controls.py:23: in _import_clustering
    if not S.ENABLE_PORTFOLIO_FEATURES:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
item = 'ENABLE_PORTFOLIO_FEATURES'

    def __getattr__(self, item: str) -&gt; Any:
        private_attributes = object.__getattribute__(self, '__private_attributes__')
        if item in private_attributes:
            attribute = private_attributes[item]
            if hasattr(attribute, '__get__'):
                return attribute.__get__(self, type(self))  # type: ignore
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                return self.__pydantic_private__[item]  # type: ignore
            except KeyError as exc:
                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
        else:
            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.
            # See `BaseModel.__repr_args__` for more details
            try:
                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')
            except AttributeError:
                pydantic_extra = None
    
            if pydantic_extra:
                try:
                    return pydantic_extra[item]
                except KeyError as exc:
                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
            else:
                if hasattr(self.__class__, item):
                    return super().__getattribute__(item)  # Raises AttributeError if appropriate
                else:
                    # this is the current error
&gt;                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E                   AttributeError: 'Settings' object has no attribute 'ENABLE_PORTFOLIO_FEATURES'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:991: AttributeError</failure></testcase><testcase classname="tests.test_metalearning_strategy.TestMetaLearning" name="test_calculate_position_size" time="0.003"><error message="failed on setup with &quot;ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)&quot;">self = &lt;tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0ead0&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</error></testcase><testcase classname="tests.test_peak_performance" name="test_determinism" time="0.007"><failure message="NameError: name 'HAS_NUMPY' is not defined">def test_determinism():
        """Test deterministic training setup."""
        from ai_trading.utils.determinism import hash_data, set_random_seeds
    
        # Test seed setting
&gt;       set_random_seeds(42)

tests/test_peak_performance.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

seed = 42

    def set_random_seeds(seed: int = 42) -&gt; None:
        """
        Set random seeds for reproducible results.
    
        Args:
            seed: Random seed value
        """
        # Python random
        random.seed(seed)
    
        # NumPy (if available)
&gt;       if HAS_NUMPY:
E       NameError: name 'HAS_NUMPY' is not defined

ai_trading/utils/determinism.py:35: NameError</failure></testcase><testcase classname="tests.test_peak_performance" name="test_drift_monitoring" time="0.016" /><testcase classname="tests.test_metalearning_strategy.TestMetaLearning" name="test_fallback_prediction" time="0.003"><error message="failed on setup with &quot;ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)&quot;">self = &lt;tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0fc10&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</error></testcase><testcase classname="tests.test_peak_performance" name="test_performance_optimizations" time="0.165" /><testcase classname="tests.test_metalearning_strategy.TestMetaLearning" name="test_caching_mechanism" time="0.003"><error message="failed on setup with &quot;ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)&quot;">self = &lt;tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a18510&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</error></testcase><testcase classname="tests.test_metalearning_strategy.TestMetaLearning" name="test_should_retrain" time="0.003"><error message="failed on setup with &quot;ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)&quot;">self = &lt;tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a18550&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</error></testcase><testcase classname="tests.test_metalearning_strategy.TestMetaLearning" name="test_signal_validation" time="0.003"><error message="failed on setup with &quot;ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)&quot;">self = &lt;tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a18b90&gt;

    def setup_method(self):
        """Set up test fixtures."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</error></testcase><testcase classname="tests.test_metalearning_strategy" name="test_metalearning_import" time="0.003"><failure message="ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)">def test_metalearning_import():
        """Test that MetaLearning can be imported without errors."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:261: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</failure></testcase><testcase classname="tests.test_metalearning_strategy" name="test_no_metalearn_invalid_prices_error" time="0.003"><failure message="ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)">def test_no_metalearn_invalid_prices_error():
        """Test that the strategy doesn't generate METALEARN_INVALID_PRICES errors."""
&gt;       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
&gt;   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError</failure></testcase><testcase classname="tests.test_peak_performance" name="test_smart_order_routing" time="0.007"><failure message="ModuleNotFoundError: No module named 'cachetools'">def test_smart_order_routing():
        """Test smart order routing functionality."""
&gt;       from ai_trading.execution.order_policy import (
            MarketData,
            OrderUrgency,
            SmartOrderRouter,
        )

tests/test_peak_performance.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_metrics_logger_smoke" name="test_log_metrics" time="0.004" /><testcase classname="tests.test_metrics_logger_smoke" name="test_compute_max_drawdown" time="0.002" /><testcase classname="tests.test_minute_cache_helpers" name="test_set_and_get" time="0.005" /><testcase classname="tests.test_minute_cache_helpers" name="test_age_cached_minute_timestamps" time="0.002" /><testcase classname="tests.test_minute_cache_helpers" name="test_clear_cached_timestamp" time="0.002" /><testcase classname="tests.test_minute_fallback_debug_path" name="test_minute_fallback_debug_path_emits_record" time="0.295"><failure message="AttributeError: 'NoneType' object has no attribute 'status_code'">caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7ff8d3986150&gt;

    def test_minute_fallback_debug_path_emits_record(caplog):
        caplog.set_level("DEBUG")
&gt;       bars_mod.fetch_minute_fallback(None, "SPY", now_utc=bars_mod.now_utc())

tests/test_minute_fallback_debug_path.py:8: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/data/bars.py:374: in fetch_minute_fallback
    df = _get_minute_bars(symbol, start_u, end_u, feed=feed_str)
ai_trading/data/bars.py:286: in _get_minute_bars
    df = get_bars(symbol=symbol, timeframe="1Min", start=start_dt, end=end_dt, feed=feed)
ai_trading/data_fetcher.py:585: in get_bars
    return _fetch_bars(
ai_trading/data_fetcher.py:511: in _fetch_bars
    return _req(fallback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fallback = ('1Min', 'sip', datetime.datetime(2025, 8, 22, 13, 30, tzinfo=datetime.timezone.utc), datetime.datetime(2025, 8, 22, 20, 0, tzinfo=datetime.timezone.utc))

    def _req(fallback: tuple[str, str, _dt.datetime, _dt.datetime] | None) -&gt; pd.DataFrame:
        nonlocal _interval, _feed, _start, _end
        params = {
            "symbols": symbol,
            "timeframe": _interval,
            "start": _start.isoformat(),
            "end": _end.isoformat(),
            "limit": 10000,
            "feed": _feed,
            "adjustment": adjustment,
        }
        if requests is None:  # pragma: no cover
            raise RuntimeError("requests not available")
        url = "https://data.alpaca.markets/v2/stocks/bars"
        headers = {
            "APCA-API-KEY-ID": os.getenv("ALPACA_API_KEY", ""),
            "APCA-API-SECRET-KEY": os.getenv("ALPACA_SECRET_KEY", ""),
        }
        try:
            resp = requests.get(url, params=params, headers=headers, timeout=10)
&gt;           status = resp.status_code
E           AttributeError: 'NoneType' object has no attribute 'status_code'

ai_trading/data_fetcher.py:349: AttributeError</failure></testcase><testcase classname="tests.test_phase2_enhancements.TestSystemHealthChecker" name="test_sentiment_health_check" time="0.003" /><testcase classname="tests.test_phase2_enhancements.TestSystemHealthChecker" name="test_system_health_checker_initialization" time="0.002" /><testcase classname="tests.test_phase2_enhancements.TestConfigurationEnhancements" name="test_order_management_config" time="0.002"><failure message="AssertionError: False is not true : Missing parameter: ORDER_MAX_RETRY_ATTEMPTS">self = &lt;tests.test_phase2_enhancements.TestConfigurationEnhancements testMethod=test_order_management_config&gt;

    def test_order_management_config(self):
        """Test order management configuration parameters."""
        required_params = [
            'ORDER_TIMEOUT_SECONDS',
            'ORDER_STALE_CLEANUP_INTERVAL',
            'ORDER_FILL_RATE_TARGET',
            'ORDER_MAX_RETRY_ATTEMPTS'
        ]
    
        for param in required_params:
&gt;           self.assertTrue(hasattr(config, param), f"Missing parameter: {param}")
E           AssertionError: False is not true : Missing parameter: ORDER_MAX_RETRY_ATTEMPTS

tests/test_phase2_enhancements.py:232: AssertionError</failure></testcase><testcase classname="tests.test_phase2_enhancements.TestConfigurationEnhancements" name="test_system_health_config" time="0.002"><failure message="AssertionError: False is not true : Missing parameter: SYSTEM_HEALTH_CHECK_INTERVAL">self = &lt;tests.test_phase2_enhancements.TestConfigurationEnhancements testMethod=test_system_health_config&gt;

    def test_system_health_config(self):
        """Test system health monitoring configuration parameters."""
        required_params = [
            'SYSTEM_HEALTH_CHECK_INTERVAL',
            'SYSTEM_HEALTH_ALERT_THRESHOLD',
            'SYSTEM_HEALTH_EXPORT_ENABLED',
            'SYSTEM_HEALTH_REPORT_PATH'
        ]
    
        for param in required_params:
&gt;           self.assertTrue(hasattr(config, param), f"Missing parameter: {param}")
E           AssertionError: False is not true : Missing parameter: SYSTEM_HEALTH_CHECK_INTERVAL

tests/test_phase2_enhancements.py:250: AssertionError</failure></testcase><testcase classname="tests.test_phase2_enhancements.TestIntegrationScenarios" name="test_monitoring_integration" time="0.003" /><testcase classname="tests.test_phase2_enhancements.TestIntegrationScenarios" name="test_phase1_and_phase2_compatibility" time="0.003" /><testcase classname="tests.test_pipeline_smoke" name="test_pipeline_basic" time="0.012" /><testcase classname="tests.test_portfolio" name="test_short_close_queued" time="0.003"><failure message="AttributeError: None has no attribute 'submit'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d84cbf4d0&gt;
caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7f8d84cbf890&gt;

    def test_short_close_queued(monkeypatch, caplog):
        state = bot_engine.BotState()
        state.position_cache = {"TSLA": -44}
        bot_engine.state = state
        caplog.set_level("INFO")
    
        orders = []
        monkeypatch.setattr(bot_engine, "submit_order", lambda ctx, symbol, qty, side: orders.append((symbol, qty, side)))
        monkeypatch.setattr(bot_engine, "is_market_open", lambda: True)
        monkeypatch.setattr(bot_engine, "fetch_minute_df_safe", lambda s: pd.DataFrame({"close": [1]}, index=[pd.Timestamp("2023-01-01")]))
        monkeypatch.setattr(bot_engine, "_safe_trade", lambda *a, **k: None)
&gt;       monkeypatch.setattr(bot_engine.prediction_executor, "submit", lambda fn, s: types.SimpleNamespace(result=lambda: fn(s)))
E       AttributeError: None has no attribute 'submit'

tests/test_portfolio.py:18: AttributeError</failure></testcase><testcase classname="tests.test_portfolio_snapshot" name="test_save_and_load_snapshot" time="0.003" /><testcase classname="tests.test_position_holding" name="test_position_manager_should_hold_profit" time="0.018" /><testcase classname="tests.test_position_holding" name="test_position_hold_signals_generation" time="0.008"><failure message="ModuleNotFoundError: No module named 'cachetools'">def test_position_hold_signals_generation():
        """Test position hold signal generation."""
&gt;       from ai_trading.signals import generate_position_hold_signals

tests/test_position_holding.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/signals.py:114: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_position_holding" name="test_signals_enhancement_with_position_logic" time="0.007"><failure message="ModuleNotFoundError: No module named 'cachetools'">def test_signals_enhancement_with_position_logic():
        """Test that signals are enhanced with position holding logic."""
&gt;       from ai_trading.signals import enhance_signals_with_position_logic

tests/test_position_holding.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/signals.py:114: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_position_holding" name="test_meta_learning_trigger" time="0.002"><failure message="AttributeError: &lt;module 'ai_trading.meta_learning' from '/workspace/ai-trading-bot/ai_trading/meta_learning.py'&gt; does not have the attribute 'config'">def test_meta_learning_trigger():
        """Test meta-learning conversion trigger."""
&gt;       with patch('meta_learning.config') as mock_config, \
             patch('meta_learning.pd') as mock_pd, \
             patch('ai_trading.meta_learning.Path') as mock_path:

tests/test_position_holding.py:108: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;unittest.mock._patch object at 0x7f8d85015a10&gt;

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
&gt;           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: &lt;module 'ai_trading.meta_learning' from '/workspace/ai-trading-bot/ai_trading/meta_learning.py'&gt; does not have the attribute 'config'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError</failure></testcase><testcase classname="tests.test_minute_fallback_none_safe" name="test_minute_fallback_none_safe" time="0.028" /><testcase classname="tests.test_position_holding" name="test_position_manager_cleanup" time="0.005"><failure message="AssertionError: assert 'GOOGL' not in {'AAPL': &lt;Mock id='140245798729232'&gt;, 'GOOGL': &lt;Mock id='140245799179088'&gt;, 'MSFT': &lt;Mock id='140245799025488'&gt;}&#10; +  where {'AAPL': &lt;Mock id='140245798729232'&gt;, 'GOOGL': &lt;Mock id='140245799179088'&gt;, 'MSFT': &lt;Mock id='140245799025488'&gt;} = &lt;ai_trading.position.legacy_manager.PositionManager object at 0x7f8d850cfc10&gt;.positions">def test_position_manager_cleanup():
        """Test position manager cleanup of stale positions."""
        from ai_trading.position.legacy_manager import PositionManager
    
        # Create mock context
        ctx = Mock()
        ctx.api = Mock()
    
        # Mock current positions (only AAPL exists now)
        current_positions = [Mock(symbol="AAPL")]
        ctx.api.get_all_positions.return_value = current_positions
    
        # Create position manager with existing tracked positions
        pm = PositionManager(ctx)
        pm.positions = {
            "AAPL": Mock(),
            "GOOGL": Mock(),  # This should be cleaned up
            "MSFT": Mock()    # This should be cleaned up
        }
    
        # Test cleanup
        pm.cleanup_stale_positions()
    
        # Only AAPL should remain
        assert "AAPL" in pm.positions
&gt;       assert "GOOGL" not in pm.positions
E       AssertionError: assert 'GOOGL' not in {'AAPL': &lt;Mock id='140245798729232'&gt;, 'GOOGL': &lt;Mock id='140245799179088'&gt;, 'MSFT': &lt;Mock id='140245799025488'&gt;}
E        +  where {'AAPL': &lt;Mock id='140245798729232'&gt;, 'GOOGL': &lt;Mock id='140245799179088'&gt;, 'MSFT': &lt;Mock id='140245799025488'&gt;} = &lt;ai_trading.position.legacy_manager.PositionManager object at 0x7f8d850cfc10&gt;.positions

tests/test_position_holding.py:183: AssertionError</failure></testcase><testcase classname="tests.test_prediction_executor.TestPredictionExecutor" name="test_prediction_executor_env_empty_string" time="0.003" /><testcase classname="tests.test_prediction_executor.TestPredictionExecutor" name="test_prediction_executor_env_invalid" time="0.003" /><testcase classname="tests.test_ml_model_extra" name="test_validate_errors" time="0.004" /><testcase classname="tests.test_prediction_executor.TestPredictionExecutor" name="test_prediction_executor_large_value" time="0.002" /><testcase classname="tests.test_ml_model_extra" name="test_fit_and_predict" time="0.003"><failure message="TypeError: '&gt;=' not supported between instances of 'MLModel' and 'int'">tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_fit_and_predict0')

    def test_fit_and_predict(tmp_path):
        model = MLModel(DummyPipe())
        df = make_df()
        mse = model.fit(df, np.array([0, 1]))
&gt;       assert mse &gt;= 0
E       TypeError: '&gt;=' not supported between instances of 'MLModel' and 'int'

tests/test_ml_model_extra.py:46: TypeError</failure></testcase><testcase classname="tests.test_prediction_executor.TestPredictionExecutor" name="test_conservative_defaults" time="0.005" /><testcase classname="tests.test_price_snapshot_minute_fallback" name="test_price_snapshot_minute_fallback" time="0.005" /><testcase classname="tests.test_problem_statement_fixes.TestProblemStatementFixes" name="test_meta_learning_minimum_trades_requirement" time="0.002"><failure message="AssertionError: bot_engine.py not found">self = &lt;tests.test_problem_statement_fixes.TestProblemStatementFixes testMethod=test_meta_learning_minimum_trades_requirement&gt;

    def test_meta_learning_minimum_trades_requirement(self):
        """Test that meta-learning minimum trade requirement is reduced to 2."""
        # Test by reading the source code directly to avoid import issues
        bot_engine_path = "bot_engine.py"
        if os.path.exists(bot_engine_path):
            with open(bot_engine_path) as f:
                content = f.read()
    
            # Look for the environment variable default
            import re
            pattern = r'METALEARN_MIN_TRADES.*"(\d+)"'
            match = re.search(pattern, content)
            if match:
                current_value = int(match.group(1))
                expected_value = 2  # Updated from 3 to 2
                self.assertEqual(current_value, expected_value,
                               f"METALEARN_MIN_TRADES default should be {expected_value}, got {current_value}")
            else:
                self.fail("Could not find METALEARN_MIN_TRADES parameter in load_global_signal_performance")
        else:
&gt;           self.fail("bot_engine.py not found")
E           AssertionError: bot_engine.py not found

tests/test_problem_statement_fixes.py:64: AssertionError</failure></testcase><testcase classname="tests.test_position_holding" name="test_position_score_calculation" time="0.006" /><testcase classname="tests.test_problem_statement_fixes.TestProblemStatementFixes" name="test_order_quantity_tracking_clarity" time="0.002"><failure message="AssertionError: trade_execution.py not found">self = &lt;tests.test_problem_statement_fixes.TestProblemStatementFixes testMethod=test_order_quantity_tracking_clarity&gt;

    def test_order_quantity_tracking_clarity(self):
        """Test that order quantity tracking provides clear distinction between
        requested, submitted, and filled quantities."""
        # Check that the trade execution logs have clear field names
        trade_execution_path = "trade_execution.py"
        if os.path.exists(trade_execution_path):
            with open(trade_execution_path) as f:
                content = f.read()
    
                # Check for clear quantity field names in FULL_FILL_SUCCESS
                self.assertIn('"requested_qty":', content,
                            "FULL_FILL_SUCCESS should include clear requested_qty field")
                self.assertIn('"filled_qty":', content,
                            "FULL_FILL_SUCCESS should include clear filled_qty field")
    
                # Check for clear quantity field names in ORDER_FILL_CONSOLIDATED
                self.assertIn('"total_filled_qty":', content,
                            "ORDER_FILL_CONSOLIDATED should use clear total_filled_qty field name")
    
        else:
&gt;           self.fail("trade_execution.py not found")
E           AssertionError: trade_execution.py not found

tests/test_problem_statement_fixes.py:102: AssertionError</failure></testcase><testcase classname="tests.test_position_holding_simple" name="test_position_holding_standalone" time="0.002" /><testcase classname="tests.test_position_holding_simple" name="test_position_score_standalone" time="0.002" /><testcase classname="tests.test_position_holding_simple" name="test_meta_learning_functions" time="0.002"><failure message="AttributeError: &lt;module 'ai_trading.meta_learning' from '/workspace/ai-trading-bot/ai_trading/meta_learning.py'&gt; does not have the attribute 'config'">def test_meta_learning_functions():
        """Test meta-learning conversion functions."""
    
&gt;       with patch('meta_learning.config') as mock_config:

tests/test_position_holding_simple.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;unittest.mock._patch object at 0x7ff8d345d150&gt;

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
&gt;           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: &lt;module 'ai_trading.meta_learning' from '/workspace/ai-trading-bot/ai_trading/meta_learning.py'&gt; does not have the attribute 'config'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError</failure></testcase><testcase classname="tests.test_problem_statement_fixes.TestProblemStatementFixes" name="test_pltr_sector_classification" time="0.002"><failure message="AssertionError: bot_engine.py not found">self = &lt;tests.test_problem_statement_fixes.TestProblemStatementFixes testMethod=test_pltr_sector_classification&gt;

    def test_pltr_sector_classification(self):
        """Test that PLTR is classified as Technology sector."""
        # Test by reading the source code directly to avoid import issues
        bot_engine_path = "bot_engine.py"
        if os.path.exists(bot_engine_path):
            with open(bot_engine_path) as f:
                content = f.read()
    
            # Check if PLTR is in the Technology sector mapping
            if '"PLTR": "Technology"' in content:
                pass
            else:
                self.fail("PLTR not found in Technology sector mapping")
        else:
&gt;           self.fail("bot_engine.py not found")
E           AssertionError: bot_engine.py not found

tests/test_problem_statement_fixes.py:80: AssertionError</failure></testcase><testcase classname="tests.test_problem_statement_fixes.TestProblemStatementFixes" name="test_sentiment_circuit_breaker_requirements" time="0.002" /><testcase classname="tests.test_problem_statement_validation" name="test_alpaca_availability_detection" time="0.008"><failure message="ImportError: cannot import name 'last_market_session' from 'ai_trading.market.calendars' (unknown location)">def test_alpaca_availability_detection():
        """Test that _alpaca_available() function works correctly."""
        # Set test environment
        os.environ['PYTEST_RUNNING'] = '1'
        os.environ['TESTING'] = '1'
    
        # Import the function
&gt;       from ai_trading.core.bot_engine import _alpaca_available

tests/test_problem_statement_validation.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    # ruff: noqa
    # fmt: off
    from __future__ import annotations
    
    import importlib
    import importlib.util
    import os
    import sys
    from typing import Dict, Iterable
    from zoneinfo import ZoneInfo  # AI-AGENT-REF: timezone conversions
    
    from json import JSONDecodeError
    # Safe 'requests' import with stub + RequestException binding
    try:  # pragma: no cover
        import requests  # type: ignore
        RequestException = requests.exceptions.RequestException  # type: ignore[attr-defined]
    except ImportError:  # pragma: no cover  # AI-AGENT-REF: narrow import handling
        class RequestException(Exception):
            pass
    
        # Minimal stub so runtime calls fail gracefully into COMMON_EXC
        class _RequestsStub:
            class exceptions:
                RequestException = RequestException
    
            def get(self, *a, **k):
                raise RequestException("requests not installed")
    
        requests = _RequestsStub()  # type: ignore
    
    from threading import Lock
    import warnings
    
    from ai_trading.data_fetcher import (
        get_bars,
        get_bars_batch,
        get_minute_df,
    )
&gt;   from ai_trading.market.calendars import last_market_session
E   ImportError: cannot import name 'last_market_session' from 'ai_trading.market.calendars' (unknown location)

ai_trading/core/bot_engine.py:39: ImportError</failure></testcase><testcase classname="tests.test_import_wiring" name="test_package_health" time="2.009" /><testcase classname="tests.test_position_holding_simple" name="test_signal_filtering" time="0.002" /><testcase classname="tests.test_position_intelligence" name="test_intelligent_position_components" time="0.003" /><testcase classname="tests.test_position_intelligence" name="test_integration_scenarios" time="0.002" /><testcase classname="tests.test_predict_smoke" name="test_predict_function" time="0.003"><failure message="NameError: name 'requests' is not defined">from __future__ import annotations
    
    from functools import lru_cache
    
    try:  # AI-AGENT-REF: optional cachetools TTL cache
&gt;       from cachetools import TTLCache
E       ModuleNotFoundError: No module named 'cachetools'

ai_trading/predict.py:6: ModuleNotFoundError

During handling of the above exception, another exception occurred:

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_predict_function0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3947090&gt;

    @pytest.mark.smoke
    def test_predict_function(tmp_path, monkeypatch):
&gt;       predict = _import_predict(monkeypatch)

tests/test_predict_smoke.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_predict_smoke.py:22: in _import_predict
    return importlib.import_module("ai_trading.predict")
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
&lt;frozen importlib._bootstrap&gt;:1204: in _gcd_import
    ???
&lt;frozen importlib._bootstrap&gt;:1176: in _find_and_load
    ???
&lt;frozen importlib._bootstrap&gt;:1147: in _find_and_load_unlocked
    ???
&lt;frozen importlib._bootstrap&gt;:690: in _load_unlocked
    ???
&lt;frozen importlib._bootstrap_external&gt;:940: in exec_module
    ???
&lt;frozen importlib._bootstrap&gt;:241: in _call_with_frames_removed
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    from __future__ import annotations
    
    from functools import lru_cache
    
    try:  # AI-AGENT-REF: optional cachetools TTL cache
        from cachetools import TTLCache
    
        _CACHETOOLS_AVAILABLE = True
        _sentiment_cache = TTLCache(maxsize=1000, ttl=3600)
&gt;   except (requests.RequestException, TimeoutError):
E   NameError: name 'requests' is not defined

ai_trading/predict.py:10: NameError</failure></testcase><testcase classname="tests.test_prediction_executor.TestPredictionExecutor" name="test_prediction_executor_default_sizing" time="0.003" /><testcase classname="tests.test_prediction_executor.TestPredictionExecutor" name="test_prediction_executor_low_cpu_count" time="0.003" /><testcase classname="tests.test_prediction_executor.TestPredictionExecutor" name="test_prediction_executor_null_cpu_count" time="0.003" /><testcase classname="tests.test_prediction_executor.TestPredictionExecutor" name="test_prediction_executor_env_override" time="0.002" /><testcase classname="tests.test_prediction_executor.TestPredictionExecutor" name="test_prediction_executor_env_zero" time="0.003" /><testcase classname="tests.test_production_fixes.TestDataStalenessThresholds" name="test_staleness_threshold_logic" time="0.002"><skipped type="pytest.skip" message="Required modules not available for data validation tests">/workspace/ai-trading-bot/tests/test_production_fixes.py:155: Required modules not available for data validation tests</skipped></testcase><testcase classname="tests.test_production_fixes.TestEnvironmentDebugging" name="test_debug_environment_structure" time="0.003"><skipped type="pytest.skip" message="validate_env module not available">/workspace/ai-trading-bot/tests/test_production_fixes.py:207: validate_env module not available</skipped></testcase><testcase classname="tests.test_production_fixes.TestEnvironmentDebugging" name="test_sensitive_value_masking" time="0.002"><skipped type="pytest.skip" message="validate_env module not available">/workspace/ai-trading-bot/tests/test_production_fixes.py:226: validate_env module not available</skipped></testcase><testcase classname="tests.test_production_fixes.TestEnvironmentDebugging" name="test_specific_env_var_validation" time="0.002"><skipped type="pytest.skip" message="validate_env module not available">/workspace/ai-trading-bot/tests/test_production_fixes.py:243: validate_env module not available</skipped></testcase><testcase classname="tests.test_production_fixes.TestIntegration" name="test_all_modules_importable" time="0.003"><failure message="AssertionError: Failed to import performance_monitor: No module named 'performance_monitor'">self = &lt;tests.test_production_fixes.TestIntegration testMethod=test_all_modules_importable&gt;

    def test_all_modules_importable(self):
        """Test that all modified modules can be imported without errors."""
        modules_to_test = [
            'performance_monitor',
            'data_validation',
            'validate_env'
        ]
    
        for module_name in modules_to_test:
            try:
&gt;               __import__(module_name)
E               ModuleNotFoundError: No module named 'performance_monitor'

tests/test_production_fixes.py:286: ModuleNotFoundError

During handling of the above exception, another exception occurred:

self = &lt;tests.test_production_fixes.TestIntegration testMethod=test_all_modules_importable&gt;

    def test_all_modules_importable(self):
        """Test that all modified modules can be imported without errors."""
        modules_to_test = [
            'performance_monitor',
            'data_validation',
            'validate_env'
        ]
    
        for module_name in modules_to_test:
            try:
                __import__(module_name)
            except ImportError as e:
                # Allow for missing dependencies in test environment
                if 'pandas' in str(e) or 'pydantic' in str(e):
                    continue
                else:
&gt;                   self.fail(f"Failed to import {module_name}: {e}")
E                   AssertionError: Failed to import performance_monitor: No module named 'performance_monitor'

tests/test_production_fixes.py:292: AssertionError</failure></testcase><testcase classname="tests.test_production_fixes.TestIntegration" name="test_env_file_contains_sentiment_config" time="0.002" /><testcase classname="tests.test_production_system" name="test_atr_position_sizer" time="0.003" /><testcase classname="tests.test_production_system" name="test_drawdown_circuit_breaker" time="0.002" /><testcase classname="tests.test_production_system" name="test_trading_halt_manager" time="0.002" /><testcase classname="tests.test_production_system" name="test_alert_manager" time="0.005" /><testcase classname="tests.test_production_system" name="test_production_execution_coordinator" time="0.002"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/_pytest/python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_prof_budget" name="test_soft_budget_elapsed_and_over" time="0.043"><failure message="assert (False is True or 0.009585136998794042 == 0.0)&#10; +  where False = over()&#10; +    where over = &lt;ai_trading.utils.prof.SoftBudget object at 0x7ff8d3323e90&gt;.over&#10; +  and   0.009585136998794042 = remaining()&#10; +    where remaining = &lt;ai_trading.utils.prof.SoftBudget object at 0x7ff8d3323e90&gt;.remaining">def test_soft_budget_elapsed_and_over():
        b = SoftBudget(interval_sec=0.1, fraction=0.5)
        time.sleep(0.02)
        assert b.elapsed_ms() &gt;= 20
        time.sleep(0.05)
&gt;       assert b.over() is True or b.remaining() == 0.0
E       assert (False is True or 0.009585136998794042 == 0.0)
E        +  where False = over()
E        +    where over = &lt;ai_trading.utils.prof.SoftBudget object at 0x7ff8d3323e90&gt;.over
E        +  and   0.009585136998794042 = remaining()
E        +    where remaining = &lt;ai_trading.utils.prof.SoftBudget object at 0x7ff8d3323e90&gt;.remaining

tests/test_prof_budget.py:11: AssertionError</failure></testcase><testcase classname="tests.test_public_api" name="test_strategy_allocator_imports" time="0.003" /><testcase classname="tests.test_pydantic_v2_migration" name="test_pydantic_v2_migration_syntax" time="0.002"><failure message="assert 'from pydantic import field_validator, Field' in 'from __future__ import annotations\n\nimport os\n\nfrom pydantic import BaseModel, Field, field_validator\n\n# AI-AGE...}&quot;)\n    return val\n\n\n__all__ = [\n    &quot;Settings&quot;,\n    &quot;debug_environment&quot;,\n    &quot;validate_specific_env_var&quot;,\n]\n'">def test_pydantic_v2_migration_syntax():
        """Test that validate_env.py uses correct Pydantic V2 syntax."""
        validate_env_path = os.path.join(
            os.path.dirname(__file__), '..', 'ai_trading', 'validation', 'validate_env.py'
        )
    
        with open(validate_env_path) as f:
            content = f.read()
    
        # Verify V2 imports
&gt;       assert 'from pydantic import field_validator, Field' in content
E       assert 'from pydantic import field_validator, Field' in 'from __future__ import annotations\n\nimport os\n\nfrom pydantic import BaseModel, Field, field_validator\n\n# AI-AGE...}")\n    return val\n\n\n__all__ = [\n    "Settings",\n    "debug_environment",\n    "validate_specific_env_var",\n]\n'

tests/test_pydantic_v2_migration.py:24: AssertionError</failure></testcase><testcase classname="tests.test_pydantic_v2_migration" name="test_validate_env_import" time="0.003"><skipped type="pytest.skip" message="Cannot import validate_env module: No module named 'ai_trading.validation.require_env'">/workspace/ai-trading-bot/tests/test_pydantic_v2_migration.py:84: Cannot import validate_env module: No module named 'ai_trading.validation.require_env'</skipped></testcase><testcase classname="tests.test_pydantic_v2_migration" name="test_field_validator_functionality" time="0.003"><skipped type="pytest.skip" message="Cannot import validate_env module">/workspace/ai-trading-bot/tests/test_pydantic_v2_migration.py:125: Cannot import validate_env module</skipped></testcase><testcase classname="tests.test_rebalancer_additional" name="test_maybe_rebalance_triggers" time="0.002" /><testcase classname="tests.test_rebalancer_additional" name="test_maybe_rebalance_skip" time="0.002" /><testcase classname="tests.test_rebalancer_additional" name="test_start_rebalancer" time="0.002" /><testcase classname="tests.test_redact" name="test_redact_masks_nested" time="0.002" /><testcase classname="tests.test_regime_and_schema_guard" name="test_validate_ohlcv_detects_missing" time="0.003" /><testcase classname="tests.test_regime_and_schema_guard" name="test_validate_ohlcv_passes_valid" time="0.004" /><testcase classname="tests.test_regime_and_schema_guard" name="test_pretrade_lookback_days_setting" time="0.002" /><testcase classname="tests.test_regime_and_schema_guard" name="test_regime_basket_proxy_function" time="0.006" /><testcase classname="tests.test_regime_filters" name="test_regime_changes" time="0.002"><failure message="FileNotFoundError: [Errno 2] No such file or directory: 'data/trades.csv'">def test_regime_changes():
&gt;       df = pd.read_csv(
            "data/trades.csv",
            engine="python",
            on_bad_lines="skip",
            skip_blank_lines=True,
        )

tests/test_regime_filters.py:6: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026: in read_csv
    return _read(filepath_or_buffer, kwds)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620: in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620: in __init__
    self._engine = self._make_engine(f, self.engine)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880: in _make_engine
    self.handles = get_handle(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path_or_buf = 'data/trades.csv', mode = 'r'

    @doc(compression_options=_shared_docs["compression_options"] % "path_or_buf")
    def get_handle(
        path_or_buf: FilePath | BaseBuffer,
        mode: str,
        *,
        encoding: str | None = None,
        compression: CompressionOptions | None = None,
        memory_map: bool = False,
        is_text: bool = True,
        errors: str | None = None,
        storage_options: StorageOptions | None = None,
    ) -&gt; IOHandles[str] | IOHandles[bytes]:
        """
        Get file handle for given path/buffer and mode.
    
        Parameters
        ----------
        path_or_buf : str or file handle
            File path or object.
        mode : str
            Mode to open path_or_buf with.
        encoding : str or None
            Encoding to use.
        {compression_options}
    
               May be a dict with key 'method' as compression mode
               and other keys as compression options if compression
               mode is 'zip'.
    
               Passing compression options as keys in dict is
               supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.
    
            .. versionchanged:: 1.4.0 Zstandard support.
    
        memory_map : bool, default False
            See parsers._parser_params for more information. Only used by read_csv.
        is_text : bool, default True
            Whether the type of the content passed to the file/buffer is string or
            bytes. This is not the same as `"b" not in mode`. If a string content is
            passed to a binary file/buffer, a wrapper is inserted.
        errors : str, default 'strict'
            Specifies how encoding and decoding errors are to be handled.
            See the errors argument for :func:`open` for a full list
            of options.
        storage_options: StorageOptions = None
            Passed to _get_filepath_or_buffer
    
        Returns the dataclass IOHandles
        """
        # Windows does not default to utf-8. Set to utf-8 for a consistent behavior
        encoding = encoding or "utf-8"
    
        errors = errors or "strict"
    
        # read_csv does not know whether the buffer is opened in binary/text mode
        if _is_binary_mode(path_or_buf, mode) and "b" not in mode:
            mode += "b"
    
        # validate encoding and errors
        codecs.lookup(encoding)
        if isinstance(errors, str):
            codecs.lookup_error(errors)
    
        # open URLs
        ioargs = _get_filepath_or_buffer(
            path_or_buf,
            encoding=encoding,
            compression=compression,
            mode=mode,
            storage_options=storage_options,
        )
    
        handle = ioargs.filepath_or_buffer
        handles: list[BaseBuffer]
    
        # memory mapping needs to be the first step
        # only used for read_csv
        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)
    
        is_path = isinstance(handle, str)
        compression_args = dict(ioargs.compression)
        compression = compression_args.pop("method")
    
        # Only for write methods
        if "r" not in mode and is_path:
            check_parent_directory(str(handle))
    
        if compression:
            if compression != "zstd":
                # compression libraries do not like an explicit text-mode
                ioargs.mode = ioargs.mode.replace("t", "")
            elif compression == "zstd" and "b" not in ioargs.mode:
                # python-zstandard defaults to text mode, but we always expect
                # compression libraries to use binary mode.
                ioargs.mode += "b"
    
            # GZ Compression
            if compression == "gzip":
                if isinstance(handle, str):
                    # error: Incompatible types in assignment (expression has type
                    # "GzipFile", variable has type "Union[str, BaseBuffer]")
                    handle = gzip.GzipFile(  # type: ignore[assignment]
                        filename=handle,
                        mode=ioargs.mode,
                        **compression_args,
                    )
                else:
                    handle = gzip.GzipFile(
                        # No overload variant of "GzipFile" matches argument types
                        # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                        fileobj=handle,  # type: ignore[call-overload]
                        mode=ioargs.mode,
                        **compression_args,
                    )
    
            # BZ Compression
            elif compression == "bz2":
                # Overload of "BZ2File" to handle pickle protocol 5
                # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                handle = get_bz2_file()(  # type: ignore[call-overload]
                    handle,
                    mode=ioargs.mode,
                    **compression_args,
                )
    
            # ZIP Compression
            elif compression == "zip":
                # error: Argument 1 to "_BytesZipFile" has incompatible type
                # "Union[str, BaseBuffer]"; expected "Union[Union[str, PathLike[str]],
                # ReadBuffer[bytes], WriteBuffer[bytes]]"
                handle = _BytesZipFile(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
                if handle.buffer.mode == "r":
                    handles.append(handle)
                    zip_names = handle.buffer.namelist()
                    if len(zip_names) == 1:
                        handle = handle.buffer.open(zip_names.pop())
                    elif not zip_names:
                        raise ValueError(f"Zero files found in ZIP file {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in ZIP file. "
                            f"Only one file per ZIP: {zip_names}"
                        )
    
            # TAR Encoding
            elif compression == "tar":
                compression_args.setdefault("mode", ioargs.mode)
                if isinstance(handle, str):
                    handle = _BytesTarFile(name=handle, **compression_args)
                else:
                    # error: Argument "fileobj" to "_BytesTarFile" has incompatible
                    # type "BaseBuffer"; expected "Union[ReadBuffer[bytes],
                    # WriteBuffer[bytes], None]"
                    handle = _BytesTarFile(
                        fileobj=handle, **compression_args  # type: ignore[arg-type]
                    )
                assert isinstance(handle, _BytesTarFile)
                if "r" in handle.buffer.mode:
                    handles.append(handle)
                    files = handle.buffer.getnames()
                    if len(files) == 1:
                        file = handle.buffer.extractfile(files[0])
                        assert file is not None
                        handle = file
                    elif not files:
                        raise ValueError(f"Zero files found in TAR archive {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in TAR archive. "
                            f"Only one file per TAR archive: {files}"
                        )
    
            # XZ Compression
            elif compression == "xz":
                # error: Argument 1 to "LZMAFile" has incompatible type "Union[str,
                # BaseBuffer]"; expected "Optional[Union[Union[str, bytes, PathLike[str],
                # PathLike[bytes]], IO[bytes]], None]"
                handle = get_lzma_file()(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
    
            # Zstd Compression
            elif compression == "zstd":
                zstd = import_optional_dependency("zstandard")
                if "r" in ioargs.mode:
                    open_args = {"dctx": zstd.ZstdDecompressor(**compression_args)}
                else:
                    open_args = {"cctx": zstd.ZstdCompressor(**compression_args)}
                handle = zstd.open(
                    handle,
                    mode=ioargs.mode,
                    **open_args,
                )
    
            # Unrecognized Compression
            else:
                msg = f"Unrecognized compression type: {compression}"
                raise ValueError(msg)
    
            assert not isinstance(handle, str)
            handles.append(handle)
    
        elif isinstance(handle, str):
            # Check whether the filename is to be opened in binary mode.
            # Binary mode does not support 'encoding' and 'newline'.
            if ioargs.encoding and "b" not in ioargs.mode:
                # Encoding
&gt;               handle = open(
                    handle,
                    ioargs.mode,
                    encoding=ioargs.encoding,
                    errors=errors,
                    newline="",
                )
E               FileNotFoundError: [Errno 2] No such file or directory: 'data/trades.csv'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/common.py:873: FileNotFoundError</failure></testcase><testcase classname="tests.test_peak_performance" name="test_backtest_cost_enforcement" time="0.007"><failure message="ModuleNotFoundError: No module named 'cachetools'">def test_backtest_cost_enforcement():
        """Test that backtester respects cost model."""
        # This would be a more complex integration test
        # For now, just ensure the cost model can be imported and used
    
&gt;       from ai_trading.execution.costs import get_cost_model

tests/test_peak_performance.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_resample_daily" name="test_get_daily_bars_resamples_minutes" time="0.004"><failure message="TypeError: test_get_daily_bars_resamples_minutes.&lt;locals&gt;.&lt;lambda&gt;() got an unexpected keyword argument 'adjustment'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d33a0f10&gt;

    def test_get_daily_bars_resamples_minutes(monkeypatch):
        """When daily bars are empty, minute bars are resampled."""  # AI-AGENT-REF
        empty = pd.DataFrame()
        monkeypatch.setattr(
            bars,
            "_fetch_daily_bars",
            lambda client, symbol, start, end, feed=None: empty,
        )
    
        idx = pd.date_range(
            "2024-01-02 14:30",
            periods=5,
            freq="1min",
            tz="UTC",
        )
        data = pd.DataFrame(
            {
                "open": [1, 2, 3, 4, 5],
                "high": [1, 2, 3, 4, 5],
                "low": [1, 2, 3, 4, 5],
                "close": [1, 2, 3, 4, 5],
                "volume": [10, 10, 10, 10, 10],
            },
            index=idx,
        )
        monkeypatch.setattr(
            bars, "_get_minute_bars", lambda symbol, start_dt, end_dt, feed: data
        )
    
&gt;       out = bars.get_daily_bars(
            "SPY", None, datetime(2024, 1, 2, tzinfo=UTC), datetime(2024, 1, 3, tzinfo=UTC)
        )

tests/test_resample_daily.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

symbol = 'SPY', client = None, start = datetime.datetime(2024, 1, 2, 0, 0, tzinfo=datetime.timezone.utc)
end = datetime.datetime(2024, 1, 3, 0, 0, tzinfo=datetime.timezone.utc), feed = 'iex'

    def get_daily_bars(
        symbol: str,
        client,
        start: datetime,
        end: datetime,
        feed: str | None = None,
    ):
        """Fetch daily bars; fallback to alternate feed then resampled minutes."""  # AI-AGENT-REF
        S = get_settings()
        if feed is None:
            feed = S.alpaca_data_feed
        adjustment = S.alpaca_adjustment
        start = ensure_utc_datetime(start)
        end = ensure_utc_datetime(end)
&gt;       df = _fetch_daily_bars(client, symbol, start, end, feed=feed, adjustment=adjustment)
E       TypeError: test_get_daily_bars_resamples_minutes.&lt;locals&gt;.&lt;lambda&gt;() got an unexpected keyword argument 'adjustment'

ai_trading/data/bars.py:332: TypeError</failure></testcase><testcase classname="tests.test_performance_allocator_conf_gate" name="test_threshold_resolution_prefers_trading_config" time="0.003" /><testcase classname="tests.test_performance_allocator_conf_gate" name="test_allocator_confidence_gate_filters_and_logs" time="0.004"><failure message="assert 0 &gt;= 2&#10; +  where 0 = len([])">caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7f867c24c3d0&gt;

    def test_allocator_confidence_gate_filters_and_logs(caplog):
        caplog.set_level(logging.INFO)
        alloc = PerformanceBasedAllocator()
        cfg = TradingConfig(score_confidence_min=0.7)
        inputs = {
            "momentum": [Sig("AAPL", 0.65), Sig("MSFT", 0.71), Sig("NVDA", 0.90)],
            "meanrev": [Sig("TSLA", 0.40), Sig("AMZN", 0.72)],
        }
    
        out = alloc.allocate(inputs, cfg)
    
        kept_symbols = {s.symbol for xs in out.values() for s in xs}
        assert kept_symbols == {"MSFT", "NVDA", "AMZN"}
    
        drops = [rec for rec in caplog.records if rec.message == "CONFIDENCE_DROP"]
&gt;       assert len(drops) &gt;= 2
E       assert 0 &gt;= 2
E        +  where 0 = len([])

tests/test_performance_allocator_conf_gate.py:40: AssertionError</failure></testcase><testcase classname="tests.test_performance_fixes" name="test_meta_learning_mixed_format" time="0.002"><failure message="AssertionError: Should detect mixed formats&#10;assert False">def test_meta_learning_mixed_format():
        """Test that meta-learning can handle mixed audit/meta-learning log formats."""
    
        from ai_trading.meta_learning import (
            retrain_meta_learner,
            validate_trade_data_quality,
        )
    
        # Test with the actual trades.csv file
        quality_report = validate_trade_data_quality('trades.csv')
    
        # Verify mixed format detection
        assert quality_report['file_exists'], "Trade log file should exist"
        assert quality_report['has_valid_format'], "Should have valid format"
&gt;       assert quality_report['mixed_format_detected'], "Should detect mixed formats"
E       AssertionError: Should detect mixed formats
E       assert False

tests/test_performance_fixes.py:36: AssertionError</failure></testcase><testcase classname="tests.test_retrain_smoke" name="test_retrain_detect_regime_and_dump" time="0.003"><failure message="ModuleNotFoundError: No module named 'retrain'">tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_retrain_detect_regime_and0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d832a590&gt;

    @pytest.mark.smoke
    def test_retrain_detect_regime_and_dump(tmp_path, monkeypatch):
&gt;       retrain = _import_retrain(monkeypatch)

tests/test_retrain_smoke.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_retrain_smoke.py:80: in _import_retrain
    return importlib.import_module("retrain")
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
&lt;frozen importlib._bootstrap&gt;:1204: in _gcd_import
    ???
&lt;frozen importlib._bootstrap&gt;:1176: in _find_and_load
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'retrain', import_ = &lt;function _gcd_import at 0x7ff8f1353d80&gt;

&gt;   ???
E   ModuleNotFoundError: No module named 'retrain'

&lt;frozen importlib._bootstrap&gt;:1140: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_performance_fixes" name="test_cache_performance_monitoring" time="0.002"><failure message="ImportError: cannot import name '_CACHE_STATS' from 'ai_trading.data_fetcher' (unknown location)">def test_cache_performance_monitoring():
        """Test that cache performance monitoring is working."""
    
&gt;       from ai_trading.data_fetcher import _CACHE_STATS, get_cache_stats
E       ImportError: cannot import name '_CACHE_STATS' from 'ai_trading.data_fetcher' (unknown location)

tests/test_performance_fixes.py:52: ImportError</failure></testcase><testcase classname="tests.test_performance_fixes" name="test_position_size_reporting" time="0.005"><failure message="ModuleNotFoundError: No module named 'cachetools'">def test_position_size_reporting():
        """Test that position size reporting is consistent."""
    
&gt;       from ai_trading.execution.engine import ExecutionEngine

tests/test_performance_fixes.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_risk" name="test_fractional_kelly_drawdown" time="0.004" /><testcase classname="tests.test_risk_engine" name="test_trailing_stop_and_reentry" time="0.002" /><testcase classname="tests.test_risk_engine_additional" name="test_can_trade_invalid_type" time="0.002" /><testcase classname="tests.test_risk_engine_additional" name="test_register_fill_invalid" time="0.002" /><testcase classname="tests.test_risk_engine_additional" name="test_check_max_drawdown_exception" time="0.003" /><testcase classname="tests.test_risk_engine_additional" name="test_position_size_invalid_signal" time="0.002" /><testcase classname="tests.test_risk_engine_additional" name="test_position_size_division_error" time="0.002"><failure message="TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'">def test_position_size_division_error():
        """Errors during quantity calc return zero."""
        eng = risk_engine.RiskEngine()
&gt;       sig = TradeSignal(symbol='A', side='buy', confidence=1.0, strategy='s')
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_additional.py:42: TypeError</failure></testcase><testcase classname="tests.test_risk_engine_additional" name="test_apply_weight_limits" time="0.002"><failure message="TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'">def test_apply_weight_limits():
        """Weight adjustments respect caps."""
        eng = risk_engine.RiskEngine()
        eng.asset_limits['equity'] = 0.5
        eng.strategy_limits['s'] = 0.3
        eng.exposure['equity'] = 0.4
&gt;       sig = TradeSignal(symbol='A', side='buy', confidence=1.0, strategy='s', weight=1.0)
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_additional.py:53: TypeError</failure></testcase><testcase classname="tests.test_performance_fixes" name="test_latency_tracking" time="0.005"><failure message="ModuleNotFoundError: No module named 'cachetools'">def test_latency_tracking():
        """Test that order execution latency tracking is more granular."""
    
        import time
    
&gt;       from ai_trading.execution.engine import ExecutionEngine

tests/test_performance_fixes.py:98: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_risk_engine_additional" name="test_compute_volatility_error" time="0.003" /><testcase classname="tests.test_risk_engine_additional" name="test_compute_volatility_nan" time="0.003" /><testcase classname="tests.test_risk_engine_additional" name="test_calculate_position_size_invalid_args" time="0.003" /><testcase classname="tests.test_risk_engine_additional" name="test_register_trade_blocked" time="0.002" /><testcase classname="tests.test_risk_engine_extra" name="test_calculate_position_size_zero_cash" time="0.003" /><testcase classname="tests.test_risk_engine_extra" name="test_calculate_position_size_negative_input" time="0.002" /><testcase classname="tests.test_risk_engine_extra" name="test_check_max_drawdown_triggers_stop" time="0.002" /><testcase classname="tests.test_risk_engine_extra" name="test_check_max_drawdown_ok" time="0.002" /><testcase classname="tests.test_risk_engine_extra" name="test_hard_stop_blocks_trading" time="0.002" /><testcase classname="tests.test_risk_engine_extra" name="test_can_trade_limits" time="0.002" /><testcase classname="tests.test_risk_engine_extra" name="test_register_and_position_size" time="0.002" /><testcase classname="tests.test_risk_engine_module" name="test_can_trade_limits" time="0.002"><failure message="TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'">def test_can_trade_limits():
        eng = RiskEngine()
&gt;       sig = make_signal()

tests/test_risk_engine_module.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def make_signal():
&gt;       return TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_module.py:25: TypeError</failure></testcase><testcase classname="tests.test_performance_fixes" name="test_comprehensive_fixes" time="0.003" /><testcase classname="tests.test_phase2_enhancements.TestOrderHealthMonitor" name="test_health_metrics_calculation" time="0.004" /><testcase classname="tests.test_phase2_enhancements.TestOrderHealthMonitor" name="test_health_summary_generation" time="0.013" /><testcase classname="tests.test_risk_engine_module" name="test_register_and_position_size" time="0.003"><failure message="TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d33d5090&gt;

    def test_register_and_position_size(monkeypatch):
        eng = RiskEngine()
&gt;       sig = make_signal()

tests/test_risk_engine_module.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def make_signal():
&gt;       return TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_module.py:25: TypeError</failure></testcase><testcase classname="tests.test_phase2_enhancements.TestOrderHealthMonitor" name="test_order_health_monitor_initialization" time="0.002" /><testcase classname="tests.test_phase2_enhancements.TestOrderHealthMonitor" name="test_partial_fill_recording" time="0.003" /><testcase classname="tests.test_phase2_enhancements.TestSystemHealthChecker" name="test_current_health_report" time="0.002" /><testcase classname="tests.test_risk_engine_module" name="test_check_max_drawdown" time="0.003" /><testcase classname="tests.test_phase2_enhancements.TestSystemHealthChecker" name="test_meta_learning_health_check" time="0.003" /><testcase classname="tests.test_risk_engine_module" name="test_compute_volatility" time="0.003" /><testcase classname="tests.test_phase2_enhancements.TestSystemHealthChecker" name="test_overall_status_determination" time="0.002" /><testcase classname="tests.test_risk_engine_module" name="test_hard_stop_blocks_trading" time="0.002"><failure message="TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'">def test_hard_stop_blocks_trading():
        eng = RiskEngine()
        eng.hard_stop = True
&gt;       sig = make_signal()

tests/test_risk_engine_module.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def make_signal():
&gt;       return TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_module.py:25: TypeError</failure></testcase><testcase classname="tests.test_risk_engine_package.TestRiskEnginePackage" name="test_risk_engine_resolver_uses_package" time="0.002" /><testcase classname="tests.test_risk_engine_package.TestRiskEnginePackage" name="test_scripts_fallback_disabled_by_default" time="0.002" /><testcase classname="tests.test_risk_engine_package.TestRiskEnginePackage" name="test_update_exposure_requires_context" time="0.002"><failure message="ImportError: cannot import name 'RiskEngine' from 'ai_trading.risk' (unknown location)">self = &lt;tests.test_risk_engine_package.TestRiskEnginePackage testMethod=test_update_exposure_requires_context&gt;

    def test_update_exposure_requires_context(self):
        """Test that update_exposure requires context parameter."""
&gt;       from ai_trading.risk import RiskEngine
E       ImportError: cannot import name 'RiskEngine' from 'ai_trading.risk' (unknown location)

tests/test_risk_engine_package.py:59: ImportError</failure></testcase><testcase classname="tests.test_risk_engine_package.TestRiskEnginePackage" name="test_update_exposure_works_with_context" time="0.002"><failure message="ImportError: cannot import name 'RiskEngine' from 'ai_trading.risk' (unknown location)">self = &lt;tests.test_risk_engine_package.TestRiskEnginePackage testMethod=test_update_exposure_works_with_context&gt;

    def test_update_exposure_works_with_context(self):
        """Test that update_exposure works with context parameter."""
&gt;       from ai_trading.risk import RiskEngine
E       ImportError: cannot import name 'RiskEngine' from 'ai_trading.risk' (unknown location)

tests/test_risk_engine_package.py:71: ImportError</failure></testcase><testcase classname="tests.test_risk_engine_module" name="test_check_max_drawdown_ok" time="0.002" /><testcase classname="tests.test_risk_engine_package.TestRiskEnginePackage" name="test_risk_engine_import_from_package" time="0.002"><failure message="ImportError: cannot import name 'RiskEngine' from 'ai_trading.risk' (unknown location)">self = &lt;tests.test_risk_engine_package.TestRiskEnginePackage testMethod=test_risk_engine_import_from_package&gt;

    def test_risk_engine_import_from_package(self):
        """Test that RiskEngine can be imported from ai_trading.risk."""
&gt;       from ai_trading.risk import RiskEngine
E       ImportError: cannot import name 'RiskEngine' from 'ai_trading.risk' (unknown location)

tests/test_risk_engine_package.py:14: ImportError</failure></testcase><testcase classname="tests.test_risk_new" name="test_stop_levels" time="0.002" /><testcase classname="tests.test_risk_new" name="test_corr_weights" time="0.002" /><testcase classname="tests.test_rl_module" name="test_rl_train_and_infer" time="0.002"><failure message="AttributeError: module 'ai_trading.rl_trading.train' has no attribute 'train'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3ed2e50&gt;
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_rl_train_and_infer0')

    def test_rl_train_and_infer(monkeypatch, tmp_path):
        data = np.random.rand(20, 4)
        class DummyPPO:
            def __init__(self, *_a, **_k): pass
            def learn(self, *a, **k): return None
            def save(self, path): open(path, 'wb').write(b'0')
            def predict(self, state, deterministic=True): return (1, None)
            @classmethod
            def load(cls, path):
                return cls()
        monkeypatch.setattr(train_mod, "PPO", DummyPPO)
        import ai_trading.rl_trading as rl
        monkeypatch.setattr(rl, "PPO", DummyPPO)
        path = tmp_path / "model.zip"
&gt;       train_mod.train(data, path, timesteps=10)
E       AttributeError: module 'ai_trading.rl_trading.train' has no attribute 'train'

tests/test_rl_module.py:20: AttributeError</failure></testcase><testcase classname="tests.test_risk_new" name="test_drawdown_circuit" time="0.001" /><testcase classname="tests.test_risk_new" name="test_volatility_filter" time="0.001" /><testcase classname="tests.test_run_overlap" name="test_run_all_trades_overlap" time="0.004"><failure message="RuntimeError: Model required but not configured. Set one of: AI_TRADER_MODEL_PATH=&lt;abs path to .joblib/.pkl&gt; or AI_TRADER_MODEL_MODULE=&lt;import.path with get_model()/Model()&gt;.">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3986e50&gt;
caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7ff8d3918750&gt;

    def test_run_all_trades_overlap(monkeypatch, caplog):
        state = bot_engine.BotState()
        runtime = bot_engine.get_ctx()
        caplog.set_level("INFO")
    
        monkeypatch.setattr(bot_engine, "is_market_open", lambda: True)
        monkeypatch.setattr(bot_engine, "check_pdt_rule", lambda ctx: False)
        monkeypatch.setattr(bot_engine, "_prepare_run", lambda ctx, st: (0.0, True, []))
        monkeypatch.setattr(bot_engine, "_process_symbols", lambda *a, **k: ([], {}))
        monkeypatch.setattr(bot_engine, "_send_heartbeat", lambda: None)
&gt;       monkeypatch.setattr(runtime.api, "get_account", lambda: types.SimpleNamespace(cash=0, equity=0))

tests/test_run_overlap.py:18: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:5483: in api
    self._ensure_initialized()
ai_trading/core/bot_engine.py:5453: in _ensure_initialized
    self._context.model = _load_required_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _load_required_model() -&gt; Any:
        """Load ML model from path or module; fail fast if missing."""  # AI-AGENT-REF: strict model loader
        path = os.getenv("AI_TRADER_MODEL_PATH")
        modname = os.getenv("AI_TRADER_MODEL_MODULE")
    
        if path and os.path.isfile(path):
            mdl = joblib.load(path)
            try:
                digest = _sha256_file(path)
            except OSError:  # hashing is best-effort; missing/perm issues shouldn't crash
                digest = "unknown"
            _log.info("MODEL_LOADED", extra={"source": "file", "path": path, "sha": digest})
            return mdl
    
        if modname:
            try:
                mod = importlib.import_module(modname)
            except COMMON_EXC as e:  # noqa: BLE001
                raise RuntimeError(
                    f"Failed to import AI_TRADER_MODEL_MODULE='{modname}': {e}"
                ) from e
            factory = getattr(mod, "get_model", None) or getattr(mod, "Model", None)
            if not factory:
                raise RuntimeError(
                    f"Module '{modname}' missing get_model()/Model() factory."
                )
            mdl = factory() if callable(factory) else factory
            _log.info(
                "MODEL_LOADED",
                extra={
                    "source": "module",
                    "model_module": modname,
                },  # AI-AGENT-REF: avoid reserved key
            )
            return mdl
    
        msg = (
            "Model required but not configured. "
            "Set one of: "
            "AI_TRADER_MODEL_PATH=&lt;abs path to .joblib/.pkl&gt; "
            "or AI_TRADER_MODEL_MODULE=&lt;import.path with get_model()/Model()&gt;."
        )
        _log.error(
            "MODEL_CONFIG_MISSING",
            extra={
                "hint_paths": ["AI_TRADER_MODEL_PATH", "TradingConfig.ml_model_path"],
                "hint_modules": ["AI_TRADER_MODEL_MODULE", "TradingConfig.ml_model_module"],
            },
        )
&gt;       raise RuntimeError(msg)
E       RuntimeError: Model required but not configured. Set one of: AI_TRADER_MODEL_PATH=&lt;abs path to .joblib/.pkl&gt; or AI_TRADER_MODEL_MODULE=&lt;import.path with get_model()/Model()&gt;.

ai_trading/core/bot_engine.py:538: RuntimeError</failure></testcase><testcase classname="tests.test_rl_features" name="test_compute_features_shape_and_finite" time="0.017" /><testcase classname="tests.test_runner" name="test_runner_as_main" time="0.003"><failure message="AttributeError: module 'ai_trading.runner' has no attribute 'time'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8676853350&gt;

    def test_runner_as_main(monkeypatch):
        mod = load_runner(monkeypatch)
        monkeypatch.setattr(mod, "main", lambda: (_ for _ in ()).throw(SystemExit(0)))
&gt;       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:62: AttributeError</failure></testcase><testcase classname="tests.test_runner" name="test_runner_import_fallback" time="0.004"><failure message="AssertionError: assert &lt;function main at 0x7f86768e07c0&gt; is &lt;function test_runner_import_fallback.&lt;locals&gt;.&lt;lambda&gt; at 0x7f86768e1a80&gt;&#10; +  where &lt;function main at 0x7f86768e07c0&gt; = &lt;module 'runner' from '/workspace/ai-trading-bot/tests/../ai_trading/runner.py'&gt;.main&#10; +  and   &lt;function test_runner_import_fallback.&lt;locals&gt;.&lt;lambda&gt; at 0x7f86768e1a80&gt; = &lt;module 'bot_engine'&gt;.main">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f86768b9c50&gt;

    def test_runner_import_fallback(monkeypatch):
        monkeypatch.setitem(sys.modules, "bot", None)
        bot_engine_mod = types.ModuleType("bot_engine")
        bot_engine_mod.main = lambda: None
        monkeypatch.setitem(sys.modules, "bot_engine", bot_engine_mod)
        import importlib
        r = importlib.reload(importlib.import_module("runner"))
&gt;       assert r.main is bot_engine_mod.main
E       AssertionError: assert &lt;function main at 0x7f86768e07c0&gt; is &lt;function test_runner_import_fallback.&lt;locals&gt;.&lt;lambda&gt; at 0x7f86768e1a80&gt;
E        +  where &lt;function main at 0x7f86768e07c0&gt; = &lt;module 'runner' from '/workspace/ai-trading-bot/tests/../ai_trading/runner.py'&gt;.main
E        +  and   &lt;function test_runner_import_fallback.&lt;locals&gt;.&lt;lambda&gt; at 0x7f86768e1a80&gt; = &lt;module 'bot_engine'&gt;.main

tests/test_runner.py:74: AssertionError</failure></testcase><testcase classname="tests.test_runner_additional" name="test_runner_starts" time="0.002"><failure message="AttributeError: module 'ai_trading.core.bot_engine' has no attribute 'ctx'">def test_runner_starts():
&gt;       ctx = bot_engine.ctx
E       AttributeError: module 'ai_trading.core.bot_engine' has no attribute 'ctx'

tests/test_runner_additional.py:7: AttributeError</failure></testcase><testcase classname="tests.test_runtime_allocator" name="test_runtime_has_allocator_when_built" time="0.011" /><testcase classname="tests.test_runtime_fixes" name="test_legacy_imports" time="0.002" /><testcase classname="tests.test_runtime_fixes" name="test_ohlcv_files_exist" time="0.002" /><testcase classname="tests.test_runtime_fixes" name="test_bot_engine_changes" time="0.020" /><testcase classname="tests.test_runtime_fixes" name="test_top_level_shims" time="0.002"><failure message="FileNotFoundError: [Errno 2] No such file or directory: 'bot_engine.py'">def test_top_level_shims():
        """Test that top-level shim files exist"""
    
        shims = ["signals.py", "rebalancer.py", "indicators.py"]
        success = True
    
        for shim in shims:
            if os.path.exists(shim):
                pass
            else:
                success = False
    
        # Check bot_engine.py has prepare_indicators
&gt;       with open("bot_engine.py") as f:
E       FileNotFoundError: [Errno 2] No such file or directory: 'bot_engine.py'

tests/test_runtime_fixes.py:108: FileNotFoundError</failure></testcase><testcase classname="tests.test_runtime_model" name="test_runtime_has_model" time="0.002" /><testcase classname="tests.test_runtime_params_hydration" name="test_trading_config_has_required_parameters" time="0.002"><failure message="assert 0.25 == 0.04&#10; +  where 0.25 = TradingConfig(daily_loss_limit=0.03, conf_threshold=0.75, kelly_fraction=0.6, slow_period=21, confirmation_count=3, ca...r_hour=10, max_trades_per_day=100, volume_threshold=50000, seed=42, entry_start_offset_min=0, entry_end_offset_min=390).capital_cap">def test_trading_config_has_required_parameters():
        """Test that TradingConfig includes required trading parameters."""
        from ai_trading.config.management import TradingConfig
    
        cfg = TradingConfig()
    
        # Verify required parameters are present as attributes
        assert hasattr(cfg, 'capital_cap')
        assert hasattr(cfg, 'dollar_risk_limit')
        assert hasattr(cfg, 'max_position_size')
    
        # Verify default values
&gt;       assert cfg.capital_cap == 0.04
E       assert 0.25 == 0.04
E        +  where 0.25 = TradingConfig(daily_loss_limit=0.03, conf_threshold=0.75, kelly_fraction=0.6, slow_period=21, confirmation_count=3, ca...r_hour=10, max_trades_per_day=100, volume_threshold=50000, seed=42, entry_start_offset_min=0, entry_end_offset_min=390).capital_cap

tests/test_runtime_params_hydration.py:25: AssertionError</failure></testcase><testcase classname="tests.test_runtime_params_hydration" name="test_trading_config_from_env_loads_parameters" time="0.004"><failure message="AssertionError: assert 8000.0 == 2.0&#10; +  where 8000.0 = TradingConfig(daily_loss_limit=0.03, conf_threshold=0.75, kelly_fraction=0.6, slow_period=21, confirmation_count=2, ca...er_day=200, volume_threshold=0.0, seed=42, entry_start_offset_min=0, entry_end_offset_min=390, trading_mode='balanced').max_position_size">def test_trading_config_from_env_loads_parameters():
        """Test that TradingConfig.from_env() loads parameters from environment."""
        from ai_trading.config.management import TradingConfig
    
        # Test with environment variables
        env_vars = {
            'CAPITAL_CAP': '0.06',
            'DOLLAR_RISK_LIMIT': '0.08',
            'MAX_POSITION_SIZE': '2.0',
        }
    
        with patch.dict(os.environ, env_vars):
            cfg = TradingConfig.from_env()
    
            assert cfg.capital_cap == 0.06
            assert cfg.dollar_risk_limit == 0.08
&gt;           assert cfg.max_position_size == 2.0
E           AssertionError: assert 8000.0 == 2.0
E            +  where 8000.0 = TradingConfig(daily_loss_limit=0.03, conf_threshold=0.75, kelly_fraction=0.6, slow_period=21, confirmation_count=2, ca...er_day=200, volume_threshold=0.0, seed=42, entry_start_offset_min=0, entry_end_offset_min=390, trading_mode='balanced').max_position_size

tests/test_runtime_params_hydration.py:46: AssertionError</failure></testcase><testcase classname="tests.test_runtime_params_hydration" name="test_trading_config_from_env_market_calendar" time="0.002" /><testcase classname="tests.test_runtime_params_hydration" name="test_build_runtime_hydrates_all_parameters" time="0.002"><failure message="assert 0.25 == 0.04">def test_build_runtime_hydrates_all_parameters():
        """Test that build_runtime creates runtime with all required parameters."""
        from ai_trading.config.management import TradingConfig
        from ai_trading.core.runtime import REQUIRED_PARAM_DEFAULTS, build_runtime
    
        cfg = TradingConfig()
        runtime = build_runtime(cfg)
    
        # Verify runtime has params dict
        assert hasattr(runtime, 'params')
        assert isinstance(runtime.params, dict)
    
        # Verify all required parameters are present
        for key in REQUIRED_PARAM_DEFAULTS.keys():
            assert key in runtime.params, f"Missing required parameter: {key}"
    
        # Verify specific values
&gt;       assert runtime.params['CAPITAL_CAP'] == 0.04
E       assert 0.25 == 0.04

tests/test_runtime_params_hydration.py:75: AssertionError</failure></testcase><testcase classname="tests.test_runtime_params_hydration" name="test_build_runtime_uses_config_values" time="0.002"><failure message="pydantic_core._pydantic_core.ValidationError: 1 validation error for TradingConfig&#10;  Value error, capital_cap must be &gt;= dollar_risk_limit [type=value_error, input_value={'capital_cap': 0.08, 'do..., 'conf_threshold': 0.9}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.11/v/value_error">def test_build_runtime_uses_config_values():
        """Test that build_runtime uses values from TradingConfig."""
        from ai_trading.config.management import TradingConfig
        from ai_trading.core.runtime import build_runtime
    
        # Create config with custom values
&gt;       cfg = TradingConfig(
            capital_cap=0.08,
            dollar_risk_limit=0.10,
            max_position_size=2.5,
            kelly_fraction=0.7,
            buy_threshold=0.8,
            conf_threshold=0.9
        )
E       pydantic_core._pydantic_core.ValidationError: 1 validation error for TradingConfig
E         Value error, capital_cap must be &gt;= dollar_risk_limit [type=value_error, input_value={'capital_cap': 0.08, 'do..., 'conf_threshold': 0.9}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.11/v/value_error

tests/test_runtime_params_hydration.py:86: ValidationError</failure></testcase><testcase classname="tests.test_runtime_params_hydration" name="test_param_helper_fallback_logic" time="0.002" /><testcase classname="tests.test_runtime_params_hydration" name="test_no_missing_parameters_validation" time="0.002" /><testcase classname="tests.test_runtime_params_hydration" name="test_parameter_values_are_floats" time="0.002" /><testcase classname="tests.test_runtime_paths" name="test_runtime_paths_writable" time="0.002" /><testcase classname="tests.test_runtime_paths" name="test_paths_module_imports" time="0.001" /><testcase classname="tests.test_runtime_paths" name="test_http_utilities_available" time="0.002"><failure message="AssertionError: assert False&#10; +  where False = hasattr(&lt;module 'ai_trading.utils.http' from '/workspace/ai-trading-bot/ai_trading/utils/http.py'&gt;, 'delete')">def test_http_utilities_available():
        """Test that HTTP utilities are available."""
        from ai_trading.utils import http
    
        assert hasattr(http, 'get')
        assert hasattr(http, 'post')
        assert hasattr(http, 'put')
&gt;       assert hasattr(http, 'delete')
E       AssertionError: assert False
E        +  where False = hasattr(&lt;module 'ai_trading.utils.http' from '/workspace/ai-trading-bot/ai_trading/utils/http.py'&gt;, 'delete')

tests/test_runtime_paths.py:62: AssertionError</failure></testcase><testcase classname="tests.test_safe_submit_order" name="test_safe_submit_order_pending_new" time="0.004" /><testcase classname="tests.test_safety_fallbacks" name="test_ensure_columns_accepts_symbol_arg" time="0.005" /><testcase classname="tests.test_problem_statement_validation" name="test_alpaca_import_exception_handling" time="0.016"><failure message="AttributeError: &lt;module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'&gt; does not have the attribute '_alpaca_available'">def test_alpaca_import_exception_handling():
        """Test that Alpaca imports handle TypeErrors and other exceptions gracefully."""
        # Set test environment
        os.environ['PYTEST_RUNNING'] = '1'
        os.environ['TESTING'] = '1'
    
        # Mock alpaca to raise TypeError (the specific error mentioned in requirements)
        with patch.dict('sys.modules', {'alpaca': MagicMock()}):
&gt;           with patch('ai_trading.core.bot_engine._alpaca_available') as mock_available:

tests/test_problem_statement_validation.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;unittest.mock._patch object at 0x7f8d84fc72d0&gt;

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
&gt;           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: &lt;module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'&gt; does not have the attribute '_alpaca_available'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError</failure></testcase><testcase classname="tests.test_safety_fallbacks" name="test_ensure_columns_backwards_compatible" time="0.003" /><testcase classname="tests.test_safety_fallbacks" name="test_pretrade_lookback_days_setting" time="0.002" /><testcase classname="tests.test_sanitizing_logger_adapter" name="test_extra_key_collisions_are_prefixed" time="0.002" /><testcase classname="tests.test_scaling_and_indicators" name="test_volatility_parity_position_basic" time="0.002" /><testcase classname="tests.test_scaling_and_indicators" name="test_volatility_parity_zero_vol" time="0.002" /><testcase classname="tests.test_settings_bridge" name="test_settings_bridge_alias" time="0.001" /><testcase classname="tests.test_settings_config" name="test_settings_defaults" time="0.004" /><testcase classname="tests.test_settings_config" name="test_settings_invalid_risk" time="0.004"><failure message="Failed: DID NOT RAISE &lt;class 'pydantic_core._pydantic_core.ValidationError'&gt;">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f86768ab290&gt;

    def test_settings_invalid_risk(monkeypatch):
        """Invalid risk values raise ValidationError."""  # AI-AGENT-REF
        monkeypatch.setenv("CAPITAL_CAP", "0")
        monkeypatch.setenv("DOLLAR_RISK_LIMIT", "0")
&gt;       with pytest.raises(ValidationError):
E       Failed: DID NOT RAISE &lt;class 'pydantic_core._pydantic_core.ValidationError'&gt;

tests/test_settings_config.py:29: Failed</failure></testcase><testcase classname="tests.test_settings_config" name="test_main_startup_log" time="0.002" /><testcase classname="tests.test_settings_config" name="test_current_qty_no_position" time="0.001" /><testcase classname="tests.test_short_selling_implementation.TestShortSellingImplementation" name="test_current_sell_logic_blocks_no_position" time="0.006"><failure message="ModuleNotFoundError: No module named 'cachetools'">self = &lt;tests.test_short_selling_implementation.TestShortSellingImplementation testMethod=test_current_sell_logic_blocks_no_position&gt;

    def test_current_sell_logic_blocks_no_position(self):
        """Test that current logic blocks sell orders when no position exists."""
        # This test documents the current behavior that we need to fix
&gt;       from ai_trading.execution.engine import ExecutionEngine

tests/test_short_selling_implementation.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_short_selling_implementation.TestShortSellingImplementation" name="test_meta_learning_graceful_degradation" time="0.016" /><testcase classname="tests.test_short_selling_implementation.TestShortSellingImplementation" name="test_order_status_monitoring_needed" time="0.010"><failure message="ModuleNotFoundError: No module named 'cachetools'">self = &lt;tests.test_short_selling_implementation.TestShortSellingImplementation testMethod=test_order_status_monitoring_needed&gt;

    def test_order_status_monitoring_needed(self):
        """Test framework for order status monitoring."""
&gt;       from ai_trading.execution.engine import ExecutionEngine

tests/test_short_selling_implementation.py:126: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_problem_statement_validation" name="test_package_safe_imports" time="0.011"><failure message="ImportError: cannot import name 'last_market_session' from 'ai_trading.market.calendars' (unknown location)">def test_package_safe_imports():
        """Test that package imports work correctly from ai_trading namespace."""
        # Set test environment
        os.environ['PYTEST_RUNNING'] = '1'
        os.environ['TESTING'] = '1'
    
        # Test logging import
        from ai_trading.logging import get_logger, setup_logging
        assert callable(setup_logging)
        assert callable(get_logger)
    
        # Test core imports
&gt;       from ai_trading.core.bot_engine import _alpaca_available

tests/test_problem_statement_validation.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    # ruff: noqa
    # fmt: off
    from __future__ import annotations
    
    import importlib
    import importlib.util
    import os
    import sys
    from typing import Dict, Iterable
    from zoneinfo import ZoneInfo  # AI-AGENT-REF: timezone conversions
    
    from json import JSONDecodeError
    # Safe 'requests' import with stub + RequestException binding
    try:  # pragma: no cover
        import requests  # type: ignore
        RequestException = requests.exceptions.RequestException  # type: ignore[attr-defined]
    except ImportError:  # pragma: no cover  # AI-AGENT-REF: narrow import handling
        class RequestException(Exception):
            pass
    
        # Minimal stub so runtime calls fail gracefully into COMMON_EXC
        class _RequestsStub:
            class exceptions:
                RequestException = RequestException
    
            def get(self, *a, **k):
                raise RequestException("requests not installed")
    
        requests = _RequestsStub()  # type: ignore
    
    from threading import Lock
    import warnings
    
    from ai_trading.data_fetcher import (
        get_bars,
        get_bars_batch,
        get_minute_df,
    )
&gt;   from ai_trading.market.calendars import last_market_session
E   ImportError: cannot import name 'last_market_session' from 'ai_trading.market.calendars' (unknown location)

ai_trading/core/bot_engine.py:39: ImportError</failure></testcase><testcase classname="tests.test_short_selling_implementation.TestShortSellingImplementation" name="test_sell_short_side_should_be_distinguished" time="0.008"><failure message="ModuleNotFoundError: No module named 'cachetools'">self = &lt;tests.test_short_selling_implementation.TestShortSellingImplementation testMethod=test_sell_short_side_should_be_distinguished&gt;

    def test_sell_short_side_should_be_distinguished(self):
        """Test that sell_short orders bypass position checks and validate short selling."""
&gt;       from ai_trading.execution.engine import ExecutionEngine

tests/test_short_selling_implementation.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_short_selling_implementation.TestShortSellingImplementation" name="test_sell_short_validation_exists" time="0.008"><failure message="ModuleNotFoundError: No module named 'cachetools'">self = &lt;tests.test_short_selling_implementation.TestShortSellingImplementation testMethod=test_sell_short_validation_exists&gt;

    def test_sell_short_validation_exists(self):
        """Test that _validate_short_selling method exists and works."""
&gt;       from ai_trading.execution.engine import ExecutionEngine

tests/test_short_selling_implementation.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_signal_handlers_logging" name="test_install_signal_handlers_logs_service_signal" time="0.003" /><testcase classname="tests.test_signals_multi_horizon" name="test_multi_horizon_indicators" time="0.019" /><testcase classname="tests.test_skip_logic" name="test_skip_logic" time="0.004"><failure message="AttributeError: None has no attribute 'submit'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f86768ba010&gt;
caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7f8677ec6150&gt;

    def test_skip_logic(monkeypatch, caplog):
        state = bot_engine.BotState()
        state.position_cache = {"MSFT": 10, "TSLA": -10}
        bot_engine.state = state
        caplog.set_level("INFO")
    
        orders = []
        monkeypatch.setattr(bot_engine, "submit_order", lambda ctx, symbol, qty, side: orders.append((symbol, qty, side)))
        monkeypatch.setattr(bot_engine, "is_market_open", lambda: True)
        monkeypatch.setattr(bot_engine, "fetch_minute_df_safe", lambda s: pd.DataFrame({"close": [1]}, index=[pd.Timestamp("2023-01-01")]))
        monkeypatch.setattr(bot_engine, "_safe_trade", lambda *a, **k: None)
&gt;       monkeypatch.setattr(bot_engine.prediction_executor, "submit", lambda fn, s: types.SimpleNamespace(result=lambda: fn(s)))
E       AttributeError: None has no attribute 'submit'

tests/test_skip_logic.py:18: AttributeError</failure></testcase><testcase classname="tests.test_slippage" name="test_slippage_limits" time="0.003"><failure message="FileNotFoundError: [Errno 2] No such file or directory: 'logs/slippage.csv'">def test_slippage_limits():
&gt;       df = pd.read_csv("logs/slippage.csv")

tests/test_slippage.py:5: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026: in read_csv
    return _read(filepath_or_buffer, kwds)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620: in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620: in __init__
    self._engine = self._make_engine(f, self.engine)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880: in _make_engine
    self.handles = get_handle(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path_or_buf = 'logs/slippage.csv', mode = 'r'

    @doc(compression_options=_shared_docs["compression_options"] % "path_or_buf")
    def get_handle(
        path_or_buf: FilePath | BaseBuffer,
        mode: str,
        *,
        encoding: str | None = None,
        compression: CompressionOptions | None = None,
        memory_map: bool = False,
        is_text: bool = True,
        errors: str | None = None,
        storage_options: StorageOptions | None = None,
    ) -&gt; IOHandles[str] | IOHandles[bytes]:
        """
        Get file handle for given path/buffer and mode.
    
        Parameters
        ----------
        path_or_buf : str or file handle
            File path or object.
        mode : str
            Mode to open path_or_buf with.
        encoding : str or None
            Encoding to use.
        {compression_options}
    
               May be a dict with key 'method' as compression mode
               and other keys as compression options if compression
               mode is 'zip'.
    
               Passing compression options as keys in dict is
               supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.
    
            .. versionchanged:: 1.4.0 Zstandard support.
    
        memory_map : bool, default False
            See parsers._parser_params for more information. Only used by read_csv.
        is_text : bool, default True
            Whether the type of the content passed to the file/buffer is string or
            bytes. This is not the same as `"b" not in mode`. If a string content is
            passed to a binary file/buffer, a wrapper is inserted.
        errors : str, default 'strict'
            Specifies how encoding and decoding errors are to be handled.
            See the errors argument for :func:`open` for a full list
            of options.
        storage_options: StorageOptions = None
            Passed to _get_filepath_or_buffer
    
        Returns the dataclass IOHandles
        """
        # Windows does not default to utf-8. Set to utf-8 for a consistent behavior
        encoding = encoding or "utf-8"
    
        errors = errors or "strict"
    
        # read_csv does not know whether the buffer is opened in binary/text mode
        if _is_binary_mode(path_or_buf, mode) and "b" not in mode:
            mode += "b"
    
        # validate encoding and errors
        codecs.lookup(encoding)
        if isinstance(errors, str):
            codecs.lookup_error(errors)
    
        # open URLs
        ioargs = _get_filepath_or_buffer(
            path_or_buf,
            encoding=encoding,
            compression=compression,
            mode=mode,
            storage_options=storage_options,
        )
    
        handle = ioargs.filepath_or_buffer
        handles: list[BaseBuffer]
    
        # memory mapping needs to be the first step
        # only used for read_csv
        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)
    
        is_path = isinstance(handle, str)
        compression_args = dict(ioargs.compression)
        compression = compression_args.pop("method")
    
        # Only for write methods
        if "r" not in mode and is_path:
            check_parent_directory(str(handle))
    
        if compression:
            if compression != "zstd":
                # compression libraries do not like an explicit text-mode
                ioargs.mode = ioargs.mode.replace("t", "")
            elif compression == "zstd" and "b" not in ioargs.mode:
                # python-zstandard defaults to text mode, but we always expect
                # compression libraries to use binary mode.
                ioargs.mode += "b"
    
            # GZ Compression
            if compression == "gzip":
                if isinstance(handle, str):
                    # error: Incompatible types in assignment (expression has type
                    # "GzipFile", variable has type "Union[str, BaseBuffer]")
                    handle = gzip.GzipFile(  # type: ignore[assignment]
                        filename=handle,
                        mode=ioargs.mode,
                        **compression_args,
                    )
                else:
                    handle = gzip.GzipFile(
                        # No overload variant of "GzipFile" matches argument types
                        # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                        fileobj=handle,  # type: ignore[call-overload]
                        mode=ioargs.mode,
                        **compression_args,
                    )
    
            # BZ Compression
            elif compression == "bz2":
                # Overload of "BZ2File" to handle pickle protocol 5
                # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                handle = get_bz2_file()(  # type: ignore[call-overload]
                    handle,
                    mode=ioargs.mode,
                    **compression_args,
                )
    
            # ZIP Compression
            elif compression == "zip":
                # error: Argument 1 to "_BytesZipFile" has incompatible type
                # "Union[str, BaseBuffer]"; expected "Union[Union[str, PathLike[str]],
                # ReadBuffer[bytes], WriteBuffer[bytes]]"
                handle = _BytesZipFile(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
                if handle.buffer.mode == "r":
                    handles.append(handle)
                    zip_names = handle.buffer.namelist()
                    if len(zip_names) == 1:
                        handle = handle.buffer.open(zip_names.pop())
                    elif not zip_names:
                        raise ValueError(f"Zero files found in ZIP file {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in ZIP file. "
                            f"Only one file per ZIP: {zip_names}"
                        )
    
            # TAR Encoding
            elif compression == "tar":
                compression_args.setdefault("mode", ioargs.mode)
                if isinstance(handle, str):
                    handle = _BytesTarFile(name=handle, **compression_args)
                else:
                    # error: Argument "fileobj" to "_BytesTarFile" has incompatible
                    # type "BaseBuffer"; expected "Union[ReadBuffer[bytes],
                    # WriteBuffer[bytes], None]"
                    handle = _BytesTarFile(
                        fileobj=handle, **compression_args  # type: ignore[arg-type]
                    )
                assert isinstance(handle, _BytesTarFile)
                if "r" in handle.buffer.mode:
                    handles.append(handle)
                    files = handle.buffer.getnames()
                    if len(files) == 1:
                        file = handle.buffer.extractfile(files[0])
                        assert file is not None
                        handle = file
                    elif not files:
                        raise ValueError(f"Zero files found in TAR archive {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in TAR archive. "
                            f"Only one file per TAR archive: {files}"
                        )
    
            # XZ Compression
            elif compression == "xz":
                # error: Argument 1 to "LZMAFile" has incompatible type "Union[str,
                # BaseBuffer]"; expected "Optional[Union[Union[str, bytes, PathLike[str],
                # PathLike[bytes]], IO[bytes]], None]"
                handle = get_lzma_file()(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
    
            # Zstd Compression
            elif compression == "zstd":
                zstd = import_optional_dependency("zstandard")
                if "r" in ioargs.mode:
                    open_args = {"dctx": zstd.ZstdDecompressor(**compression_args)}
                else:
                    open_args = {"cctx": zstd.ZstdCompressor(**compression_args)}
                handle = zstd.open(
                    handle,
                    mode=ioargs.mode,
                    **open_args,
                )
    
            # Unrecognized Compression
            else:
                msg = f"Unrecognized compression type: {compression}"
                raise ValueError(msg)
    
            assert not isinstance(handle, str)
            handles.append(handle)
    
        elif isinstance(handle, str):
            # Check whether the filename is to be opened in binary mode.
            # Binary mode does not support 'encoding' and 'newline'.
            if ioargs.encoding and "b" not in ioargs.mode:
                # Encoding
&gt;               handle = open(
                    handle,
                    ioargs.mode,
                    encoding=ioargs.encoding,
                    errors=errors,
                    newline="",
                )
E               FileNotFoundError: [Errno 2] No such file or directory: 'logs/slippage.csv'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/common.py:873: FileNotFoundError</failure></testcase><testcase classname="tests.test_stage1_1" name="test_meta_learning_import_without_sklearn" time="0.002" /><testcase classname="tests.test_stage1_1" name="test_fetch_sentiment_graceful_when_requests_unavailable" time="0.003"><failure message="AssertionError: assert 0 &gt;= 1&#10; +  where 0 = &lt;module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'&gt;._SENTIMENT_FAILURES">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f86768f5810&gt;

    def test_fetch_sentiment_graceful_when_requests_unavailable(monkeypatch):
        from ai_trading.core import bot_engine as be
    
        # Force a stub that raises RequestException on .get()
        class _ReqStub:
            class exceptions:
                class RequestException(Exception):
                    pass
    
            def get(self, *a, **k):
                raise self.exceptions.RequestException("no network")
    
        be.requests = _ReqStub()
        be.RequestException = _ReqStub.exceptions.RequestException
    
        # Ensure it won't bail early for missing key
        monkeypatch.setenv("SENTIMENT_API_KEY", "dummy")
        be.SENTIMENT_API_URL = "http://127.0.0.1:1"
        be._SENTIMENT_FAILURES = 0
        out = be.fetch_sentiment("AAPL")
        assert isinstance(out, float) and out == 0.0
&gt;       assert be._SENTIMENT_FAILURES &gt;= 1
E       AssertionError: assert 0 &gt;= 1
E        +  where 0 = &lt;module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'&gt;._SENTIMENT_FAILURES

tests/test_stage1_1.py:35: AssertionError</failure></testcase><testcase classname="tests.test_stage1_1" name="test_alpaca_stubs_are_not_exceptions" time="0.002" /><testcase classname="tests.test_staleness_guard.TestStalenessGuard" name="test_staleness_guard_fresh_data" time="0.004"><failure message="AssertionError: Should not raise exception for fresh data&#10;assert False">self = &lt;tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c52bd50&gt;

    def test_staleness_guard_fresh_data(self):
        """Test staleness guard with fresh data."""
        # Import the function we're testing
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Create a mock fetcher that returns fresh data
        now = datetime.datetime.now(datetime.UTC)
        fresh_timestamp = now - datetime.timedelta(seconds=30)  # 30 seconds old
    
        # Create test dataframe with fresh timestamp
        df = pd.DataFrame({
            'open': [100.0],
            'high': [101.0],
            'low': [99.0],
            'close': [100.5],
            'volume': [1000],
            'timestamp': [fresh_timestamp]
        })
    
        # Mock fetcher
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(return_value=df)
    
        # Should not raise any exception for fresh data
        try:
            _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
            success = True
        except (ValueError, TypeError):
            success = False
    
&gt;       assert success, "Should not raise exception for fresh data"
E       AssertionError: Should not raise exception for fresh data
E       assert False

tests/test_staleness_guard.py:44: AssertionError</failure></testcase><testcase classname="tests.test_staleness_guard.TestStalenessGuard" name="test_staleness_guard_stale_data" time="0.004"><failure message="TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'">self = &lt;tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c52a390&gt;

    def test_staleness_guard_stale_data(self):
        """Test staleness guard with stale data."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Create a mock fetcher that returns stale data
        now = datetime.datetime.now(datetime.UTC)
        stale_timestamp = now - datetime.timedelta(seconds=600)  # 10 minutes old
    
        # Create test dataframe with stale timestamp
        df = pd.DataFrame({
            'open': [100.0],
            'high': [101.0],
            'low': [99.0],
            'close': [100.5],
            'volume': [1000],
            'timestamp': [stale_timestamp]
        })
    
        # Mock fetcher
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(return_value=df)
    
        # Should raise RuntimeError for stale data
        with pytest.raises(RuntimeError, match="Stale data for symbols"):
&gt;           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:70: TypeError</failure></testcase><testcase classname="tests.test_staleness_guard.TestStalenessGuard" name="test_staleness_guard_no_data" time="0.003"><failure message="TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'">self = &lt;tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c529710&gt;

    def test_staleness_guard_no_data(self):
        """Test staleness guard with no data."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Mock fetcher that returns None/empty data
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(return_value=None)
    
        # Should raise RuntimeError for no data
        with pytest.raises(RuntimeError, match="Stale data for symbols"):
&gt;           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:82: TypeError</failure></testcase><testcase classname="tests.test_staleness_guard.TestStalenessGuard" name="test_staleness_guard_empty_dataframe" time="0.005"><failure message="TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'">self = &lt;tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c529990&gt;

    def test_staleness_guard_empty_dataframe(self):
        """Test staleness guard with empty dataframe."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Mock fetcher that returns empty dataframe
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(return_value=pd.DataFrame())
    
        # Should raise RuntimeError for empty data
        with pytest.raises(RuntimeError, match="Stale data for symbols"):
&gt;           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:94: TypeError</failure></testcase><testcase classname="tests.test_staleness_guard.TestStalenessGuard" name="test_staleness_guard_multiple_symbols" time="0.003"><failure message="TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'">self = &lt;tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c52aa90&gt;

    def test_staleness_guard_multiple_symbols(self):
        """Test staleness guard with multiple symbols."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        now = datetime.datetime.now(datetime.UTC)
    
        # Create mock fetcher that returns different data for different symbols
        def mock_get_minute_df(symbol, start, end):
            if symbol == "AAPL":
                # Fresh data for AAPL
                fresh_ts = now - datetime.timedelta(seconds=30)
                return pd.DataFrame({
                    'timestamp': [fresh_ts],
                    'close': [150.0]
                })
            elif symbol == "MSFT":
                # Stale data for MSFT
                stale_ts = now - datetime.timedelta(seconds=600)
                return pd.DataFrame({
                    'timestamp': [stale_ts],
                    'close': [300.0]
                })
            else:
                # No data for other symbols
                return None
    
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(side_effect=mock_get_minute_df)
    
        # Should raise RuntimeError mentioning the stale symbol
        with pytest.raises(RuntimeError) as exc_info:
&gt;           _ensure_data_fresh(mock_fetcher, ["AAPL", "MSFT", "GOOGL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:127: TypeError</failure></testcase><testcase classname="tests.test_staleness_guard.TestStalenessGuard" name="test_staleness_guard_utc_logging" time="0.004"><failure message="TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'">self = &lt;tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c52b050&gt;

    def test_staleness_guard_utc_logging(self):
        """Test that staleness guard logs UTC timestamps."""
        from unittest.mock import patch
    
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Mock logger to capture log messages
        with patch('ai_trading.core.bot_engine.logger') as mock_logger:
            now = datetime.datetime.now(datetime.UTC)
            fresh_timestamp = now - datetime.timedelta(seconds=30)
    
            df = pd.DataFrame({
                'timestamp': [fresh_timestamp],
                'close': [100.0]
            })
    
            mock_fetcher = Mock()
            mock_fetcher.get_minute_df = Mock(return_value=df)
    
            # Call the function
&gt;           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:153: TypeError</failure></testcase><testcase classname="tests.test_staleness_guard.TestStalenessGuard" name="test_staleness_guard_timezone_handling" time="0.015"><failure message="AssertionError: Should handle both timezone-aware and naive timestamps&#10;assert False">self = &lt;tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c52b190&gt;

    def test_staleness_guard_timezone_handling(self):
        """Test staleness guard handles timezone-aware and naive timestamps."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        now = datetime.datetime.now(datetime.UTC)
    
        # Test with timezone-naive timestamp (should be treated as UTC)
        naive_timestamp = datetime.datetime.now(datetime.UTC).replace(tzinfo=None) - datetime.timedelta(seconds=30)  # AI-AGENT-REF: Create naive datetime from UTC
        df_naive = pd.DataFrame({
            'timestamp': [naive_timestamp],
            'close': [100.0]
        })
    
        # Test with timezone-aware timestamp
        aware_timestamp = (now - datetime.timedelta(seconds=30)).replace(tzinfo=datetime.UTC)
        df_aware = pd.DataFrame({
            'timestamp': [aware_timestamp],
            'close': [100.0]
        })
    
        mock_fetcher = Mock()
    
        # Test both cases should work without error
        for df in [df_naive, df_aware]:
            mock_fetcher.get_minute_df = Mock(return_value=df)
            try:
                _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
                success = True
            except (ValueError, TypeError):
                success = False
&gt;           assert success, "Should handle both timezone-aware and naive timestamps"
E           AssertionError: Should handle both timezone-aware and naive timestamps
E           assert False

tests/test_staleness_guard.py:193: AssertionError</failure></testcase><testcase classname="tests.test_problem_statement_validation" name="test_utc_datetime_handling" time="0.006"><failure message="ModuleNotFoundError: No module named 'cachetools'">def test_utc_datetime_handling():
        """Test that datetime operations use timezone-aware UTC timestamps."""
        # Set test environment
        os.environ['PYTEST_RUNNING'] = '1'
        os.environ['TESTING'] = '1'
    
        # Test execution engine datetime handling
        from ai_trading.core.enums import OrderSide, OrderType
&gt;       from ai_trading.execution.engine import Order

tests/test_problem_statement_validation.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in &lt;module&gt;
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
&gt;   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_staleness_guard.TestStalenessGuard" name="test_staleness_guard_error_handling" time="0.002"><failure message="TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'">self = &lt;tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c433150&gt;

    def test_staleness_guard_error_handling(self):
        """Test staleness guard handles fetcher errors gracefully."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Mock fetcher that raises an exception
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(side_effect=Exception("Network error"))
    
        # Should raise RuntimeError with error details
        with pytest.raises(RuntimeError) as exc_info:
&gt;           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:205: TypeError</failure></testcase><testcase classname="tests.test_static_compile" name="test_package_compiles" time="0.196" /><testcase classname="tests.test_problem_statement_validation" name="test_async_modernization" time="0.014" /><testcase classname="tests.test_problem_statement_validation" name="test_start_script_portability" time="0.002" /><testcase classname="tests.test_problem_statement_validation" name="test_python_version_requirements" time="0.002"><failure message="AssertionError: Should use flexible Python 3.12 range&#10;assert 'requires-python = &quot;&gt;=3.12,&lt;3.13&quot;' in '[project]\nname = &quot;ai-trading-bot&quot;\nversion = &quot;0.0.0&quot;\ndescription = &quot;AI trading bot (lightweight testable build)&quot;\nr...\n&quot;tests/**&quot; = [&quot;T201&quot;]\n&quot;tools/**&quot; = [&quot;T201&quot;, &quot;E402&quot;]\n&quot;scripts/**&quot; = [&quot;T201&quot;, &quot;E402&quot;]\n&quot;**/__init__.py&quot; = [&quot;F401&quot;]\n'">def test_python_version_requirements():
        """Test that pyproject.toml has correct Python version requirements."""
        with open('pyproject.toml') as f:
            content = f.read()
    
        # Should use flexible version range
&gt;       assert 'requires-python = "&gt;=3.12,&lt;3.13"' in content, "Should use flexible Python 3.12 range"
E       AssertionError: Should use flexible Python 3.12 range
E       assert 'requires-python = "&gt;=3.12,&lt;3.13"' in '[project]\nname = "ai-trading-bot"\nversion = "0.0.0"\ndescription = "AI trading bot (lightweight testable build)"\nr...\n"tests/**" = ["T201"]\n"tools/**" = ["T201", "E402"]\n"scripts/**" = ["T201", "E402"]\n"**/__init__.py" = ["F401"]\n'

tests/test_problem_statement_validation.py:134: AssertionError</failure></testcase><testcase classname="tests.test_problem_statement_validation" name="test_env_example_exists" time="0.002" /><testcase classname="tests.test_problem_statement_validation" name="test_no_inappropriate_shebangs" time="0.010" /><testcase classname="tests.test_production_fixes.TestSentimentAPIConfiguration" name="test_sentiment_api_backwards_compatibility" time="0.005" /><testcase classname="tests.test_production_fixes.TestSentimentAPIConfiguration" name="test_sentiment_api_env_vars_in_config" time="0.003"><failure message="AssertionError: False is not true">self = &lt;tests.test_production_fixes.TestSentimentAPIConfiguration testMethod=test_sentiment_api_env_vars_in_config&gt;

    def test_sentiment_api_env_vars_in_config(self):
        """Test that sentiment API variables are properly configured."""
        from ai_trading import config
    
        # Test that the new environment variables are accessible
&gt;       self.assertTrue(hasattr(config, 'SENTIMENT_API_KEY') or 'SENTIMENT_API_KEY' in dir(config))
E       AssertionError: False is not true

tests/test_production_fixes.py:41: AssertionError</failure></testcase><testcase classname="tests.test_production_fixes.TestProcessDetection" name="test_alert_threshold_adjustment" time="0.002"><skipped type="pytest.skip" message="performance_monitor module not available">/workspace/ai-trading-bot/tests/test_production_fixes.py:103: performance_monitor module not available</skipped></testcase><testcase classname="tests.test_production_fixes.TestProcessDetection" name="test_process_filtering" time="0.002"><skipped type="pytest.skip" message="performance_monitor module not available">/workspace/ai-trading-bot/tests/test_production_fixes.py:84: performance_monitor module not available</skipped></testcase><testcase classname="tests.test_production_fixes.TestProcessDetection" name="test_trading_bot_process_detection" time="0.002"><skipped type="pytest.skip" message="performance_monitor module not available">/workspace/ai-trading-bot/tests/test_production_fixes.py:76: performance_monitor module not available</skipped></testcase><testcase classname="tests.test_production_fixes.TestDataStalenessThresholds" name="test_data_freshness_with_market_awareness" time="0.003"><skipped type="pytest.skip" message="Required modules not available for data validation tests">/workspace/ai-trading-bot/tests/test_production_fixes.py:172: Required modules not available for data validation tests</skipped></testcase><testcase classname="tests.test_production_fixes.TestDataStalenessThresholds" name="test_market_hours_detection" time="0.002"><skipped type="pytest.skip" message="Required modules not available for data validation tests">/workspace/ai-trading-bot/tests/test_production_fixes.py:141: Required modules not available for data validation tests</skipped></testcase><testcase classname="tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression" name="test_config_missing_min_confidence_attribute" time="0.002"><failure message="TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'">self = &lt;tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f8d85397710&gt;

    def test_config_missing_min_confidence_attribute(self):
        """
        Regression test for missing min_confidence attribute in config.
    
        Previously, if min_confidence was missing from config, it could cause
        AttributeError or incorrect behavior.
        """
        alloc = strategy_allocator.StrategyAllocator()
    
        # Remove min_confidence attribute to simulate missing config
        if hasattr(alloc.config, 'min_confidence'):
            delattr(alloc.config, 'min_confidence')
    
        alloc.config.delta_threshold = 0.0
        alloc.config.signal_confirmation_bars = 2
    
&gt;       sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:58: TypeError</failure></testcase><testcase classname="tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression" name="test_config_none_min_confidence" time="0.002"><failure message="TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'">self = &lt;tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f8d85395850&gt;

    def test_config_none_min_confidence(self):
        """
        Regression test for None min_confidence value.
    
        Previously, if min_confidence was set to None, it could cause
        comparison errors or unexpected behavior.
        """
        alloc = strategy_allocator.StrategyAllocator()
    
        alloc.config.min_confidence = None
        alloc.config.delta_threshold = 0.0
        alloc.config.signal_confirmation_bars = 2
    
&gt;       sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:81: TypeError</failure></testcase><testcase classname="tests.test_run_strategy_no_signals" name="test_run_strategy_no_signals" time="0.016"><failure message="AttributeError: module 'requests' has no attribute 'Response'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3bf8450&gt;

    def test_run_strategy_no_signals(monkeypatch):
        ctx = SimpleNamespace(
            strategies=[DummyStrategy()],
            allocator=FailAllocator(),
            api=SimpleNamespace(list_open_positions=lambda: []),
            data_fetcher=SimpleNamespace(
                get_daily_df=lambda ctx, sym: pd.DataFrame(),
                get_minute_df=lambda ctx, sym: pd.DataFrame(),
            ),
        )
    
        monkeypatch.setattr(bot_engine, "RL_AGENT", None)
&gt;       import ai_trading.signals as sig

tests/test_run_strategy_no_signals.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/signals.py:114: in &lt;module&gt;
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in &lt;module&gt;
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:35: in &lt;module&gt;
    _alpaca_rest = _optional_import("alpaca_trade_api.rest")
ai_trading/execution/engine.py:29: in _optional_import
    return importlib.import_module(name)
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/__init__.py:3: in &lt;module&gt;
    from .rest import REST, TimeFrame, TimeFrameUnit  # noqa
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import logging
    import os
    from typing import Iterator, List, Optional, Union
    import requests
    from requests.exceptions import HTTPError
    import time
    from enum import Enum
    from alpaca_trade_api import __version__
    from .common import (
        get_base_url,
        get_data_url,
        get_credentials,
        get_api_version, URL, FLOAT,
    )
    from .entity import (
        Bar, Entity, Account, AccountConfigurations, AccountActivity,
        Asset, Order, Position, Clock, Calendar,
        Trade, Quote, Watchlist, PortfolioHistory
    )
    from .entity_v2 import (
        BarV2, BarsV2, LatestBarsV2, LatestQuotesV2, LatestTradesV2,
        SnapshotV2, SnapshotsV2, TradesV2, TradeV2, QuotesV2, QuoteV2,
        NewsV2, NewsListV2, OrderbookV2, OrderbooksV2
    )
    
    logger = logging.getLogger(__name__)
    Positions = List[Position]
    Orders = List[Order]
    Assets = List[Asset]
    AccountActivities = List[AccountActivity]
    Calendars = List[Calendar]
    Watchlists = List[Watchlist]
    TradeIterator = Iterator[Union[Trade, dict]]
    QuoteIterator = Iterator[Union[Quote, dict]]
    BarIterator = Iterator[Union[Bar, dict]]
    NewsIterator = Iterator[Union[NewsV2, dict]]
    
    DATA_V2_MAX_LIMIT = 10000  # max items per api call
    NEWS_MAX_LIMIT = 50  # max items per api call
    
    
    class RetryException(Exception):
        pass
    
    
    class APIError(Exception):
        """
        Represent API related error.
        error.status_code will have http status code.
        """
    
        def __init__(self, error, http_error=None):
            super().__init__(error['message'])
            self._error = error
            self._http_error = http_error
    
        @property
        def code(self):
            return self._error.get('code', self.status_code)
    
        @property
        def status_code(self):
            http_error = self._http_error
            if http_error is not None and hasattr(http_error, 'response'):
                return http_error.response.status_code
    
        @property
        def request(self):
            if self._http_error is not None:
                return self._http_error.request
    
        @property
        def response(self):
            if self._http_error is not None:
                return self._http_error.response
    
&gt;   def raise_api_error(resp: requests.Response, http_error: requests.HTTPError):
E   AttributeError: module 'requests' has no attribute 'Response'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:77: AttributeError</failure></testcase><testcase classname="tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression" name="test_signal_confirmation_boundary_conditions" time="0.002"><failure message="TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'">self = &lt;tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f8d854e4750&gt;

    def test_signal_confirmation_boundary_conditions(self):
        """
        Test signal confirmation at various boundary conditions.
    
        Ensures that the confirmation logic works correctly at edge cases
        that could have caused the original failure.
        """
        test_cases = [
            # (min_confidence, signal_confidence, should_confirm)
            (0.0, 0.0, True),    # Zero threshold, zero confidence
            (0.0, 1.0, True),    # Zero threshold, high confidence
            (0.6, 0.6, True),    # Exact threshold match
            (0.8, 0.5, False),   # Below threshold
            (0.5, 0.8, True),    # Above threshold
        ]
    
        for min_conf, sig_conf, should_confirm in test_cases:
            alloc = strategy_allocator.StrategyAllocator()
            alloc.config.delta_threshold = 0.0
            alloc.config.signal_confirmation_bars = 2
            alloc.config.min_confidence = min_conf
    
&gt;           sig = TradeSignal(symbol="AAPL", side="buy", confidence=sig_conf, strategy="s1")
E           TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:113: TypeError</failure></testcase><testcase classname="tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression" name="test_invalid_signal_confidence_handling" time="0.002"><failure message="TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'">self = &lt;tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f8d854e7ad0&gt;

    def test_invalid_signal_confidence_handling(self):
        """
        Test handling of invalid signal confidence values.
    
        Ensures that out-of-range confidence values are properly normalized
        and don't cause the confirmation logic to fail.
        """
        alloc = strategy_allocator.StrategyAllocator()
        alloc.config.delta_threshold = 0.0
        alloc.config.signal_confirmation_bars = 2
        alloc.config.min_confidence = 0.0
    
        # Test high confidence (&gt; 1.0)
&gt;       sig_high = TradeSignal(symbol="AAPL", side="buy", confidence=2.0, strategy="s1")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:137: TypeError</failure></testcase><testcase classname="tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression" name="test_multiple_instances_no_shared_state" time="0.002"><failure message="TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'">self = &lt;tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f8d854e5350&gt;

    def test_multiple_instances_no_shared_state(self):
        """
        Test that multiple allocator instances don't share state.
    
        Ensures that the signal confirmation works consistently across
        different allocator instances.
        """
        for i in range(3):
            alloc = strategy_allocator.StrategyAllocator()
            alloc.config.delta_threshold = 0.0
            alloc.config.signal_confirmation_bars = 2
            alloc.config.min_confidence = 0.0
    
&gt;           sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
E           TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:174: TypeError</failure></testcase><testcase classname="tests.test_strategy_allocator_smoke" name="test_allocator" time="0.002"><failure message="TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'">@pytest.mark.smoke
    def test_allocator():
        alloc = strategy_allocator.StrategyAllocator()
    
        # Configuration that properly tests signal confirmation workflow
        alloc.config.delta_threshold = 0.0        # Allow repeated signals
        alloc.config.signal_confirmation_bars = 2  # Require 2 bars for proper confirmation testing
        alloc.config.min_confidence = 0.0         # Ensure confidence threshold is met
    
        # AI-AGENT-REF: Add defensive verification to ensure config is applied correctly
        assert alloc.config.signal_confirmation_bars == 2, f"Expected signal_confirmation_bars=2, got {alloc.config.signal_confirmation_bars}"
        assert alloc.config.min_confidence == 0.0, f"Expected min_confidence=0.0, got {alloc.config.min_confidence}"
        assert alloc.config.delta_threshold == 0.0, f"Expected delta_threshold=0.0, got {alloc.config.delta_threshold}"
    
&gt;       sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_smoke.py:29: TypeError</failure></testcase><testcase classname="tests.test_strategy_components" name="test_multi_timeframe_analyzer" time="0.036" /><testcase classname="tests.test_strategies_base_extra" name="test_asset_class_for_crypto" time="0.002" /><testcase classname="tests.test_strategy_components" name="test_regime_detector" time="0.063" /><testcase classname="tests.test_strategies_base_extra" name="test_strategy_generate_base" time="0.002"><failure message="TypeError: Can't instantiate abstract class BaseStrategy with abstract methods calculate_position_size, generate_signals">def test_strategy_generate_base():
        """Base Strategy.generate returns empty list."""
&gt;       assert Strategy().generate(None) == []
E       TypeError: Can't instantiate abstract class BaseStrategy with abstract methods calculate_position_size, generate_signals

tests/test_strategies_base_extra.py:12: TypeError</failure></testcase><testcase classname="tests.test_strategies_module" name="test_get_strategies_non_empty_for_empty_settings" time="0.003" /><testcase classname="tests.test_strategies_module" name="test_get_strategies_non_empty_for_unknown_settings" time="0.003" /><testcase classname="tests.test_strategies_module" name="test_get_strategies_non_empty_when_env_unset" time="0.003" /><testcase classname="tests.test_strategy_allocator_exit" name="test_exit_confirmation" time="0.002"><failure message="TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'">ensure_real_strategy_allocator = &lt;module 'ai_trading.strategy_allocator' from '/workspace/ai-trading-bot/ai_trading/strategy_allocator.py'&gt;

    def test_exit_confirmation(ensure_real_strategy_allocator):
        strategy_allocator = ensure_real_strategy_allocator
        alloc = strategy_allocator.StrategyAllocator()
        # Explicitly set configuration to ensure test isolation
        alloc.config.delta_threshold = 0.0  # Allow repeated signals with same confidence
        alloc.config.signal_confirmation_bars = 2  # Ensure we have expected confirmation bars
    
&gt;       buy = TradeSignal(symbol="A", side="buy", confidence=1.0, strategy="s")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_exit.py:45: TypeError</failure></testcase><testcase classname="tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression" name="test_signal_confirmation_with_zero_min_confidence" time="0.002"><failure message="TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'">self = &lt;tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f8677fdcb50&gt;

    def test_signal_confirmation_with_zero_min_confidence(self):
        """
        Regression test for the original failing scenario.
    
        The original issue was that with min_confidence=0.0, the second call
        to allocate() was returning an empty list instead of confirmed signals.
        """
        alloc = strategy_allocator.StrategyAllocator()
    
        # Set exact configuration from original failing test
        alloc.config.delta_threshold = 0.0
        alloc.config.signal_confirmation_bars = 2
        alloc.config.min_confidence = 0.0
    
&gt;       sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:30: TypeError</failure></testcase><testcase classname="tests.test_stream_subscription_fix.TestStreamSubscriptionFix" name="test_bot_engine_import_with_stream_fix" time="0.010" /><testcase classname="tests.test_stream_subscription_fix.TestStreamSubscriptionFix" name="test_stream_subscription_with_none_stream" time="0.005" /><testcase classname="tests.test_stream_subscription_fix.TestStreamSubscriptionFix" name="test_stream_subscription_with_valid_stream" time="0.004" /><testcase classname="tests.test_stubs_and_prices" name="test_timeframe_has_basic_members" time="0.002" /><testcase classname="tests.test_stubs_and_prices" name="test_get_latest_close_handles_empty_and_variants" time="0.007" /><testcase classname="tests.test_strategy_components" name="test_integrated_strategy_system" time="0.092" /><testcase classname="tests.test_submit_order_fix" name="test_submit_order_with_uninitialized_exec_engine" time="0.006" /><testcase classname="tests.test_submit_order_fix" name="test_submit_order_with_market_closed" time="0.004" /><testcase classname="tests.test_submit_order_fix" name="test_submit_order_successful_execution" time="0.004" /><testcase classname="tests.test_submit_order_fix" name="test_submit_order_execution_error_propagation" time="0.005" /><testcase classname="tests.test_talib_enforcement" name="test_talib_import_enforcement" time="0.003"><failure message="AssertionError: Could not find end of TA library section&#10;assert None is not None">def test_talib_import_enforcement():
        """Test that TA library import gracefully handles missing dependency."""
        # Read the imports file to test the TA library section
        imports_file = (
            Path(__file__).parent.parent / "ai_trading" / "strategies" / "imports.py"
        )
    
        with open(imports_file) as f:
            content = f.read()
    
        # Find the TA library section
        lines = content.split("\n")
        ta_start = None
        ta_end = None
    
        for i, line in enumerate(lines):
            if "# TA library for optimized technical analysis" in line:
                ta_start = i
            elif ta_start is not None and "ta = MockTa()" in line:
                ta_end = i + 1
                break
    
        assert ta_start is not None, "Could not find TA library section"
&gt;       assert ta_end is not None, "Could not find end of TA library section"
E       AssertionError: Could not find end of TA library section
E       assert None is not None

tests/test_talib_enforcement.py:34: AssertionError</failure></testcase><testcase classname="tests.test_talib_enforcement" name="test_audit_file_creation_and_permissions" time="0.003"><failure message="TypeError: log_trade() got an unexpected keyword argument 'exposure'">tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw2/test_audit_file_creation_and_p0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8676851d10&gt;

    def test_audit_file_creation_and_permissions(tmp_path, monkeypatch):
        """Test that audit.py creates trade log file with proper permissions."""
        import sys
    
        # Mock config to use temporary path
        trade_log_path = tmp_path / "data" / "trades.csv"
    
        # Create mock config module
        # Temporarily replace config module
        original_config = sys.modules.get("config")
        sys.modules["config"] = MockConfig()
    
        try:
            # Import audit after mocking config
            if "audit" in sys.modules:
                del sys.modules["audit"]
            from ai_trading import audit  # AI-AGENT-REF: canonical import
    
            # Ensure the file doesn't exist initially
            assert not trade_log_path.exists()
            assert not trade_log_path.parent.exists()
    
            # Call log_trade which should create the directory and file
&gt;           audit.log_trade(
                symbol="TEST",
                qty=10,
                side="buy",
                fill_price=100.0,
                timestamp="2024-01-01T10:00:00Z",
                extra_info="TEST_MODE",
                exposure=0.1,
            )
E           TypeError: log_trade() got an unexpected keyword argument 'exposure'

tests/test_talib_enforcement.py:80: TypeError</failure></testcase><testcase classname="tests.test_talib_enforcement" name="test_audit_file_multiple_trades" time="0.003"><failure message="FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pytest-of-root/pytest-0/popen-gw2/test_audit_file_multiple_trade0/trades.csv'">tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw2/test_audit_file_multiple_trade0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8675c5bf90&gt;

    def test_audit_file_multiple_trades(tmp_path, monkeypatch):
        """Test that multiple trades are appended correctly without duplicate headers."""
        import sys
    
        trade_log_path = tmp_path / "trades.csv"
    
        original_config = sys.modules.get("config")
        sys.modules["config"] = MockConfig()
    
        try:
            if "audit" in sys.modules:
                del sys.modules["audit"]
            from ai_trading import audit  # AI-AGENT-REF: canonical import
    
            # Log first trade
            audit.log_trade("AAPL", 5, "buy", 150.0, "2024-01-01T10:00:00Z", "TEST_MODE")
    
            # Log second trade
            audit.log_trade("MSFT", 3, "sell", 250.0, "2024-01-01T11:00:00Z", "TEST_MODE")
    
            # Verify both trades are in file
&gt;           with open(trade_log_path) as f:
E           FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pytest-of-root/pytest-0/popen-gw2/test_audit_file_multiple_trade0/trades.csv'

tests/test_talib_enforcement.py:152: FileNotFoundError</failure></testcase><testcase classname="tests.test_tenacity_import" name="test_real_tenacity_import" time="0.014" /><testcase classname="tests.test_tenacity_import" name="test_tenacity_functionality" time="0.003" /><testcase classname="tests.test_time_utc_now" name="test_now_is_aware_utc" time="0.002" /><testcase classname="tests.test_timeutils" name="test_nyse_session_dst" time="0.003"><failure message="AssertionError: assert (13 == 13 and datetime.timezone.utc == zoneinfo.ZoneInfo(key='UTC'))&#10; +  where 13 = datetime.datetime(2024, 7, 15, 13, 30, tzinfo=datetime.timezone.utc).hour&#10; +  and   datetime.timezone.utc = datetime.datetime(2024, 7, 15, 13, 30, tzinfo=datetime.timezone.utc).tzinfo&#10; +  and   zoneinfo.ZoneInfo(key='UTC') = ZoneInfo('UTC')">def test_nyse_session_dst():
        # July 15, 2024 (DST)
        s, e = nyse_session_utc(date(2024, 7, 15))
&gt;       assert s.hour == 13 and s.tzinfo == ZoneInfo("UTC")
E       AssertionError: assert (13 == 13 and datetime.timezone.utc == zoneinfo.ZoneInfo(key='UTC'))
E        +  where 13 = datetime.datetime(2024, 7, 15, 13, 30, tzinfo=datetime.timezone.utc).hour
E        +  and   datetime.timezone.utc = datetime.datetime(2024, 7, 15, 13, 30, tzinfo=datetime.timezone.utc).tzinfo
E        +  and   zoneinfo.ZoneInfo(key='UTC') = ZoneInfo('UTC')

tests/test_timeutils.py:10: AssertionError</failure></testcase><testcase classname="tests.test_timeutils" name="test_nyse_session_standard" time="0.002" /><testcase classname="tests.test_trade_logic" name="test_should_enter_trade_basic" time="0.002" /><testcase classname="tests.test_trade_logic" name="test_extract_price_generic" time="0.003" /><testcase classname="tests.test_trade_logic" name="test_compute_order_price_slippage" time="0.002" /><testcase classname="tests.test_trading_parameter_validation" name="test_validate_trading_parameters_no_name_error" time="0.003"><failure message="FileNotFoundError: [Errno 2] No such file or directory: '/workspace/ai-trading-bot/bot_engine.py'">def test_validate_trading_parameters_no_name_error():
        """Test that validate_trading_parameters function references only defined parameters.
    
        This test parses the bot_engine.py source code and validates that all parameters
        referenced in validate_trading_parameters() are defined before the function call.
        """
    
        # Read the bot_engine.py source code
        src_path = Path(__file__).resolve().parents[1] / 'bot_engine.py'
&gt;       source = src_path.read_text()

tests/test_trading_parameter_validation.py:15: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/pathlib.py:1058: in read_text
    with self.open(mode='r', encoding=encoding, errors=errors) as f:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = PosixPath('/workspace/ai-trading-bot/bot_engine.py'), mode = 'r', buffering = -1, encoding = 'locale', errors = None
newline = None

    def open(self, mode='r', buffering=-1, encoding=None,
             errors=None, newline=None):
        """
        Open the file pointed by this path and return a file object, as
        the built-in open() function does.
        """
        if "b" not in mode:
            encoding = io.text_encoding(encoding)
&gt;       return io.open(self, mode, buffering, encoding, errors, newline)
E       FileNotFoundError: [Errno 2] No such file or directory: '/workspace/ai-trading-bot/bot_engine.py'

/root/.pyenv/versions/3.11.12/lib/python3.11/pathlib.py:1044: FileNotFoundError</failure></testcase><testcase classname="tests.test_imports" name="test_compute_atr_import_path" time="0.003" /><testcase classname="tests.test_strategy_components" name="test_strategy_performance_scenarios" time="0.134" /><testcase classname="tests.test_imports_no_cycle" name="test_imports" time="0.006" /><testcase classname="tests.test_imports_smoke" name="test_submodules_import" time="0.022"><failure message="ModuleNotFoundError: No module named 'sklearn.model_selection'; 'sklearn' is not a package">def test_submodules_import() -&gt; None:
        pkg = importlib.import_module("ai_trading")
        for modinfo in pkgutil.walk_packages(pkg.__path__, pkg.__name__ + "."):
&gt;           _safe_import(modinfo.name)

tests/test_imports_smoke.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_imports_smoke.py:16: in _safe_import
    importlib.import_module(name)
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
&lt;frozen importlib._bootstrap&gt;:1204: in _gcd_import
    ???
&lt;frozen importlib._bootstrap&gt;:1176: in _find_and_load
    ???
&lt;frozen importlib._bootstrap&gt;:1147: in _find_and_load_unlocked
    ???
&lt;frozen importlib._bootstrap&gt;:690: in _load_unlocked
    ???
&lt;frozen importlib._bootstrap_external&gt;:940: in exec_module
    ???
&lt;frozen importlib._bootstrap&gt;:241: in _call_with_frames_removed
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Time series cross-validation splits with purging and embargo.
    
    Provides leak-proof data splitting for financial time series,
    including purged group time series splits and walk-forward analysis.
    """
    
    from collections.abc import Iterator
    from datetime import datetime, timedelta
    
    import numpy as np
    import pandas as pd
    
    # sklearn is a hard dependency
&gt;   from sklearn.model_selection import BaseCrossValidator
E   ModuleNotFoundError: No module named 'sklearn.model_selection'; 'sklearn' is not a package

ai_trading/data/splits.py:15: ModuleNotFoundError</failure></testcase><testcase classname="tests.test_trading_parameter_validation" name="test_buy_threshold_definition_order" time="0.003"><failure message="FileNotFoundError: [Errno 2] No such file or directory: '/workspace/ai-trading-bot/bot_engine.py'">def test_buy_threshold_definition_order():
        """Specific test to ensure BUY_THRESHOLD is defined before validate_trading_parameters call."""
    
        src_path = Path(__file__).resolve().parents[1] / 'bot_engine.py'
&gt;       source = src_path.read_text()

tests/test_trading_parameter_validation.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/pathlib.py:1058: in read_text
    with self.open(mode='r', encoding=encoding, errors=errors) as f:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = PosixPath('/workspace/ai-trading-bot/bot_engine.py'), mode = 'r', buffering = -1, encoding = 'locale', errors = None
newline = None

    def open(self, mode='r', buffering=-1, encoding=None,
             errors=None, newline=None):
        """
        Open the file pointed by this path and return a file object, as
        the built-in open() function does.
        """
        if "b" not in mode:
            encoding = io.text_encoding(encoding)
&gt;       return io.open(self, mode, buffering, encoding, errors, newline)
E       FileNotFoundError: [Errno 2] No such file or directory: '/workspace/ai-trading-bot/bot_engine.py'

/root/.pyenv/versions/3.11.12/lib/python3.11/pathlib.py:1044: FileNotFoundError</failure></testcase><testcase classname="tests.test_runner" name="test_handle_signal_sets_shutdown" time="0.003"><failure message="AttributeError: module 'ai_trading.runner' has no attribute '_handle_signal'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d37b6990&gt;

    def test_handle_signal_sets_shutdown(monkeypatch):
        mod = load_runner(monkeypatch)
        mod._shutdown = False
&gt;       mod._handle_signal(15, None)
E       AttributeError: module 'ai_trading.runner' has no attribute '_handle_signal'

tests/test_runner.py:14: AttributeError</failure></testcase><testcase classname="tests.test_runner" name="test_run_forever_exit" time="0.003"><failure message="AttributeError: module 'ai_trading.runner' has no attribute 'time'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d345b350&gt;

    def test_run_forever_exit(monkeypatch):
        mod = load_runner(monkeypatch)
        monkeypatch.setattr(mod, "main", lambda: (_ for _ in ()).throw(SystemExit(0)))
&gt;       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:21: AttributeError</failure></testcase><testcase classname="tests.test_runner" name="test_run_forever_exception" time="0.002"><failure message="AttributeError: module 'ai_trading.runner' has no attribute 'time'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d345a2d0&gt;

    def test_run_forever_exception(monkeypatch):
        mod = load_runner(monkeypatch)
        monkeypatch.setattr(mod, "main", lambda: (_ for _ in ()).throw(ValueError("bad")))
&gt;       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:29: AttributeError</failure></testcase><testcase classname="tests.test_runner" name="test_run_forever_request_exception" time="0.002"><failure message="AttributeError: module 'ai_trading.runner' has no attribute 'time'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d345a310&gt;

    def test_run_forever_request_exception(monkeypatch):
        mod = load_runner(monkeypatch)
        monkeypatch.setattr(mod, "main", lambda: (_ for _ in ()).throw(requests.exceptions.RequestException("boom")))
&gt;       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:38: AttributeError</failure></testcase><testcase classname="tests.test_runner" name="test_run_forever_system_exit_nonzero" time="0.003"><failure message="AttributeError: module 'ai_trading.runner' has no attribute 'time'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d36de690&gt;

    def test_run_forever_system_exit_nonzero(monkeypatch):
        mod = load_runner(monkeypatch)
        seq = [SystemExit(1), SystemExit(0)]
    
        def side():
            exc = seq.pop(0)
            raise exc
    
        monkeypatch.setattr(mod, "main", side)
&gt;       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:53: AttributeError</failure></testcase><testcase classname="tests.test_trigger_meta_learning_conversion" name="test_trigger_meta_learning_conversion_pure_meta_format" time="0.004"><failure message="NameError: name 'config' is not defined">def test_trigger_meta_learning_conversion_pure_meta_format():
        """Test trigger function with pure meta-learning format - should return True immediately."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            # Write meta-learning format data
            f.write("symbol,entry_time,entry_price,exit_time,exit_price,qty,side,strategy,classification,signal_tags,confidence,reward\n")
            f.write("TEST,2025-08-05T23:17:35Z,100.0,2025-08-05T23:18:35Z,105.0,10,buy,test_strategy,test,signal1+signal2,0.8,5.0\n")
            f.write("AAPL,2025-08-05T23:19:35Z,150.0,2025-08-05T23:20:35Z,155.0,5,buy,test_strategy,test,signal3,0.7,25.0\n")
            f.write("MSFT,2025-08-05T23:21:35Z,300.0,2025-08-05T23:22:35Z,295.0,2,sell,test_strategy,test,signal4,0.6,-10.0\n")
            test_file = f.name
    
        try:
            # Set the trade log file path
            MockConfig.TRADE_LOG_FILE = test_file
    
            # Test trade data
            test_trade = {
                'symbol': 'TEST',
                'qty': 10,
                'side': 'buy',
                'price': 100.0,
                'timestamp': '2025-08-05T23:17:35Z',
                'order_id': 'test-001',
                'status': 'filled'
            }
    
            # Verify quality report shows pure meta format
            quality_report = meta_learning.validate_trade_data_quality(test_file)
            assert quality_report['mixed_format_detected'] is False
            assert quality_report['audit_format_rows'] == 0
            assert quality_report['meta_format_rows'] &gt; 0
    
            # Test the trigger function - should return True immediately (no conversion needed)
&gt;           result = meta_learning.trigger_meta_learning_conversion(test_trade)

tests/test_trigger_meta_learning_conversion.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -&gt; bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
&gt;           if config is not None:
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError</failure></testcase><testcase classname="tests.test_trigger_meta_learning_conversion" name="test_trigger_meta_learning_conversion_mixed_format" time="0.003"><failure message="NameError: name 'config' is not defined">def test_trigger_meta_learning_conversion_mixed_format():
        """Test trigger function with mixed format - should attempt conversion."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            # Write mixed format data (meta headers with audit data)
            f.write("symbol,entry_time,entry_price,exit_time,exit_price,qty,side,strategy,classification,signal_tags,confidence,reward\n")
            f.write("123e4567-e89b-12d3-a456-426614174000,2025-08-05T23:17:35Z,TEST,buy,10,100.0,live,filled\n")
            f.write("234e5678-e89b-12d3-a456-426614174001,2025-08-05T23:18:35Z,TEST,sell,10,105.0,live,filled\n")
            test_file = f.name
    
        try:
            # Set the trade log file path
            MockConfig.TRADE_LOG_FILE = test_file
    
            # Test trade data
            test_trade = {
                'symbol': 'TEST',
                'qty': 10,
                'side': 'buy',
                'price': 100.0,
                'timestamp': '2025-08-05T23:17:35Z',
                'order_id': 'test-001',
                'status': 'filled'
            }
    
            # Verify quality report shows mixed format
            quality_report = meta_learning.validate_trade_data_quality(test_file)
            assert quality_report['mixed_format_detected'] is True
    
            # Test the trigger function - should attempt conversion and return True if successful
&gt;           result = meta_learning.trigger_meta_learning_conversion(test_trade)

tests/test_trigger_meta_learning_conversion.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -&gt; bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
&gt;           if config is not None:
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError</failure></testcase><testcase classname="tests.test_indicator_manager" name="test_indicator_manager_streaming_basic" time="0.006" /><testcase classname="tests.test_kelly_confidence_fix" name="test_kelly_confidence_normalization" time="0.002"><failure message="NameError: name 'MockBotContext' is not defined">def test_kelly_confidence_normalization():
        """Test that high confidence values are properly normalized to probabilities."""
        # Mock BotContext for testing
        # Import the actual function (if available)
        try:
            from ai_trading.core.bot_engine import fractional_kelly_size
    
&gt;           ctx = MockBotContext()
E           NameError: name 'MockBotContext' is not defined

tests/test_kelly_confidence_fix.py:24: NameError</failure></testcase><testcase classname="tests.test_kelly_confidence_fix" name="test_kelly_input_validation" time="0.002"><failure message="NameError: name 'MockBotContext' is not defined">def test_kelly_input_validation():
        """Test that Kelly calculation properly validates all inputs."""
        # Mock BotContext for testing
        try:
            from ai_trading.core.bot_engine import fractional_kelly_size
    
&gt;           ctx = MockBotContext()
E           NameError: name 'MockBotContext' is not defined

tests/test_kelly_confidence_fix.py:77: NameError</failure></testcase><testcase classname="tests.test_kelly_drawdown_taper" name="test_drawdown_adjusted_kelly_basic" time="0.004" /><testcase classname="tests.test_kelly_drawdown_taper" name="test_drawdown_adjusted_kelly_zero_drawdown" time="0.003" /><testcase classname="tests.test_logger" name="test_get_rotating_handler_fallback" time="0.006" /><testcase classname="tests.test_logger" name="test_setup_logging_idempotent" time="0.013"><failure message="AssertionError: No rotating handler paths created. Captured: []&#10;assert []">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c074c0d0&gt;
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw4/test_setup_logging_idempotent0')

    def test_setup_logging_idempotent(monkeypatch, tmp_path):
        mod = reload_module(logger)
        created = []
    
        def fake_get_rotating(path, **_):
            created.append(path)
            return logging.StreamHandler()
    
        monkeypatch.setattr(mod, "get_rotating_handler", fake_get_rotating)
        lg = mod.setup_logging(debug=True, log_file=str(tmp_path / "f.log"))
        assert lg.level in (logging.DEBUG, logging.INFO)
&gt;       assert created, f"No rotating handler paths created. Captured: {created}"
E       AssertionError: No rotating handler paths created. Captured: []
E       assert []

tests/test_logger.py:36: AssertionError</failure></testcase><testcase classname="tests.test_logger" name="test_get_logger" time="0.010"><failure message="AttributeError: 'SanitizingLoggerAdapter' object has no attribute 'handlers'">def test_get_logger():
        mod = reload_module(logger)
        root = mod.setup_logging(debug=True)
        lg = mod.get_logger("test")
        assert lg is mod._loggers["test"]
&gt;       assert len(lg.handlers) == len(root.handlers)
E       AttributeError: 'SanitizingLoggerAdapter' object has no attribute 'handlers'

tests/test_logger.py:48: AttributeError</failure></testcase><testcase classname="tests.test_trigger_meta_learning_conversion" name="test_trigger_meta_learning_conversion_missing_file" time="0.003"><failure message="NameError: name 'config' is not defined">def test_trigger_meta_learning_conversion_missing_file():
        """Test trigger function with missing file - should return False."""
        # Set a non-existent file path
        MockConfig.TRADE_LOG_FILE = '/tmp/non_existent_file.csv'
    
        test_trade = {
            'symbol': 'TEST',
            'qty': 10,
            'side': 'buy',
            'price': 100.0,
            'timestamp': '2025-08-05T23:17:35Z',
            'order_id': 'test-001',
            'status': 'filled'
        }
    
        # Test the trigger function - should return False for missing file
&gt;       result = meta_learning.trigger_meta_learning_conversion(test_trade)

tests/test_trigger_meta_learning_conversion.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -&gt; bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
&gt;           if config is not None:
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError</failure></testcase><testcase classname="tests.test_logger_file" name="test_setup_logging_with_file" time="0.003"><failure message="assert []">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c0c05450&gt;
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw4/test_setup_logging_with_file0')

    def test_setup_logging_with_file(monkeypatch, tmp_path):
        """File handler is added when log_file is provided."""
        logger._configured = False
        fake = logging.NullHandler()
    
        def fake_makedirs(path, exist_ok=False):
            pass
    
        calls = []
    
        def fake_get_handler(*args, **kwargs):
            calls.append((args, kwargs))
            return fake
    
        monkeypatch.setattr(logger.os, "makedirs", fake_makedirs)
        monkeypatch.setattr(logger, "get_rotating_handler", fake_get_handler)
    
        log_file = tmp_path / "x" / "app.log"
        logger.setup_logging(log_file=str(log_file))
&gt;       assert calls
E       assert []

tests/test_logger_file.py:25: AssertionError</failure></testcase><testcase classname="tests.test_systemd_startup.TestSystemdStartupCompatibility" name="test_import_no_crash_without_credentials" time="0.104"><failure message="subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp28f6ub4o.py']' returned non-zero exit status 1.">self = &lt;tests.test_systemd_startup.TestSystemdStartupCompatibility object at 0x7f8d8580b1d0&gt;

        def test_import_no_crash_without_credentials(self):
            """Test that imports don't crash without credentials."""
            # Create a test script that imports key modules
            test_script = '''
    import os
    import sys
    
    # Clear all credential environment variables
    for key in ["ALPACA_API_KEY", "APCA_API_KEY_ID", "ALPACA_SECRET_KEY", "APCA_API_SECRET_KEY"]:
        os.environ.pop(key, None)
    
    try:
        # Test importing key modules without credentials
        from ai_trading.config.management import _resolve_alpaca_env
        print("✓ Config management imported")
    
        from ai_trading import runner
        print("✓ Runner imported")
    
        from ai_trading.utils.timefmt import utc_now_iso
        print("✓ Time utilities imported")
    
        # Test that credential resolution works
        api_key, secret_key, base_url = _resolve_alpaca_env()
        assert api_key is None
        assert secret_key is None
        assert base_url == "https://paper-api.alpaca.markets"
        print("✓ Credential resolution works with missing creds")
    
        # Test UTC timestamp doesn't have double Z
        timestamp = utc_now_iso()
        assert timestamp.endswith('Z')
        assert timestamp.count('Z') == 1
        print("✓ UTC timestamp has single Z")
    
        print("SUCCESS: No import-time crashes!")
    
    except SystemExit as e:
        print(f"FAIL: SystemExit called: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"FAIL: Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    '''
    
            # Write test script to temporary file
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(test_script)
                script_path = f.name
    
            try:
                # Run the test script in a clean subprocess
&gt;               result = subprocess.run(
                    [sys.executable, script_path],
                    capture_output=True,
                    text=True,
                    timeout=30,
                    check=True
                )

tests/test_systemd_startup.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 30, check = True
popenargs = (['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp28f6ub4o.py'],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}
process = &lt;Popen: returncode: 1 args: ['/root/.pyenv/versions/3.11.12/bin/python3.11',...&gt;
stdout = "FAIL: Unexpected error: No module named 'ai_trading'\n"
stderr = 'Traceback (most recent call last):\n  File "/tmp/tmp28f6ub4o.py", line 11, in &lt;module&gt;\n    from ai_trading.config.management import _resolve_alpaca_env\nModuleNotFoundError: No module named \'ai_trading\'\n'
retcode = 1

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output &amp; stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired as exc:
                process.kill()
                if _mswindows:
                    # Windows accumulates the output in a single blocking
                    # read() call run on child threads, with the timeout
                    # being done in a join() on those threads.  communicate()
                    # _after_ kill() is required to collect that and add it
                    # to the exception.
                    exc.stdout, exc.stderr = process.communicate()
                else:
                    # POSIX _communicate already populated the output so
                    # far into the TimeoutExpired exception.
                    process.wait()
                raise
            except:  # Including KeyboardInterrupt, communicate handled that.
                process.kill()
                # We don't call process.wait() as .__exit__ does that for us.
                raise
            retcode = process.poll()
            if check and retcode:
&gt;               raise CalledProcessError(retcode, process.args,
                                         output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp28f6ub4o.py']' returned non-zero exit status 1.

/root/.pyenv/versions/3.11.12/lib/python3.11/subprocess.py:571: CalledProcessError</failure></testcase><testcase classname="tests.test_logger_module" name="test_get_logger_singleton" time="0.006"><failure message="AttributeError: 'SanitizingLoggerAdapter' object has no attribute 'propagate'">tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw4/test_get_logger_singleton0')

    def test_get_logger_singleton(tmp_path):
        lg1 = logger.get_logger("test")
        lg2 = logger.get_logger("test")
        assert lg1 is lg2
        # Updated test: With our new design, child loggers use propagation
        # instead of having their own handlers to prevent duplicates
&gt;       assert lg1.propagate  # Should propagate to root logger
E       AttributeError: 'SanitizingLoggerAdapter' object has no attribute 'propagate'

tests/test_logger_module.py:15: AttributeError</failure></testcase><testcase classname="tests.test_logging_normalize" name="test_canon_timeframe_basic" time="0.003" /><testcase classname="tests.test_logging_normalize" name="test_canon_timeframe_odd_values" time="0.003" /><testcase classname="tests.test_logging_normalize" name="test_canon_feed_basic" time="0.002" /><testcase classname="tests.test_logging_normalize" name="test_normalize_extra_applies_canonicalization" time="0.003" /><testcase classname="tests.test_logging_queue_listener" name="test_setup_logging_idempotent_no_runtime_error" time="0.003" /><testcase classname="tests.test_logging_queue_listener" name="test_logger_emits_after_setup" time="0.004" /><testcase classname="tests.test_trigger_meta_learning_conversion" name="test_trigger_meta_learning_conversion_problem_statement_exact" time="0.012"><failure message="NameError: name 'config' is not defined">def test_trigger_meta_learning_conversion_problem_statement_exact():
        """Test the exact scenario from the problem statement."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            # Create exactly the scenario: mixed_format_detected=False, audit_format_rows=0, meta_format_rows=4
            f.write("symbol,entry_time,entry_price,exit_time,exit_price,qty,side,strategy,classification,signal_tags,confidence,reward\n")
            f.write("TEST,2025-08-05T23:17:35Z,100.0,2025-08-05T23:18:35Z,105.0,10,buy,test_strategy,test,signal1+signal2,0.8,5.0\n")
            f.write("AAPL,2025-08-05T23:19:35Z,150.0,2025-08-05T23:20:35Z,155.0,5,buy,test_strategy,test,signal3,0.7,25.0\n")
            f.write("MSFT,2025-08-05T23:21:35Z,300.0,2025-08-05T23:22:35Z,295.0,2,sell,test_strategy,test,signal4,0.6,-10.0\n")
            f.write("GOOGL,2025-08-05T23:23:35Z,2500.0,2025-08-05T23:24:35Z,2505.0,1,buy,test_strategy,test,signal5,0.9,5.0\n")
            test_file = f.name
    
        try:
            MockConfig.TRADE_LOG_FILE = test_file
    
            test_trade = {
                'symbol': 'TEST',
                'qty': 10,
                'side': 'buy',
                'price': 100.0,
                'timestamp': '2025-08-05T23:17:35Z',
                'order_id': 'test-001',
                'status': 'filled'
            }
    
            # Verify we have the exact scenario from problem statement
            quality_report = meta_learning.validate_trade_data_quality(test_file)
            assert quality_report['mixed_format_detected'] is False
            assert quality_report['audit_format_rows'] == 0
            assert quality_report['meta_format_rows'] &gt; 0  # Should be 5 (4 data + 1 header)
    
            # This should return True immediately (no conversion needed)
&gt;           result = meta_learning.trigger_meta_learning_conversion(test_trade)

tests/test_trigger_meta_learning_conversion.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -&gt; bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
&gt;           if config is not None:
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError</failure></testcase><testcase classname="tests.test_logging_sanitizer" name="test_reserved_keys_are_prefixed" time="0.004" /><testcase classname="tests.test_logging_scrubbed" name="test_no_secrets_in_logs" time="0.004"><failure message="AssertionError: assert 'TOPSECRETKEY' not in 'boot with key=TOPSECRETKEY'&#10;  &#10;  'TOPSECRETKEY' is contained here:&#10;    boot with key=TOPSECRETKEY">caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7ff3baf7f510&gt;
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff3baf7dad0&gt;

    def test_no_secrets_in_logs(caplog, monkeypatch):
        caplog.set_level(logging.INFO)
        monkeypatch.setenv("NEWS_API_KEY", "TOPSECRETKEY")
        logger = get_logger(__name__)
        logger.info("boot with key=%s", os.getenv("NEWS_API_KEY"))
        joined = "\n".join(m.message for m in caplog.records)
&gt;       assert "TOPSECRETKEY" not in joined
E       AssertionError: assert 'TOPSECRETKEY' not in 'boot with key=TOPSECRETKEY'
E         
E         'TOPSECRETKEY' is contained here:
E           boot with key=TOPSECRETKEY

tests/test_logging_scrubbed.py:13: AssertionError</failure></testcase><testcase classname="tests.test_main_extended2" name="test_run_flask_app" time="0.005"><failure message="TypeError: test_run_flask_app.&lt;locals&gt;.App.run() got an unexpected keyword argument 'debug'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c08b5b90&gt;

    def test_run_flask_app(monkeypatch):
        """Flask app runs on provided port."""
        called = {}
    
        class App:
            def run(self, host, port):
                called["args"] = (host, port)
    
        monkeypatch.setattr(app, "create_app", lambda: App())
&gt;       main.run_flask_app(1234)

tests/test_main_extended2.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

port = 1234, ready_signal = None

    def run_flask_app(port: int = 5000, ready_signal: threading.Event = None) -&gt; None:
        """Launch Flask API on an available port."""
        # AI-AGENT-REF: simplified port fallback logic with get_free_port fallback
        max_attempts = 10
        original_port = port
    
        for _attempt in range(max_attempts):
            if not get_pid_on_port(port):
                break
            port += 1
        else:
            # If consecutive ports are all occupied, use get_free_port as fallback
            free_port = get_free_port()
            if free_port is None:
                raise RuntimeError(
                    f"Could not find available port starting from {original_port}"
                )
            port = free_port
    
        # Defer app import to avoid import-time side effects
        from ai_trading import app
    
        application = app.create_app()
    
        # AI-AGENT-REF: Signal ready immediately after Flask app creation for faster startup
        if ready_signal is not None:
            logger.info(f"Flask app created successfully, signaling ready on port {port}")
            ready_signal.set()
    
        logger.info(f"Starting Flask app on 0.0.0.0:{port}")
        # AI-AGENT-REF: disable debug mode in production server
&gt;       application.run(host="0.0.0.0", port=port, debug=False)
E       TypeError: test_run_flask_app.&lt;locals&gt;.App.run() got an unexpected keyword argument 'debug'

ai_trading/main.py:299: TypeError</failure></testcase><testcase classname="tests.test_main_extended2" name="test_run_flask_app_port_in_use" time="0.003"><failure message="AttributeError: module 'ai_trading.main' has no attribute 'utils'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c06e1650&gt;

    def test_run_flask_app_port_in_use(monkeypatch):
        """Port conflict triggers fallback port."""
        called = []
    
        class App:
            def run(self, host, port):
                called.append(port)
    
        monkeypatch.setattr(app, "create_app", lambda: App())
&gt;       monkeypatch.setattr(main.utils, "get_pid_on_port", lambda p: 111)
E       AttributeError: module 'ai_trading.main' has no attribute 'utils'

tests/test_main_extended2.py:44: AttributeError</failure></testcase><testcase classname="tests.test_main_extended2" name="test_run_bot_calls_cycle" time="0.004"><failure message="AttributeError: 'Settings' object has no attribute 'alpaca_secret_key_plain'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff3baf29650&gt;

    def test_run_bot_calls_cycle(monkeypatch):
        """run_bot executes a trading cycle in-process."""
        called = {}
    
        monkeypatch.setattr(
            main, "run_cycle", lambda: called.setdefault("ran", True)
        )
&gt;       assert main.run_bot() == 0

tests/test_main_extended2.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/main.py:245: in run_bot
    validate_environment()
ai_trading/main.py:201: in validate_environment
    if not cfg.alpaca_api_key or not cfg.alpaca_secret_key_plain:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
item = 'alpaca_secret_key_plain'

    def __getattr__(self, item: str) -&gt; Any:
        private_attributes = object.__getattribute__(self, '__private_attributes__')
        if item in private_attributes:
            attribute = private_attributes[item]
            if hasattr(attribute, '__get__'):
                return attribute.__get__(self, type(self))  # type: ignore
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                return self.__pydantic_private__[item]  # type: ignore
            except KeyError as exc:
                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
        else:
            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.
            # See `BaseModel.__repr_args__` for more details
            try:
                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')
            except AttributeError:
                pydantic_extra = None
    
            if pydantic_extra:
                try:
                    return pydantic_extra[item]
                except KeyError as exc:
                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
            else:
                if hasattr(self.__class__, item):
                    return super().__getattribute__(item)  # Raises AttributeError if appropriate
                else:
                    # this is the current error
&gt;                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E                   AttributeError: 'Settings' object has no attribute 'alpaca_secret_key_plain'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:991: AttributeError</failure></testcase><testcase classname="tests.test_universe_csv" name="test_env_overrides_packaged" time="0.007" /><testcase classname="tests.test_universe_csv" name="test_packaged_exists_without_env" time="0.005" /><testcase classname="tests.test_universe_csv" name="test_missing_returns_empty" time="0.003" /><testcase classname="tests.test_universe_fetch_pooling" name="test_universe_fetch_pooling" time="0.002"><failure message="AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute '_parse_bars'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d34432d0&gt;

    def test_universe_fetch_pooling(monkeypatch):
        calls = {}
    
        def fake_map_get(urls, timeout=None, headers=None):
            calls['count'] = calls.get('count', 0) + 1
            calls['len'] = len(urls)
            return [((u, 200, f"BODY{i}".encode()), None) for i, u in enumerate(urls)]
    
        monkeypatch.setattr(http, "map_get", fake_map_get)
&gt;       monkeypatch.setattr(data_fetcher, "_parse_bars", lambda s, c, b: b.decode())
E       AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute '_parse_bars'

tests/test_universe_fetch_pooling.py:14: AttributeError</failure></testcase><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_utc_now_iso_format" time="0.002" /><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_utc_now_iso_is_recent" time="0.004" /><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_format_datetime_utc_with_utc_datetime" time="0.003" /><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_format_datetime_utc_with_naive_datetime" time="0.002" /><testcase classname="tests.test_trigger_meta_learning_conversion" name="test_trigger_meta_learning_conversion_pure_audit_format" time="0.006"><failure message="NameError: name 'config' is not defined">def test_trigger_meta_learning_conversion_pure_audit_format():
        """Test trigger function with pure audit format - should attempt conversion."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            # Write audit format data
            f.write("order_id,timestamp,symbol,side,qty,price,mode,status\n")
            f.write("123e4567-e89b-12d3-a456-426614174000,2025-08-05T23:17:35Z,TEST,buy,10,100.0,live,filled\n")
            f.write("234e5678-e89b-12d3-a456-426614174001,2025-08-05T23:18:35Z,TEST,sell,10,105.0,live,filled\n")
            f.write("345e6789-e89b-12d3-a456-426614174002,2025-08-05T23:19:35Z,AAPL,buy,5,150.0,live,filled\n")
            test_file = f.name
    
        try:
            # Set the trade log file path
            MockConfig.TRADE_LOG_FILE = test_file
    
            # Test trade data
            test_trade = {
                'symbol': 'TEST',
                'qty': 10,
                'side': 'buy',
                'price': 100.0,
                'timestamp': '2025-08-05T23:17:35Z',
                'order_id': 'test-001',
                'status': 'filled'
            }
    
            # Verify quality report shows pure audit format
            quality_report = meta_learning.validate_trade_data_quality(test_file)
            assert quality_report['mixed_format_detected'] is False
            assert quality_report['audit_format_rows'] &gt; 0
            assert quality_report['meta_format_rows'] == 0
    
            # Test the trigger function - should attempt conversion and return True if successful
&gt;           result = meta_learning.trigger_meta_learning_conversion(test_trade)

tests/test_trigger_meta_learning_conversion.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -&gt; bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
&gt;           if config is not None:
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError</failure></testcase><testcase classname="tests.test_main_extended2" name="test_validate_environment_missing" time="0.002"><failure message="ValueError: &quot;Settings&quot; object has no field &quot;WEBHOOK_SECRET&quot;">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c0916c10&gt;

    def test_validate_environment_missing(monkeypatch):
        """validate_environment errors when secret missing."""
&gt;       monkeypatch.setattr(main.config, 'WEBHOOK_SECRET', '', raising=False)

tests/test_main_extended2.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:997: in __setattr__
    elif (setattr_handler := self._setattr_handler(name, value)) is not None:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
name = 'WEBHOOK_SECRET', value = ''

    def _setattr_handler(self, name: str, value: Any) -&gt; Callable[[BaseModel, str, Any], None] | None:
        """Get a handler for setting an attribute on the model instance.
    
        Returns:
            A handler for setting an attribute on the model instance. Used for memoization of the handler.
            Memoizing the handlers leads to a dramatic performance improvement in `__setattr__`
            Returns `None` when memoization is not safe, then the attribute is set directly.
        """
        cls = self.__class__
        if name in cls.__class_vars__:
            raise AttributeError(
                f'{name!r} is a ClassVar of `{cls.__name__}` and cannot be set on an instance. '
                f'If you want to set a value on the class, use `{cls.__name__}.{name} = value`.'
            )
        elif not _fields.is_valid_field_name(name):
            if (attribute := cls.__private_attributes__.get(name)) is not None:
                if hasattr(attribute, '__set__'):
                    return lambda model, _name, val: attribute.__set__(model, val)
                else:
                    return _SIMPLE_SETATTR_HANDLERS['private']
            else:
                _object_setattr(self, name, value)
                return None  # Can not return memoized handler with possibly freeform attr names
    
        attr = getattr(cls, name, None)
        # NOTE: We currently special case properties and `cached_property`, but we might need
        # to generalize this to all data/non-data descriptors at some point. For non-data descriptors
        # (such as `cached_property`), it isn't obvious though. `cached_property` caches the value
        # to the instance's `__dict__`, but other non-data descriptors might do things differently.
        if isinstance(attr, cached_property):
            return _SIMPLE_SETATTR_HANDLERS['cached_property']
    
        _check_frozen(cls, name, value)
    
        # We allow properties to be set only on non frozen models for now (to match dataclasses).
        # This can be changed if it ever gets requested.
        if isinstance(attr, property):
            return lambda model, _name, val: attr.__set__(model, val)
        elif cls.model_config.get('validate_assignment'):
            return _SIMPLE_SETATTR_HANDLERS['validate_assignment']
        elif name not in cls.__pydantic_fields__:
            if cls.model_config.get('extra') != 'allow':
                # TODO - matching error
&gt;               raise ValueError(f'"{cls.__name__}" object has no field "{name}"')
E               ValueError: "Settings" object has no field "WEBHOOK_SECRET"

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1044: ValueError</failure></testcase><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_format_datetime_utc_with_non_utc_datetime" time="0.002" /><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_parse_iso_utc_with_offset" time="0.002" /><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_parse_iso_utc_with_invalid_format" time="0.002" /><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_ensure_utc_format_fixes_double_z" time="0.002" /><testcase classname="tests.test_systemd_startup.TestSystemdStartupCompatibility" name="test_dual_credential_schema_with_env_file" time="0.156"><failure message="subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp5_crc_4s.py']' returned non-zero exit status 1.">self = &lt;tests.test_systemd_startup.TestSystemdStartupCompatibility object at 0x7f8d8580b450&gt;

        def test_dual_credential_schema_with_env_file(self):
            """Test that both credential schemas work with .env files."""
            # Test ALPACA_* schema
            alpaca_env_content = """
    ALPACA_API_KEY=test_alpaca_key_from_env
    ALPACA_SECRET_KEY=test_alpaca_secret_from_env
    ALPACA_BASE_URL=https://paper-api.alpaca.markets
    """
    
            with tempfile.NamedTemporaryFile(mode='w', suffix='.env', delete=False) as f:
                f.write(alpaca_env_content)
                alpaca_env_path = f.name
    
            # Test APCA_* schema
            apca_env_content = """
    APCA_API_KEY_ID=test_apca_key_from_env
    APCA_API_SECRET_KEY=test_apca_secret_from_env
    APCA_API_BASE_URL=https://api.alpaca.markets
    """
    
            with tempfile.NamedTemporaryFile(mode='w', suffix='.env', delete=False) as f:
                f.write(apca_env_content)
                apca_env_path = f.name
    
            try:
                # Test ALPACA schema
                test_script = f'''
    import os
    from dotenv import load_dotenv
    load_dotenv("{alpaca_env_path}", override=True)
    
    from ai_trading.config.management import _resolve_alpaca_env
    api_key, secret_key, base_url = _resolve_alpaca_env()
    
    assert api_key == "test_alpaca_key_from_env"
    assert secret_key == "test_alpaca_secret_from_env"
    assert base_url == "https://paper-api.alpaca.markets"
    print("✓ ALPACA schema with .env file works")
    '''
    
                with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                    f.write(test_script)
                    script_path = f.name
    
&gt;               result = subprocess.run([sys.executable, script_path], capture_output=True, text=True, timeout=30, check=True)  # AI-AGENT-REF: Added timeout and check for security

tests/test_systemd_startup.py:135: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 30, check = True
popenargs = (['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp5_crc_4s.py'],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}
process = &lt;Popen: returncode: 1 args: ['/root/.pyenv/versions/3.11.12/bin/python3.11',...&gt;, stdout = ''
stderr = 'Traceback (most recent call last):\n  File "/tmp/tmp5_crc_4s.py", line 6, in &lt;module&gt;\n    from ai_trading.config.management import _resolve_alpaca_env\nModuleNotFoundError: No module named \'ai_trading\'\n'
retcode = 1

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output &amp; stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired as exc:
                process.kill()
                if _mswindows:
                    # Windows accumulates the output in a single blocking
                    # read() call run on child threads, with the timeout
                    # being done in a join() on those threads.  communicate()
                    # _after_ kill() is required to collect that and add it
                    # to the exception.
                    exc.stdout, exc.stderr = process.communicate()
                else:
                    # POSIX _communicate already populated the output so
                    # far into the TimeoutExpired exception.
                    process.wait()
                raise
            except:  # Including KeyboardInterrupt, communicate handled that.
                process.kill()
                # We don't call process.wait() as .__exit__ does that for us.
                raise
            retcode = process.poll()
            if check and retcode:
&gt;               raise CalledProcessError(retcode, process.args,
                                         output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp5_crc_4s.py']' returned non-zero exit status 1.

/root/.pyenv/versions/3.11.12/lib/python3.11/subprocess.py:571: CalledProcessError</failure></testcase><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_ensure_utc_format_fixes_offset" time="0.002" /><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_ensure_utc_format_with_multiple_z" time="0.002" /><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_ensure_utc_format_with_empty_string" time="0.002" /><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_roundtrip_formatting" time="0.002" /><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_no_double_z_in_any_function" time="0.002" /><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_microseconds_handling" time="0.002" /><testcase classname="tests.test_utils_sleep_shadowing" name="test_sleep_uses_stdlib" time="0.002" /><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_format_datetime_utc_with_none" time="0.003" /><testcase classname="tests.test_validate_logging_setup_single_handler" name="test_validate_logging_setup_single_handler" time="0.002" /><testcase classname="tests.test_workers" name="test_get_executor_singleton" time="0.002" /><testcase classname="tests.test_utc_timefmt.TestUTCTimestampFormatting" name="test_parse_iso_utc_with_z_suffix" time="0.003" /><testcase classname="tests.test_yf_auto_adjust_and_cache" name="test_yfinance_auto_adjust_and_cache" time="0.002"><failure message="ImportError: cannot import name '_yahoo_get_bars' from 'ai_trading.data_fetcher' (unknown location)">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d2162fd0&gt;

    def test_yfinance_auto_adjust_and_cache(monkeypatch):
        calls = {"auto_adjust": None, "cache_called": False}
    
        fake = types.SimpleNamespace()
    
        def set_tz_cache_location(path):  # AI-AGENT-REF: track tz cache invocation
            calls["cache_called"] = True
    
        def download(*args, auto_adjust=None, **kwargs):  # AI-AGENT-REF: capture auto_adjust
            calls["auto_adjust"] = auto_adjust
            import pandas as pd
    
            return pd.DataFrame(
                {"Open": [1.0], "High": [1.0], "Low": [1.0], "Close": [1.0], "Volume": [100]},
                index=pd.date_range(datetime(2025, 8, 1, tzinfo=UTC), periods=1, name="Date"),
            )
    
        fake.set_tz_cache_location = set_tz_cache_location
        fake.download = download
        monkeypatch.setitem(sys.modules, "yfinance", fake)
    
&gt;       from ai_trading.data_fetcher import _yahoo_get_bars
E       ImportError: cannot import name '_yahoo_get_bars' from 'ai_trading.data_fetcher' (unknown location)

tests/test_yf_auto_adjust_and_cache.py:29: ImportError</failure></testcase><testcase classname="tests.test_workers" name="test_submit_and_map_background" time="0.009" /><testcase classname="tests.tools.test_audit_exceptions_output" name="test_audit_exceptions_first_line_is_json" time="1.966" /><testcase classname="tests.tools.test_audit_exceptions" name="test_auditor_runs" time="1.980" /><testcase classname="tests.test_main_extended2" name="test_validate_environment_missing" time="0.001"><error message="failed on teardown with &quot;AttributeError: 'Settings' object has no attribute 'WEBHOOK_SECRET'&quot;">self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
item = 'WEBHOOK_SECRET'

    def __delattr__(self, item: str) -&gt; Any:
        cls = self.__class__
    
        if item in self.__private_attributes__:
            attribute = self.__private_attributes__[item]
            if hasattr(attribute, '__delete__'):
                attribute.__delete__(self)  # type: ignore
                return
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                del self.__pydantic_private__[item]  # type: ignore
                return
            except KeyError as exc:
                raise AttributeError(f'{cls.__name__!r} object has no attribute {item!r}') from exc
    
        # Allow cached properties to be deleted (even if the class is frozen):
        attr = getattr(cls, item, None)
        if isinstance(attr, cached_property):
            return object.__delattr__(self, item)
    
        _check_frozen(cls, name=item, value=None)
    
        if item in self.__pydantic_fields__:
            object.__delattr__(self, item)
        elif self.__pydantic_extra__ is not None and item in self.__pydantic_extra__:
            del self.__pydantic_extra__[item]
        else:
            try:
&gt;               object.__delattr__(self, item)
E               AttributeError: 'Settings' object has no attribute 'WEBHOOK_SECRET'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1084: AttributeError

During handling of the above exception, another exception occurred:

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
item = 'WEBHOOK_SECRET'

    def __delattr__(self, item: str) -&gt; Any:
        cls = self.__class__
    
        if item in self.__private_attributes__:
            attribute = self.__private_attributes__[item]
            if hasattr(attribute, '__delete__'):
                attribute.__delete__(self)  # type: ignore
                return
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                del self.__pydantic_private__[item]  # type: ignore
                return
            except KeyError as exc:
                raise AttributeError(f'{cls.__name__!r} object has no attribute {item!r}') from exc
    
        # Allow cached properties to be deleted (even if the class is frozen):
        attr = getattr(cls, item, None)
        if isinstance(attr, cached_property):
            return object.__delattr__(self, item)
    
        _check_frozen(cls, name=item, value=None)
    
        if item in self.__pydantic_fields__:
            object.__delattr__(self, item)
        elif self.__pydantic_extra__ is not None and item in self.__pydantic_extra__:
            del self.__pydantic_extra__[item]
        else:
            try:
                object.__delattr__(self, item)
            except AttributeError:
&gt;               raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E               AttributeError: 'Settings' object has no attribute 'WEBHOOK_SECRET'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1086: AttributeError</error></testcase><testcase classname="tests.test_main_extended2" name="test_main_runs_once" time="0.005"><failure message="ValueError: &quot;Settings&quot; object has no field &quot;max_position_size&quot;">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff3bae7e5d0&gt;

    def test_main_runs_once(monkeypatch):
        """main executes a single cycle when configured."""
        monkeypatch.setenv("SCHEDULER_ITERATIONS", "1")
        called = {}
    
        # AI-AGENT-REF: Fix lambda signature to accept ready_signal parameter and set it
        def mock_start_api(ready_signal=None):
            called.setdefault("api", True)
            if ready_signal:
                ready_signal.set()  # Important: signal that API is ready
        monkeypatch.setattr(main, "start_api", mock_start_api)
        def _cycle():
            called["cycle"] = called.get("cycle", 0) + 1
        monkeypatch.setattr(main, "run_cycle", _cycle)
        monkeypatch.setattr(main.time, "sleep", lambda s: None)
&gt;       main.main()

tests/test_main_extended2.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/main.py:341: in main
    _validate_runtime_config(config, S)
ai_trading/main.py:166: in _validate_runtime_config
    setattr(tcfg, "max_position_size", float(fallback))
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:997: in __setattr__
    elif (setattr_handler := self._setattr_handler(name, value)) is not None:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
name = 'max_position_size', value = 8000.0

    def _setattr_handler(self, name: str, value: Any) -&gt; Callable[[BaseModel, str, Any], None] | None:
        """Get a handler for setting an attribute on the model instance.
    
        Returns:
            A handler for setting an attribute on the model instance. Used for memoization of the handler.
            Memoizing the handlers leads to a dramatic performance improvement in `__setattr__`
            Returns `None` when memoization is not safe, then the attribute is set directly.
        """
        cls = self.__class__
        if name in cls.__class_vars__:
            raise AttributeError(
                f'{name!r} is a ClassVar of `{cls.__name__}` and cannot be set on an instance. '
                f'If you want to set a value on the class, use `{cls.__name__}.{name} = value`.'
            )
        elif not _fields.is_valid_field_name(name):
            if (attribute := cls.__private_attributes__.get(name)) is not None:
                if hasattr(attribute, '__set__'):
                    return lambda model, _name, val: attribute.__set__(model, val)
                else:
                    return _SIMPLE_SETATTR_HANDLERS['private']
            else:
                _object_setattr(self, name, value)
                return None  # Can not return memoized handler with possibly freeform attr names
    
        attr = getattr(cls, name, None)
        # NOTE: We currently special case properties and `cached_property`, but we might need
        # to generalize this to all data/non-data descriptors at some point. For non-data descriptors
        # (such as `cached_property`), it isn't obvious though. `cached_property` caches the value
        # to the instance's `__dict__`, but other non-data descriptors might do things differently.
        if isinstance(attr, cached_property):
            return _SIMPLE_SETATTR_HANDLERS['cached_property']
    
        _check_frozen(cls, name, value)
    
        # We allow properties to be set only on non frozen models for now (to match dataclasses).
        # This can be changed if it ever gets requested.
        if isinstance(attr, property):
            return lambda model, _name, val: attr.__set__(model, val)
        elif cls.model_config.get('validate_assignment'):
            return _SIMPLE_SETATTR_HANDLERS['validate_assignment']
        elif name not in cls.__pydantic_fields__:
            if cls.model_config.get('extra') != 'allow':
                # TODO - matching error
&gt;               raise ValueError(f'"{cls.__name__}" object has no field "{name}"')
E               ValueError: "Settings" object has no field "max_position_size"

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1044: ValueError</failure></testcase><testcase classname="tests.unit.test_health_check" name="test_min_rows_precedence_logic" time="0.002" /><testcase classname="tests.unit.test_http_retry_narrowing" name="test_map_get_aggregates_decode_error" time="0.004" /><testcase classname="tests.unit.test_logging_dedupe" name="test_phase_logger_no_propagation" time="0.003" /><testcase classname="tests.unit.test_retry" name="test_retry_eventually_succeeds" time="0.713"><failure message="assert 3 == 2&#10; +  where 3 = &lt;tests.unit.test_retry._Flaky object at 0x7ff3c0790790&gt;.calls">@pytest.mark.unit
    def test_retry_eventually_succeeds() -&gt; None:
        flaky = _Flaky()
        result = retry_call(flaky, exceptions=(RuntimeError,), retries=2)
        assert result == "ok"
&gt;       assert flaky.calls == 2
E       assert 3 == 2
E        +  where 3 = &lt;tests.unit.test_retry._Flaky object at 0x7ff3c0790790&gt;.calls

tests/unit/test_retry.py:36: AssertionError</failure></testcase><testcase classname="tests.test_systemd_startup.TestSystemdStartupCompatibility" name="test_utc_timestamp_no_double_z" time="0.054"><failure message="subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp0lzdplu4.py']' returned non-zero exit status 1.">self = &lt;tests.test_systemd_startup.TestSystemdStartupCompatibility object at 0x7f8d8580ae10&gt;

        def test_utc_timestamp_no_double_z(self):
            """Test that UTC timestamps don't have double Z suffix."""
            test_script = '''
    from ai_trading.utils.timefmt import utc_now_iso, format_datetime_utc, ensure_utc_format
    from datetime import datetime, timezone
    
    # Test utc_now_iso
    timestamp = utc_now_iso()
    assert timestamp.endswith('Z')
    assert timestamp.count('Z') == 1
    print(f"✓ utc_now_iso: {timestamp}")
    
    # Test format_datetime_utc
    dt = datetime(2024, 1, 1, 12, 0, 0, tzinfo=timezone.utc)
    formatted = format_datetime_utc(dt)
    assert formatted == "2024-01-01T12:00:00Z"
    assert formatted.count('Z') == 1
    print(f"✓ format_datetime_utc: {formatted}")
    
    # Test ensure_utc_format fixes double Z
    fixed = ensure_utc_format("2024-01-01T12:00:00ZZ")
    assert fixed == "2024-01-01T12:00:00Z"
    assert fixed.count('Z') == 1
    print(f"✓ ensure_utc_format: {fixed}")
    
    print("✓ All UTC timestamp functions work correctly")
    '''
    
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(test_script)
                script_path = f.name
    
            try:
&gt;               result = subprocess.run([sys.executable, script_path], capture_output=True, text=True, timeout=30, check=True)  # AI-AGENT-REF: Added timeout and check for security

tests/test_systemd_startup.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 30, check = True
popenargs = (['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp0lzdplu4.py'],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}
process = &lt;Popen: returncode: 1 args: ['/root/.pyenv/versions/3.11.12/bin/python3.11',...&gt;, stdout = ''
stderr = 'Traceback (most recent call last):\n  File "/tmp/tmp0lzdplu4.py", line 2, in &lt;module&gt;\n    from ai_trading.utils.timefmt import utc_now_iso, format_datetime_utc, ensure_utc_format\nModuleNotFoundError: No module named \'ai_trading\'\n'
retcode = 1

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output &amp; stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired as exc:
                process.kill()
                if _mswindows:
                    # Windows accumulates the output in a single blocking
                    # read() call run on child threads, with the timeout
                    # being done in a join() on those threads.  communicate()
                    # _after_ kill() is required to collect that and add it
                    # to the exception.
                    exc.stdout, exc.stderr = process.communicate()
                else:
                    # POSIX _communicate already populated the output so
                    # far into the TimeoutExpired exception.
                    process.wait()
                raise
            except:  # Including KeyboardInterrupt, communicate handled that.
                process.kill()
                # We don't call process.wait() as .__exit__ does that for us.
                raise
            retcode = process.poll()
            if check and retcode:
&gt;               raise CalledProcessError(retcode, process.args,
                                         output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp0lzdplu4.py']' returned non-zero exit status 1.

/root/.pyenv/versions/3.11.12/lib/python3.11/subprocess.py:571: CalledProcessError</failure></testcase><testcase classname="tests.test_systemd_startup.TestSystemdStartupCompatibility" name="test_lazy_import_behavior" time="0.047"><failure message="subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmpj6_2y3b9.py']' returned non-zero exit status 1.">self = &lt;tests.test_systemd_startup.TestSystemdStartupCompatibility object at 0x7f8d858082d0&gt;

        def test_lazy_import_behavior(self):
            """Test that lazy imports work correctly."""
            test_script = '''
    import os
    
    # Clear credentials
    for key in ["ALPACA_API_KEY", "APCA_API_KEY_ID", "ALPACA_SECRET_KEY", "APCA_API_SECRET_KEY"]:
        os.environ.pop(key, None)
    
    # Import runner (should work without credentials)
    from ai_trading import runner
    
    # Verify lazy loading variables exist
    assert hasattr(runner, '_load_engine')
    assert hasattr(runner, '_bot_engine')
    assert hasattr(runner, '_bot_state_class')
    
    # Verify initial state is None (not loaded)
    assert runner._bot_engine is None
    assert runner._bot_state_class is None
    
    print("✓ Lazy import mechanism working correctly")
    '''
    
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(test_script)
                script_path = f.name
    
            try:
&gt;               result = subprocess.run([sys.executable, script_path], capture_output=True, text=True, timeout=30, check=True)  # AI-AGENT-REF: Added timeout and check for security

tests/test_systemd_startup.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 30, check = True
popenargs = (['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmpj6_2y3b9.py'],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}
process = &lt;Popen: returncode: 1 args: ['/root/.pyenv/versions/3.11.12/bin/python3.11',...&gt;, stdout = ''
stderr = 'Traceback (most recent call last):\n  File "/tmp/tmpj6_2y3b9.py", line 9, in &lt;module&gt;\n    from ai_trading import runner\nModuleNotFoundError: No module named \'ai_trading\'\n'
retcode = 1

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output &amp; stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired as exc:
                process.kill()
                if _mswindows:
                    # Windows accumulates the output in a single blocking
                    # read() call run on child threads, with the timeout
                    # being done in a join() on those threads.  communicate()
                    # _after_ kill() is required to collect that and add it
                    # to the exception.
                    exc.stdout, exc.stderr = process.communicate()
                else:
                    # POSIX _communicate already populated the output so
                    # far into the TimeoutExpired exception.
                    process.wait()
                raise
            except:  # Including KeyboardInterrupt, communicate handled that.
                process.kill()
                # We don't call process.wait() as .__exit__ does that for us.
                raise
            retcode = process.poll()
            if check and retcode:
&gt;               raise CalledProcessError(retcode, process.args,
                                         output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmpj6_2y3b9.py']' returned non-zero exit status 1.

/root/.pyenv/versions/3.11.12/lib/python3.11/subprocess.py:571: CalledProcessError</failure></testcase><testcase classname="tests.unit.test_retry" name="test_fast_retry_skips_sleep" time="0.518"><failure message="assert 0.5142596170007891 &lt; 0.01">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d84adc490&gt;

    @pytest.mark.unit
    def test_fast_retry_skips_sleep(monkeypatch: pytest.MonkeyPatch) -&gt; None:
        monkeypatch.setenv("FAST_RETRY_IN_TESTS", "1")
    
        calls = {"n": 0}
    
        def func() -&gt; str:
            calls["n"] += 1
            if calls["n"] &lt; 2:
                raise RuntimeError("boom")
            return "done"
    
        start = time.perf_counter()
        result = retry_call(func, exceptions=(RuntimeError,), retries=1, backoff=0.5)
        elapsed = time.perf_counter() - start
        assert result == "done"
        assert calls["n"] == 2
&gt;       assert elapsed &lt; 0.01
E       assert 0.5142596170007891 &lt; 0.01

tests/unit/test_retry.py:64: AssertionError</failure></testcase><testcase classname="tests.unit.test_retry" name="test_retry_raises_after_exhaustion" time="0.715" /><testcase classname="tests.utils.test_http_retry" name="test_get_retries_and_logs" time="0.318" /><testcase classname="tests.utils.test_retry" name="test_retry_succeeds_and_sleeps" time="0.764"><failure message="assert 0 == 2&#10; +  where 0 = len([])">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f8d84adc450&gt;

    def test_retry_succeeds_and_sleeps(monkeypatch: pytest.MonkeyPatch) -&gt; None:
        sleeps: list[float] = []
        monkeypatch.setattr(time, "sleep", lambda s: sleeps.append(s))
        fn = Flaky(2)
        assert retry_call(fn, exceptions=(TimeoutError,), retries=3) == "ok"
        assert fn.calls == 3
&gt;       assert len(sleeps) == 2
E       assert 0 == 2
E        +  where 0 = len([])

tests/utils/test_retry.py:30: AssertionError</failure></testcase><testcase classname="tests.utils.test_portfolio_lock_export" name="test_portfolio_lock_is_exported_and_is_same_object" time="0.002" /><testcase classname="tests.utils.test_retry" name="test_backoff_caps" time="0.904"><failure message="IndexError: list index out of range">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c09da0d0&gt;

    def test_backoff_caps(monkeypatch: pytest.MonkeyPatch) -&gt; None:
        sleeps: list[float] = []
        monkeypatch.setattr(time, "sleep", lambda s: sleeps.append(s))
        fn = Flaky(5)
        with pytest.raises(TimeoutError):
            retry_call(fn, exceptions=(TimeoutError,), retries=4, backoff=0.1, max_backoff=0.3, jitter=0)
&gt;       assert sleeps[-1] &lt;= 0.3
E       IndexError: list index out of range

tests/utils/test_retry.py:45: IndexError</failure></testcase><testcase classname="tests.unit.test_broker_alpaca_import_narrowing" name="test_alpaca_import_without_requests" time="0.004" /><testcase classname="tests.unit.test_health_check" name="test_pre_trade_health_resolves_min_rows_without_ctx_attr" time="0.004" /><testcase classname="tests.utils.test_retry" name="test_non_listed_exception" time="0.003" /><testcase classname="tests.test_critical_trading_issues.TestOrderExecutionTracking" name="test_order_status_polling_integration" time="3.005" /><testcase classname="tests.test_critical_trading_issues.TestOrderExecutionTracking" name="test_safe_submit_order_quantity_validation" time="0.007"><failure message="AttributeError: 'NoneType' object has no attribute 'filled_qty'">self = &lt;tests.test_critical_trading_issues.TestOrderExecutionTracking testMethod=test_safe_submit_order_quantity_validation&gt;

    def test_safe_submit_order_quantity_validation(self):
        """Test that safe_submit_order validates filled_qty matches intended qty."""
    
        # Mock order request
        mock_req = Mock()
        mock_req.symbol = "AAPL"
        mock_req.qty = 100
    
        # Mock order with partial fill
        partial_order = Mock()
        partial_order.status = "partially_filled"
        partial_order.filled_qty = "50"  # Only half filled
        partial_order.qty = "100"
    
        with patch.object(self.mock_ctx.api, 'submit_order', return_value=partial_order), \
             patch.object(self.mock_ctx.api, 'get_order_by_id', return_value=partial_order):
    
            if hasattr(bot_engine, 'safe_submit_order'):
                result = bot_engine.safe_submit_order(self.mock_ctx.api, mock_req)
    
                # The issue: function returns the order but doesn't validate
                # that filled_qty (50) matches intended qty (100)
&gt;               self.assertEqual(result.filled_qty, "50")
E               AttributeError: 'NoneType' object has no attribute 'filled_qty'

tests/test_critical_trading_issues.py:141: AttributeError</failure></testcase><testcase classname="tests.test_critical_trading_issues.TestMetaLearningLogFormat" name="test_audit_to_meta_format_conversion" time="0.009" /><testcase classname="tests.test_critical_trading_issues.TestMetaLearningLogFormat" name="test_meta_learning_empty_log_issue" time="0.003" /><testcase classname="tests.test_critical_trading_issues.TestMetaLearningLogFormat" name="test_mixed_format_detection" time="0.002" /><testcase classname="tests.test_critical_trading_issues.TestLiquidityManagement" name="test_conservative_spread_threshold" time="0.003"><failure message="NotImplementedError">self = &lt;tests.test_critical_trading_issues.TestLiquidityManagement testMethod=test_conservative_spread_threshold&gt;

    def test_conservative_spread_threshold(self):
        """Test that 0.05 spread threshold is too conservative."""
    
        symbol = "AAPL"
    
        # Mock quote with moderate spread
        mock_quote = Mock()
        mock_quote.ask_price = 150.05
        mock_quote.bid_price = 150.00
        mock_quote.spread = 0.05  # Exactly at threshold
    
        # Mock volume data
    
        with patch.object(self.mock_ctx.data_client, 'get_stock_latest_quote', return_value=mock_quote):
            if hasattr(bot_engine, 'liquidity_factor'):
&gt;               bot_engine.liquidity_factor(self.mock_ctx, symbol)

tests/test_critical_trading_issues.py:263: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:7169: in liquidity_factor
    df = fetch_minute_df_safe(symbol)
ai_trading/core/bot_engine.py:2047: in fetch_minute_df_safe
    df = get_minute_df(symbol, start_dt, now_utc)
ai_trading/data_fetcher.py:531: in get_minute_df
    fh_fetcher.fetch(symbol, start_dt, end_dt, resolution="1")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;ai_trading.data_fetcher._FinnhubFetcherStub object at 0x7f3d462c2850&gt;
args = ('AAPL', datetime.datetime(2025, 8, 21, 17, 39, 22, 250670, tzinfo=datetime.timezone.utc), datetime.datetime(2025, 8, 22, 17, 39, 22, 250670, tzinfo=datetime.timezone.utc))
kwargs = {'resolution': '1'}

    def fetch(self, *args, **kwargs):
&gt;       raise NotImplementedError
E       NotImplementedError

ai_trading/data_fetcher.py:149: NotImplementedError</failure></testcase><testcase classname="tests.test_critical_trading_issues.TestLiquidityManagement" name="test_pov_slice_reduction_on_spread" time="0.005" /><testcase classname="tests.test_critical_trading_issues.TestLiquidityManagement" name="test_volatility_retry_frequency" time="0.003" /><testcase classname="tests.test_critical_trading_issues.TestResourceManagement" name="test_memory_optimization_available" time="0.003" /><testcase classname="tests.test_critical_trading_issues.TestResourceManagement" name="test_order_submission_lock" time="0.002" /><testcase classname="tests.test_critical_trading_issues.TestResourceManagement" name="test_recent_buys_cleanup" time="0.002" /><testcase classname="tests.test_daily_bars_datetime_sanitization" name="test_daily_request_sanitizes_inputs" time="0.005" /><testcase classname="tests.test_daily_sanitization_retry" name="test_daily_retry_handles_callable" time="0.010" /><testcase classname="tests.test_daily_sanitize_debug" name="test_callable_triggers_single_debug" time="0.005" /><testcase classname="tests.test_data_cache" name="test_mem_cache_ttl_basic" time="0.003" /><testcase classname="tests.test_data_cache" name="test_disk_cache_basic" time="0.005"><failure message="assert None is not None">tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw3/test_disk_cache_basic0')

    def test_disk_cache_basic(tmp_path):
        """Test disk cache functionality"""
        cache_dir = str(tmp_path / "cache")
        df = pd.DataFrame({"timestamp":[1], "open":[2], "high":[3], "low":[1], "close":[2.5], "volume":[1000]})
    
        # Put data in disk cache
        mcache.put_disk(cache_dir, "TSLA", "1H", "2024-01-01", "2024-01-02", df)
    
        # Retrieve from disk cache
        retrieved = mcache.get_disk(cache_dir, "TSLA", "1H", "2024-01-01", "2024-01-02")
&gt;       assert retrieved is not None
E       assert None is not None

tests/test_data_cache.py:25: AssertionError</failure></testcase><testcase classname="tests.test_data_cache" name="test_cache_key_generation" time="0.002" /><testcase classname="tests.test_data_cache" name="test_memory_cache_thread_safety" time="0.022" /><testcase classname="tests.test_data_cache" name="test_settings_integration" time="0.002" /><testcase classname="tests.test_data_fetch" name="test_get_bars_df_spy_day" time="0.002"><failure message="AttributeError: type object '_TFUnit' has no attribute 'Week'">@pytest.mark.requires_credentials
    def test_get_bars_df_spy_day():
        if not (os.getenv("ALPACA_API_KEY") and os.getenv("ALPACA_SECRET_KEY")):
            pytest.skip("missing Alpaca credentials")
&gt;       df = get_bars_df("SPY", TimeFrame.Day)

tests/test_data_fetch.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:174: in get_bars_df
    base_tf = tf_raw if isinstance(tf_raw, TimeFrame) else TimeFrame(1, TimeFrameUnit.Day)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:40: in __init__
    self.validate_timeframe(amount, unit)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amount = 1, unit = &lt;TimeFrameUnit.Day: 'Day'&gt;

    @staticmethod
    def validate_timeframe(amount: int, unit: TimeFrameUnit):
        """Validates the amount value against the TimeFrameUnit value for consistency
    
        Args:
            amount (int): The number of multiples of unit
            unit (TimeFrameUnit): The base unit of time interval the TimeFrame is measured by
    
        Raises:
            ValueError: Raised if the values of amount and unit are not consistent with each other
        """
        if amount &lt;= 0:
            raise ValueError("Amount must be a positive integer value.")
    
        if unit == TimeFrameUnit.Minute and amount &gt; 59:
            raise ValueError(
                "Second or Minute units can only be "
                + "used with amounts between 1-59."
            )
    
        if unit == TimeFrameUnit.Hour and amount &gt; 23:
            raise ValueError("Hour units can only be used with amounts 1-23")
    
&gt;       if unit in (TimeFrameUnit.Day, TimeFrameUnit.Week) and amount != 1:
E       AttributeError: type object '_TFUnit' has no attribute 'Week'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:94: AttributeError</failure></testcase><testcase classname="tests.test_data_fetch" name="test_bars_time_window_day" time="0.002" /><testcase classname="tests.test_data_fetcher" name="test_get_minute_df" time="0.003"><failure message="NotImplementedError">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f3d461bef90&gt;

    def test_get_minute_df(monkeypatch):
        df = pd.DataFrame(
            {"open": [1.0], "high": [2.0], "low": [0.5], "close": [1.5], "volume": [100]},
            index=[pd.Timestamp("2023-01-01T09:30")],
        )
    
        monkeypatch.setattr(data_fetcher, "_fetch_bars", lambda *a, **k: df.reset_index().rename(columns={"index": "timestamp"}))
        monkeypatch.setattr(data_fetcher, "is_market_open", lambda: True)
&gt;       result = data_fetcher.get_minute_df("AAPL", datetime.date(2023, 1, 1), datetime.date(2023, 1, 2))

tests/test_data_fetcher.py:104: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/data_fetcher.py:531: in get_minute_df
    fh_fetcher.fetch(symbol, start_dt, end_dt, resolution="1")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;ai_trading.data_fetcher._FinnhubFetcherStub object at 0x7f3d462c2850&gt;
args = ('AAPL', datetime.datetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2023, 1, 2, 0, 0, tzinfo=datetime.timezone.utc))
kwargs = {'resolution': '1'}

    def fetch(self, *args, **kwargs):
&gt;       raise NotImplementedError
E       NotImplementedError

ai_trading/data_fetcher.py:149: NotImplementedError</failure></testcase><testcase classname="tests.test_data_fetcher" name="test_subscription_error_logged" time="0.003"><failure message="AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute 'client'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f3d461bf650&gt;
caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7f3d46308c90&gt;

    def test_subscription_error_logged(monkeypatch, caplog):
        df = pd.DataFrame(
            {"open": [1.0], "high": [2.0], "low": [0.5], "close": [1.5], "volume": [100]},
            index=[pd.Timestamp("2023-01-01T09:30")],
        )
    
        class DummyClient:
            def get_stock_bars(self, req):
                if getattr(req, "feed", None) == "iex":
                    return FakeBars(df)
                raise data_fetcher.APIError("subscription does not permit querying recent SIP data")
    
&gt;       monkeypatch.setattr(data_fetcher, "client", DummyClient())
E       AttributeError: &lt;module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'&gt; has no attribute 'client'

tests/test_data_fetcher.py:120: AttributeError</failure></testcase><testcase classname="tests.test_data_fetcher" name="test_default_feed_constant" time="0.002" /><testcase classname="tests.test_data_fetcher" name="test_fetch_bars_retry_invalid_feed" time="0.003"><failure message="TypeError: _fetch_bars() takes 4 positional arguments but 5 were given">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f3d457704d0&gt;

    def test_fetch_bars_retry_invalid_feed(monkeypatch):
        calls = []
    
        class Resp:
            def __init__(self, status, text, data=None):
                self.status_code = status
                self.text = text
                self._data = data or {}
    
            def json(self):
                return self._data
    
        def fake_get(url, params=None, headers=None, timeout=10):
            calls.append(params["feed"])
            if len(calls) == 1:
                return Resp(400, "invalid feed")
            return Resp(200, "", {"bars": [{"t": "2023-01-01T00:00:00Z", "o": 1, "h": 1, "l": 1, "c": 1, "v": 1}]})
    
        monkeypatch.setattr(data_fetcher.requests, "get", fake_get)
    
        start = pd.Timestamp("2023-01-01", tz="UTC")
        end = start + pd.Timedelta(minutes=1)
&gt;       df = data_fetcher._fetch_bars("AAPL", start, end, "1Min", "iex")
E       TypeError: _fetch_bars() takes 4 positional arguments but 5 were given

tests/test_data_fetcher.py:164: TypeError</failure></testcase><testcase classname="tests.test_data_fetcher" name="test_finnhub_403_yfinance" time="0.002"><failure message="AttributeError: None has no attribute 'download'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f3d458b6cd0&gt;

    def test_finnhub_403_yfinance(monkeypatch):
        def raise_fetch(*a, **k):
            raise data_fetcher.DataFetchException("AAPL", "alpaca", "", "err")
    
        def raise_finnhub(*a, **k):
            raise data_fetcher.FinnhubAPIException(status_code=403)
    
        called = []
    
        def fake_yf(symbol, *args, **kwargs):
            called.append(symbol)
            return pd.DataFrame(
                {"open": [1], "high": [1], "low": [1], "close": [1], "volume": [1]},
                index=[pd.Timestamp("2023-01-01", tz="UTC")],
            )
    
        monkeypatch.setattr(data_fetcher, "_fetch_bars", raise_fetch)
        monkeypatch.setattr(data_fetcher.fh_fetcher, "fetch", raise_finnhub)
&gt;       monkeypatch.setattr(data_fetcher.yf, "download", fake_yf)
E       AttributeError: None has no attribute 'download'

tests/test_data_fetcher.py:187: AttributeError</failure></testcase><testcase classname="tests.test_data_fetcher" name="test_empty_bars_handled" time="0.005" /><testcase classname="tests.test_data_fetcher" name="test_fetch_bars_empty_raises" time="0.003"><failure message="TypeError: _fetch_bars() takes 4 positional arguments but 5 were given">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f3d45af6f50&gt;

    def test_fetch_bars_empty_raises(monkeypatch):
        """_fetch_bars propagates empty results for Yahoo fallback."""  # AI-AGENT-REF
    
        class Resp:
            status_code = 200
            text = ""
    
            def json(self):
                return {"bars": []}
    
        monkeypatch.setattr(data_fetcher.requests, "get", lambda *a, **k: Resp())
    
        with pytest.raises(ValueError):
&gt;           data_fetcher._fetch_bars(
                "AAPL",
                pd.Timestamp("2023-01-02", tz="UTC"),
                pd.Timestamp("2023-01-02", tz="UTC"),
                "1Day",
                "iex",
            )
E           TypeError: _fetch_bars() takes 4 positional arguments but 5 were given

tests/test_data_fetcher.py:226: TypeError</failure></testcase></testsuite></testsuites>