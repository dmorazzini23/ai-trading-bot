bringing up nodes...
bringing up nodes...

...............................................F.FFF..F.F...F.F.....F.......F..F.......F.FF.......F.F.F.x............... [ 12%]
.......F...................F....F..F......FFF.......................F...F.......s...s...F....FFF....sFsssssFs.ss.ssss... [ 25%]
s.F.s.s....F.........F.F..F.FF.....................F....FFFF..F....F.F.FF.F.F.FFF........F.........F..sF.sss...FFF..F... [ 38%]
FFFF.F.FFFFFFF.FFFFFFF..F..F...FsssF..........EEEEEFF.....FFFFFF.FFFF.F...FFFFFF.................F......ssss.....F..F... [ 51%]
.......................F.F......FF.FFF.FFFF...F..F.Fs..FFEEFEEFFEF....Fs..E......EFEFFFFEFE.EEEF.F.....F..FF...F..FFFFF. [ 64%]
......FF...FF.FF...F.....ssssF.....sF.Fss........FFF.FFFFF......FFF...........F..F...F.......FF.F.F..F..FFF....F.FF.FF.. [ 77%]
...F.F........F..F.FFFF..FF.F.FFFFFFFFFF..F...FsssssFFFFFFF...F...FF..........FFF....F.......FFFFFFFFF.FF....FFFFF....F. [ 90%]
..FFFF...F..F.F....F.......F.....F.FEF...FFFFF.......F.F..F...F.........F...F.FF.FF.F                                    [100%]
============================================================ ERRORS ============================================================
__________________________________ ERROR collecting tests/institutional/test_live_trading.py ___________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/institutional/test_live_trading.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/institutional/test_live_trading.py:21: in <module>
    from ai_trading.execution.live_trading import AlpacaExecutionEngine
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
_______________________________________ ERROR collecting tests/test_advanced_features.py _______________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_advanced_features.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_advanced_features.py:31: in <module>
    from ai_trading.execution import slippage  # AI-AGENT-REF: use prod slippage module
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
_______________________________________ ERROR collecting tests/test_batch_and_warmup.py ________________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_batch_and_warmup.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_batch_and_warmup.py:6: in <module>
    from ai_trading.data_fetcher import get_bars_batch, warmup_cache
E   ImportError: cannot import name 'warmup_cache' from 'ai_trading.data_fetcher' (/workspace/ai-trading-bot/ai_trading/data_fetcher.py)
__________________________________________ ERROR collecting tests/test_benchmarks.py ___________________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_benchmarks.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_benchmarks.py:6: in <module>
    from ai_trading import indicators, signals
ai_trading/signals.py:114: in <module>
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
____________________________________ ERROR collecting tests/test_critical_trading_fixes.py _____________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_critical_trading_fixes.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_critical_trading_fixes.py:32: in <module>
    from ai_trading.execution.engine import ExecutionEngine
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
------------------------------------------------------- Captured stdout --------------------------------------------------------
{"ts": "2025-08-22 17:37:20,718", "level": "INFO", "name": "ai_trading.utils.device", "msg": "ML_Dâ€¦CTED", "device": "cpu", "reason": "torch_unavailable", "bot_phase": "GENERAL"}
_______________________________________ ERROR collecting tests/test_enhanced_signals.py ________________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_enhanced_signals.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_enhanced_signals.py:10: in <module>
    from ai_trading import signals
ai_trading/signals.py:114: in <module>
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
_______________________________________ ERROR collecting tests/test_execution_classes.py _______________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_execution_classes.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_execution_classes.py:10: in <module>
    from ai_trading.execution import ExecutionResult, OrderRequest
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
_________________________________ ERROR collecting tests/test_execution_engine_check_stops.py __________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_execution_engine_check_stops.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_execution_engine_check_stops.py:1: in <module>
    from ai_trading.execution.engine import ExecutionEngine
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
_______________________________________ ERROR collecting tests/test_execution_methods.py _______________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_execution_methods.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_execution_methods.py:1: in <module>
    from ai_trading.execution import ExecutionEngine
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
_______________________________________ ERROR collecting tests/test_ml_model_loading.py ________________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_ml_model_loading.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_ml_model_loading.py:9: in <module>
    from sklearn.dummy import DummyClassifier
E   ModuleNotFoundError: No module named 'sklearn.dummy'; 'sklearn' is not a package
___________________________________ ERROR collecting tests/test_model_registry_roundtrip.py ____________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_model_registry_roundtrip.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_model_registry_roundtrip.py:8: in <module>
    from sklearn.linear_model import LinearRegression
E   ImportError: cannot import name 'LinearRegression' from 'sklearn.linear_model' (unknown location)
________________________________________ ERROR collecting tests/test_parallel_speed.py _________________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_parallel_speed.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_parallel_speed.py:4: in <module>
    from ai_trading import signals
ai_trading/signals.py:114: in <module>
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
_____________________________________ ERROR collecting tests/test_portfolio_integration.py _____________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_portfolio_integration.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_portfolio_integration.py:28: in <module>
    from ai_trading.signals import filter_signals_with_portfolio_optimization
ai_trading/signals.py:114: in <module>
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
____________________________________ ERROR collecting tests/test_portfolio_optimization.py _____________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_portfolio_optimization.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_portfolio_optimization.py:13: in <module>
    from ai_trading.execution.transaction_costs import (  # AI-AGENT-REF: normalized import
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
________________________________________ ERROR collecting tests/test_property_based.py _________________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_property_based.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_property_based.py:13: in <module>
    from ai_trading import signals, utils
ai_trading/signals.py:114: in <module>
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
____________________________________________ ERROR collecting tests/test_signals.py ____________________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_signals.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_signals.py:11: in <module>
    from ai_trading.signals import GaussianHMM, detect_market_regime_hmm
ai_trading/signals.py:114: in <module>
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
_______________________________________ ERROR collecting tests/test_signals_extended.py ________________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_signals_extended.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_signals_extended.py:1: in <module>
    from ai_trading import signals
ai_trading/signals.py:114: in <module>
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
________________________________________ ERROR collecting tests/test_signals_scoring.py ________________________________________
ImportError while importing test module '/workspace/ai-trading-bot/tests/test_signals_scoring.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_signals_scoring.py:3: in <module>
    from ai_trading import signals
ai_trading/signals.py:114: in <module>
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
ai_trading/execution/idempotency.py:13: in <module>
    from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'
__________________________ ERROR at setup of TestKellyCalculator.test_kelly_calculator_initialization __________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyCalculator object at 0x7ff8d81a0550>

    def setup_method(self):
        """Set up test fixtures."""
>       self.calculator = KellyCalculator()

tests/test_institutional_kelly.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d34431d0>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
____________________________ ERROR at setup of TestKellyCalculator.test_portfolio_kelly_calculation ____________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyCalculator object at 0x7ff8d3e98990>

    def setup_method(self):
        """Set up test fixtures."""
>       self.calculator = KellyCalculator()

tests/test_institutional_kelly.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d334f490>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
_____________________________ ERROR at setup of TestKellyCalculator.test_dynamic_kelly_adjustment ______________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyCalculator object at 0x7ff8d3e98a50>

    def setup_method(self):
        """Set up test fixtures."""
>       self.calculator = KellyCalculator()

tests/test_institutional_kelly.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d3ad0c10>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
______________________________ ERROR at setup of TestKellyCalculator.test_kelly_with_correlation _______________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyCalculator object at 0x7ff8d3e99790>

    def setup_method(self):
        """Set up test fixtures."""
>       self.calculator = KellyCalculator()

tests/test_institutional_kelly.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d3ad13d0>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
___________________________ ERROR at setup of TestKellyCalculator.test_calculation_history_recording ___________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyCalculator object at 0x7ff8d3e9a190>

    def setup_method(self):
        """Set up test fixtures."""
>       self.calculator = KellyCalculator()

tests/test_institutional_kelly.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/risk/kelly.py:264: in __init__
    self.kelly_criterion = KellyCriterion()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d39868d0>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
_______________________________ ERROR at setup of TestMetaLearning.test_strategy_initialization ________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0c310>

    def setup_method(self):
        """Set up test fixtures."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
___________________________________ ERROR at setup of TestMetaLearning.test_extract_features ___________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0c9d0>

    def setup_method(self):
        """Set up test fixtures."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
_____________________________________ ERROR at setup of TestMetaLearning.test_train_model ______________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0d0d0>

    def setup_method(self):
        """Set up test fixtures."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
____________________________ ERROR at setup of TestMetaLearning.test_train_model_insufficient_data _____________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0d410>

    def setup_method(self):
        """Set up test fixtures."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
________________________________ ERROR at setup of TestMetaLearning.test_predict_price_movement ________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0da50>

    def setup_method(self):
        """Set up test fixtures."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
______________________________ ERROR at setup of TestMetaLearning.test_execute_strategy_with_data ______________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0df90>

    def setup_method(self):
        """Set up test fixtures."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
_______________________________ ERROR at setup of TestMetaLearning.test_execute_strategy_no_data _______________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0fe10>

    def setup_method(self):
        """Set up test fixtures."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
___________________________________ ERROR at setup of TestMetaLearning.test_generate_signals ___________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0e1d0>

    def setup_method(self):
        """Set up test fixtures."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
_______________________________ ERROR at setup of TestMetaLearning.test_calculate_position_size ________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0ead0>

    def setup_method(self):
        """Set up test fixtures."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
_________________________________ ERROR at setup of TestMetaLearning.test_fallback_prediction __________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a0fc10>

    def setup_method(self):
        """Set up test fixtures."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
__________________________________ ERROR at setup of TestMetaLearning.test_caching_mechanism ___________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a18510>

    def setup_method(self):
        """Set up test fixtures."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
____________________________________ ERROR at setup of TestMetaLearning.test_should_retrain ____________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a18550>

    def setup_method(self):
        """Set up test fixtures."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
__________________________________ ERROR at setup of TestMetaLearning.test_signal_validation ___________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_metalearning_strategy.TestMetaLearning object at 0x7ff8d3a18b90>

    def setup_method(self):
        """Set up test fixtures."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
____________________________________ ERROR at teardown of test_validate_environment_missing ____________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
item = 'WEBHOOK_SECRET'

    def __delattr__(self, item: str) -> Any:
        cls = self.__class__
    
        if item in self.__private_attributes__:
            attribute = self.__private_attributes__[item]
            if hasattr(attribute, '__delete__'):
                attribute.__delete__(self)  # type: ignore
                return
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                del self.__pydantic_private__[item]  # type: ignore
                return
            except KeyError as exc:
                raise AttributeError(f'{cls.__name__!r} object has no attribute {item!r}') from exc
    
        # Allow cached properties to be deleted (even if the class is frozen):
        attr = getattr(cls, item, None)
        if isinstance(attr, cached_property):
            return object.__delattr__(self, item)
    
        _check_frozen(cls, name=item, value=None)
    
        if item in self.__pydantic_fields__:
            object.__delattr__(self, item)
        elif self.__pydantic_extra__ is not None and item in self.__pydantic_extra__:
            del self.__pydantic_extra__[item]
        else:
            try:
>               object.__delattr__(self, item)
E               AttributeError: 'Settings' object has no attribute 'WEBHOOK_SECRET'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1084: AttributeError

During handling of the above exception, another exception occurred:

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
item = 'WEBHOOK_SECRET'

    def __delattr__(self, item: str) -> Any:
        cls = self.__class__
    
        if item in self.__private_attributes__:
            attribute = self.__private_attributes__[item]
            if hasattr(attribute, '__delete__'):
                attribute.__delete__(self)  # type: ignore
                return
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                del self.__pydantic_private__[item]  # type: ignore
                return
            except KeyError as exc:
                raise AttributeError(f'{cls.__name__!r} object has no attribute {item!r}') from exc
    
        # Allow cached properties to be deleted (even if the class is frozen):
        attr = getattr(cls, item, None)
        if isinstance(attr, cached_property):
            return object.__delattr__(self, item)
    
        _check_frozen(cls, name=item, value=None)
    
        if item in self.__pydantic_fields__:
            object.__delattr__(self, item)
        elif self.__pydantic_extra__ is not None and item in self.__pydantic_extra__:
            del self.__pydantic_extra__[item]
        else:
            try:
                object.__delattr__(self, item)
            except AttributeError:
>               raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E               AttributeError: 'Settings' object has no attribute 'WEBHOOK_SECRET'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1086: AttributeError
=========================================================== FAILURES ===========================================================
__________________________________________________ test_daily_uses_date_only ___________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

mock_rest_cls = <MagicMock name='TradeApiREST' id='140245807055184'>

    @patch("ai_trading.alpaca_api.TradeApiREST")
    def test_daily_uses_date_only(mock_rest_cls):
        mock_rest = MagicMock()
        mock_rest.get_bars.return_value = _Resp(pd.DataFrame({"open": [1.0], "close": [1.1]}))
        mock_rest_cls.return_value = mock_rest
    
>       df = get_bars_df("SPY", "Day", feed="iex", adjustment="all")

tests/test_alpaca_time_params.py:21: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:174: in get_bars_df
    base_tf = tf_raw if isinstance(tf_raw, TimeFrame) else TimeFrame(1, TimeFrameUnit.Day)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:40: in __init__
    self.validate_timeframe(amount, unit)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amount = 1, unit = <TimeFrameUnit.Day: 'Day'>

    @staticmethod
    def validate_timeframe(amount: int, unit: TimeFrameUnit):
        """Validates the amount value against the TimeFrameUnit value for consistency
    
        Args:
            amount (int): The number of multiples of unit
            unit (TimeFrameUnit): The base unit of time interval the TimeFrame is measured by
    
        Raises:
            ValueError: Raised if the values of amount and unit are not consistent with each other
        """
        if amount <= 0:
            raise ValueError("Amount must be a positive integer value.")
    
        if unit == TimeFrameUnit.Minute and amount > 59:
            raise ValueError(
                "Second or Minute units can only be "
                + "used with amounts between 1-59."
            )
    
        if unit == TimeFrameUnit.Hour and amount > 23:
            raise ValueError("Hour units can only be used with amounts 1-23")
    
>       if unit in (TimeFrameUnit.Day, TimeFrameUnit.Week) and amount != 1:
E       AttributeError: type object '_TFUnit' has no attribute 'Week'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:94: AttributeError
________________________________________________ test_day_timeframe_normalized _________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

mock_rest_cls = <MagicMock name='TradeApiREST' id='140245799324304'>

    @patch("ai_trading.alpaca_api.TradeApiREST")
    def test_day_timeframe_normalized(mock_rest_cls):
        mock_rest = MagicMock()
        mock_rest.get_bars.return_value = _Resp(pd.DataFrame({"open": [1.0], "close": [1.1]}))
        mock_rest_cls.return_value = mock_rest
    
>       df = get_bars_df("SPY", "Day", feed="iex", adjustment="all")

tests/test_alpaca_timeframe_mapping.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:174: in get_bars_df
    base_tf = tf_raw if isinstance(tf_raw, TimeFrame) else TimeFrame(1, TimeFrameUnit.Day)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:40: in __init__
    self.validate_timeframe(amount, unit)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amount = 1, unit = <TimeFrameUnit.Day: 'Day'>

    @staticmethod
    def validate_timeframe(amount: int, unit: TimeFrameUnit):
        """Validates the amount value against the TimeFrameUnit value for consistency
    
        Args:
            amount (int): The number of multiples of unit
            unit (TimeFrameUnit): The base unit of time interval the TimeFrame is measured by
    
        Raises:
            ValueError: Raised if the values of amount and unit are not consistent with each other
        """
        if amount <= 0:
            raise ValueError("Amount must be a positive integer value.")
    
        if unit == TimeFrameUnit.Minute and amount > 59:
            raise ValueError(
                "Second or Minute units can only be "
                + "used with amounts between 1-59."
            )
    
        if unit == TimeFrameUnit.Hour and amount > 23:
            raise ValueError("Hour units can only be used with amounts 1-23")
    
>       if unit in (TimeFrameUnit.Day, TimeFrameUnit.Week) and amount != 1:
E       AttributeError: type object '_TFUnit' has no attribute 'Week'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:94: AttributeError
____________________________________ TestCriticalFixes.test_short_selling_validation_exists ____________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_fixes_focused.TestCriticalFixes testMethod=test_short_selling_validation_exists>

    def test_short_selling_validation_exists(self):
        """Test that short selling validation method exists."""
        # P2 Fix: Short selling validation
>       from ai_trading.execution.engine import ExecutionEngine

tests/test_critical_fixes_focused.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
__________________________________________________ test_tf_object_normalized ___________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

mock_rest_cls = <MagicMock name='TradeApiREST' id='140245798861584'>

    @patch("ai_trading.alpaca_api.TradeApiREST")
    def test_tf_object_normalized(mock_rest_cls):
        mock_rest = MagicMock()
        mock_rest.get_bars.return_value = _Resp(pd.DataFrame({"open": [1.0], "close": [1.1]}))
        mock_rest_cls.return_value = mock_rest
    
>       df = get_bars_df("SPY", TimeFrame(1, TimeFrameUnit.Day), feed="iex", adjustment="all")

tests/test_alpaca_timeframe_mapping.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:40: in __init__
    self.validate_timeframe(amount, unit)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amount = 1, unit = <TimeFrameUnit.Day: 'Day'>

    @staticmethod
    def validate_timeframe(amount: int, unit: TimeFrameUnit):
        """Validates the amount value against the TimeFrameUnit value for consistency
    
        Args:
            amount (int): The number of multiples of unit
            unit (TimeFrameUnit): The base unit of time interval the TimeFrame is measured by
    
        Raises:
            ValueError: Raised if the values of amount and unit are not consistent with each other
        """
        if amount <= 0:
            raise ValueError("Amount must be a positive integer value.")
    
        if unit == TimeFrameUnit.Minute and amount > 59:
            raise ValueError(
                "Second or Minute units can only be "
                + "used with amounts between 1-59."
            )
    
        if unit == TimeFrameUnit.Hour and amount > 23:
            raise ValueError("Hour units can only be used with amounts 1-23")
    
>       if unit in (TimeFrameUnit.Day, TimeFrameUnit.Week) and amount != 1:
E       AttributeError: type object '_TFUnit' has no attribute 'Week'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:94: AttributeError
_______________________________________ test_data_fetcher_json_decode_is_valueerror_only _______________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_data_fetcher_json_decode_is_valueerror_only():
        src = _source(df_mod)
        # The JSON decode guard around resp.json() should not be broad
>       assert re.search(r"resp\.json\(\)\n\s*except ValueError:\n\s*payload\s*=\s*\{\}", src)
E       assert None
E        +  where None = <function search at 0x7ff8f111a200>('resp\\.json\\(\\)\\n\\s*except ValueError:\\n\\s*payload\\s*=\\s*\\{\\}', 'from __future__ import annotations\n\nimport datetime as _dt\nimport os\nimport warnings  # AI-AGENT-REF: control yfi..._minute_yfinance",\n    "is_market_open",\n    "get_last_available_bar",\n    "fh_fetcher",\n    "get_minute_df",\n]\n')
E        +    where <function search at 0x7ff8f111a200> = re.search

tests/runtime/test_exception_narrowing_df_main.py:23: AssertionError
____________________________________________________ test_minute_normalized ____________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

mock_rest_cls = <MagicMock name='TradeApiREST' id='140245803049232'>

    @patch("ai_trading.alpaca_api.TradeApiREST")
    def test_minute_normalized(mock_rest_cls):
        mock_rest = MagicMock()
        mock_rest.get_bars.return_value = _Resp(pd.DataFrame({"open": [1.0], "close": [1.1]}))
        mock_rest_cls.return_value = mock_rest
    
>       df = get_bars_df("SPY", "Minute", feed="iex", adjustment="all")

tests/test_alpaca_timeframe_mapping.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:174: in get_bars_df
    base_tf = tf_raw if isinstance(tf_raw, TimeFrame) else TimeFrame(1, TimeFrameUnit.Day)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:40: in __init__
    self.validate_timeframe(amount, unit)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amount = 1, unit = <TimeFrameUnit.Day: 'Day'>

    @staticmethod
    def validate_timeframe(amount: int, unit: TimeFrameUnit):
        """Validates the amount value against the TimeFrameUnit value for consistency
    
        Args:
            amount (int): The number of multiples of unit
            unit (TimeFrameUnit): The base unit of time interval the TimeFrame is measured by
    
        Raises:
            ValueError: Raised if the values of amount and unit are not consistent with each other
        """
        if amount <= 0:
            raise ValueError("Amount must be a positive integer value.")
    
        if unit == TimeFrameUnit.Minute and amount > 59:
            raise ValueError(
                "Second or Minute units can only be "
                + "used with amounts between 1-59."
            )
    
        if unit == TimeFrameUnit.Hour and amount > 23:
            raise ValueError("Hour units can only be used with amounts 1-23")
    
>       if unit in (TimeFrameUnit.Day, TimeFrameUnit.Week) and amount != 1:
E       AttributeError: type object '_TFUnit' has no attribute 'Week'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:94: AttributeError
_____________________________________________ test_wrapped_get_retries_and_parses ______________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3d471d0>

    def test_wrapped_get_retries_and_parses(monkeypatch):
        calls = []
    
        def fake_request(self, method, url, **kwargs):
            calls.append(kwargs)
            assert kwargs["timeout"] == clamp_timeout(None, default_non_test=HTTP_TIMEOUT)
            if len(calls) == 1:
                raise requests.exceptions.RequestException("boom")
            return DummyResp({"ok": True})
    
        # Patch session.request used by wrapper
        monkeypatch.setattr(requests.Session, "request", fake_request)
        # Patch requests.get per requirement, though wrapper uses session
        monkeypatch.setattr(requests, "get", lambda url, **kw: fake_request(None, "GET", url, **kw))
    
>       resp = http.get("https://example.com")

tests/runtime/test_http_wrapped.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/utils/http.py:196: in get
    return request("GET", url, **kwargs)
ai_trading/utils/http.py:131: in request
    resp = retry_call(
ai_trading/utils/retry.py:31: in retry_call
    return func(*args, **kwargs)
ai_trading/utils/http.py:119: in _do_request
    return sess.request(method, url, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7ff8d80b4710>, method = 'GET', url = 'https://example.com'
kwargs = {'timeout': 0.25}, @py_assert0 = None, @py_assert4 = None, @py_assert7 = None, @py_assert2 = None

    def fake_request(self, method, url, **kwargs):
        calls.append(kwargs)
        assert kwargs["timeout"] == clamp_timeout(None, default_non_test=HTTP_TIMEOUT)
        if len(calls) == 1:
>           raise requests.exceptions.RequestException("boom")
E           Exception: boom

tests/runtime/test_http_wrapped.py:21: Exception
__________________________________ TestCriticalFixes.test_trade_execution_quantity_fix_exists __________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_fixes_focused.TestCriticalFixes testMethod=test_trade_execution_quantity_fix_exists>

    def test_trade_execution_quantity_fix_exists(self):
        """Test that trade execution has the quantity calculation fix."""
        # P0 Fix: Quantity calculation bug
        # We can't easily test the actual fix without mocking orders, but we can verify
        # the _reconcile_partial_fills method exists and has been updated
    
>       from ai_trading.execution.engine import ExecutionEngine

tests/test_critical_fixes_focused.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
_____________________________________________________ test_model_registry ______________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_model_registry():
        """Test model registry functionality."""
        try:
            import os
            import tempfile
    
            from ai_trading.model_registry import ModelRegistry
    
            # Create temporary directory for testing
            with tempfile.TemporaryDirectory() as temp_dir:
                registry = ModelRegistry(temp_dir)
    
                # Create a mock model
                mock_model = Mock()
                mock_model.__class__.__name__ = "MockModel"
    
                metadata = {
                    "training_date": "2024-01-01",
                    "cv_score": 0.85,
                    "feature_count": 10
                }
    
                # Register model
>               model_id = registry.register_model(
                    model=mock_model,
                    strategy="test_strategy",
                    model_type="mock",
                    metadata=metadata
                )

tests/test_alpha_quality.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.model_registry.ModelRegistry object at 0x7f8d853fd990>, model = <MockModel id='140245802133392'>
strategy = 'test_strategy', model_type = 'mock'
metadata = {'cv_score': 0.85, 'feature_count': 10, 'training_date': '2024-01-01'}, dataset_fingerprint = None, tags = None

    def register_model(
        self,
        model: Any,
        strategy: str,
        model_type: str,
        metadata: dict[str, Any] | None = None,
        dataset_fingerprint: str | None = None,
        tags: list[str] | None = None,
    ) -> str:
        """Store model + metadata and return deterministic ID."""
        try:
>           blob = pickle.dumps(model)
E           _pickle.PicklingError: Can't pickle <class 'unittest.mock.Mock'>: it's not the same object as unittest.mock.Mock

ai_trading/model_registry.py:65: PicklingError
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.logging:model_registry.py:32 Modeâ€¦stry initialized at /tmp/tmpuq_w5yua
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 17:37:25,195", "level": "INFO", "name": "ai_trading.logging", "msg": "Modeâ€¦stry initialized at /tmp/tmpuq_w5yua", "bot_phase": "GENERAL"}
_________________________________________ test_sentiment_cache_memory_leak_prevention __________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    from __future__ import annotations
    
    from functools import lru_cache
    
    try:  # AI-AGENT-REF: optional cachetools TTL cache
>       from cachetools import TTLCache
E       ModuleNotFoundError: No module named 'cachetools'

ai_trading/predict.py:6: ModuleNotFoundError

During handling of the above exception, another exception occurred:

    def test_sentiment_cache_memory_leak_prevention():
        """Test sentiment cache prevents memory leaks."""
        # Mock the imports to avoid external dependencies
>       from ai_trading import predict

tests/test_critical_fixes_implementation.py:99: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    from __future__ import annotations
    
    from functools import lru_cache
    
    try:  # AI-AGENT-REF: optional cachetools TTL cache
        from cachetools import TTLCache
    
        _CACHETOOLS_AVAILABLE = True
        _sentiment_cache = TTLCache(maxsize=1000, ttl=3600)
>   except (requests.RequestException, TimeoutError):
E   NameError: name 'requests' is not defined

ai_trading/predict.py:10: NameError
_____________________________________________ test_walkforward_artifacts_directory _____________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_walkforward_artifacts_directory():
        """Test that walkforward creates artifacts directory with env override."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Set custom artifacts directory
            custom_artifacts = os.path.join(temp_dir, "custom_artifacts")
            os.environ["ARTIFACTS_DIR"] = custom_artifacts
    
            try:
                # Import and create evaluator
>               from ai_trading.evaluation.walkforward import WalkForwardEvaluator

tests/test_artifacts_directories.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/evaluation/walkforward.py:41: in <module>
    from ..data.splits import walkforward_splits
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Time series cross-validation splits with purging and embargo.
    
    Provides leak-proof data splitting for financial time series,
    including purged group time series splits and walk-forward analysis.
    """
    
    from collections.abc import Iterator
    from datetime import datetime, timedelta
    
    import numpy as np
    import pandas as pd
    
    # sklearn is a hard dependency
>   from sklearn.model_selection import BaseCrossValidator
E   ModuleNotFoundError: No module named 'sklearn.model_selection'; 'sklearn' is not a package

ai_trading/data/splits.py:15: ModuleNotFoundError
____________________________________________________ test_security_manager _____________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_security_manager():
        """Test security manager functionality."""
        sys.path.append('ai_trading')
>       from security import mask_sensitive_data

tests/test_critical_fixes_implementation.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """Security enhancements for production trading platform.
    
    Provides secure configuration with encryption for API keys,
    comprehensive audit logging for compliance, and prevents
    API key exposure in logs and error messages.
    
    AI-AGENT-REF: Security enhancements for institutional-grade trading
    """
    
    from __future__ import annotations
    
    import base64
    import json
    import logging
    import os
    import secrets
    from dataclasses import dataclass
    from datetime import UTC, datetime
    from enum import Enum
    from pathlib import Path
    from typing import Any
    
    # Optional cryptography import; tests may run without the package
    try:  # AI-AGENT-REF: handle missing cryptography gracefully
>       from cryptography.fernet import Fernet
E       ModuleNotFoundError: No module named 'cryptography'

ai_trading/security.py:25: ModuleNotFoundError
__________________________________________________ test_dependency_injection ___________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_dependency_injection():
        """Test dependency injection container."""
        sys.path.append('ai_trading')
        from core.interfaces import IConfigManager, SimpleDependencyContainer
    
        container = SimpleDependencyContainer()
    
        # Mock implementation
        # Register implementation
>       container.register(IConfigManager, MockConfigManager)
E       NameError: name 'MockConfigManager' is not defined

tests/test_critical_fixes_implementation.py:260: NameError
________________________________________________ test_performance_optimizations ________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_performance_optimizations():
        """Test performance optimizations work correctly."""
        sys.path.append('ai_trading')
        from indicator_manager import IndicatorManager, IndicatorType
    
        manager = IndicatorManager()
    
        # Create indicators
>       sma_id = manager.create_indicator(IndicatorType.SIMPLE_MOVING_AVERAGE, "TEST", 5)
E       AttributeError: 'IndicatorManager' object has no attribute 'create_indicator'

tests/test_critical_fixes_implementation.py:282: AttributeError
_________________________________ TestCriticalFixes.test_data_staleness_detection_improvement __________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_fixes_validation.TestCriticalFixes testMethod=test_data_staleness_detection_improvement>

    def test_data_staleness_detection_improvement(self):
        """Test 4: Data Staleness Detection - Weekend/holiday awareness."""
        from ai_trading.utils.base import is_market_holiday, is_weekend
    
        # Test weekend detection
        saturday = datetime(2024, 1, 6, 12, 0, tzinfo=UTC)  # Saturday
        sunday = datetime(2024, 1, 7, 12, 0, tzinfo=UTC)  # Sunday
        monday = datetime(2024, 1, 8, 12, 0, tzinfo=UTC)  # Monday
    
        self.assertTrue(is_weekend(saturday), "Saturday should be detected as weekend")
        self.assertTrue(is_weekend(sunday), "Sunday should be detected as weekend")
        self.assertFalse(is_weekend(monday), "Monday should not be detected as weekend")
    
        # Test holiday detection
        new_years = date(2024, 1, 1)  # New Year's Day
        christmas = date(2024, 12, 25)  # Christmas
        regular_day = date(2024, 3, 15)  # Regular Friday
    
        self.assertTrue(
            is_market_holiday(new_years), "New Year's should be detected as holiday"
        )
        self.assertTrue(
            is_market_holiday(christmas), "Christmas should be detected as holiday"
        )
>       self.assertFalse(
            is_market_holiday(regular_day),
            "Regular day should not be detected as holiday",
        )
E       AssertionError: True is not false : Regular day should not be detected as holiday

tests/test_critical_fixes_validation.py:72: AssertionError
____________________________________ TestCriticalFixes.test_meta_learning_price_validation _____________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_fixes_validation.TestCriticalFixes testMethod=test_meta_learning_price_validation>

    def test_meta_learning_price_validation(self):
        """Test 2: MetaLearning Data Validation - Price validation logic."""
        # Mock pandas for testing
        try:
            import pandas as pd
    
            # Test data with mixed price types
            test_data = {
                "entry_price": ["100.50", "200", "invalid", "50.25"],
                "exit_price": ["105.75", "195", "0", "55.00"],
                "side": ["buy", "sell", "buy", "sell"],
                "signal_tags": ["momentum", "mean_revert", "momentum", "trend"],
            }
            df = pd.DataFrame(test_data)
    
            # Apply the validation logic from meta_learning.py
            df["entry_price"] = pd.to_numeric(df["entry_price"], errors="coerce")
            df["exit_price"] = pd.to_numeric(df["exit_price"], errors="coerce")
            df = df.dropna(subset=["entry_price", "exit_price"])
    
            # Filter out non-positive prices
            df = df[(df["entry_price"] > 0) & (df["exit_price"] > 0)]
    
            # Should have 2 valid rows (first and last)
>           self.assertEqual(
                len(df), 2, "Should have 2 rows with valid positive prices"
            )
E           AssertionError: 3 != 2 : Should have 2 rows with valid positive prices

tests/test_critical_fixes_validation.py:101: AssertionError
_____________________________________ TestCriticalFixes.test_systemd_service_configuration _____________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_fixes_validation.TestCriticalFixes testMethod=test_systemd_service_configuration>

    def test_systemd_service_configuration(self):
        """Test 3: Service Configuration - systemd service file."""
        service_file = os.path.join(
            os.getcwd(), "packaging", "systemd", "ai-trading.service"
        )
        self.assertTrue(os.path.exists(service_file), "service file should exist")
    
        # Legacy service files should be absent
        self.assertFalse(os.path.exists("ai-trading-bot.service"))
        self.assertFalse(os.path.exists(os.path.join("deploy", "ai-trading.service")))
    
        with open(service_file) as f:
            content = f.read()
    
        # Check key configuration elements
        self.assertIn("User=aiuser", content, "Service should run as aiuser")
        self.assertIn("Group=aiuser", content, "Service should run as aiuser group")
        self.assertIn(
            "WorkingDirectory=/home/aiuser/ai-trading-bot",
            content,
            "Should have correct working directory",
        )
>       self.assertIn(
            "NoNewPrivileges=true", content, "Should have security restrictions"
        )
E       AssertionError: 'NoNewPrivileges=true' not found in '[Unit]\nDescription=AI Trading Bot\nAfter=network.target\n\n[Service]\nType=simple\nUser=aiuser\nGroup=aiuser\nWorkingDirectory=/home/aiuser/ai-trading-bot\nEnvironment=PATH=/home/aiuser/ai-trading-bot/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin\nEnvironment=AI_TRADER_MODEL_MODULE=ai_trading.models.baseline\nEnvironmentFile=-/home/aiuser/ai-trading-bot/.env\nExecStart=/home/aiuser/ai-trading-bot/venv/bin/python -m ai_trading.main\nRestart=always\nRestartSec=10\nStandardOutput=journal\nStandardError=journal\n\n[Install]\nWantedBy=multi-user.target\n' : Should have security restrictions

tests/test_critical_fixes_validation.py:137: AssertionError
____________________________________________ test_import_contract_timeout_simulated ____________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3d46010>

    def test_import_contract_timeout_simulated(monkeypatch):
        env = os.environ.copy()
        env["IMPORT_CONTRACT_SIMULATE_HANG"] = "1"
        cp = subprocess.run(
            [sys.executable, _script_path(), "--ci", "--timeout", "0.1", "--modules", "sys"],
            capture_output=True,
            text=True,
            env=env,
            check=False,
        )
        assert cp.returncode != 0
>       assert "TIMEOUT" in (cp.stderr or "")
E       AssertionError: assert 'TIMEOUT' in (('' or ''))
E        +  where '' = CompletedProcess(args=['/root/.pyenv/versions/3.11.12/bin/python3.11', '/workspace/ai-trading-bot/tools/import_contract.py', '--ci', '--timeout', '0.1', '--modules', 'sys'], returncode=124, stdout='', stderr='').stderr

tests/runtime/test_import_contract_cli.py:32: AssertionError
________________________________________________ test_fetch_minute_df_safe_open ________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f3d458f6250>

    def test_fetch_minute_df_safe_open(monkeypatch):
        """DataFrame is returned when the market is open."""
        df = pd.DataFrame({"close": [1]}, index=[pd.Timestamp("2024-01-01")])
        monkeypatch.setattr(bot, "get_minute_df", lambda symbol, start_date, end_date: df)
>       result = bot.fetch_minute_df_safe("AAPL")

tests/test_bot_extended.py:229: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:2060: in fetch_minute_df_safe
    _ensure_data_fresh(symbols=[symbol], max_age_seconds=600)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

symbols = ['AAPL'], max_age_seconds = 600

    def _ensure_data_fresh(symbols, max_age_seconds: int) -> None:
        """
        Validate that the cached minute data for each symbol is recent enough.
        Logs UTC timestamps and fails fast if any symbol is stale.
        """
        try:
>           from ai_trading.data_fetcher import last_minute_bar_age_seconds
E           ImportError: cannot import name 'last_minute_bar_age_seconds' from 'ai_trading.data_fetcher' (unknown location)

ai_trading/core/bot_engine.py:5792: ImportError
---------------------------------------------------- Captured stdout setup -----------------------------------------------------
{"ts": "2025-08-22 17:37:25,025", "level": "WARNING", "name": "ai_trading.core.bot_engine", "msg": "FETCâ€¦MPTY", "reason": "empty", "context": "market_closed", "bot_phase": "GENERAL"}
________________________________________________ test_positions_and_account_old ________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_positions_and_account_old():
        fake = FakeOld()
        b = AlpacaBroker(fake)
>       assert b.list_open_positions() == ["pos-old"]
E       AssertionError: assert [] == ['pos-old']
E         
E         Right contains one more item: 'pos-old'
E         Use -v to get more diff

tests/test_broker_alpaca_adapter.py:86: AssertionError
____________________________________ TestEllipsisFix.test_get_runtime_context_or_none_error ____________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_ellipsis_fix.TestEllipsisFix testMethod=test_get_runtime_context_or_none_error>

    def test_get_runtime_context_or_none_error(self):
        """Test runtime context accessor handles errors gracefully."""
        with patch('ai_trading.core.bot_engine.get_ctx') as mock_get_ctx:
            with patch('ai_trading.core.bot_engine._log') as mock_log:
                # Test error handling
                mock_get_ctx.side_effect = Exception("Context unavailable")
    
>               result = _get_runtime_context_or_none()

tests/test_ellipsis_fix.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:5596: in _get_runtime_context_or_none
    lbc = get_ctx()
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1124: in __call__
    return self._mock_call(*args, **kwargs)
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1128: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='get_ctx' id='140684882813392'>, args = (), kwargs = {}, effect = Exception('Context unavailable')

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
>               raise effect
E               Exception: Context unavailable

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1183: Exception
____________________________________________________ test_safe_account_none ____________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_safe_account_none():
        # AI-AGENT-REF: ensure None is returned when Alpaca client missing
        ctx = SimpleNamespace(api=None)
>       assert safe_alpaca_get_account(ctx) is None

tests/test_broker_unavailable_paths.py:10: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:1617: in _wrapped
    return func(*a, **kw)
ai_trading/core/bot_engine.py:3288: in safe_alpaca_get_account
    return ctx.api.get_account()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.broker.alpaca.AlpacaBroker object at 0x7f3d4530bcd0>

    def get_account(self) -> Any:
        if self._is_new:
            return self._call_with_retry("get_account", self._api.get_account)
>       return self._call_with_retry("get_account", self._api.get_account)
E       AttributeError: '_TClient' object has no attribute 'get_account'

ai_trading/broker/alpaca.py:281: AttributeError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:26,131", "level": "INFO", "name": "ai_trading.logging", "msg": "ENV_â€¦AULT override=True", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:26,132", "level": "INFO", "name": "ai_trading.core.bot_engine", "msg": "ALPACA_DIAG", "initialized": true, "has_key": "***REDACTED***", "has_secret": "***REDACTED***", "base_url": "https://paper-api.alpaca.markets", "paper": true, "shadow_mode": true, "cwd": "/workspace/ai-trading-bot", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.logging:__init__.py:293 ENV_â€¦AULT override=True
DEBUG    ai_trading.core.bot_engine:bot_engine.py:5315 Successfully imported Alpaca SDK classes
INFO     ai_trading.core.bot_engine:bot_engine.py:5341 ALPACA_DIAG
_________________________________________________ test_main_starts_api_thread __________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d37b6a10>

    def test_main_starts_api_thread(monkeypatch):
        """main launches the API thread and runs a cycle."""
        monkeypatch.setenv("SCHEDULER_ITERATIONS", "1")
        # AI-AGENT-REF: Mock required environment variables for validation
        monkeypatch.setenv("WEBHOOK_SECRET", "test_secret")
        monkeypatch.setenv("ALPACA_API_KEY", "test_key")
        # AI-AGENT-REF: Use environment variables to avoid hardcoded secrets
        monkeypatch.setenv("TEST_ALPACA_SECRET_KEY", "test_secret_key")
    
        # AI-AGENT-REF: Mock the config object directly to ensure environment validation passes
        monkeypatch.setattr(main, "config", MockConfig())
    
        called = {}
    
        class DummyThread:
            def __init__(self, target, args=(), daemon=None):
                called["created"] = True
                self.target = target
                self.args = args
    
            def start(self):
                called["started"] = True
                self.target(*self.args)
    
            def is_alive(self):
                # AI-AGENT-REF: Add missing is_alive method to prevent AttributeError
                return True
    
        monkeypatch.setattr(main, "Thread", DummyThread)
        # AI-AGENT-REF: Fix lambda signature to accept ready_signal parameter
        monkeypatch.setattr(
            main, "start_api", lambda ready_signal=None: called.setdefault("api", True)
        )
        monkeypatch.setattr(
            main,
            "run_cycle",
            lambda: called.setdefault("cycle", 0)
            or called.update(cycle=called.get("cycle", 0) + 1),
        )
        monkeypatch.setattr(main.time, "sleep", lambda s: None)
    
>       main.main()

tests/test_additional_coverage.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/main.py:341: in main
    _validate_runtime_config(config, S)
ai_trading/main.py:166: in _validate_runtime_config
    setattr(tcfg, "max_position_size", float(fallback))
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:997: in __setattr__
    elif (setattr_handler := self._setattr_handler(name, value)) is not None:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
name = 'max_position_size', value = 8000.0

    def _setattr_handler(self, name: str, value: Any) -> Callable[[BaseModel, str, Any], None] | None:
        """Get a handler for setting an attribute on the model instance.
    
        Returns:
            A handler for setting an attribute on the model instance. Used for memoization of the handler.
            Memoizing the handlers leads to a dramatic performance improvement in `__setattr__`
            Returns `None` when memoization is not safe, then the attribute is set directly.
        """
        cls = self.__class__
        if name in cls.__class_vars__:
            raise AttributeError(
                f'{name!r} is a ClassVar of `{cls.__name__}` and cannot be set on an instance. '
                f'If you want to set a value on the class, use `{cls.__name__}.{name} = value`.'
            )
        elif not _fields.is_valid_field_name(name):
            if (attribute := cls.__private_attributes__.get(name)) is not None:
                if hasattr(attribute, '__set__'):
                    return lambda model, _name, val: attribute.__set__(model, val)
                else:
                    return _SIMPLE_SETATTR_HANDLERS['private']
            else:
                _object_setattr(self, name, value)
                return None  # Can not return memoized handler with possibly freeform attr names
    
        attr = getattr(cls, name, None)
        # NOTE: We currently special case properties and `cached_property`, but we might need
        # to generalize this to all data/non-data descriptors at some point. For non-data descriptors
        # (such as `cached_property`), it isn't obvious though. `cached_property` caches the value
        # to the instance's `__dict__`, but other non-data descriptors might do things differently.
        if isinstance(attr, cached_property):
            return _SIMPLE_SETATTR_HANDLERS['cached_property']
    
        _check_frozen(cls, name, value)
    
        # We allow properties to be set only on non frozen models for now (to match dataclasses).
        # This can be changed if it ever gets requested.
        if isinstance(attr, property):
            return lambda model, _name, val: attr.__set__(model, val)
        elif cls.model_config.get('validate_assignment'):
            return _SIMPLE_SETATTR_HANDLERS['validate_assignment']
        elif name not in cls.__pydantic_fields__:
            if cls.model_config.get('extra') != 'allow':
                # TODO - matching error
>               raise ValueError(f'"{cls.__name__}" object has no field "{name}"')
E               ValueError: "Settings" object has no field "max_position_size"

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1044: ValueError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:26,980", "level": "INFO", "name": "ai_trading.main", "msg": "DATA_CONFIG feed=iex adjustment=all timeframe=1Day/1Min provider=alpaca", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:26,981", "level": "INFO", "name": "ai_trading.position_sizing", "msg": "CONFâ€¦OFIX", "field": "max_position_size", "given": 0.0, "fallback": 8000.0, "reason": "derived_equity_cap", "equity": null, "capital_cap": 0.04, "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:26,981", "level": "CRITICAL", "name": "ai_trading.main", "msg": "RUNTâ€¦ALID", "error": "\"Settings\" object has no field \"max_position_size\"", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.main:main.py:335 DATA_CONFIG feed=iex adjustment=all timeframe=1Day/1Min provider=alpaca
INFO     ai_trading.position_sizing:position_sizing.py:60 CONFâ€¦OFIX
CRITICAL ai_trading.main:main.py:343 RUNTâ€¦ALID
____________________________________________ test_pdt_rule_skips_without_false_fail ____________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7f3d45f0f250>

    def test_pdt_rule_skips_without_false_fail(caplog):
        # AI-AGENT-REF: verify PDT check logs skip and not failure
        ctx = SimpleNamespace(api=None)
        with caplog.at_level(logging.INFO):
>           assert check_pdt_rule(ctx) is False
E           assert namespace(api=None) is False
E            +  where namespace(api=None) = check_pdt_rule(namespace(api=None))

tests/test_broker_unavailable_paths.py:17: AssertionError
____________________________________ TestEllipsisFix.test_update_risk_engine_exposure_error ____________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_ellipsis_fix.TestEllipsisFix testMethod=test_update_risk_engine_exposure_error>

    def test_update_risk_engine_exposure_error(self):
        """Test risk exposure update handles errors gracefully."""
        with patch('ai_trading.core.bot_engine._get_runtime_context_or_none') as mock_get_ctx:
            with patch('ai_trading.core.bot_engine._log') as mock_log:
                # Setup mock context with failing risk engine
                mock_context = Mock()
                mock_risk_engine = Mock()
                mock_risk_engine.update_exposure.side_effect = Exception("Update failed")
                mock_context.risk_engine = mock_risk_engine
                mock_get_ctx.return_value = mock_context
    
                _update_risk_engine_exposure()
    
                # Should log warning about failure
>               mock_log.warning.assert_called_once()

tests/test_ellipsis_fix.py:154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='_log.warning' id='140684884164048'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'warning' to have been called once. Called 0 times.

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:918: AssertionError
_______________________________ TestEllipsisFix.test_update_risk_engine_exposure_no_risk_engine ________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_ellipsis_fix.TestEllipsisFix testMethod=test_update_risk_engine_exposure_no_risk_engine>

    def test_update_risk_engine_exposure_no_risk_engine(self):
        """Test risk exposure update handles missing risk engine gracefully."""
        with patch('ai_trading.core.bot_engine._get_runtime_context_or_none') as mock_get_ctx:
            with patch('ai_trading.core.bot_engine._log') as mock_log:
                # Setup mock context without risk engine
                mock_context = Mock()
                mock_context.risk_engine = None
                mock_get_ctx.return_value = mock_context
    
                _update_risk_engine_exposure()
    
                # Should log debug message about missing risk engine
                mock_log.debug.assert_called_once()
>               self.assertIn("No risk_engine", str(mock_log.debug.call_args))
E               AssertionError: 'No risk_engine' not found in "call('Skipping exposure update: runtime not ready')"

tests/test_ellipsis_fix.py:138: AssertionError
________________________________ TestEllipsisFix.test_update_risk_engine_exposure_with_context _________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_ellipsis_fix.TestEllipsisFix testMethod=test_update_risk_engine_exposure_with_context>

    def test_update_risk_engine_exposure_with_context(self):
        """Test risk exposure update works with valid context."""
        with patch('ai_trading.core.bot_engine._get_runtime_context_or_none') as mock_get_ctx:
            with patch('ai_trading.core.bot_engine._log'):
                # Setup mock context with risk engine
                mock_context = Mock()
                mock_risk_engine = Mock()
                mock_context.risk_engine = mock_risk_engine
                mock_get_ctx.return_value = mock_context
    
                _update_risk_engine_exposure()
    
                # Verify risk engine update_exposure was called
>               mock_risk_engine.update_exposure.assert_called_once_with(mock_context)

tests/test_ellipsis_fix.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Mock name='_get_runtime_context_or_none().risk_engine.update_exposure' id='140684883619472'>
args = (<Mock name='_get_runtime_context_or_none()' id='140684888641104'>,), kwargs = {}
msg = "Expected 'update_exposure' to be called once. Called 0 times."

    def assert_called_once_with(self, /, *args, **kwargs):
        """assert that the mock was called exactly once and that that call was
        with the specified arguments."""
        if not self.call_count == 1:
            msg = ("Expected '%s' to be called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'update_exposure' to be called once. Called 0 times.

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:950: AssertionError
______________________________________________ test_fetch_minute_df_safe_no_retry ______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d854d9dd0>

    def test_fetch_minute_df_safe_no_retry(monkeypatch):
        calls = []
    
        def fake_get(sym, start, end):
            calls.append(1)
            return pd.DataFrame({"close": [1]}, index=[pd.Timestamp("2023-01-01")])
    
        monkeypatch.setattr("ai_trading.core.bot_engine.get_minute_df", fake_get)
>       result = fetch_minute_df_safe("AAPL")

tests/test_data_fetcher.py:246: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:2060: in fetch_minute_df_safe
    _ensure_data_fresh(symbols=[symbol], max_age_seconds=600)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

symbols = ['AAPL'], max_age_seconds = 600

    def _ensure_data_fresh(symbols, max_age_seconds: int) -> None:
        """
        Validate that the cached minute data for each symbol is recent enough.
        Logs UTC timestamps and fails fast if any symbol is stale.
        """
        try:
>           from ai_trading.data_fetcher import last_minute_bar_age_seconds
E           ImportError: cannot import name 'last_minute_bar_age_seconds' from 'ai_trading.data_fetcher' (unknown location)

ai_trading/core/bot_engine.py:5792: ImportError
____________________________________________________ test_utils_edge_cases _____________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_utils_edge_cases0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3944f10>

    def test_utils_edge_cases(tmp_path, monkeypatch):
        """Cover utility helper edge cases."""
        # AI-AGENT-REF: Ensure FORCE_MARKET_OPEN doesn't interfere with market hours test
        monkeypatch.setenv("FORCE_MARKET_OPEN", "false")
    
        assert utils.get_latest_close(pd.DataFrame()) == 0.0
        df = pd.DataFrame({"close": [np.nan]})
>       assert utils.get_latest_close(df) == 0.0

tests/test_additional_coverage.py:318: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/utils/__init__.py:118: in get_latest_close
    val = float(df["close"].dropna().iloc[-1])
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/core/indexing.py:1191: in __getitem__
    return self._getitem_axis(maybe_callable, axis=axis)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/core/indexing.py:1752: in _getitem_axis
    self._validate_integer(key, axis)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pandas.core.indexing._iLocIndexer object at 0x7ff8d353c5f0>, key = -1, axis = 0

    def _validate_integer(self, key: int | np.integer, axis: AxisInt) -> None:
        """
        Check that 'key' is a valid position in the desired axis.
    
        Parameters
        ----------
        key : int
            Requested position.
        axis : int
            Desired axis.
    
        Raises
        ------
        IndexError
            If 'key' is not a valid position in axis 'axis'.
        """
        len_axis = len(self.obj._get_axis(axis))
        if key >= len_axis or key < -len_axis:
>           raise IndexError("single positional indexer is out-of-bounds")
E           IndexError: single positional indexer is out-of-bounds

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/core/indexing.py:1685: IndexError
____________________________________________________ test_validate_env_main ____________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

mod_name = 'validate_env', error = <class 'ImportError'>

>   ???

<frozen runpy>:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'validate_env', package = None

>   ???
E   ValueError: validate_env.__spec__ is None

<frozen importlib.util>:115: ValueError

The above exception was the direct cause of the following exception:

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d39255d0>

    def test_validate_env_main(monkeypatch):
        """Running validate_env as script calls _main."""
        # AI-AGENT-REF: Mock environment variables to ensure validation passes
        monkeypatch.setenv(
            "WEBHOOK_SECRET",
            "fake_test_webhook_secret_that_is_at_least_32_characters_long_for_security_not_real",
        )
        monkeypatch.setenv(
            "ALPACA_API_KEY", "FAKE_TEST_API_KEY_NOT_REAL_123456789012345"
        )  # Realistic length
        monkeypatch.setenv(
            "ALPACA_SECRET_KEY",
            "FAKE_TEST_SECRET_KEY_NOT_REAL_123456789012345678901234567890ABCDEFGHIJKLMN",
        )  # Realistic length
        monkeypatch.setenv("ALPACA_BASE_URL", "https://paper-api.alpaca.markets")
    
        # AI-AGENT-REF: Clear sys.argv to prevent pytest args from interfering with validate_env argument parsing
        original_argv = sys.argv[:]
        try:
            sys.argv = ["validate_env"]  # Simulate clean module execution
>           runpy.run_module("validate_env", run_name="__main__")

tests/test_additional_coverage.py:350: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
<frozen runpy>:222: in run_module
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

mod_name = 'validate_env', error = <class 'ImportError'>

>   ???
E   ImportError: Error while finding module specification for 'validate_env' (ValueError: validate_env.__spec__ is None)

<frozen runpy>:140: ImportError
_________________________________________________ test_submit_order_http_error _________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_submit_order_http_error():
        def submit_order(**_):
            raise HTTPError(500)
    
        api = types.SimpleNamespace(submit_order=submit_order)
>       res = alpaca_api.submit_order(api, symbol="AAPL", qty=1, side="buy")

tests/test_alpaca_api_extended.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:301: in submit_order
    resp = submit_fn(**payload)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

_ = {'client_order_id': 'ai-1755884247437-5aedfbc4', 'qty': 1, 'side': 'buy', 'symbol': 'AAPL', ...}

    def submit_order(**_):
>       raise HTTPError(500)
E       tests.test_alpaca_api_extended.HTTPError: 500

tests/test_alpaca_api_extended.py:13: HTTPError
_______________________________________________ test_submit_order_generic_error ________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_submit_order_generic_error():
        def submit_order(**_):
            raise Exception("boom")
    
        api = types.SimpleNamespace(submit_order=submit_order)
>       res = alpaca_api.submit_order(api, symbol="AAPL", qty=1, side="buy")

tests/test_alpaca_api_extended.py:27: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:301: in submit_order
    resp = submit_fn(**payload)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

_ = {'client_order_id': 'ai-1755884247458-6848049c', 'qty': 1, 'side': 'buy', 'symbol': 'AAPL', ...}

    def submit_order(**_):
>       raise Exception("boom")
E       Exception: boom

tests/test_alpaca_api_extended.py:24: Exception
_________________________________________________ test_submit_order_rate_limit _________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d81be550>

    def test_submit_order_rate_limit(monkeypatch):
        monkeypatch.setattr(alpaca_api, "SHADOW_MODE", False)
        api = DummyAPI(fail_status=429)
>       res = alpaca_api.submit_order(api, symbol="AAPL", qty=1, side="buy")

tests/test_alpaca_api_module.py:40: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:301: in submit_order
    resp = submit_fn(**payload)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tests.test_alpaca_api_module.DummyAPI object at 0x7ff8d39546d0>
order_data = {'client_order_id': 'ai-1755884247482-82f63bc8', 'qty': 1, 'side': 'buy', 'symbol': 'AAPL', ...}
err = Exception('fail')

    def submit_order(self, **order_data):
        self.calls += 1
        if self.fail_status and self.calls == 1:
            err = Exception("fail")
            err.status = self.fail_status
>           raise err
E           Exception: fail

tests/test_alpaca_api_module.py:16: Exception
____________________________________________ test_ai_trading_import_without_alpaca _____________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_ai_trading_import_without_alpaca():
        """Test that ai_trading can be imported even when alpaca packages are missing."""
        # Remove alpaca modules from sys.modules to simulate missing packages
        alpaca_modules = [module for module in sys.modules.keys() if 'alpaca' in module.lower()]
        for module in alpaca_modules:
            sys.modules.pop(module, None)
    
        # Simulate missing alpaca packages by setting them to None
        sys.modules['alpaca_trade_api'] = None
        sys.modules['alpaca.trading'] = None
        sys.modules['alpaca.data'] = None
        sys.modules['alpaca'] = None
    
        # Set testing mode
        import os
        os.environ['TESTING'] = 'true'
    
        try:
            # This should not raise an exception
            import ai_trading
            import ai_trading.core.bot_engine
    
            # Check that ALPACA_AVAILABLE is False
            assert hasattr(ai_trading.core.bot_engine, 'ALPACA_AVAILABLE')
>           assert ai_trading.core.bot_engine.ALPACA_AVAILABLE is False
E           AssertionError: assert True is False
E            +  where True = <module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'>.ALPACA_AVAILABLE
E            +    where <module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'> = <module 'ai_trading.core' from '/workspace/ai-trading-bot/ai_trading/core/__init__.py'>.bot_engine
E            +      where <module 'ai_trading.core' from '/workspace/ai-trading-bot/ai_trading/core/__init__.py'> = <module 'ai_trading' from '/workspace/ai-trading-bot/ai_trading/__init__.py'>.core

tests/test_alpaca_import.py:30: AssertionError
____________________________________________ test_disable_daily_retrain_env_parsing ____________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_disable_daily_retrain_env_parsing():
        """Test DISABLE_DAILY_RETRAIN parsing for various values."""
        test_cases = [
            ("true", True),
            ("True", True),
            ("TRUE", True),
            ("1", True),
            ("false", False),
            ("False", False),
            ("FALSE", False),
            ("0", False),
            ("", False),  # empty string should default to False
            ("invalid", False),  # invalid values should default to False
        ]
    
        for env_value, expected in test_cases:
            # Set the environment variable
            os.environ["DISABLE_DAILY_RETRAIN"] = env_value
            os.environ["TESTING"] = "1"  # Enable testing mode
    
            # Clear module cache to force re-import
            if 'config' in os.sys.modules:
                del os.sys.modules['config']
    
            # Import config module
            from ai_trading import config
    
            # Test the result
>           actual = config.DISABLE_DAILY_RETRAIN

tests/test_env_flags.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'DISABLE_DAILY_RETRAIN'

    def __getattr__(name: str):  # AI-AGENT-REF: lazy export for TradingConfig
        if name == "TradingConfig":
            from .management import TradingConfig as _TC
            return _TC
>       raise AttributeError(name)
E       AttributeError: DISABLE_DAILY_RETRAIN

ai_trading/config/__init__.py:46: AttributeError
___________________________ TestEnvironmentOrderAndLazyImport.test_env_loaded_multiple_times_safely ____________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7ff8d818c7d0>

    def test_env_loaded_multiple_times_safely(self):
        """Test that loading .env multiple times is safe."""
        # Create temp .env with test values
        with tempfile.NamedTemporaryFile(mode='w', suffix='.env', delete=False) as f:
            f.write("MULTI_LOAD_TEST=safe_value\n")
            temp_env_path = f.name
    
        try:
            # Clear environment
            os.environ.pop('MULTI_LOAD_TEST', None)
    
            # Mock load_dotenv to use our temp file
            def mock_load_side_effect(*args, **kwargs):
                with open(temp_env_path) as env_file:
                    for line in env_file:
                        if '=' in line and not line.startswith('#'):
                            key, value = line.strip().split('=', 1)
                            os.environ[key] = value
    
            with patch('dotenv.load_dotenv', side_effect=mock_load_side_effect):
                # Load multiple times (simulating multiple imports)
                from ai_trading.main import load_dotenv
                load_dotenv(override=True)  # First load
                load_dotenv(override=True)  # Second load
                load_dotenv(override=True)  # Third load
    
                # Should still have the correct value
>               assert os.environ.get('MULTI_LOAD_TEST') == 'safe_value'
E               AssertionError: assert None == 'safe_value'
E                +  where None = get('MULTI_LOAD_TEST')
E                +    where get = environ({'COREPACK_ENABLE_AUTO_PIN': '0', 'PYENV_HOOK_PATH': '/root/.pyenv/pyenv.d:/usr/etc/pyenv.d:/usr/local/etc/pye...stEnvironmentOrderAndLazyImport::test_env_loaded_multiple_times_safely (call)', 'AI_TRADER_OFFLINE': '1', 'TZ': 'UTC'}).get
E                +      where environ({'COREPACK_ENABLE_AUTO_PIN': '0', 'PYENV_HOOK_PATH': '/root/.pyenv/pyenv.d:/usr/etc/pyenv.d:/usr/local/etc/pye...stEnvironmentOrderAndLazyImport::test_env_loaded_multiple_times_safely (call)', 'AI_TRADER_OFFLINE': '1', 'TZ': 'UTC'}) = os.environ

tests/test_env_order_and_lazy_import.py:210: AssertionError
_______________________________________________ test_disable_daily_retrain_unset _______________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_disable_daily_retrain_unset():
        """Test DISABLE_DAILY_RETRAIN when environment variable is unset."""
        # Remove the environment variable if it exists
        if "DISABLE_DAILY_RETRAIN" in os.environ:
            del os.environ["DISABLE_DAILY_RETRAIN"]
    
        os.environ["TESTING"] = "1"  # Enable testing mode
    
        # Clear module cache
        if 'config' in os.sys.modules:
            del os.sys.modules['config']
    
        # Import config module
        from ai_trading import config
    
        # Should default to False
>       assert config.DISABLE_DAILY_RETRAIN is False

tests/test_env_flags.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'DISABLE_DAILY_RETRAIN'

    def __getattr__(name: str):  # AI-AGENT-REF: lazy export for TradingConfig
        if name == "TradingConfig":
            from .management import TradingConfig as _TC
            return _TC
>       raise AttributeError(name)
E       AttributeError: DISABLE_DAILY_RETRAIN

ai_trading/config/__init__.py:46: AttributeError
______________________________ TestEnvironmentOrderAndLazyImport.test_lazy_import_error_handling _______________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7ff8d8062d90>

    def test_lazy_import_error_handling(self):
        """Test that lazy import handles import errors gracefully."""
        from ai_trading import runner
    
        # Reset cache
        runner._bot_engine = None
        runner._bot_state_class = None
    
        with patch('ai_trading.core.bot_engine.run_all_trades_worker', side_effect=ImportError("Mock import error")):
>           with pytest.raises(RuntimeError) as exc_info:
E           Failed: DID NOT RAISE <class 'RuntimeError'>

tests/test_env_order_and_lazy_import.py:239: Failed
_________________________________________ test_disable_daily_retrain_fallback_settings _________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_disable_daily_retrain_fallback_settings():
        """Test DISABLE_DAILY_RETRAIN through fallback settings."""
        # Test the fallback _FallbackSettings class directly
        if 'config' in os.sys.modules:
            del os.sys.modules['config']
    
        os.environ["TESTING"] = "1"
        os.environ["DISABLE_DAILY_RETRAIN"] = "true"
    
        from ai_trading import config
    
        # Check that fallback settings work
>       fallback = config._FallbackSettings()

tests/test_env_flags.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = '_FallbackSettings'

    def __getattr__(name: str):  # AI-AGENT-REF: lazy export for TradingConfig
        if name == "TradingConfig":
            from .management import TradingConfig as _TC
            return _TC
>       raise AttributeError(name)
E       AttributeError: _FallbackSettings

ai_trading/config/__init__.py:46: AttributeError
______________________ TestEnvironmentOrderAndLazyImport.test_dotenv_loaded_before_settings_construction _______________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7ff3c0ede550>

    def test_dotenv_loaded_before_settings_construction(self):
        """Test that .env is loaded before Settings is constructed."""
        # Create a temporary .env file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.env', delete=False) as f:
            f.write("TEST_DOTENV_ORDER=loaded_early\n")
            f.write("ALPACA_API_KEY=test_from_dotenv\n")
            temp_env_path = f.name
    
        try:
            # Clear any existing env var
            if 'TEST_DOTENV_ORDER' in os.environ:
                del os.environ['TEST_DOTENV_ORDER']
            if 'ALPACA_API_KEY' in os.environ:
                del os.environ['ALPACA_API_KEY']
    
            # Mock dotenv.load_dotenv to load our temp file
            with patch('dotenv.load_dotenv') as mock_load_dotenv:
                def side_effect(*args, **kwargs):
                    # Simulate loading the .env file
                    with open(temp_env_path) as env_file:
                        for line in env_file:
                            if '=' in line and not line.startswith('#'):
                                key, value = line.strip().split('=', 1)
                                os.environ[key] = value
    
                mock_load_dotenv.side_effect = side_effect
    
                # Import main module (this should load .env before Settings)
    
                # Verify .env was loaded before Settings construction
>               mock_load_dotenv.assert_called()

tests/test_env_order_and_lazy_import.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='load_dotenv' id='140684884540048'>

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
>           raise AssertionError(msg)
E           AssertionError: Expected 'load_dotenv' to have been called.

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:908: AssertionError
_________________________ TestEnvironmentOrderAndLazyImport.test_lazy_engine_loading_caches_components _________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7ff3c0eddf10>

    def test_lazy_engine_loading_caches_components(self):
        """Test that engine components are cached after first load."""
        from ai_trading import runner
    
        # Reset the lazy import cache
        runner._bot_engine = None
        runner._bot_state_class = None
    
        with patch('ai_trading.core.bot_engine.run_all_trades_worker') as mock_worker:
            with patch('ai_trading.core.bot_engine.BotState') as mock_state:
                mock_worker.return_value = "cached_worker"
                mock_state.return_value = "cached_state"
    
                # First call should import
                worker1, state1 = runner._load_engine()
    
                # Second call should use cached values
                worker2, state2 = runner._load_engine()
    
                # Should be the same objects
>               assert worker1 == worker2 == "cached_worker"
E               AssertionError: assert <MagicMock name='run_all_trades_worker' id='140684884148176'> == 'cached_worker'

tests/test_env_order_and_lazy_import.py:130: AssertionError
____________________________________________________ test_critical_imports _____________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_critical_imports():
        """Test that all critical modules can be imported without errors."""
        critical_modules = ["bot_engine", "data_fetcher", "signals", "risk_engine", "trade_execution"]
        failed_imports = []
    
        for module_name in critical_modules:
            try:
                __import__(module_name)
            except ImportError as e:
                failed_imports.append((module_name, str(e)))
    
        if failed_imports:
            fail_msg = "Failed to import critical modules: " + ", ".join(f"{mod} ({err})" for mod, err in failed_imports)
            logger.error(fail_msg)
>           raise ImportError(fail_msg)
E           ImportError: Failed to import critical modules: data_fetcher (cannot import name 'ConnectionError' from 'requests.exceptions' (unknown location)), signals (No module named 'cachetools')

tests/test_coverage_hack.py:40: ImportError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:27,658", "level": "ERROR", "name": "tests.test_coverage_hack", "msg": "Failed to import critical modules: dataâ€¦cher (cannot import name 'Connâ€¦rror' from 'requests.exceptions' (unknown location)), signals (No module named 'cachetools')", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.logging:data_fetcher.py:64 HTTP_INIT_PRIMARY
ERROR    tests.test_coverage_hack:test_coverage_hack.py:39 Failed to import critical modules: dataâ€¦cher (cannot import name 'Connâ€¦rror' from 'requests.exceptions' (unknown location)), signals (No module named 'cachetools')
______________________________ TestDatetimeTimezoneAwareness.test_alpaca_api_format_compatibility ______________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_datetime_fixes.TestDatetimeTimezoneAwareness testMethod=test_alpaca_api_format_compatibility>

    def test_alpaca_api_format_compatibility(self):
        """Test that datetime format is compatible with Alpaca API RFC3339 requirements."""
>       from ai_trading.data_fetcher import ensure_datetime
E       ImportError: cannot import name 'ensure_datetime' from 'ai_trading.data_fetcher' (unknown location)

tests/test_critical_datetime_fixes.py:34: ImportError
__________________________ TestDatetimeTimezoneAwareness.test_ensure_datetime_returns_timezone_aware ___________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_datetime_fixes.TestDatetimeTimezoneAwareness testMethod=test_ensure_datetime_returns_timezone_aware>

    def test_ensure_datetime_returns_timezone_aware(self):
        """Test that ensure_datetime returns timezone-aware datetime objects."""
>       from ai_trading.data_fetcher import ensure_datetime
E       ImportError: cannot import name 'ensure_datetime' from 'ai_trading.data_fetcher' (unknown location)

tests/test_critical_datetime_fixes.py:23: ImportError
_________________________________________________ test_equity_curve_monotonic __________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_equity_curve_monotonic():
>       df = pd.read_csv("data/last_equity.txt", names=["equity"])

tests/test_equity_curve.py:5: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026: in read_csv
    return _read(filepath_or_buffer, kwds)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620: in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620: in __init__
    self._engine = self._make_engine(f, self.engine)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880: in _make_engine
    self.handles = get_handle(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path_or_buf = 'data/last_equity.txt', mode = 'r'

    @doc(compression_options=_shared_docs["compression_options"] % "path_or_buf")
    def get_handle(
        path_or_buf: FilePath | BaseBuffer,
        mode: str,
        *,
        encoding: str | None = None,
        compression: CompressionOptions | None = None,
        memory_map: bool = False,
        is_text: bool = True,
        errors: str | None = None,
        storage_options: StorageOptions | None = None,
    ) -> IOHandles[str] | IOHandles[bytes]:
        """
        Get file handle for given path/buffer and mode.
    
        Parameters
        ----------
        path_or_buf : str or file handle
            File path or object.
        mode : str
            Mode to open path_or_buf with.
        encoding : str or None
            Encoding to use.
        {compression_options}
    
               May be a dict with key 'method' as compression mode
               and other keys as compression options if compression
               mode is 'zip'.
    
               Passing compression options as keys in dict is
               supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.
    
            .. versionchanged:: 1.4.0 Zstandard support.
    
        memory_map : bool, default False
            See parsers._parser_params for more information. Only used by read_csv.
        is_text : bool, default True
            Whether the type of the content passed to the file/buffer is string or
            bytes. This is not the same as `"b" not in mode`. If a string content is
            passed to a binary file/buffer, a wrapper is inserted.
        errors : str, default 'strict'
            Specifies how encoding and decoding errors are to be handled.
            See the errors argument for :func:`open` for a full list
            of options.
        storage_options: StorageOptions = None
            Passed to _get_filepath_or_buffer
    
        Returns the dataclass IOHandles
        """
        # Windows does not default to utf-8. Set to utf-8 for a consistent behavior
        encoding = encoding or "utf-8"
    
        errors = errors or "strict"
    
        # read_csv does not know whether the buffer is opened in binary/text mode
        if _is_binary_mode(path_or_buf, mode) and "b" not in mode:
            mode += "b"
    
        # validate encoding and errors
        codecs.lookup(encoding)
        if isinstance(errors, str):
            codecs.lookup_error(errors)
    
        # open URLs
        ioargs = _get_filepath_or_buffer(
            path_or_buf,
            encoding=encoding,
            compression=compression,
            mode=mode,
            storage_options=storage_options,
        )
    
        handle = ioargs.filepath_or_buffer
        handles: list[BaseBuffer]
    
        # memory mapping needs to be the first step
        # only used for read_csv
        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)
    
        is_path = isinstance(handle, str)
        compression_args = dict(ioargs.compression)
        compression = compression_args.pop("method")
    
        # Only for write methods
        if "r" not in mode and is_path:
            check_parent_directory(str(handle))
    
        if compression:
            if compression != "zstd":
                # compression libraries do not like an explicit text-mode
                ioargs.mode = ioargs.mode.replace("t", "")
            elif compression == "zstd" and "b" not in ioargs.mode:
                # python-zstandard defaults to text mode, but we always expect
                # compression libraries to use binary mode.
                ioargs.mode += "b"
    
            # GZ Compression
            if compression == "gzip":
                if isinstance(handle, str):
                    # error: Incompatible types in assignment (expression has type
                    # "GzipFile", variable has type "Union[str, BaseBuffer]")
                    handle = gzip.GzipFile(  # type: ignore[assignment]
                        filename=handle,
                        mode=ioargs.mode,
                        **compression_args,
                    )
                else:
                    handle = gzip.GzipFile(
                        # No overload variant of "GzipFile" matches argument types
                        # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                        fileobj=handle,  # type: ignore[call-overload]
                        mode=ioargs.mode,
                        **compression_args,
                    )
    
            # BZ Compression
            elif compression == "bz2":
                # Overload of "BZ2File" to handle pickle protocol 5
                # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                handle = get_bz2_file()(  # type: ignore[call-overload]
                    handle,
                    mode=ioargs.mode,
                    **compression_args,
                )
    
            # ZIP Compression
            elif compression == "zip":
                # error: Argument 1 to "_BytesZipFile" has incompatible type
                # "Union[str, BaseBuffer]"; expected "Union[Union[str, PathLike[str]],
                # ReadBuffer[bytes], WriteBuffer[bytes]]"
                handle = _BytesZipFile(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
                if handle.buffer.mode == "r":
                    handles.append(handle)
                    zip_names = handle.buffer.namelist()
                    if len(zip_names) == 1:
                        handle = handle.buffer.open(zip_names.pop())
                    elif not zip_names:
                        raise ValueError(f"Zero files found in ZIP file {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in ZIP file. "
                            f"Only one file per ZIP: {zip_names}"
                        )
    
            # TAR Encoding
            elif compression == "tar":
                compression_args.setdefault("mode", ioargs.mode)
                if isinstance(handle, str):
                    handle = _BytesTarFile(name=handle, **compression_args)
                else:
                    # error: Argument "fileobj" to "_BytesTarFile" has incompatible
                    # type "BaseBuffer"; expected "Union[ReadBuffer[bytes],
                    # WriteBuffer[bytes], None]"
                    handle = _BytesTarFile(
                        fileobj=handle, **compression_args  # type: ignore[arg-type]
                    )
                assert isinstance(handle, _BytesTarFile)
                if "r" in handle.buffer.mode:
                    handles.append(handle)
                    files = handle.buffer.getnames()
                    if len(files) == 1:
                        file = handle.buffer.extractfile(files[0])
                        assert file is not None
                        handle = file
                    elif not files:
                        raise ValueError(f"Zero files found in TAR archive {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in TAR archive. "
                            f"Only one file per TAR archive: {files}"
                        )
    
            # XZ Compression
            elif compression == "xz":
                # error: Argument 1 to "LZMAFile" has incompatible type "Union[str,
                # BaseBuffer]"; expected "Optional[Union[Union[str, bytes, PathLike[str],
                # PathLike[bytes]], IO[bytes]], None]"
                handle = get_lzma_file()(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
    
            # Zstd Compression
            elif compression == "zstd":
                zstd = import_optional_dependency("zstandard")
                if "r" in ioargs.mode:
                    open_args = {"dctx": zstd.ZstdDecompressor(**compression_args)}
                else:
                    open_args = {"cctx": zstd.ZstdCompressor(**compression_args)}
                handle = zstd.open(
                    handle,
                    mode=ioargs.mode,
                    **open_args,
                )
    
            # Unrecognized Compression
            else:
                msg = f"Unrecognized compression type: {compression}"
                raise ValueError(msg)
    
            assert not isinstance(handle, str)
            handles.append(handle)
    
        elif isinstance(handle, str):
            # Check whether the filename is to be opened in binary mode.
            # Binary mode does not support 'encoding' and 'newline'.
            if ioargs.encoding and "b" not in ioargs.mode:
                # Encoding
>               handle = open(
                    handle,
                    ioargs.mode,
                    encoding=ioargs.encoding,
                    errors=errors,
                    newline="",
                )
E               FileNotFoundError: [Errno 2] No such file or directory: 'data/last_equity.txt'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/common.py:873: FileNotFoundError
_________________________________________________ test_executor_env_validation _________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_executor_env_validation():
        """Test that environment variable parsing handles edge cases."""
        test_cases = [
            ("", 0),      # Empty string
            ("0", 0),     # Zero
            ("1", 1),     # Valid number
            ("10", 10),   # Valid number
            ("invalid", 0),  # Invalid should default to 0 (fallback to auto-size)
        ]
    
        for env_val, expected in test_cases:
            os.environ["EXECUTOR_WORKERS"] = env_val
    
>           _exec_env = int(os.getenv("EXECUTOR_WORKERS", "0") or "0")
E           ValueError: invalid literal for int() with base 10: 'invalid'

tests/test_executors_sizing.py:119: ValueError
_________________________________________________ test_daily_fallback_parallel _________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3761910>

    def test_daily_fallback_parallel(monkeypatch):
        # Force batch to return empty so we hit fallback path for all.
        ctx = types.SimpleNamespace()
        calls = {"single": []}
        monkeypatch.setattr(be, "get_bars_batch", lambda *a, **k: {})
        def fake_single(sym, *a, **k):
            calls["single"].append(sym)
            return _mk_df()
        monkeypatch.setattr(be, "get_bars", fake_single)
        out = be._fetch_universe_bars(ctx, ["A","B","C","D"], "1D", "2024-01-01", "2024-02-01", None)
>       assert set(out.keys()) == {"A","B","C","D"}
E       AssertionError: assert set() == {'A', 'B', 'C', 'D'}
E         
E         Extra items in the right set:
E         'A'
E         'C'
E         'D'
E         'B'
E         Use -v to get more diff

tests/test_fallback_concurrency.py:27: AssertionError
________________________________________________ test_parallel_execution_timing ________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d857cf10>

    def test_parallel_execution_timing(monkeypatch):
        """Test that parallel execution provides performance benefit."""
        ctx = types.SimpleNamespace()
        call_times = []
    
        monkeypatch.setattr(be, "get_bars_batch", lambda *a, **k: {})
    
        def slow_single(sym, *a, **k):
            # Simulate slow API call
            time.sleep(0.1)
            call_times.append((sym, time.time()))
            return _mk_df()
    
        monkeypatch.setattr(be, "get_bars", slow_single)
    
        # Test with 4 symbols that should run in parallel
        start_time = time.time()
        out = be._fetch_universe_bars(ctx, ["A","B","C","D"], "1D", "2024-01-01", "2024-02-01", None)
        end_time = time.time()
    
        # Should complete faster than sequential (0.4s) due to parallelism
        # Allow some overhead but should be significantly faster than sequential
        assert end_time - start_time < 0.3, f"Parallel execution took {end_time - start_time:.2f}s, expected < 0.3s"
>       assert len(out) == 4
E       assert 0 == 4
E        +  where 0 = len({})

tests/test_fallback_concurrency.py:66: AssertionError
___________________________________________ test_bounded_concurrency_respects_limit ____________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3f15d90>

    def test_bounded_concurrency_respects_limit(monkeypatch):
        """Test that the worker limit is respected."""
        ctx = types.SimpleNamespace()
        active_workers = []
        max_concurrent = 0
    
        # Mock settings to use only 2 workers
        def mock_get_settings():
            settings = types.SimpleNamespace()
            settings.batch_fallback_workers = 2
            return settings
    
        monkeypatch.setattr(be, "get_settings", mock_get_settings)
        monkeypatch.setattr(be, "get_bars_batch", lambda *a, **k: {})
    
        def track_concurrent(sym, *a, **k):
            thread_id = threading.current_thread().ident
            active_workers.append(thread_id)
    
            nonlocal max_concurrent
            current_count = len(set(active_workers))
            max_concurrent = max(max_concurrent, current_count)
    
            time.sleep(0.1)  # Simulate work
            return _mk_df()
    
        monkeypatch.setattr(be, "get_bars", track_concurrent)
    
        # Test with 6 symbols but limit to 2 workers
        out = be._fetch_universe_bars(ctx, ["A","B","C","D","E","F"], "1D", "2024-01-01", "2024-02-01", None)
    
>       assert len(out) == 6
E       assert 0 == 6
E        +  where 0 = len({})

tests/test_fallback_concurrency.py:108: AssertionError
______________________________ TestEnvironmentOrderAndLazyImport.test_run_cycle_uses_lazy_loading ______________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7ff3c0eddd50>

    def test_run_cycle_uses_lazy_loading(self):
        """Test that run_cycle uses lazy loading for bot engine."""
        from ai_trading import runner
    
        # Reset lazy import cache
        runner._bot_engine = None
        runner._bot_state_class = None
    
        # Mock the components
        mock_worker = MagicMock()
        mock_state_class = MagicMock()
        mock_state_instance = MagicMock()
        mock_state_class.return_value = mock_state_instance
    
        with patch.object(runner, '_load_engine') as mock_load:
            mock_load.return_value = (mock_worker, mock_state_class)
    
            # Call run_cycle
            runner.run_cycle()
    
            # Verify lazy loading was called
            mock_load.assert_called_once()
    
            # Verify worker was called with state instance
>           mock_worker.assert_called_once_with(mock_state_instance, None)

tests/test_env_order_and_lazy_import.py:161: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock id='140684884132112'>, args = (<MagicMock name='mock()' id='140684883775888'>, None), kwargs = {}
msg = "Expected 'mock' to be called once. Called 0 times."

    def assert_called_once_with(self, /, *args, **kwargs):
        """assert that the mock was called exactly once and that that call was
        with the specified arguments."""
        if not self.call_count == 1:
            msg = ("Expected '%s' to be called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'mock' to be called once. Called 0 times.

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:950: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:27,665", "level": "WARNING", "name": "ai_trading.runner", "msg": "Failed to warm cache during state setup: 'Settings' object has no attribute 'dataâ€¦days'", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:27,666", "level": "WARNING", "name": "ai_trading.logging", "msg": "DEPRâ€¦LIAS", "alias": "BOT_MODE", "use": "TRADING_MODE", "value": "balanced", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:27,666", "level": "INFO", "name": "ai_trading.runner", "msg": "PARAâ€¦TIVE", "CAPITAL_CAP": 0.04, "DOLLAR_RISK_LIMIT": 0.05, "MAX_POSITION_SIZE": 8000.0, "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:27,669", "level": "INFO", "name": "ai_trading.logging", "msg": "ENV_â€¦AULT override=True", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:27,670", "level": "INFO", "name": "ai_trading.core.bot_engine", "msg": "ALPACA_DIAG", "initialized": true, "has_key": "***REDACTED***", "has_secret": "***REDACTED***", "base_url": "https://paper-api.alpaca.markets", "paper": true, "shadow_mode": true, "cwd": "/workspace/ai-trading-bot", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:27,670", "level": "INFO", "name": "ai_trading.core.bot_engine", "msg": "Risk engine: ai_trading.risk.engine.RiskEngine", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:27,671", "level": "INFO", "name": "ai_trading.logging", "msg": "Perfâ€¦ator initialized with 20 day window", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:27,671", "level": "INFO", "name": "ai_trading.logging", "msg": "Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:27,671", "level": "INFO", "name": "ai_trading.logging", "msg": "Loaded strategies: Momeâ€¦tegy", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:27,672", "level": "INFO", "name": "ai_trading.logging", "msg": "Drawâ€¦aker initialized", "max_drawdown": "8.00%", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:27,672", "level": "ERROR", "name": "ai_trading.core.bot_engine", "msg": "MODEâ€¦SING", "hint_paths": ["AI_TRADER_MODEL_PATH", "TradingConfig.ml_model_path"], "hint_modules": ["AI_TRADER_MODEL_MODULE", "TradingConfig.ml_model_module"], "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.runner:runner.py:148 Failed to warm cache during state setup: 'Settings' object has no attribute 'data_warmup_lookback_days'
WARNING  ai_trading.logging:__init__.py:293 DEPRâ€¦LIAS
INFO     ai_trading.runner:runner.py:169 PARAâ€¦TIVE
INFO     ai_trading.logging:__init__.py:293 ENV_â€¦AULT override=True
DEBUG    ai_trading.core.bot_engine:bot_engine.py:5315 Successfully imported Alpaca SDK classes
INFO     ai_trading.core.bot_engine:bot_engine.py:5341 ALPACA_DIAG
INFO     ai_trading.core.bot_engine:bot_engine.py:550 Risk engine: ai_trading.risk.engine.RiskEngine
INFO     ai_trading.logging:performance_allocator.py:115 Perfâ€¦ator initialized with 20 day window
INFO     ai_trading.logging:__init__.py:293 Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate
INFO     ai_trading.logging:__init__.py:293 Loaded strategies: Momeâ€¦tegy
INFO     ai_trading.logging:emit_once.py:21 Drawâ€¦aker initialized
ERROR    ai_trading.core.bot_engine:bot_engine.py:531 MODEâ€¦SING
ERROR    ai_trading.runner:runner.py:187 Trading cycle failed: Model required but not configured. Set one of: AI_TRADER_MODEL_PATH=<abs path to .joblib/.pkl> or AI_TRADER_MODEL_MODULE=<import.path with get_model()/Model()>.
Traceback (most recent call last):
  File "/workspace/ai-trading-bot/ai_trading/runner.py", line 180, in run_cycle
    runtime = enhance_runtime_with_context(runtime, lazy_ctx)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/ai-trading-bot/ai_trading/core/runtime.py", line 112, in enhance_runtime_with_context
    runtime.api = getattr(lazy_context, 'api', None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/ai-trading-bot/ai_trading/core/bot_engine.py", line 5483, in api
    self._ensure_initialized()
  File "/workspace/ai-trading-bot/ai_trading/core/bot_engine.py", line 5453, in _ensure_initialized
    self._context.model = _load_required_model()
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/ai-trading-bot/ai_trading/core/bot_engine.py", line 538, in _load_required_model
    raise RuntimeError(msg)
RuntimeError: Model required but not configured. Set one of: AI_TRADER_MODEL_PATH=<abs path to .joblib/.pkl> or AI_TRADER_MODEL_MODULE=<import.path with get_model()/Model()>.
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 17:37:27,672", "level": "ERROR", "name": "ai_trading.runner", "msg": "Trading cycle failed: Model required but not configured. Set one of: AI_Tâ€¦PATH=<abs path to .joblib/.pkl> or AI_Tâ€¦DULE=<import.path with get_model()/Model()>.\nTraceback (most recent call last):\n  File \"/workspace/ai-tâ€¦-bot/ai_trading/runner.py\", line 180, in run_cycle\n    runtime = enhaâ€¦text(runtime, lazy_ctx)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/ai-tâ€¦-bot/ai_trading/core/runtime.py\", line 112, in enhaâ€¦text\n    runtime.api = getattr(lazyâ€¦text, 'api', None)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/ai-tâ€¦-bot/ai_trading/core/bot_engine.py\", line 5483, in api\n    self._ensâ€¦ized()\n  File \"/workspace/ai-tâ€¦-bot/ai_trading/core/bot_engine.py\", line 5453, in _ensâ€¦ized\n    self._context.model = _loaâ€¦odel()\n                          ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/ai-tâ€¦-bot/ai_trading/core/bot_engine.py\", line 538, in _loaâ€¦odel\n    raise Runtâ€¦rror(msg)\nRuntâ€¦rror: Model required but not configured. Set one of: AI_Tâ€¦PATH=<abs path to .joblib/.pkl> or AI_Tâ€¦DULE=<import.path with get_model()/Model()>.", "bot_phase": "GENERAL"}
_________________________________________________ test_fetch_fallback_to_daily _________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8eb3a7850>

    def test_fetch_fallback_to_daily(monkeypatch):
        df = _stub_df()
        monkeypatch.setattr(data_fetcher, "get_minute_df", lambda *a, **k: None)
>       monkeypatch.setattr(data_fetcher, "get_daily_df", lambda *a, **k: df)
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute 'get_daily_df'

tests/test_fetch_and_screen.py:24: AttributeError
___________________________________________________ test_get_bars_never_none ___________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3b85e10>

    def test_get_bars_never_none(monkeypatch):
        now = pd.Timestamp("2024-01-01", tz="UTC")
        df = pd.DataFrame(
            {
                "timestamp": [now],
                "open": [1.0],
                "high": [2.0],
                "low": [0.5],
                "close": [1.5],
                "volume": [100],
            }
        )
>       monkeypatch.setattr(
            data_fetcher,
            "_alpaca_get_bars",
            lambda client, symbol, start, end, timeframe="1Day": df,
        )
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute '_alpaca_get_bars'

tests/test_fetch_contract.py:34: AttributeError
_______________________________________________________ test_run_success _______________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

obj = <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'>, name = '_build_daily_url'
ann = 'ai_trading.data_fetcher'

    def annotated_getattr(obj: object, name: str, ann: str) -> object:
        try:
>           obj = getattr(obj, name)
E           AttributeError: module 'ai_trading.data_fetcher' has no attribute '_build_daily_url'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/_pytest/monkeypatch.py:90: AttributeError

The above exception was the direct cause of the following exception:

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3718790>

    def test_run_success(monkeypatch):
        urls_captured = []
        logged = []
    
        def fake_build(symbol, start, end):
            return f"https://example.com/{symbol}"
    
        def fake_map_get(urls, timeout=None):
            urls_captured.extend(urls)
            return [(u, 200, b"OK") for u in urls]
    
        def fake_info(msg, *args, **kwargs):
            logged.append((msg, kwargs.get("extra", {})))
    
>       monkeypatch.setattr("ai_trading.data_fetcher._build_daily_url", fake_build)

tests/test_fetch_sample_universe_cli.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/_pytest/monkeypatch.py:104: in derive_importpath
    annotated_getattr(target, attr, ann=module)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'>, name = '_build_daily_url'
ann = 'ai_trading.data_fetcher'

    def annotated_getattr(obj: object, name: str, ann: str) -> object:
        try:
            obj = getattr(obj, name)
        except AttributeError as e:
>           raise AttributeError(
                f"{type(obj).__name__!r} object at {ann} has no attribute {name!r}"
            ) from e
E           AttributeError: 'module' object at ai_trading.data_fetcher has no attribute '_build_daily_url'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/_pytest/monkeypatch.py:92: AttributeError
___________________________________________ test_fetch_minute_df_safe_handles_empty ____________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85397750>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7f8d859fd990>

    def test_fetch_minute_df_safe_handles_empty(monkeypatch, caplog):
        """fetch_minute_df_safe returns empty DataFrame without error."""  # AI-AGENT-REF
        monkeypatch.setattr("ai_trading.core.bot_engine.get_minute_df", lambda *a, **k: pd.DataFrame())
        caplog.set_level("INFO")
>       result = fetch_minute_df_safe("AAPL")

tests/test_data_fetcher.py:255: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

symbol = 'AAPL'

    def fetch_minute_df_safe(symbol: str) -> pd.DataFrame:
        """Fetch the last day of minute bars and raise on empty."""
        # AI-AGENT-REF: raise on empty DataFrame
        now_utc = datetime.now(UTC)
        start_dt = now_utc - timedelta(days=1)
    
        # AI-AGENT-REF: Cache wrapper (optional around fetch)
        if hasattr(CFG, "market_cache_enabled") and CFG.market_cache_enabled:
            try:
                from ai_trading.market.cache import get_or_load as _get_or_load
    
                cache_key = f"minute:{symbol}:{start_dt.isoformat()}"
                df = _get_or_load(
                    key=cache_key,
                    loader=lambda: get_minute_df(symbol, start_dt, now_utc),
                    ttl=getattr(S, "market_cache_ttl", 900),
                )
            except (
                FileNotFoundError,
                PermissionError,
                IsADirectoryError,
                JSONDecodeError,
                ValueError,
                KeyError,
                TypeError,
                OSError,
            ) as e:  # AI-AGENT-REF: narrow exception
                _log.debug("Cache layer unavailable/failed: %s", e)
                df = get_minute_df(symbol, start_dt, now_utc)
        else:
            df = get_minute_df(symbol, start_dt, now_utc)
    
        if df.empty:
            msg = "Minute bars DataFrame is empty after fallbacks; market likely closed"  # AI-AGENT-REF
            _log.warning(
                "FETCH_MINUTE_EMPTY",
                extra={"reason": "empty", "context": "market_closed"},
            )
>           raise DataFetchError(msg)
E           ai_trading.core.bot_engine.DataFetchError: Minute bars DataFrame is empty after fallbacks; market likely closed

ai_trading/core/bot_engine.py:2055: DataFetchError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:27,374", "level": "WARNING", "name": "ai_trading.core.bot_engine", "msg": "FETCâ€¦MPTY", "reason": "empty", "context": "market_closed", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.core.bot_engine:bot_engine.py:2051 FETCâ€¦MPTY
________________________ TestEnvironmentOrderAndLazyImport.test_main_loads_dotenv_before_runner_import _________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_env_order_and_lazy_import.TestEnvironmentOrderAndLazyImport object at 0x7ff3c0ede990>

    def test_main_loads_dotenv_before_runner_import(self):
        """Test that main.py loads .env before importing runner."""
        # Mock load_dotenv to track when it's called
        with patch('dotenv.load_dotenv') as mock_load_dotenv:
            with patch('ai_trading.runner.run_cycle') as mock_run_cycle:
                # Import and call run_bot from main
                from ai_trading.main import run_bot
    
                # Call run_bot
>               result = run_bot()

tests/test_env_order_and_lazy_import.py:172: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/main.py:245: in run_bot
    validate_environment()
ai_trading/main.py:201: in validate_environment
    if not cfg.alpaca_api_key or not cfg.alpaca_secret_key_plain:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
item = 'alpaca_secret_key_plain'

    def __getattr__(self, item: str) -> Any:
        private_attributes = object.__getattribute__(self, '__private_attributes__')
        if item in private_attributes:
            attribute = private_attributes[item]
            if hasattr(attribute, '__get__'):
                return attribute.__get__(self, type(self))  # type: ignore
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                return self.__pydantic_private__[item]  # type: ignore
            except KeyError as exc:
                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
        else:
            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.
            # See `BaseModel.__repr_args__` for more details
            try:
                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')
            except AttributeError:
                pydantic_extra = None
    
            if pydantic_extra:
                try:
                    return pydantic_extra[item]
                except KeyError as exc:
                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
            else:
                if hasattr(self.__class__, item):
                    return super().__getattribute__(item)  # Raises AttributeError if appropriate
                else:
                    # this is the current error
>                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E                   AttributeError: 'Settings' object has no attribute 'alpaca_secret_key_plain'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:991: AttributeError
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.logging:__init__.py:950 WARNING: 5 handlers detected - possible duplicate logging setup
ERROR    ai_trading.logging:__init__.py:966 Logging validation failed: ['Too many handlers detected: 5 (expected â‰¤ 2)']
ERROR    root:main.py:237 Logging validation failed: ['Too many handlers detected: 5 (expected â‰¤ 2)']
INFO     root:main.py:240 Application startup - logging configured once
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 17:37:27,958", "level": "ERROR", "name": "root", "msg": "Logging validation failed: ['Too many handlers detected: 5 (expected â‰¤ 2)']", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:27,958", "level": "INFO", "name": "root", "msg": "Application startup - logging configured once", "bot_phase": "GENERAL"}
_________________________________________________ test_data_validation_module __________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_data_validation_module():
        """Test data validation module exists and has required functions."""
    
        try:
            from ai_trading import data_validation
    
            # Test required functions exist
            required_functions = [
                'check_data_freshness',
                'validate_trading_data',
                'get_stale_symbols',
                'should_halt_trading',
                'emergency_data_check'
            ]
    
            for func_name in required_functions:
>               assert hasattr(data_validation, func_name), f"{func_name} function missing"
E               AssertionError: should_halt_trading function missing
E               assert False
E                +  where False = hasattr(<module 'ai_trading.data_validation' from '/workspace/ai-trading-bot/ai_trading/data_validation.py'>, 'should_halt_trading')

tests/test_fixes_minimal.py:127: AssertionError
______________________________________________ test_health_check_empty_dataframe _______________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c0772550>

    def test_health_check_empty_dataframe(monkeypatch):
        monkeypatch.setenv("HEALTH_MIN_ROWS", "30")
        ctx = DummyCtx(pd.DataFrame())
        summary = pre_trade_health_check(ctx, ["AAA"])
>       assert summary["failures"] == ["AAA"]
E       AssertionError: assert [('AAA', 'no_data')] == ['AAA']
E         
E         At index 0 diff: ('AAA', 'no_data') != 'AAA'
E         Use -v to get more diff

tests/test_health.py:254: AssertionError
_______________________________________________ test_host_semaphore_respects_env _______________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c0c42890>

    def test_host_semaphore_respects_env(monkeypatch):
        def fake_get(url, timeout=None, headers=None):
            return DummyResp()
    
        monkeypatch.setattr(H, "get", fake_get)
        monkeypatch.setenv("HTTP_MAX_PER_HOST", "3")
        _ = H.map_get(["https://example.com"])
>       assert H.pool_stats()["per_host"] == 3
E       assert 6 == 3

tests/test_http_pooling.py:25: AssertionError
____________________________________________ test_httpsession_sets_default_timeout _____________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c0c43690>

    def test_httpsession_sets_default_timeout(monkeypatch):
>       s = http.HTTPSession(timeout=7)
E       AttributeError: module 'ai_trading.utils.http' has no attribute 'HTTPSession'

tests/test_http_timeouts.py:25: AttributeError
__________________________________________________ test_ensure_datetime_none ___________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

value = None

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
>               raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
E               TypeError: Unsupported datetime type: NoneType

ai_trading/data/timeutils.py:45: TypeError

The above exception was the direct cause of the following exception:

value = None

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
>           return ensure_utc_datetime(value, allow_callables=False)

ai_trading/data_fetcher.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
                raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
        except (ValueError, TypeError) as e:
            if default is not None:
                return ensure_utc_datetime(default, allow_callables=allow_callables, clamp_to=clamp_to)
>           raise ValueError(f"Invalid datetime input: {value!r}") from e
E           ValueError: Invalid datetime input: None

ai_trading/data/timeutils.py:49: ValueError

The above exception was the direct cause of the following exception:

    def test_ensure_datetime_none():
        with pytest.raises(ValueError):
>           data_fetcher.ensure_datetime(None)

tests/test_data_fetcher_datetime.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
            return ensure_utc_datetime(value, allow_callables=False)
        except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
>           raise TypeError(f"Invalid datetime input: {e}") from e
E           TypeError: Invalid datetime input: Invalid datetime input: None

ai_trading/data_fetcher.py:205: TypeError
________________________________________________ test_ensure_datetime_empty_str ________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

value = ''

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
>               tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
E               ValueError: Invalid isoformat string: ''

ai_trading/data/timeutils.py:42: ValueError

The above exception was the direct cause of the following exception:

value = ''

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
>           return ensure_utc_datetime(value, allow_callables=False)

ai_trading/data_fetcher.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = ''

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
                raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
        except (ValueError, TypeError) as e:
            if default is not None:
                return ensure_utc_datetime(default, allow_callables=allow_callables, clamp_to=clamp_to)
>           raise ValueError(f"Invalid datetime input: {value!r}") from e
E           ValueError: Invalid datetime input: ''

ai_trading/data/timeutils.py:49: ValueError

The above exception was the direct cause of the following exception:

    def test_ensure_datetime_empty_str():
        with pytest.raises(ValueError):
>           data_fetcher.ensure_datetime("")

tests/test_data_fetcher_datetime.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = ''

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
            return ensure_utc_datetime(value, allow_callables=False)
        except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
>           raise TypeError(f"Invalid datetime input: {e}") from e
E           TypeError: Invalid datetime input: Invalid datetime input: ''

ai_trading/data_fetcher.py:205: TypeError
_____________________________________ TestMarketMicrostructure.test_microstructure_engine ______________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_enhancements.TestMarketMicrostructure testMethod=test_microstructure_engine>

    def setUp(self):
        """Set up test fixtures."""
        try:
>           from ai_trading.execution.microstructure import (
                BidAskSpreadAnalyzer,
                MarketMicrostructureEngine,
                MarketRegimeFeature,
                OrderFlowAnalyzer,
            )

tests/test_institutional_enhancements.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:35: in <module>
    _alpaca_rest = _optional_import("alpaca_trade_api.rest")
ai_trading/execution/engine.py:29: in _optional_import
    return importlib.import_module(name)
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/__init__.py:3: in <module>
    from .rest import REST, TimeFrame, TimeFrameUnit  # noqa
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import logging
    import os
    from typing import Iterator, List, Optional, Union
    import requests
    from requests.exceptions import HTTPError
    import time
    from enum import Enum
    from alpaca_trade_api import __version__
    from .common import (
        get_base_url,
        get_data_url,
        get_credentials,
        get_api_version, URL, FLOAT,
    )
    from .entity import (
        Bar, Entity, Account, AccountConfigurations, AccountActivity,
        Asset, Order, Position, Clock, Calendar,
        Trade, Quote, Watchlist, PortfolioHistory
    )
    from .entity_v2 import (
        BarV2, BarsV2, LatestBarsV2, LatestQuotesV2, LatestTradesV2,
        SnapshotV2, SnapshotsV2, TradesV2, TradeV2, QuotesV2, QuoteV2,
        NewsV2, NewsListV2, OrderbookV2, OrderbooksV2
    )
    
    logger = logging.getLogger(__name__)
    Positions = List[Position]
    Orders = List[Order]
    Assets = List[Asset]
    AccountActivities = List[AccountActivity]
    Calendars = List[Calendar]
    Watchlists = List[Watchlist]
    TradeIterator = Iterator[Union[Trade, dict]]
    QuoteIterator = Iterator[Union[Quote, dict]]
    BarIterator = Iterator[Union[Bar, dict]]
    NewsIterator = Iterator[Union[NewsV2, dict]]
    
    DATA_V2_MAX_LIMIT = 10000  # max items per api call
    NEWS_MAX_LIMIT = 50  # max items per api call
    
    
    class RetryException(Exception):
        pass
    
    
    class APIError(Exception):
        """
        Represent API related error.
        error.status_code will have http status code.
        """
    
        def __init__(self, error, http_error=None):
            super().__init__(error['message'])
            self._error = error
            self._http_error = http_error
    
        @property
        def code(self):
            return self._error.get('code', self.status_code)
    
        @property
        def status_code(self):
            http_error = self._http_error
            if http_error is not None and hasattr(http_error, 'response'):
                return http_error.response.status_code
    
        @property
        def request(self):
            if self._http_error is not None:
                return self._http_error.request
    
        @property
        def response(self):
            if self._http_error is not None:
                return self._http_error.response
    
>   def raise_api_error(resp: requests.Response, http_error: requests.HTTPError):
E   AttributeError: module 'requests' has no attribute 'Response'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:77: AttributeError
_______________________________________________ test_bot_engine_import_fallbacks _______________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_bot_engine_import_fallbacks():
        """Test that bot_engine import fallbacks work correctly."""
        # Test that the import patterns are present in the code
        # Check that the file contains the expected try/except patterns
        import inspect
    
        from ai_trading.core import bot_engine
    
        source = inspect.getsource(bot_engine)
    
        # Look for the expected import patterns
        expected_patterns = [
            "from ai_trading.meta_learning import optimize_signals",
            "from meta_learning import optimize_signals",
            "from ai_trading.pipeline import model_pipeline",
            "from pipeline import model_pipeline",
            "from ai_trading.data_fetcher import",
            "from data_fetcher import",
            "from ai_trading.indicators import rsi",
            "from indicators import rsi",
            "from ai_trading.signals import generate_position_hold_signals",
            "from signals import generate_position_hold_signals",
            "from ai_trading import portfolio",
            "import portfolio",
            "from ai_trading.alpaca_api import alpaca_get",
            "from alpaca_api import alpaca_get",
        ]
    
        for pattern in expected_patterns:
>           assert pattern in source, f"Expected import pattern not found: {pattern}"
E           AssertionError: Expected import pattern not found: from meta_learning import optimize_signals
E           assert 'from meta_learning import optimize_signals' in '# ruff: noqa\n# fmt: off\nfrom __future__ import annotations\n\nimport importlib\nimport importlib.util\nimport os\ni...eption\n            _log.exception("Scheduler loop error: %s", exc)\n        time.sleep(CFG.scheduler_sleep_seconds)\n'

tests/test_import_fallbacks.py:53: AssertionError
_________________________________________________ test_runner_import_fallbacks _________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_runner_import_fallbacks():
        """Test that runner.py import fallbacks are correctly implemented."""
        import inspect
    
        from ai_trading import runner
    
        source = inspect.getsource(runner)
    
        # Check for expected fallback patterns
        expected_patterns = [
            "from ai_trading.indicators import",
            "from indicators import",
        ]
    
        for pattern in expected_patterns:
>           assert pattern in source, f"Expected import pattern not found in runner.py: {pattern}"
E           AssertionError: Expected import pattern not found in runner.py: from ai_trading.indicators import
E           assert 'from ai_trading.indicators import' in 'from __future__ import annotations\n\n# ruff: noqa\nimport os\nimport time as _time\nfrom threading import RLock\nimp...and-line invocation."""\n    run_cycle()\n\n\nif __name__ == "__main__":\n    _preflight_import_health()\n    main()\n'

tests/test_import_fallbacks.py:71: AssertionError
_______________________________________________ test_ensure_datetime_invalid_str _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

value = 'notadate'

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
>               tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
E               ValueError: Invalid isoformat string: 'notadate'

ai_trading/data/timeutils.py:42: ValueError

The above exception was the direct cause of the following exception:

value = 'notadate'

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
>           return ensure_utc_datetime(value, allow_callables=False)

ai_trading/data_fetcher.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = 'notadate'

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
                raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
        except (ValueError, TypeError) as e:
            if default is not None:
                return ensure_utc_datetime(default, allow_callables=allow_callables, clamp_to=clamp_to)
>           raise ValueError(f"Invalid datetime input: {value!r}") from e
E           ValueError: Invalid datetime input: 'notadate'

ai_trading/data/timeutils.py:49: ValueError

The above exception was the direct cause of the following exception:

    def test_ensure_datetime_invalid_str():
        with pytest.raises(ValueError):
>           data_fetcher.ensure_datetime("notadate")

tests/test_data_fetcher_datetime.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = 'notadate'

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
            return ensure_utc_datetime(value, allow_callables=False)
        except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
>           raise TypeError(f"Invalid datetime input: {e}") from e
E           TypeError: Invalid datetime input: Invalid datetime input: 'notadate'

ai_trading/data_fetcher.py:205: TypeError
___________________________________________________ test_ensure_datetime_nat ___________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_ensure_datetime_nat():
>       with pytest.raises(ValueError):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/test_data_fetcher_datetime.py:49: Failed
___________________________________________________ test_get_historical_data ___________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85444a50>

    def test_get_historical_data(monkeypatch):
        df = make_df()
>       setup_tf(monkeypatch)

tests/test_data_fetcher_extended.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85444a50>

    def setup_tf(monkeypatch):
>       monkeypatch.setattr(data_fetcher, "TimeFrame", TF)
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute 'TimeFrame'

tests/test_data_fetcher_extended.py:36: AttributeError
____________________________________________ test_get_historical_data_bad_timeframe ____________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85445610>

    def test_get_historical_data_bad_timeframe(monkeypatch):
>       setup_tf(monkeypatch)

tests/test_data_fetcher_extended.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85445610>

    def setup_tf(monkeypatch):
>       monkeypatch.setattr(data_fetcher, "TimeFrame", TF)
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute 'TimeFrame'

tests/test_data_fetcher_extended.py:36: AttributeError
______________________________________ TestMarketMicrostructure.test_order_flow_analyzer _______________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_enhancements.TestMarketMicrostructure testMethod=test_order_flow_analyzer>

    def setUp(self):
        """Set up test fixtures."""
        try:
>           from ai_trading.execution.microstructure import (
                BidAskSpreadAnalyzer,
                MarketMicrostructureEngine,
                MarketRegimeFeature,
                OrderFlowAnalyzer,
            )

tests/test_institutional_enhancements.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:35: in <module>
    _alpaca_rest = _optional_import("alpaca_trade_api.rest")
ai_trading/execution/engine.py:29: in _optional_import
    return importlib.import_module(name)
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/__init__.py:3: in <module>
    from .rest import REST, TimeFrame, TimeFrameUnit  # noqa
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import logging
    import os
    from typing import Iterator, List, Optional, Union
    import requests
    from requests.exceptions import HTTPError
    import time
    from enum import Enum
    from alpaca_trade_api import __version__
    from .common import (
        get_base_url,
        get_data_url,
        get_credentials,
        get_api_version, URL, FLOAT,
    )
    from .entity import (
        Bar, Entity, Account, AccountConfigurations, AccountActivity,
        Asset, Order, Position, Clock, Calendar,
        Trade, Quote, Watchlist, PortfolioHistory
    )
    from .entity_v2 import (
        BarV2, BarsV2, LatestBarsV2, LatestQuotesV2, LatestTradesV2,
        SnapshotV2, SnapshotsV2, TradesV2, TradeV2, QuotesV2, QuoteV2,
        NewsV2, NewsListV2, OrderbookV2, OrderbooksV2
    )
    
    logger = logging.getLogger(__name__)
    Positions = List[Position]
    Orders = List[Order]
    Assets = List[Asset]
    AccountActivities = List[AccountActivity]
    Calendars = List[Calendar]
    Watchlists = List[Watchlist]
    TradeIterator = Iterator[Union[Trade, dict]]
    QuoteIterator = Iterator[Union[Quote, dict]]
    BarIterator = Iterator[Union[Bar, dict]]
    NewsIterator = Iterator[Union[NewsV2, dict]]
    
    DATA_V2_MAX_LIMIT = 10000  # max items per api call
    NEWS_MAX_LIMIT = 50  # max items per api call
    
    
    class RetryException(Exception):
        pass
    
    
    class APIError(Exception):
        """
        Represent API related error.
        error.status_code will have http status code.
        """
    
        def __init__(self, error, http_error=None):
            super().__init__(error['message'])
            self._error = error
            self._http_error = http_error
    
        @property
        def code(self):
            return self._error.get('code', self.status_code)
    
        @property
        def status_code(self):
            http_error = self._http_error
            if http_error is not None and hasattr(http_error, 'response'):
                return http_error.response.status_code
    
        @property
        def request(self):
            if self._http_error is not None:
                return self._http_error.request
    
        @property
        def response(self):
            if self._http_error is not None:
                return self._http_error.response
    
>   def raise_api_error(resp: requests.Response, http_error: requests.HTTPError):
E   AttributeError: module 'requests' has no attribute 'Response'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:77: AttributeError
_______________________________________________ test_backtester_import_fallbacks _______________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_backtester_import_fallbacks():
        """Test that backtester.py import fallbacks are correctly implemented."""
        import inspect
    
>       from ai_trading.strategies import backtester

tests/test_import_fallbacks.py:78: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/strategies/backtester.py:20: in <module>
    from ai_trading import (
ai_trading/signals.py:114: in <module>
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
_______________________________________________ test_get_minute_df_market_closed _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85444f90>

    def test_get_minute_df_market_closed(monkeypatch):
        monkeypatch.setattr(data_fetcher, "is_market_open", lambda: False)
        today = datetime.date.today()
>       result = data_fetcher.get_minute_df("AAPL", today, today)

tests/test_data_fetcher_extended.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/data_fetcher.py:531: in get_minute_df
    fh_fetcher.fetch(symbol, start_dt, end_dt, resolution="1")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.data_fetcher._FinnhubFetcherStub object at 0x7f8d86253cd0>
args = ('AAPL', datetime.datetime(2025, 8, 22, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2025, 8, 22, 0, 0, tzinfo=datetime.timezone.utc))
kwargs = {'resolution': '1'}

    def fetch(self, *args, **kwargs):
>       raise NotImplementedError
E       NotImplementedError

ai_trading/data_fetcher.py:149: NotImplementedError
___________________________________________ test_profile_indicators_import_fallbacks ___________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_profile_indicators_import_fallbacks():
        """Test that profile_indicators.py import fallbacks are correctly implemented."""
        import inspect
    
>       import profile_indicators
E       ModuleNotFoundError: No module named 'profile_indicators'

tests/test_import_fallbacks.py:98: ModuleNotFoundError
______________________________________________ test_get_minute_df_missing_columns ______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d861c0910>

    def test_get_minute_df_missing_columns(monkeypatch):
        df_bad = pd.DataFrame({"price": [1]}, index=[pd.Timestamp("2024-01-01")])
        df_good = make_df()
>       setup_tf(monkeypatch)

tests/test_data_fetcher_extended.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d861c0910>

    def setup_tf(monkeypatch):
>       monkeypatch.setattr(data_fetcher, "TimeFrame", TF)
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute 'TimeFrame'

tests/test_data_fetcher_extended.py:36: AttributeError
_____________________________________________ test_data_fetcher_helpers_available ______________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_data_fetcher_helpers_available():
        """Test that the new data_fetcher helper functions are available."""
        try:
>           from ai_trading.data_fetcher import (
                clear_cached_minute_cache,
                get_cached_age_seconds,
                get_cached_minute_timestamp,
                set_cached_minute_timestamp,
            )
E           ImportError: cannot import name 'clear_cached_minute_cache' from 'ai_trading.data_fetcher' (unknown location)

tests/test_import_fallbacks.py:143: ImportError

During handling of the above exception, another exception occurred:

    def test_data_fetcher_helpers_available():
        """Test that the new data_fetcher helper functions are available."""
        try:
            from ai_trading.data_fetcher import (
                clear_cached_minute_cache,
                get_cached_age_seconds,
                get_cached_minute_timestamp,
                set_cached_minute_timestamp,
            )
    
            assert callable(get_cached_minute_timestamp)
            assert callable(set_cached_minute_timestamp)
            assert callable(get_cached_age_seconds)
            assert callable(clear_cached_minute_cache)
        except ImportError:
>           from ai_trading.data_fetcher import (
                clear_cached_minute_cache,
                get_cached_age_seconds,
                get_cached_minute_timestamp,
                set_cached_minute_timestamp,
            )
E           ImportError: cannot import name 'clear_cached_minute_cache' from 'ai_trading.data_fetcher' (unknown location)

tests/test_import_fallbacks.py:155: ImportError
______________________________________________ test_get_minute_df_invalid_inputs _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

value = None

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
>               raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
E               TypeError: Unsupported datetime type: NoneType

ai_trading/data/timeutils.py:45: TypeError

The above exception was the direct cause of the following exception:

value = None

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
>           return ensure_utc_datetime(value, allow_callables=False)

ai_trading/data_fetcher.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None

    def ensure_utc_datetime(
        value: Any,
        *,
        default: datetime | None = None,
        clamp_to: str | None = None,
        allow_callables: bool = False,
    ) -> datetime:
        """Normalize a variety of inputs to a timezone-aware UTC datetime.
    
        - If ``value`` is callable and ``allow_callables`` is ``True``, call it (no args) and
          re-run normalization on the result.
        - If ``value`` is callable and ``allow_callables`` is ``False``, raise ``TypeError``.
        - If normalization fails, return ``default`` if provided; otherwise raise ``ValueError``.
        """
        # Reject/handle callables early
        if callable(value):
            if allow_callables:
                try:
                    value = value()
                except (ValueError, TypeError) as e:
                    raise TypeError(f"datetime argument callable failed: {e}") from e
            else:
                raise TypeError("datetime argument was callable")
    
        try:
            if isinstance(value, datetime):
                dt = value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
            elif isinstance(value, date):
                dt = datetime(value.year, value.month, value.day, tzinfo=UTC)
            elif isinstance(value, str):
                tmp = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
                dt = tmp.astimezone(UTC) if tmp.tzinfo else tmp.replace(tzinfo=UTC)
            else:
                raise TypeError(f"Unsupported datetime type: {type(value).__name__}")
        except (ValueError, TypeError) as e:
            if default is not None:
                return ensure_utc_datetime(default, allow_callables=allow_callables, clamp_to=clamp_to)
>           raise ValueError(f"Invalid datetime input: {value!r}") from e
E           ValueError: Invalid datetime input: None

ai_trading/data/timeutils.py:49: ValueError

The above exception was the direct cause of the following exception:

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d861c2ed0>

    def test_get_minute_df_invalid_inputs(monkeypatch):
        monkeypatch.setattr(data_fetcher, "is_market_open", lambda: True)
        with pytest.raises(ValueError):
>           data_fetcher.get_minute_df("AAPL", None, datetime.date.today())

tests/test_data_fetcher_extended.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/data_fetcher.py:524: in get_minute_df
    start_dt = ensure_datetime(start)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None

    def ensure_datetime(value: Any) -> _dt.datetime:
        """Coerce various datetime inputs into timezone-aware UTC datetime.
    
        Rules for market-data windows:
        - If ``value`` is callable, call it (no args) and re-normalize.
        - If ``value`` is a *naive* ``datetime``, interpret it as **America/New_York**
          (exchange time) before converting to UTC.
        - Otherwise, delegate to ``ensure_utc_datetime``.
        """
    
        # AI-AGENT-REF: unwrap callables early
        if callable(value):
            try:
                value = value()
            except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
                raise TypeError(f"Invalid datetime input: {e}") from e
    
        # AI-AGENT-REF: localize naive ET datetimes before UTC coercion
        if isinstance(value, _dt.datetime) and value.tzinfo is None:
            value = value.replace(tzinfo=ZoneInfo("America/New_York"))
    
        try:
            return ensure_utc_datetime(value, allow_callables=False)
        except (TypeError, ValueError, AttributeError, OutOfBoundsDatetime) as e:
>           raise TypeError(f"Invalid datetime input: {e}") from e
E           TypeError: Invalid datetime input: Invalid datetime input: None

ai_trading/data_fetcher.py:205: TypeError
________________________________________________ test_minute_fallback_on_empty _________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d85a0bcd0>

    def test_minute_fallback_on_empty(monkeypatch):
        """Minute bars fall back to Yahoo when Alpaca yields empty."""  # AI-AGENT-REF
        monkeypatch.setattr(dfetch, "_fetch_bars", lambda *a, **k: pd.DataFrame())
>       monkeypatch.setattr(dfetch.yf, "download", _fake_yf)
E       AttributeError: None has no attribute 'download'

tests/test_data_fetcher_fallbacks.py:26: AttributeError
______________________________________________ test_minute_fallback_on_exception _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d852ca750>

    def test_minute_fallback_on_exception(monkeypatch):
        """Minute bars fall back to Yahoo when Alpaca errors."""  # AI-AGENT-REF
        def _boom(*_, **__):
            raise ValueError("json error")
    
        monkeypatch.setattr(dfetch, "_fetch_bars", _boom)
        monkeypatch.setattr(dfetch, "fh_fetcher", None)
>       monkeypatch.setattr(dfetch.yf, "download", _fake_yf)
E       AttributeError: None has no attribute 'download'

tests/test_data_fetcher_fallbacks.py:40: AttributeError
_________________________________________________ test_daily_fallback_on_empty _________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d857dbcd0>

    def test_daily_fallback_on_empty(monkeypatch):
        """Daily bars fall back to Yahoo when Alpaca yields empty."""  # AI-AGENT-REF
        monkeypatch.setattr(dfetch, "get_bars", lambda *a, **k: pd.DataFrame())
>       monkeypatch.setattr(dfetch.yf, "download", _fake_yf)
E       AttributeError: None has no attribute 'download'

tests/test_data_fetcher_fallbacks.py:49: AttributeError
______________________________________ test_yahoo_get_bars_accepts_various_datetime_types ______________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d8540bd90>

    def test_yahoo_get_bars_accepts_various_datetime_types(monkeypatch):
>       from ai_trading.data_fetcher import _yahoo_get_bars
E       ImportError: cannot import name '_yahoo_get_bars' from 'ai_trading.data_fetcher' (unknown location)

tests/test_data_fetcher_timezone.py:38: ImportError
_________________________________ TestMarketMicrostructure.test_spread_analyzer_initialization _________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_enhancements.TestMarketMicrostructure testMethod=test_spread_analyzer_initialization>

    def setUp(self):
        """Set up test fixtures."""
        try:
>           from ai_trading.execution.microstructure import (
                BidAskSpreadAnalyzer,
                MarketMicrostructureEngine,
                MarketRegimeFeature,
                OrderFlowAnalyzer,
            )

tests/test_institutional_enhancements.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:35: in <module>
    _alpaca_rest = _optional_import("alpaca_trade_api.rest")
ai_trading/execution/engine.py:29: in _optional_import
    return importlib.import_module(name)
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/__init__.py:3: in <module>
    from .rest import REST, TimeFrame, TimeFrameUnit  # noqa
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import logging
    import os
    from typing import Iterator, List, Optional, Union
    import requests
    from requests.exceptions import HTTPError
    import time
    from enum import Enum
    from alpaca_trade_api import __version__
    from .common import (
        get_base_url,
        get_data_url,
        get_credentials,
        get_api_version, URL, FLOAT,
    )
    from .entity import (
        Bar, Entity, Account, AccountConfigurations, AccountActivity,
        Asset, Order, Position, Clock, Calendar,
        Trade, Quote, Watchlist, PortfolioHistory
    )
    from .entity_v2 import (
        BarV2, BarsV2, LatestBarsV2, LatestQuotesV2, LatestTradesV2,
        SnapshotV2, SnapshotsV2, TradesV2, TradeV2, QuotesV2, QuoteV2,
        NewsV2, NewsListV2, OrderbookV2, OrderbooksV2
    )
    
    logger = logging.getLogger(__name__)
    Positions = List[Position]
    Orders = List[Order]
    Assets = List[Asset]
    AccountActivities = List[AccountActivity]
    Calendars = List[Calendar]
    Watchlists = List[Watchlist]
    TradeIterator = Iterator[Union[Trade, dict]]
    QuoteIterator = Iterator[Union[Quote, dict]]
    BarIterator = Iterator[Union[Bar, dict]]
    NewsIterator = Iterator[Union[NewsV2, dict]]
    
    DATA_V2_MAX_LIMIT = 10000  # max items per api call
    NEWS_MAX_LIMIT = 50  # max items per api call
    
    
    class RetryException(Exception):
        pass
    
    
    class APIError(Exception):
        """
        Represent API related error.
        error.status_code will have http status code.
        """
    
        def __init__(self, error, http_error=None):
            super().__init__(error['message'])
            self._error = error
            self._http_error = http_error
    
        @property
        def code(self):
            return self._error.get('code', self.status_code)
    
        @property
        def status_code(self):
            http_error = self._http_error
            if http_error is not None and hasattr(http_error, 'response'):
                return http_error.response.status_code
    
        @property
        def request(self):
            if self._http_error is not None:
                return self._http_error.request
    
        @property
        def response(self):
            if self._http_error is not None:
                return self._http_error.response
    
>   def raise_api_error(resp: requests.Response, http_error: requests.HTTPError):
E   AttributeError: module 'requests' has no attribute 'Response'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:77: AttributeError
___________________________________________________ test_position_none_safe ____________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d8540afd0>

    def test_position_none_safe(monkeypatch):
        class Dummy:
            def get_open_position(self, symbol):
                return None
    
        class Ctx:
            pass
    
        ctx = Ctx()
        ctx.api = Dummy()
        from ai_trading.core import bot_engine as be
    
>       assert be._current_position_qty(ctx, "SPY") == 0
E       AttributeError: module 'ai_trading.core.bot_engine' has no attribute '_current_position_qty'

tests/test_data_pipeline.py:34: AttributeError
________________________________ TestSentimentCaching.test_sentiment_cache_rate_limit_handling _________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_datetime_fixes.TestSentimentCaching testMethod=test_sentiment_cache_rate_limit_handling>

    def test_sentiment_cache_rate_limit_handling(self):
        """Test that sentiment caching properly handles rate limits."""
        try:
            import time
    
            from ai_trading.core.bot_engine import _SENTIMENT_CACHE, fetch_sentiment
            from requests.exceptions import HTTPError
    
            # Clear cache
            _SENTIMENT_CACHE.clear()
    
            # Mock the API key variables in bot_engine module
            with patch("ai_trading.core.bot_engine.SENTIMENT_API_KEY", "test_key"):
                with patch("ai_trading.core.bot_engine.NEWS_API_KEY", "test_key"):
                    # Mock the requests to simulate rate limiting
                    with patch("requests.get") as mock_get:
                        # First call - simulate rate limit (429)
                        mock_response = MagicMock()
                        mock_response.status_code = 429
                        mock_response.raise_for_status.side_effect = HTTPError(
                            "429 Too Many Requests"
                        )
                        mock_get.return_value = mock_response
    
                        # Mock context for fetch_sentiment
                        mock_ctx = MagicMock()
    
                        # This should handle the rate limit gracefully and cache neutral score
>                       score = fetch_sentiment(mock_ctx, "AAPL")

tests/test_critical_datetime_fixes.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

symbol_or_ctx = <MagicMock id='140215586815184'>, symbol = 'AAPL'

    def fetch_sentiment(
        symbol_or_ctx, symbol: str | None = None, *, ttl_s: int = 300
    ) -> float:
        global _SENTIMENT_FAILURES
        """Fetch sentiment score with basic caching and failure tracking."""
        if symbol is None:
            symbol = symbol_or_ctx  # backward compat: first arg was context
        now = time.time()
        cached = _SENTIMENT_CACHE.get(symbol)
        if cached and now - cached[0] < ttl_s:
            return cached[1]
        if _SENTIMENT_FAILURES >= SENTIMENT_FAILURE_THRESHOLD or not SENTIMENT_API_KEY:
            return 0.0
        params = {"symbol": symbol, "apikey": SENTIMENT_API_KEY}
        try:
            # fmt: off
            resp = requests.get(SENTIMENT_API_URL, params=params, timeout=HTTP_TIMEOUT)
            # fmt: on
>           if resp.status_code in {429, 500, 502, 503, 504}:
E           AttributeError: 'NoneType' object has no attribute 'status_code'

ai_trading/core/bot_engine.py:462: AttributeError
____________________________________ TestMarketMicrostructure.test_spread_feature_analysis _____________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_enhancements.TestMarketMicrostructure testMethod=test_spread_feature_analysis>

    def setUp(self):
        """Set up test fixtures."""
        try:
>           from ai_trading.execution.microstructure import (
                BidAskSpreadAnalyzer,
                MarketMicrostructureEngine,
                MarketRegimeFeature,
                OrderFlowAnalyzer,
            )

tests/test_institutional_enhancements.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:35: in <module>
    _alpaca_rest = _optional_import("alpaca_trade_api.rest")
ai_trading/execution/engine.py:29: in _optional_import
    return importlib.import_module(name)
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/__init__.py:3: in <module>
    from .rest import REST, TimeFrame, TimeFrameUnit  # noqa
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import logging
    import os
    from typing import Iterator, List, Optional, Union
    import requests
    from requests.exceptions import HTTPError
    import time
    from enum import Enum
    from alpaca_trade_api import __version__
    from .common import (
        get_base_url,
        get_data_url,
        get_credentials,
        get_api_version, URL, FLOAT,
    )
    from .entity import (
        Bar, Entity, Account, AccountConfigurations, AccountActivity,
        Asset, Order, Position, Clock, Calendar,
        Trade, Quote, Watchlist, PortfolioHistory
    )
    from .entity_v2 import (
        BarV2, BarsV2, LatestBarsV2, LatestQuotesV2, LatestTradesV2,
        SnapshotV2, SnapshotsV2, TradesV2, TradeV2, QuotesV2, QuoteV2,
        NewsV2, NewsListV2, OrderbookV2, OrderbooksV2
    )
    
    logger = logging.getLogger(__name__)
    Positions = List[Position]
    Orders = List[Order]
    Assets = List[Asset]
    AccountActivities = List[AccountActivity]
    Calendars = List[Calendar]
    Watchlists = List[Watchlist]
    TradeIterator = Iterator[Union[Trade, dict]]
    QuoteIterator = Iterator[Union[Quote, dict]]
    BarIterator = Iterator[Union[Bar, dict]]
    NewsIterator = Iterator[Union[NewsV2, dict]]
    
    DATA_V2_MAX_LIMIT = 10000  # max items per api call
    NEWS_MAX_LIMIT = 50  # max items per api call
    
    
    class RetryException(Exception):
        pass
    
    
    class APIError(Exception):
        """
        Represent API related error.
        error.status_code will have http status code.
        """
    
        def __init__(self, error, http_error=None):
            super().__init__(error['message'])
            self._error = error
            self._http_error = http_error
    
        @property
        def code(self):
            return self._error.get('code', self.status_code)
    
        @property
        def status_code(self):
            http_error = self._http_error
            if http_error is not None and hasattr(http_error, 'response'):
                return http_error.response.status_code
    
        @property
        def request(self):
            if self._http_error is not None:
                return self._http_error.request
    
        @property
        def response(self):
            if self._http_error is not None:
                return self._http_error.response
    
>   def raise_api_error(resp: requests.Response, http_error: requests.HTTPError):
E   AttributeError: module 'requests' has no attribute 'Response'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:77: AttributeError
___________________________________ TestEnhancedRebalancer.test_enhanced_rebalancer_fallback ___________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_enhancements.TestEnhancedRebalancer testMethod=test_enhanced_rebalancer_fallback>

    def test_enhanced_rebalancer_fallback(self):
        """Test that enhanced rebalancer falls back gracefully."""
        import os
        import sys
        sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    
>       from ai_trading.rebalancer import enhanced_maybe_rebalance, rebalance_portfolio
E       ImportError: cannot import name 'enhanced_maybe_rebalance' from 'ai_trading.rebalancer' (unknown location)

tests/test_institutional_enhancements.py:419: ImportError
_______________________________________ TestKellyIntegration.test_kelly_with_risk_levels _______________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyIntegration object at 0x7ff8d3ebffd0>

    def test_kelly_with_risk_levels(self):
        """Test Kelly integration with different risk levels."""
        # Conservative risk level
>       conservative_kelly = KellyCriterion(max_fraction=RiskLevel.CONSERVATIVE.max_position_size)

tests/test_institutional_kelly.py:278: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d37fadd0>, config = None, min_sample_size = None
max_fraction = 0.02, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
___________________________________________ TestKellyIntegration.test_kelly_logging ____________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_institutional_kelly.TestKellyIntegration object at 0x7ff8d3e9a0d0>
mock_logger = <MagicMock name='logger' id='140706683029648'>

    @patch('ai_trading.risk.kelly.logger')
    def test_kelly_logging(self, mock_logger):
        """Test Kelly Criterion logging functionality."""
>       kelly = KellyCriterion()

tests/test_institutional_kelly.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.risk.kelly.KellyCriterion object at 0x7ff8d8329110>, config = None, min_sample_size = None
max_fraction = None, kwargs = {}

    def __init__(
        self,
        config: TradingConfig | None = None,
        min_sample_size: int | None = None,
        max_fraction: float | None = None,
        **kwargs,
    ):
        """Initialize Kelly Criterion calculator with centralized configuration.
    
        Args:
            config: TradingConfig instance (optional, uses default if not provided)
            min_sample_size: Minimum sample size for calculations (for backward compatibility)
            max_fraction: Maximum Kelly fraction allowed (for backward compatibility)
            **kwargs: Additional parameters for backward compatibility
        """
        # Use provided config or default
        self.config = config or _DEFAULT_CONFIG
    
        # Support backward compatibility: use passed parameters if provided, otherwise use config
        self.min_sample_size = (
            min_sample_size
            if min_sample_size is not None
>           else self.config.min_sample_size
        )
E       AttributeError: 'NoneType' object has no attribute 'min_sample_size'

ai_trading/risk/kelly.py:75: AttributeError
_______________________________________ TestTrailingStopManager.test_stop_initialization _______________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestTrailingStopManager object at 0x7ff8d81ce010>

    def test_stop_initialization(self):
        """Test trailing stop initialization."""
>       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:243: NameError
__________________________________________ TestTrailingStopManager.test_stop_movement __________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestTrailingStopManager object at 0x7ff8d3d05f90>

    def test_stop_movement(self):
        """Test that stops move up with price for long positions."""
>       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:259: NameError
_____________________________________ TestTrailingStopManager.test_stop_trigger_detection ______________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestTrailingStopManager object at 0x7ff8d3d06390>

    def test_stop_trigger_detection(self):
        """Test stop trigger detection."""
>       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:279: NameError
_______________________________________ TestProfitTakingEngine.test_profit_plan_creation _______________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestProfitTakingEngine object at 0x7ff8d3d065d0>

    def test_profit_plan_creation(self):
        """Test profit plan creation."""
>       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:306: NameError
________________________________________ TestProfitTakingEngine.test_target_triggering _________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestProfitTakingEngine object at 0x7ff8d3d06e90>

    def test_target_triggering(self):
        """Test profit target triggering."""
>       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=11000.0
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:326: NameError
________________________________ TestPortfolioCorrelationAnalyzer.test_position_data_extraction ________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestPortfolioCorrelationAnalyzer object at 0x7ff8d3d76e50>

    def test_position_data_extraction(self):
        """Test position data extraction."""
        positions = [
>           MockPosition('AAPL', 100, 100.0, 11000.0),
            MockPosition('MSFT', 50, 200.0, 10500.0),
            MockPosition('GOOGL', 25, 150.0, 3750.0)
        ]
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:355: NameError
_________________________________ TestPortfolioCorrelationAnalyzer.test_concentration_analysis _________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestPortfolioCorrelationAnalyzer object at 0x7ff8d8191510>

    def test_concentration_analysis(self):
        """Test concentration level analysis."""
        positions = [
>           MockPosition('AAPL', 100, 100.0, 50000.0),  # 50% of portfolio
            MockPosition('MSFT', 50, 200.0, 25000.0),   # 25% of portfolio
            MockPosition('GOOGL', 25, 150.0, 25000.0)   # 25% of portfolio
        ]
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:377: NameError
__________________________________ TestIntegrationScenarios.test_profitable_position_scenario __________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestIntegrationScenarios object at 0x7ff8d8192890>

    def test_profitable_position_scenario(self):
        """Test scenario with profitable position."""
>       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=12000.0  # 20% gain
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:399: NameError
_____________________________________ TestIntegrationScenarios.test_loss_position_scenario _____________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestIntegrationScenarios object at 0x7ff8d87a5dd0>

    def test_loss_position_scenario(self):
        """Test scenario with losing position."""
>       position = MockPosition(
            symbol='AAPL',
            qty=100,
            avg_entry_price=100.0,
            market_value=9000.0  # 10% loss
        )
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:417: NameError
________________________________ TestIntegrationScenarios.test_portfolio_level_recommendations _________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_intelligent_position_management.TestIntegrationScenarios object at 0x7ff8d81cef10>

    def test_portfolio_level_recommendations(self):
        """Test portfolio-level analysis and recommendations."""
        positions = [
>           MockPosition('AAPL', 100, 100.0, 11000.0),
            MockPosition('MSFT', 50, 200.0, 10500.0),
            MockPosition('TSLA', 30, 150.0, 4800.0)
        ]
E       NameError: name 'MockPosition' is not defined

tests/test_intelligent_position_management.py:434: NameError
________________________________________ test_json_formatter_custom_fields_and_masking _________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_json_formatter_custom_fields_and_masking():
        fmt = logger.JSONFormatter("%(asctime)sZ")
        rec = _make_record(symbol="AAPL", api_key="abcdef1234", pathname="skip")
        out = fmt.format(rec)
        data = json.loads(out)
        assert set(data) >= {"ts", "level", "name", "msg", "symbol", "api_key"}
>       assert data["api_key"].endswith("1234") and set(data["api_key"]) <= set("*1234")
E       AssertionError: assert (False)
E        +  where False = <built-in method endswith of str object at 0x7ff8d33236b0>('1234')
E        +    where <built-in method endswith of str object at 0x7ff8d33236b0> = 'ab***34'.endswith

tests/test_json_formatter.py:28: AssertionError
_____________________________________________ test_update_signal_weights_norm_zero _____________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7ff8d39d35d0>

    def test_update_signal_weights_norm_zero(caplog):
        caplog.set_level("WARNING")
        w = {"a": 0.0}
        perf = {"a": 1.0}
        res = meta_learning.update_signal_weights(w, perf)
        assert res == w
>       assert "Normalization factor zero" in caplog.text
E       AssertionError: assert 'Normalization factor zero' in 'WARNING  ai_trading.meta_learning:meta_learning.py:616 Normâ€¦tion factor zero in weight update\n'
E        +  where 'WARNING  ai_trading.meta_learning:meta_learning.py:616 Normâ€¦tion factor zero in weight update\n' = <_pytest.logging.LogCaptureFixture object at 0x7ff8d39d35d0>.text

tests/test_meta_learning.py:154: AssertionError
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.meta_learning:meta_learning.py:616 Normâ€¦tion factor zero in weight update
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 17:37:29,099", "level": "WARNING", "name": "ai_trading.meta_learning", "msg": "Normâ€¦tion factor zero in weight update", "bot_phase": "GENERAL"}
_____________________________________________ test_bot_engine_deprecation_warning ______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_bot_engine_deprecation_warning():
        """Importing bot_engine emits DeprecationWarning."""  # AI-AGENT-REF
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")
>           import ai_trading.core.bot_engine  # noqa: F401

tests/test_deprecation_warnings.py:11: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    # ruff: noqa
    # fmt: off
    from __future__ import annotations
    
    import importlib
    import importlib.util
    import os
    import sys
    from typing import Dict, Iterable
    from zoneinfo import ZoneInfo  # AI-AGENT-REF: timezone conversions
    
    from json import JSONDecodeError
    # Safe 'requests' import with stub + RequestException binding
    try:  # pragma: no cover
        import requests  # type: ignore
        RequestException = requests.exceptions.RequestException  # type: ignore[attr-defined]
    except ImportError:  # pragma: no cover  # AI-AGENT-REF: narrow import handling
        class RequestException(Exception):
            pass
    
        # Minimal stub so runtime calls fail gracefully into COMMON_EXC
        class _RequestsStub:
            class exceptions:
                RequestException = RequestException
    
            def get(self, *a, **k):
                raise RequestException("requests not installed")
    
        requests = _RequestsStub()  # type: ignore
    
    from threading import Lock
    import warnings
    
    from ai_trading.data_fetcher import (
        get_bars,
        get_bars_batch,
        get_minute_df,
    )
>   from ai_trading.market.calendars import last_market_session
E   ImportError: cannot import name 'last_market_session' from 'ai_trading.market.calendars' (unknown location)

ai_trading/core/bot_engine.py:39: ImportError
__________________________________________________ test_portfolio_rl_trigger ___________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d39dbd50>

    def test_portfolio_rl_trigger(monkeypatch):
        torch = pytest.importorskip("torch")
        # AI-AGENT-REF: ensure real torch is loaded during tests
        # if not hasattr(torch, "nn") or not hasattr(torch.nn, "Parameter"):
        #     pytest.skip("torch stubs active")
        class FakeLinear(nn.Module):
            def __init__(self, *a, **k):
                super().__init__()
                self.weight = nn.Parameter(torch.tensor([0.0]))
    
            def forward(self, x):
                return x
    
        monkeypatch.setattr(nn, "Linear", lambda *a, **k: FakeLinear())
>       import portfolio_rl
E       ModuleNotFoundError: No module named 'portfolio_rl'

tests/test_meta_learning.py:171: ModuleNotFoundError
____________________________________________ test_data_fetcher_deprecation_warning _____________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_data_fetcher_deprecation_warning():
        """Test that importing data_fetcher shows deprecation warning."""
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")
            import ai_trading.data_fetcher  # noqa: F401
    
            # Check that a deprecation warning was raised
>           assert len(w) >= 1
E           assert 0 >= 1
E            +  where 0 = len([])

tests/test_deprecation_warnings.py:22: AssertionError
_____________________________________________ test_partial_initial_rebalance_fill ______________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f867cdb1c90>

    def test_partial_initial_rebalance_fill(monkeypatch):
        ctx = types.SimpleNamespace(
            api=DummyAPI(),
            data_fetcher=DummyFetcher(),
            rebalance_ids={},
            rebalance_attempts={},
            rebalance_buys={},
        )
    
        class FakeDateTime(datetime.datetime):
            @classmethod
            def now(cls, tz=None):
                return datetime.datetime(2025, 7, 26, 0, 16, tzinfo=datetime.UTC)
    
        monkeypatch.setattr(bot_engine, "datetime", FakeDateTime)
    
        def fake_submit(ctx_, symbol, qty, side):
            ctx_.api.orders.append((symbol, qty, side))
            ctx_.api.positions[symbol] = ctx_.api.positions.get(symbol, 0) + qty // 2
            return object()
    
        monkeypatch.setattr(bot_engine, "submit_order", fake_submit)
    
>       bot_engine.initial_rebalance(ctx, ["AAPL"])

tests/test_initial_rebalance.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ctx = namespace(api=<tests.test_initial_rebalance.DummyAPI object at 0x7f8677fc1050>, data_fetcher=<tests.test_initial_rebalance.DummyFetcher object at 0x7f8677fc2850>, rebalance_ids={}, rebalance_attempts={}, rebalance_buys={})
symbols = ['AAPL']

    def initial_rebalance(ctx: BotContext, symbols: list[str]) -> None:
        """Initial portfolio rebalancing."""
    
        if ctx.api is None:
            _log.warning("ctx.api is None - cannot perform initial rebalance")
            return
    
        try:
            datetime.now(UTC).astimezone(PACIFIC)
            acct = ctx.api.get_account()
            float(acct.equity)
    
            cash = float(acct.cash)
            buying_power = float(getattr(acct, "buying_power", cash))
            n = len(symbols)
            if n == 0 or cash <= 0 or buying_power <= 0:
                _log.info("INITIAL_REBALANCE_NO_SYMBOLS_OR_NO_CASH")
                return
        except (
            APIError,
            TimeoutError,
            ConnectionError,
        ) as e:  # AI-AGENT-REF: tighten rebalance account fetch errors
            _log.warning(
                "INITIAL_REBALANCE_ACCOUNT_FAIL",
                extra={"cause": e.__class__.__name__, "detail": str(e)},
            )
            return
    
        # Determine current UTC time
        now_utc = datetime.now(UTC)
        # If itâ€™s between 00:00 and 00:15 UTC, daily bars may not be published yet.
        if now_utc.hour == 0 and now_utc.minute < 15:
            _log.info("INITIAL_REBALANCE: Too earlyâ€”daily bars not live yet.")
        else:
            # Gather all symbols that have a valid, nonzero close
            valid_symbols = []
            valid_prices = {}
            for symbol in symbols:
                df_daily = ctx.data_fetcher.get_daily_df(ctx, symbol)
                price = get_latest_close(df_daily)
                if price <= 0:
                    # skip symbols with no real close data
                    continue
                valid_symbols.append(symbol)
                valid_prices[symbol] = price
    
            if not valid_symbols:
                log_level = logging.ERROR if in_trading_hours(now_utc) else logging.WARNING
                _log.log(
                    log_level,
                    (
                        "INITIAL_REBALANCE: No valid prices for any symbolâ€”skipping "
                        "rebalance. Possible data outage or market holiday. "
                        "Check data provider/API status."
                    ),
                )
            else:
                # Compute equal weights on valid symbols only
                total_capital = cash
                weight_per = 1.0 / len(valid_symbols)
    
>               positions = {p.symbol: int(p.qty) for p in ctx.api.list_open_positions()}
E               AttributeError: 'DummyAPI' object has no attribute 'list_open_positions'

ai_trading/core/bot_engine.py:12988: AttributeError
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.core.bot_engine:bot_engine.py:1913 get_latest_close called with df: DataFrame
DEBUG    ai_trading.core.bot_engine:bot_engine.py:1938 get_latest_close last_valid_close length: 1
DEBUG    ai_trading.core.bot_engine:bot_engine.py:1944 get_latest_close price from iloc[-1]: 100 (type: int64)
DEBUG    ai_trading.core.bot_engine:bot_engine.py:1959 get_latest_close returning: 100.0
_______________________________________________ test_runner_deprecation_warning ________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_runner_deprecation_warning():
        """Test that importing runner shows deprecation warning."""
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")
            import ai_trading.runner  # noqa: F401
    
            # Check that a deprecation warning was raised
>           assert len(w) >= 1
E           assert 0 >= 1
E            +  where 0 = len([])

tests/test_deprecation_warnings.py:34: AssertionError
_________________________________________________ test_load_weights_save_fail __________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3996350>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_load_weights_save_fail0')
caplog = <_pytest.logging.LogCaptureFixture object at 0x7ff8d334c950>

    def test_load_weights_save_fail(monkeypatch, tmp_path, caplog):
        """Failure to write default weights is logged and default returned."""
        p = tmp_path / "w.csv"
        monkeypatch.setattr(meta_learning.Path, "exists", lambda self: False)
        def fail(*a, **k):
            raise OSError("fail")
        monkeypatch.setattr(meta_learning.np, "savetxt", fail)
        caplog.set_level("ERROR")
>       arr = meta_learning.load_weights(str(p), default=np.array([1.0]))

/workspace/ai-trading-bot/tests/test_meta_learning_additional.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/workspace/ai-trading-bot/ai_trading/meta_learning.py:540: in load_weights
    np.savetxt(p, default, delimiter=",")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = (PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_load_weights_save_fail0/w.csv'), array([1.]))
k = {'delimiter': ','}

    def fail(*a, **k):
>       raise OSError("fail")
E       OSError: fail

/workspace/ai-trading-bot/tests/test_meta_learning_additional.py:14: OSError
_______________________________________________ test_generate_insufficient_data ________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7f8d8503a710>

    def test_generate_insufficient_data(caplog):
        """Insufficient history skips generation."""
        df = pd.DataFrame({"close": [1, 2]})
        ctx = Ctx(df)
        strat = MeanReversionStrategy(lookback=5)
        caplog.set_level('WARNING')
        assert strat.generate(ctx) == []
>       assert "insufficient" in caplog.text
E       AssertionError: assert 'insufficient' in 'WARNING  ai_trading.logging:mean_reversion.py:27 meanâ€¦sion: insuâ€¦ient data\n'
E        +  where 'WARNING  ai_trading.logging:mean_reversion.py:27 meanâ€¦sion: insuâ€¦ient data\n' = <_pytest.logging.LogCaptureFixture object at 0x7f8d8503a710>.text

tests/test_mean_reversion_extra.py:24: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:29,252", "level": "WARNING", "name": "ai_trading.logging", "msg": "meanâ€¦sion: insuâ€¦ient data", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.logging:mean_reversion.py:27 meanâ€¦sion: insuâ€¦ient data
_________________________________________________ test_generate_invalid_stats __________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7f8d859ba350>

    def test_generate_invalid_stats(caplog):
        """Invalid rolling statistics skip generation."""
        df = pd.DataFrame({"close": [1]*10})
        ctx = Ctx(df)
        strat = MeanReversionStrategy(lookback=3)
        caplog.set_level('WARNING')
        ctx.data_fetcher.df.loc[ctx.data_fetcher.df.index[-1], "close"] = float('nan')
        assert strat.generate(ctx) == []
>       assert "invalid rolling" in caplog.text
E       AssertionError: assert 'invalid rolling' in 'WARNING  ai_trading.logging:mean_reversion.py:33 meanâ€¦sion: invalid stats\n'
E        +  where 'WARNING  ai_trading.logging:mean_reversion.py:33 meanâ€¦sion: invalid stats\n' = <_pytest.logging.LogCaptureFixture object at 0x7f8d859ba350>.text

tests/test_mean_reversion_extra.py:35: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:29,280", "level": "WARNING", "name": "ai_trading.logging", "msg": "meanâ€¦sion: invalid stats", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.logging:mean_reversion.py:33 meanâ€¦sion: invalid stats
__________________________________________ TestModelRegistry.test_model_not_picklable __________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_model_registry.TestModelRegistry object at 0x7f867c093390>

    def test_model_not_picklable(self):
        """Test that non-picklable models raise RuntimeError."""
        with tempfile.TemporaryDirectory() as temp_dir:
            registry = ModelRegistry(temp_dir)
    
            # Create a mock object that raises an exception when pickled
            mock_model = Mock()
    
            def pickle_side_effect(*args, **kwargs):
                raise Exception("Cannot pickle this object")
    
            with pytest.raises(RuntimeError, match="Model not picklable"):
                with tempfile.NamedTemporaryFile():
                    # Patch pickle.dumps to raise an exception
                    import pickle as pickle_module
                    original_dumps = pickle_module.dumps
                    pickle_module.dumps = pickle_side_effect
                    try:
>                       registry.register_model(
                            model=mock_model,
                            strategy="test_strategy",
                            model_type="test_type"
                        )

tests/test_model_registry.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/model_registry.py:65: in register_model
    blob = pickle.dumps(model)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<Mock id='140215515290512'>,), kwargs = {}

    def pickle_side_effect(*args, **kwargs):
>       raise Exception("Cannot pickle this object")
E       Exception: Cannot pickle this object

tests/test_model_registry.py:139: Exception
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:29,384", "level": "INFO", "name": "ai_trading.logging", "msg": "Modeâ€¦stry initialized at /tmp/tmpcp8mkhs8", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.logging:model_registry.py:32 Modeâ€¦stry initialized at /tmp/tmpcp8mkhs8
_______________________________________________ test_generate_insufficient_data ________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7f8676b021d0>

    def test_generate_insufficient_data(caplog):
        df = pd.DataFrame({"close": [1]})
        ctx = Ctx(df)
        strat = MomentumStrategy(lookback=2)
        caplog.set_level('WARNING')
        assert strat.generate(ctx) == []
>       assert "Insufficient data" in caplog.text
E       AssertionError: assert 'Insufficient data' in 'INFO     ai_trading.logging:__init__.py:293 Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate\n'
E        +  where 'INFO     ai_trading.logging:__init__.py:293 Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate\n' = <_pytest.logging.LogCaptureFixture object at 0x7f8676b021d0>.text

tests/test_momentum_extra.py:24: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:29,399", "level": "INFO", "name": "ai_trading.logging", "msg": "Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.logging:__init__.py:293 Strategy Simple Momentum Strategy (momentum) initialized with risk level moderate
_______________________________________________ test_generate_insufficient_data ________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7f8676b03050>

    def test_generate_insufficient_data(caplog):
        df = pd.DataFrame({"close": [1, 2]})
        ctx = Ctx(df)
>       strat = MovingAverageCrossoverStrategy(short=3, long=5)
E       TypeError: MovingAverageCrossoverStrategy.__init__() got an unexpected keyword argument 'short'

tests/test_moving_average_crossover_extra.py:26: TypeError
___________________________________________________ test_generate_buy_signal ___________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_generate_buy_signal():
        df = pd.DataFrame({"close": [1, 2, 3, 4, 5, 6]})
        ctx = Ctx(df)
>       strat = MovingAverageCrossoverStrategy(short=2, long=3)
E       TypeError: MovingAverageCrossoverStrategy.__init__() got an unexpected keyword argument 'short'

tests/test_moving_average_crossover_extra.py:35: TypeError
______________________________________ TestMyFixes.test_confidence_normalization_improved ______________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_my_fixes.TestMyFixes testMethod=test_confidence_normalization_improved>

    def test_confidence_normalization_improved(self):
        """Test that confidence score normalization is improved."""
>       with open("strategy_allocator.py") as f:
E       FileNotFoundError: [Errno 2] No such file or directory: 'strategy_allocator.py'

tests/test_my_fixes.py:41: FileNotFoundError
_______________________________________ TestMyFixes.test_data_quality_handling_improved ________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_my_fixes.TestMyFixes testMethod=test_data_quality_handling_improved>

    def test_data_quality_handling_improved(self):
        """Test that data quality validation is improved."""
>       with open("trade_execution.py") as f:
E       FileNotFoundError: [Errno 2] No such file or directory: 'trade_execution.py'

tests/test_my_fixes.py:81: FileNotFoundError
___________________________________________________ test_optional_ml_imports ___________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d8505e410>

    def test_optional_ml_imports(monkeypatch):
        for mod in ("bs4", "transformers"):
            sys.modules.pop(mod, None)
    
        real_import = builtins.__import__
    
        def fake_import(name, *args, **kwargs):
            if name.startswith("bs4") or name.startswith("transformers"):
                raise ImportError
            return real_import(name, *args, **kwargs)
    
        monkeypatch.setattr(builtins, "__import__", fake_import)
    
        from ai_trading.analysis import sentiment
    
>       res = sentiment.analyze_text("hello")

tests/test_optional_ml_imports.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/analysis/sentiment.py:532: in analyze_text
    deps = _load_transformers(logger)
ai_trading/analysis/sentiment.py:70: in _load_transformers
    from transformers import AutoModelForSequenceClassification, AutoTokenizer  # type: ignore
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'transformers'
args = ({'DEVICE': 'cpu', 'HTTP_TIMEOUT': 10.0, 'Lock': <built-in function allocate_lock>, 'SENTIMENT_API_KEY': '', ...}, None, ('AutoModelForSequenceClassification', 'AutoTokenizer'), 0)
kwargs = {}

    def fake_import(name, *args, **kwargs):
        if name.startswith("bs4") or name.startswith("transformers"):
>           raise ImportError
E           ImportError

tests/test_optional_ml_imports.py:13: ImportError
____________________________________________ TestMyFixes.test_duplicate_logging_fix ____________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_my_fixes.TestMyFixes testMethod=test_duplicate_logging_fix>

    def test_duplicate_logging_fix(self):
        """Test that duplicate event logging is eliminated."""
        debug_tracker_path = "ai_trading/execution/debug_tracker.py"
        if os.path.exists(debug_tracker_path):
            with open(debug_tracker_path) as f:
                content = f.read()
    
            # Should use elif instead of else to prevent double logging
>           self.assertIn('elif phase in [ExecutionPhase.SIGNAL_GENERATED', content)
E           AssertionError: 'elif phase in [ExecutionPhase.SIGNAL_GENERATED' not found in '"""Enhanced trade execution debugging and tracking system.\n\nThis module provides comprehensive logging and tracking for the complete\nsignal-to-execution pipeline, including correlation IDs, order lifecycle\ntracking, and detailed execution logging.\n"""\n\nfrom __future__ import annotations\n\nimport logging\nimport time\nimport uuid\nfrom collections import defaultdict, deque\nfrom datetime import UTC, datetime\nfrom enum import Enum\nfrom threading import Lock\nfrom typing import Any\n\nfrom ai_trading.logging import get_logger\n\n\ndef get_phase_logger(name: str, phase: str) -> logging.Logger:\n    """Get a logger for a specific phase - fallback implementation."""\n    logger_name = f"{name}.{phase}" if phase else name\n    return get_logger(logger_name)\n\n\nclass ExecutionPhase(Enum):\n    """Phases of order execution lifecycle."""\n\n    SIGNAL_GENERATED = "signal_generated"\n    RISK_CHECK = "risk_check"\n    ORDER_PREPARED = "order_prepared"\n    ORDER_SUBMITTED = "order_submitted"\n    ORDER_ACKNOWLEDGED = "order_acknowledged"\n    ORDER_FILLED = "order_filled"\n    ORDER_PARTIALLY_FILLED = "order_partially_filled"\n    ORDER_REJECTED = "order_rejected"\n    ORDER_CANCELLED = "order_cancelled"\n    POSITION_UPDATED = "position_updated"\n    PNL_CALCULATED = "pnl_calculated"\n\n\nclass OrderStatus(Enum):\n    """Order execution status."""\n\n    PENDING = "pending"\n    SUBMITTED = "submitted"\n    ACKNOWLEDGED = "acknowledged"\n    FILLED = "filled"\n    PARTIALLY_FILLED = "partially_filled"\n    REJECTED = "rejected"\n    CANCELLED = "cancelled"\n    FAILED = "failed"\n\n\nclass ExecutionDebugTracker:\n    """Comprehensive execution debugging and correlation tracking."""\n\n    def __init__(self):\n        self.logger = get_phase_logger(__name__, "EXEC_DEBUG")\n        self._lock = Lock()\n\n        # Track active orders by correlation ID\n        self._active_orders: dict[str, dict[str, Any]] = {}\n\n        # Track execution timeline for each correlation ID\n        self._execution_timelines: dict[str, list[dict[str, Any]]] = defaultdict(list)\n\n        # Track order lifecycle events\n        self._order_events: dict[str, list[dict[str, Any]]] = defaultdict(list)\n\n        # Track recent execution statistics\n        self._recent_executions: deque = deque(maxlen=1000)\n\n        # Track failed executions for analysis\n        self._failed_executions: deque = deque(maxlen=500)\n\n        # Track position updates\n        self._position_updates: deque = deque(maxlen=500)\n\n        # Debug flags\n        self.verbose_logging = False\n        self.trace_mode = False\n\n    def generate_correlation_id(self, symbol: str, side: str) -> str:\n        """Generate unique correlation ID for tracking order lifecycle."""\n        timestamp = int(time.time() * 1000)  # milliseconds\n        unique_id = str(uuid.uuid4())[:8]\n        return f"{symbol}_{side}_{timestamp}_{unique_id}"\n\n    def start_execution_tracking(\n        self,\n        correlation_id: str,\n        symbol: str,\n        qty: int,\n        side: str,\n        signal_data: dict | None = None,\n    ) -> None:\n        """Start tracking a new order execution."""\n        execution_start = {\n            "correlation_id": correlation_id,\n            "symbol": symbol,\n            "qty": qty,\n            "side": side,\n            "start_time": datetime.now(UTC).isoformat(),\n            "signal_data": signal_data or {},\n            "status": OrderStatus.PENDING.value,\n            "phases": [],\n        }\n\n        # AI-AGENT-REF: Use timeout-based lock to prevent deadlock\n        lock_acquired = False\n        try:\n            lock_acquired = self._lock.acquire(timeout=5.0)\n            if lock_acquired:\n                self._active_orders[correlation_id] = execution_start\n        except (ValueError, TypeError) as e:\n            self.logger.error(\n                "START_TRACKING_ERROR",\n                extra={"correlation_id": correlation_id, "error": str(e)},\n            )\n        finally:\n            if lock_acquired:\n                self._lock.release()\n\n        # AI-AGENT-REF: Call log_execution_event outside of lock to prevent recursive deadlock\n        self.log_execution_event(\n            correlation_id,\n            ExecutionPhase.SIGNAL_GENERATED,\n            {"symbol": symbol, "qty": qty, "side": side, "signal_data": signal_data},\n        )\n\n    def log_execution_event(\n        self,\n        correlation_id: str,\n        phase: ExecutionPhase,\n        data: dict[str, Any] | None = None,\n    ) -> None:\n        """Log an execution phase event with correlation ID."""\n        timestamp = datetime.now(UTC).isoformat()\n\n        event = {\n            "timestamp": timestamp,\n            "correlation_id": correlation_id,\n            "phase": phase.value,\n            "data": data or {},\n        }\n\n        # AI-AGENT-REF: Use timeout-based lock acquisition to prevent deadlock\n        lock_acquired = False\n        try:\n            lock_acquired = self._lock.acquire(timeout=5.0)  # 5 second timeout\n            if not lock_acquired:\n                # Fallback: log without state update to prevent blocking\n                self.logger.warning(\n                    "LOCK_TIMEOUT_EXECUTION_EVENT",\n                    extra={\n                        "correlation_id": correlation_id,\n                        "phase": phase.value,\n                        "message": "Failed to acquire lock within timeout, logging without state update",\n                    },\n                )\n                return\n\n            self._execution_timelines[correlation_id].append(event)\n\n            # Update active order status if relevant\n            if correlation_id in self._active_orders:\n                self._active_orders[correlation_id]["phases"].append(event)\n\n                # Update status based on phase\n                if phase == ExecutionPhase.ORDER_SUBMITTED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.SUBMITTED.value\n                elif phase == ExecutionPhase.ORDER_ACKNOWLEDGED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.ACKNOWLEDGED.value\n                elif phase == ExecutionPhase.ORDER_FILLED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.FILLED.value\n                elif phase == ExecutionPhase.ORDER_PARTIALLY_FILLED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.PARTIALLY_FILLED.value\n                elif phase == ExecutionPhase.ORDER_REJECTED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.REJECTED.value\n                elif phase == ExecutionPhase.ORDER_CANCELLED:\n                    self._active_orders[correlation_id][\n                        "status"\n                    ] = OrderStatus.CANCELLED.value\n        except (ValueError, TypeError) as e:\n            # AI-AGENT-REF: Graceful error handling for lock operations\n            self.logger.error(\n                "EXECUTION_EVENT_ERROR",\n                extra={\n                    "correlation_id": correlation_id,\n                    "phase": phase.value,\n                    "error": str(e),\n                    "message": "Error updating execution event state",\n                },\n            )\n        finally:\n            if lock_acquired:\n                self._lock.release()\n\n        # Log the event (moved outside lock to prevent circular logging)\n        log_data = {\n            "correlation_id": correlation_id,\n            "phase": phase.value,\n            "timestamp": timestamp,\n        }\n        log_data.update(data or {})\n\n        try:\n            if self.verbose_logging or self.trace_mode:\n                self.logger.info(f"EXEC_EVENT_{phase.value.upper()}", extra=log_data)\n            elif phase in [\n                ExecutionPhase.SIGNAL_GENERATED,\n                ExecutionPhase.ORDER_SUBMITTED,\n                ExecutionPhase.ORDER_FILLED,\n                ExecutionPhase.ORDER_REJECTED,\n            ]:\n                # Log only key phases in normal mode (but not if already logged in verbose mode)\n                self.logger.info(f"EXEC_EVENT_{phase.value.upper()}", extra=log_data)\n        except (ValueError, TypeError, AttributeError) as e:\n            # AI-AGENT-REF: Prevent logging errors from cascading\n            self.logger.exception(\n                "debug_tracker: logging error during execution event", exc_info=e\n            )\n\n    def log_order_result(\n        self,\n        correlation_id: str,\n        success: bool,\n        order_data: dict | None = None,\n        error: str | None = None,\n    ) -> None:\n        """Log the final result of an order execution."""\n        timestamp = datetime.now(UTC).isoformat()\n\n        result_data = {\n            "correlation_id": correlation_id,\n            "success": success,\n            "timestamp": timestamp,\n            "order_data": order_data or {},\n            "error": error,\n        }\n\n        # AI-AGENT-REF: Use timeout-based lock to prevent deadlock\n        lock_acquired = False\n        order_info = None\n        found_order = False\n\n        try:\n            lock_acquired = self._lock.acquire(timeout=5.0)\n            if lock_acquired and correlation_id in self._active_orders:\n                order_info = self._active_orders[correlation_id].copy()\n                order_info.update(result_data)\n                found_order = True\n\n                if success:\n                    self._recent_executions.append(order_info)\n                else:\n                    self._failed_executions.append(order_info)\n\n                # Remove from active orders\n                del self._active_orders[correlation_id]\n        except (ValueError, TypeError) as e:\n            self.logger.error(\n                "ORDER_RESULT_ERROR",\n                extra={"correlation_id": correlation_id, "error": str(e)},\n            )\n        finally:\n            if lock_acquired:\n                self._lock.release()\n\n        # AI-AGENT-REF: Log outside of lock to prevent circular logging deadlock\n        try:\n            if found_order:\n                if success:\n                    self.logger.info("ORDER_EXECUTION_SUCCESS", extra=result_data)\n                else:\n                    self.logger.error("ORDER_EXECUTION_FAILED", extra=result_data)\n            else:\n                self.logger.warning(\n                    "UNKNOWN_CORRELATION_ID",\n                    extra={\n                        "correlation_id": correlation_id,\n                        "message": "Attempted to log result for unknown correlation ID",\n                    },\n                )\n        except (ValueError, TypeError, AttributeError) as e:\n            # AI-AGENT-REF: Prevent logging errors from cascading\n            self.logger.exception(\n                "debug_tracker: logging error during order result", exc_info=e\n            )\n\n    def log_position_update(\n        self,\n        symbol: str,\n        old_qty: float,\n        new_qty: float,\n        correlation_id: str | None = None,\n    ) -> None:\n        """Log position updates with optional correlation to order."""\n        position_update = {\n            "timestamp": datetime.now(UTC).isoformat(),\n            "symbol": symbol,\n            "old_qty": old_qty,\n            "new_qty": new_qty,\n            "qty_change": new_qty - old_qty,\n            "correlation_id": correlation_id,\n        }\n\n        with self._lock:\n            self._position_updates.append(position_update)\n\n        if correlation_id:\n            self.log_execution_event(\n                correlation_id, ExecutionPhase.POSITION_UPDATED, position_update\n            )\n\n        self.logger.info("POSITION_UPDATE", extra=position_update)\n\n    def get_active_orders(self) -> dict[str, dict[str, Any]]:\n        """Get all currently active orders being tracked."""\n        with self._lock:\n            return self._active_orders.copy()\n\n    def get_execution_timeline(self, correlation_id: str) -> list[dict[str, Any]]:\n        """Get the complete execution timeline for a correlation ID."""\n        with self._lock:\n            return self._execution_timelines[correlation_id].copy()\n\n    def get_recent_executions(self, limit: int = 50) -> list[dict[str, Any]]:\n        """Get recent successful executions."""\n        with self._lock:\n            return list(self._recent_executions)[-limit:]\n\n    def get_failed_executions(self, limit: int = 50) -> list[dict[str, Any]]:\n        """Get recent failed executions for analysis."""\n        with self._lock:\n            return list(self._failed_executions)[-limit:]\n\n    def get_position_updates(\n        self, symbol: str | None = None, limit: int = 50\n    ) -> list[dict[str, Any]]:\n        """Get recent position updates, optionally filtered by symbol."""\n        with self._lock:\n            updates = list(self._position_updates)[-limit:]\n            if symbol:\n                updates = [u for u in updates if u["symbol"] == symbol]\n            return updates\n\n    def set_debug_mode(self, verbose: bool = True, trace: bool = False) -> None:\n        """Enable/disable debug logging modes."""\n        self.verbose_logging = verbose\n        self.trace_mode = trace\n\n        mode = "TRACE" if trace else "VERBOSE" if verbose else "NORMAL"\n        self.logger.info("DEBUG_MODE_CHANGED", extra={"mode": mode})\n\n    def get_execution_stats(self) -> dict[str, Any]:\n        """Get execution statistics for monitoring."""\n        with self._lock:\n            active_count = len(self._active_orders)\n            recent_success_count = len(self._recent_executions)\n            recent_failure_count = len(self._failed_executions)\n\n            # Calculate success rate from recent executions\n            total_recent = recent_success_count + recent_failure_count\n            success_rate = (\n                recent_success_count / total_recent if total_recent > 0 else 0\n            )\n\n            # Get status breakdown of active orders\n            status_breakdown = {}\n            for order in self._active_orders.values():\n                status = order.get("status", "unknown")\n                status_breakdown[status] = status_breakdown.get(status, 0) + 1\n\n            return {\n                "active_orders": active_count,\n                "recent_successes": recent_success_count,\n                "recent_failures": recent_failure_count,\n                "success_rate": success_rate,\n                "status_breakdown": status_breakdown,\n                "position_updates_count": len(self._position_updates),\n            }\n\n\n# Global debug tracker instance\n_debug_tracker: ExecutionDebugTracker | None = None\n_tracker_lock = Lock()\n\n\ndef get_debug_tracker() -> ExecutionDebugTracker:\n    """Get or create the global debug tracker instance."""\n    global _debug_tracker\n    with _tracker_lock:\n        if _debug_tracker is None:\n            _debug_tracker = ExecutionDebugTracker()\n        return _debug_tracker\n\n\ndef enable_debug_mode(verbose: bool = True, trace: bool = False) -> None:\n    """Enable debug mode for execution tracking."""\n    tracker = get_debug_tracker()\n    tracker.set_debug_mode(verbose, trace)\n\n\ndef log_signal_to_execution(\n    symbol: str, side: str, qty: int, signal_data: dict | None = None\n) -> str:\n    """Start tracking a signal-to-execution flow and return correlation ID."""\n    tracker = get_debug_tracker()\n    correlation_id = tracker.generate_correlation_id(symbol, side)\n    tracker.start_execution_tracking(correlation_id, symbol, qty, side, signal_data)\n    return correlation_id\n\n\ndef log_execution_phase(\n    correlation_id: str, phase: ExecutionPhase, data: dict | None = None\n) -> None:\n    """Log an execution phase with correlation ID."""\n    tracker = get_debug_tracker()\n    tracker.log_execution_event(correlation_id, phase, data)\n\n\ndef log_order_outcome(\n    correlation_id: str,\n    success: bool,\n    order_data: dict | None = None,\n    error: str | None = None,\n) -> None:\n    """Log the final outcome of an order execution."""\n    tracker = get_debug_tracker()\n    tracker.log_order_result(correlation_id, success, order_data, error)\n\n\ndef log_position_change(\n    symbol: str, old_qty: float, new_qty: float, correlation_id: str | None = None\n) -> None:\n    """Log a position change with optional correlation to order."""\n    tracker = get_debug_tracker()\n    tracker.log_position_update(symbol, old_qty, new_qty, correlation_id)\n\n\ndef get_execution_statistics() -> dict[str, Any]:\n    """Get current execution statistics."""\n    tracker = get_debug_tracker()\n    return tracker.get_execution_stats()\n'

tests/test_my_fixes.py:32: AssertionError
_______________________________________ TestMyFixes.test_liquidity_thresholds_increased ________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_my_fixes.TestMyFixes testMethod=test_liquidity_thresholds_increased>

    def test_liquidity_thresholds_increased(self):
        """Test that liquidity thresholds are made less aggressive."""
>       with open("config.py") as f:
E       FileNotFoundError: [Errno 2] No such file or directory: 'config.py'

tests/test_my_fixes.py:69: FileNotFoundError
__________________________________________________ test_retrain_meta_learner ___________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d33d9310>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_retrain_meta_learner0')

    def test_retrain_meta_learner(monkeypatch, tmp_path):
        """Meta learner retrains with small dataset."""
        data = Path(tmp_path / "trades.csv")
        df = meta_learning.pd.DataFrame({
            "entry_price": [1, 2],
            "exit_price": [2, 3],
            "signal_tags": ["a", "b"],
            "side": ["buy", "sell"],
        })
        df.to_csv(data, index=False)
        monkeypatch.setattr(meta_learning, "save_model_checkpoint", lambda *a, **k: None)
        monkeypatch.setattr(meta_learning, "load_model_checkpoint", lambda *a, **k: [])
        monkeypatch.setattr(sklearn.linear_model, "Ridge", lambda *a, **k: types.SimpleNamespace(fit=lambda X,y, sample_weight=None: None, predict=lambda X:[0]*len(X)))
        ok = meta_learning.retrain_meta_learner(str(data), str(tmp_path/"m.pkl"), str(tmp_path/"hist.pkl"), min_samples=1)
>       assert ok
E       assert False

tests/test_meta_learning_additional.py:52: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:29,214", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "METAâ€¦TART", "trade_log": "/tmp/pytest-of-root/pytest-0/popen-gw0/test_retrain_meta_learner0/trades.csv", "model_path": "/tmp/pytest-of-root/pytest-0/popen-gw0/test_retrain_meta_learner0/m.pkl", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:29,221", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "METAâ€¦HECK", "file_exists": true, "valid_format": true, "total_rows": 2, "valid_price_rows": 2, "quality_score": 1.0, "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.meta_learning:meta_learning.py:681 METAâ€¦TART
INFO     ai_trading.meta_learning:meta_learning.py:731 METAâ€¦HECK
DEBUG    ai_trading.meta_learning:meta_learning.py:760 META_LEARNING_RAW_DATA: 2 total rows loaded from /tmp/pytest-of-root/pytest-0/popen-gw0/test_retrain_meta_learner0/trades.csv
DEBUG    ai_trading.meta_learning:meta_learning.py:799 META_LEARNING_PURE_FORMAT: Detected pure meta-learning format
DEBUG    ai_trading.meta_learning:meta_learning.py:838 META_LEARNING_INITIAL_DATA: 2 rows before validation
INFO     ai_trading.meta_learning:meta_learning.py:920 METAâ€¦LITY: Retained 2/2 trades (100.0%)
DEBUG    ai_trading.meta_learning:meta_learning.py:936 META_LEARNING_PRICE_STATS: Entry prices $1.00-$3.00 (avg: $1.50)
DEBUG    ai_trading.meta_learning:meta_learning.py:939 META_LEARNING_PRICE_STATS: Exit prices $2.00-$3.00 (avg: $2.50)
INFO     ai_trading.meta_learning:meta_learning.py:969 sklearn disabled, metaâ€¦ning disabled
______________________________________ TestMyFixes.test_meta_learning_thresholds_reduced _______________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_my_fixes.TestMyFixes testMethod=test_meta_learning_thresholds_reduced>

    def test_meta_learning_thresholds_reduced(self):
        """Test that meta-learning thresholds are reduced to allow easier activation."""
>       with open("bot_engine.py") as f:
E       FileNotFoundError: [Errno 2] No such file or directory: 'bot_engine.py'

tests/test_my_fixes.py:14: FileNotFoundError
_________________________________________ TestMyFixes.test_position_limit_rebalancing __________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_my_fixes.TestMyFixes testMethod=test_position_limit_rebalancing>

    def test_position_limit_rebalancing(self):
        """Test that position limits allow rebalancing."""
>       with open("bot_engine.py") as f:
E       FileNotFoundError: [Errno 2] No such file or directory: 'bot_engine.py'

tests/test_my_fixes.py:56: FileNotFoundError
_________________________________________ test_timeoutsession_injects_default_timeout __________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8677eee510>

    def test_timeoutsession_injects_default_timeout(monkeypatch):
        captured = {}
    
        def fake_request(self, method, url, **kwargs):  # AI-AGENT-REF: capture timeout
            captured.update(kwargs)
            return types.SimpleNamespace(ok=True)
    
>       monkeypatch.setattr(requests.Session, "request", fake_request, raising=True)
E       AttributeError: module 'requests' has no attribute 'Session'

tests/test_net_http_timeout.py:16: AttributeError
_____________________________________________ test_build_retrying_session_defaults _____________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f867c24ed90>

    def test_build_retrying_session_defaults(monkeypatch):
        captured = {}
    
        def fake_request(self, method, url, **kwargs):  # AI-AGENT-REF: capture timeout
            captured.update(kwargs)
            return types.SimpleNamespace(ok=True)
    
>       monkeypatch.setattr(requests.Session, "request", fake_request, raising=True)
E       AttributeError: module 'requests' has no attribute 'Session'

tests/test_net_http_timeout.py:34: AttributeError
______________________________________________ test_legacy_modules_not_importable ______________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    @pytest.mark.unit
    def test_legacy_modules_not_importable():  # AI-AGENT-REF
        for name in BANNED:
>           assert importlib.util.find_spec(name) is None
E           AssertionError: assert ModuleSpec(name='metrics', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7f8677eeeb10>, origin='/wor.../ai_trading/metrics/__init__.py', submodule_search_locations=['/workspace/ai-trading-bot/tests/../ai_trading/metrics']) is None
E            +  where ModuleSpec(name='metrics', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7f8677eeeb10>, origin='/wor.../ai_trading/metrics/__init__.py', submodule_search_locations=['/workspace/ai-trading-bot/tests/../ai_trading/metrics']) = <function find_spec at 0x7f86948498a0>('metrics')
E            +    where <function find_spec at 0x7f86948498a0> = <module 'importlib.util' (frozen)>.find_spec
E            +      where <module 'importlib.util' (frozen)> = importlib.util

tests/test_no_legacy_imports.py:19: AssertionError
________________________________________________ test_optimize_signals_fallback ________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d37eb9d0>

    def test_optimize_signals_fallback(monkeypatch):
        # Force missing meta module -> fallback should return input unchanged
        sys.modules.pop("ai_trading.meta_learning", None)
        import importlib
        eng = importlib.import_module("ai_trading.core.bot_engine")
        dummy = [{"sym":"AAPL","score":0.5}, {"sym":"MSFT","score":0.4}]
>       out = eng.optimize_signals(dummy)  # type: ignore[attr-defined]
E       TypeError: optimize_signals() missing 1 required positional argument: 'cfg'

tests/test_meta_learning_optional.py:21: TypeError
_________________________________________________ test_no_raw_requests_in_src __________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_no_raw_requests_in_src():
        root = pathlib.Path(__file__).resolve().parents[1] / "ai_trading"
        banned = []
        for p in root.rglob("*.py"):
            if "utils/http.py" in str(p):
                continue
            txt = p.read_text(encoding="utf-8", errors="ignore")
            if re.search(r"\brequests\.(get|post|put|delete|patch|head|options)\b", txt):
                banned.append(str(p))
>       assert not banned, f"Raw requests.* found in: {banned}"
E       AssertionError: Raw requests.* found in: ['/workspace/ai-trading-bot/ai_trading/predict.py', '/workspace/ai-trading-bot/ai_trading/data_fetcher.py', '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py', '/workspace/ai-trading-bot/ai_trading/analysis/sentiment.py']
E       assert not ['/workspace/ai-trading-bot/ai_trading/predict.py', '/workspace/ai-trading-bot/ai_trading/data_fetcher.py', '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py', '/workspace/ai-trading-bot/ai_trading/analysis/sentiment.py']

tests/test_no_raw_requests.py:14: AssertionError
________________________________________________ test_ai_trading_module_imports ________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_ai_trading_module_imports():
        # Test that modules can be imported from the package
        import importlib
    
        # Test each moved module can be imported from ai_trading
        modules = ["signals", "data_fetcher", "trade_execution", "indicators", "pipeline", "portfolio", "rebalancer"]
        for module_name in modules:
>           pkg_module = importlib.import_module(f"ai_trading.{module_name}")

tests/test_package_first_smoke.py:15: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1204: in _gcd_import
    ???
<frozen importlib._bootstrap>:1176: in _find_and_load
    ???
<frozen importlib._bootstrap>:1147: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:690: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:940: in exec_module
    ???
<frozen importlib._bootstrap>:241: in _call_with_frames_removed
    ???
ai_trading/signals.py:114: in <module>
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
_________________________________________________ test_ai_trading_init_exports _________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_ai_trading_init_exports():
        # Test that ai_trading.__init__ properly exports the modules
        import ai_trading
    
        modules = ["signals", "data_fetcher", "trade_execution", "indicators", "pipeline", "portfolio", "rebalancer"]
        for module_name in modules:
>           assert hasattr(ai_trading, module_name)
E           AssertionError: assert False
E            +  where False = hasattr(<module 'ai_trading' from '/workspace/ai-trading-bot/ai_trading/__init__.py'>, 'signals')

tests/test_package_first_smoke.py:24: AssertionError
______________________________________________ test_kelly_parameters_optimization ______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_kelly_parameters_optimization():
        """Test that Kelly parameters are optimized correctly."""
        from ai_trading.core.constants import KELLY_PARAMETERS
    
        # Verify optimized Kelly parameters
>       assert KELLY_PARAMETERS["MAX_KELLY_FRACTION"] == 0.15, f"Expected 0.15, got {KELLY_PARAMETERS['MAX_KELLY_FRACTION']}"
E       AssertionError: Expected 0.15, got 0.3
E       assert 0.3 == 0.15

tests/test_parameter_optimization.py:21: AssertionError
______________________________________________ test_adaptive_sizing_optimization _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_adaptive_sizing_optimization():
        """Test that adaptive sizing uses optimized parameters."""
        try:
            from ai_trading.core.enums import RiskLevel
            from ai_trading.risk.adaptive_sizing import AdaptivePositionSizer
    
            # Test that sizer can be instantiated with optimized parameters
>           sizer = AdaptivePositionSizer(RiskLevel.MODERATE)
E           TypeError: object() takes no arguments

tests/test_parameter_optimization.py:101: TypeError
____________________________________________________ test_order_idempotency ____________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_order_idempotency():
        """Test order idempotency caching."""
        # Clear any existing cache
>       from ai_trading.execution.idempotency import (
            get_idempotency_cache,
            is_duplicate_order,
            mark_order_submitted,
        )

tests/test_peak_performance.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
_________________________________________________ test_position_reconciliation _________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_position_reconciliation():
        """Test position reconciliation logic."""
        from datetime import datetime
    
        from ai_trading.core.interfaces import Position
>       from ai_trading.execution.reconcile import PositionReconciler

tests/test_peak_performance.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
______________________________________________________ test_aligned_clock ______________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_aligned_clock():
        """Test exchange-aligned clock functionality."""
        from ai_trading.scheduler.aligned_clock import AlignedClock
    
        clock = AlignedClock(max_skew_ms=250.0)
    
        # Test skew checking
>       skew = clock.check_skew()

tests/test_peak_performance.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/scheduler/aligned_clock.py:195: in check_skew
    exchange_time = self.get_exchange_time()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.scheduler.aligned_clock.AlignedClock object at 0x7f8d8522c3d0>

    def get_exchange_time(self) -> datetime:
        """
        Get current exchange time (EST/EDT for NYSE).
    
        Returns:
            Current time in exchange timezone
        """
        utc_now = datetime.now(UTC)
    
        if self.calendar:
            try:
                # Get exchange timezone from calendar
>               exchange_tz = self.calendar.tz
E               AttributeError: 'types.SimpleNamespace' object has no attribute 'tz'

ai_trading/scheduler/aligned_clock.py:81: AttributeError
______________________________________________________ test_symbol_costs _______________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_symbol_costs():
        """Test symbol-aware cost model."""
>       from ai_trading.execution.costs import SymbolCostModel, SymbolCosts

tests/test_peak_performance.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
_________________________________________________ test_adaptive_risk_controls __________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_adaptive_risk_controls():
        """Test adaptive risk control system."""
        from ai_trading.portfolio.risk_controls import AdaptiveRiskController
    
        # Create test data
        np.random.seed(42)
        dates = pd.date_range('2023-01-01', periods=100, freq='D')
        symbols = ['AAPL', 'GOOGL', 'MSFT']
    
        returns_data = pd.DataFrame(
            np.random.normal(0, 0.02, (100, 3)),
            index=dates,
            columns=symbols
        )
    
        controller = AdaptiveRiskController()
    
        # Test volatility calculation
        vols = controller.calculate_volatilities(returns_data)
        assert len(vols) == 3
        for symbol in symbols:
            assert symbol in vols
            assert vols[symbol] > 0
    
        # Test correlation clustering (skip if scipy not available)
        try:
>           clusters = controller.calculate_correlation_clusters(returns_data)

tests/test_peak_performance.py:188: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/portfolio/risk_controls.py:185: in calculate_correlation_clusters
    fcluster, linkage, squareform, clustering_available = _import_clustering()
ai_trading/portfolio/risk_controls.py:23: in _import_clustering
    if not S.ENABLE_PORTFOLIO_FEATURES:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
item = 'ENABLE_PORTFOLIO_FEATURES'

    def __getattr__(self, item: str) -> Any:
        private_attributes = object.__getattribute__(self, '__private_attributes__')
        if item in private_attributes:
            attribute = private_attributes[item]
            if hasattr(attribute, '__get__'):
                return attribute.__get__(self, type(self))  # type: ignore
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                return self.__pydantic_private__[item]  # type: ignore
            except KeyError as exc:
                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
        else:
            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.
            # See `BaseModel.__repr_args__` for more details
            try:
                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')
            except AttributeError:
                pydantic_extra = None
    
            if pydantic_extra:
                try:
                    return pydantic_extra[item]
                except KeyError as exc:
                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
            else:
                if hasattr(self.__class__, item):
                    return super().__getattribute__(item)  # Raises AttributeError if appropriate
                else:
                    # this is the current error
>                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E                   AttributeError: 'Settings' object has no attribute 'ENABLE_PORTFOLIO_FEATURES'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:991: AttributeError
_______________________________________________________ test_determinism _______________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_determinism():
        """Test deterministic training setup."""
        from ai_trading.utils.determinism import hash_data, set_random_seeds
    
        # Test seed setting
>       set_random_seeds(42)

tests/test_peak_performance.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

seed = 42

    def set_random_seeds(seed: int = 42) -> None:
        """
        Set random seeds for reproducible results.
    
        Args:
            seed: Random seed value
        """
        # Python random
        random.seed(seed)
    
        # NumPy (if available)
>       if HAS_NUMPY:
E       NameError: name 'HAS_NUMPY' is not defined

ai_trading/utils/determinism.py:35: NameError
___________________________________________________ test_metalearning_import ___________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_metalearning_import():
        """Test that MetaLearning can be imported without errors."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:261: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
____________________________________________ test_no_metalearn_invalid_prices_error ____________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_no_metalearn_invalid_prices_error():
        """Test that the strategy doesn't generate METALEARN_INVALID_PRICES errors."""
>       from ai_trading.strategies.metalearning import MetaLearning

tests/test_metalearning_strategy.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    MetaLearning trading strategy using machine learning for price prediction.
    
    This strategy implements ensemble machine learning methods to predict price movements
    and generate trading signals with confidence scoring and risk assessment.
    """
    
    import warnings
    from datetime import UTC, datetime, timedelta
    from typing import Any
    
    from ai_trading.exc import COMMON_EXC  # AI-AGENT-REF: narrow handler
    
    warnings.filterwarnings("ignore")
    
    # AI-AGENT-REF: Use centralized logger as per AGENTS.md
    # AI-AGENT-REF: Import dependencies - sklearn is a hard dependency
    import numpy as np
    
    from ai_trading.logging import logger
    
    NUMPY_AVAILABLE = True
    
    
    PANDAS_AVAILABLE = True
    
    # AI-AGENT-REF: Import data fetcher for historical data
    # Machine learning imports - sklearn is a hard dependency
>   from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
E   ImportError: cannot import name 'GradientBoostingClassifier' from 'sklearn.ensemble' (unknown location)

ai_trading/strategies/metalearning.py:29: ImportError
___________________________________________________ test_smart_order_routing ___________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_smart_order_routing():
        """Test smart order routing functionality."""
>       from ai_trading.execution.order_policy import (
            MarketData,
            OrderUrgency,
            SmartOrderRouter,
        )

tests/test_peak_performance.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
__________________________________ TestConfigurationEnhancements.test_order_management_config __________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_phase2_enhancements.TestConfigurationEnhancements testMethod=test_order_management_config>

    def test_order_management_config(self):
        """Test order management configuration parameters."""
        required_params = [
            'ORDER_TIMEOUT_SECONDS',
            'ORDER_STALE_CLEANUP_INTERVAL',
            'ORDER_FILL_RATE_TARGET',
            'ORDER_MAX_RETRY_ATTEMPTS'
        ]
    
        for param in required_params:
>           self.assertTrue(hasattr(config, param), f"Missing parameter: {param}")
E           AssertionError: False is not true : Missing parameter: ORDER_MAX_RETRY_ATTEMPTS

tests/test_phase2_enhancements.py:232: AssertionError
___________________________________ TestConfigurationEnhancements.test_system_health_config ____________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_phase2_enhancements.TestConfigurationEnhancements testMethod=test_system_health_config>

    def test_system_health_config(self):
        """Test system health monitoring configuration parameters."""
        required_params = [
            'SYSTEM_HEALTH_CHECK_INTERVAL',
            'SYSTEM_HEALTH_ALERT_THRESHOLD',
            'SYSTEM_HEALTH_EXPORT_ENABLED',
            'SYSTEM_HEALTH_REPORT_PATH'
        ]
    
        for param in required_params:
>           self.assertTrue(hasattr(config, param), f"Missing parameter: {param}")
E           AssertionError: False is not true : Missing parameter: SYSTEM_HEALTH_CHECK_INTERVAL

tests/test_phase2_enhancements.py:250: AssertionError
___________________________________________________ test_short_close_queued ____________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d84cbf4d0>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7f8d84cbf890>

    def test_short_close_queued(monkeypatch, caplog):
        state = bot_engine.BotState()
        state.position_cache = {"TSLA": -44}
        bot_engine.state = state
        caplog.set_level("INFO")
    
        orders = []
        monkeypatch.setattr(bot_engine, "submit_order", lambda ctx, symbol, qty, side: orders.append((symbol, qty, side)))
        monkeypatch.setattr(bot_engine, "is_market_open", lambda: True)
        monkeypatch.setattr(bot_engine, "fetch_minute_df_safe", lambda s: pd.DataFrame({"close": [1]}, index=[pd.Timestamp("2023-01-01")]))
        monkeypatch.setattr(bot_engine, "_safe_trade", lambda *a, **k: None)
>       monkeypatch.setattr(bot_engine.prediction_executor, "submit", lambda fn, s: types.SimpleNamespace(result=lambda: fn(s)))
E       AttributeError: None has no attribute 'submit'

tests/test_portfolio.py:18: AttributeError
____________________________________________ test_position_hold_signals_generation _____________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_position_hold_signals_generation():
        """Test position hold signal generation."""
>       from ai_trading.signals import generate_position_hold_signals

tests/test_position_holding.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/signals.py:114: in <module>
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
_________________________________________ test_signals_enhancement_with_position_logic _________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_signals_enhancement_with_position_logic():
        """Test that signals are enhanced with position holding logic."""
>       from ai_trading.signals import enhance_signals_with_position_logic

tests/test_position_holding.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/signals.py:114: in <module>
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
_________________________________________ test_minute_fallback_debug_path_emits_record _________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7ff8d3986150>

    def test_minute_fallback_debug_path_emits_record(caplog):
        caplog.set_level("DEBUG")
>       bars_mod.fetch_minute_fallback(None, "SPY", now_utc=bars_mod.now_utc())

tests/test_minute_fallback_debug_path.py:8: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/data/bars.py:374: in fetch_minute_fallback
    df = _get_minute_bars(symbol, start_u, end_u, feed=feed_str)
ai_trading/data/bars.py:286: in _get_minute_bars
    df = get_bars(symbol=symbol, timeframe="1Min", start=start_dt, end=end_dt, feed=feed)
ai_trading/data_fetcher.py:585: in get_bars
    return _fetch_bars(
ai_trading/data_fetcher.py:511: in _fetch_bars
    return _req(fallback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fallback = ('1Min', 'sip', datetime.datetime(2025, 8, 22, 13, 30, tzinfo=datetime.timezone.utc), datetime.datetime(2025, 8, 22, 20, 0, tzinfo=datetime.timezone.utc))

    def _req(fallback: tuple[str, str, _dt.datetime, _dt.datetime] | None) -> pd.DataFrame:
        nonlocal _interval, _feed, _start, _end
        params = {
            "symbols": symbol,
            "timeframe": _interval,
            "start": _start.isoformat(),
            "end": _end.isoformat(),
            "limit": 10000,
            "feed": _feed,
            "adjustment": adjustment,
        }
        if requests is None:  # pragma: no cover
            raise RuntimeError("requests not available")
        url = "https://data.alpaca.markets/v2/stocks/bars"
        headers = {
            "APCA-API-KEY-ID": os.getenv("ALPACA_API_KEY", ""),
            "APCA-API-SECRET-KEY": os.getenv("ALPACA_SECRET_KEY", ""),
        }
        try:
            resp = requests.get(url, params=params, headers=headers, timeout=10)
>           status = resp.status_code
E           AttributeError: 'NoneType' object has no attribute 'status_code'

ai_trading/data_fetcher.py:349: AttributeError
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.data.bars:bars.py:48 DATA_FALLBACK_WINDOW_DEBUG
__________________________________________________ test_meta_learning_trigger __________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_meta_learning_trigger():
        """Test meta-learning conversion trigger."""
>       with patch('meta_learning.config') as mock_config, \
             patch('meta_learning.pd') as mock_pd, \
             patch('ai_trading.meta_learning.Path') as mock_path:

tests/test_position_holding.py:108: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f8d85015a10>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'ai_trading.meta_learning' from '/workspace/ai-trading-bot/ai_trading/meta_learning.py'> does not have the attribute 'config'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError
________________________________________________ test_position_manager_cleanup _________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_position_manager_cleanup():
        """Test position manager cleanup of stale positions."""
        from ai_trading.position.legacy_manager import PositionManager
    
        # Create mock context
        ctx = Mock()
        ctx.api = Mock()
    
        # Mock current positions (only AAPL exists now)
        current_positions = [Mock(symbol="AAPL")]
        ctx.api.get_all_positions.return_value = current_positions
    
        # Create position manager with existing tracked positions
        pm = PositionManager(ctx)
        pm.positions = {
            "AAPL": Mock(),
            "GOOGL": Mock(),  # This should be cleaned up
            "MSFT": Mock()    # This should be cleaned up
        }
    
        # Test cleanup
        pm.cleanup_stale_positions()
    
        # Only AAPL should remain
        assert "AAPL" in pm.positions
>       assert "GOOGL" not in pm.positions
E       AssertionError: assert 'GOOGL' not in {'AAPL': <Mock id='140245798729232'>, 'GOOGL': <Mock id='140245799179088'>, 'MSFT': <Mock id='140245799025488'>}
E        +  where {'AAPL': <Mock id='140245798729232'>, 'GOOGL': <Mock id='140245799179088'>, 'MSFT': <Mock id='140245799025488'>} = <ai_trading.position.legacy_manager.PositionManager object at 0x7f8d850cfc10>.positions

tests/test_position_holding.py:183: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:30,737", "level": "INFO", "name": "ai_trading.position.legacy_manager.PositionManager", "msg": "Intelligent position manager not available: No module named 'inteâ€¦ager'; using legacy", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:30,738", "level": "WARNING", "name": "ai_trading.position.legacy_manager.PositionManager", "msg": "cleaâ€¦ions failed: 'Mock' object is not iterable", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.position.legacy_manager.PositionManager:legacy_manager.py:86 Intelligent position manager not available: No module named 'intelligent_manager'; using legacy
WARNING  ai_trading.position.legacy_manager.PositionManager:legacy_manager.py:432 cleaâ€¦ions failed: 'Mock' object is not iterable
_____________________________________________________ test_fit_and_predict _____________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_fit_and_predict0')

    def test_fit_and_predict(tmp_path):
        model = MLModel(DummyPipe())
        df = make_df()
        mse = model.fit(df, np.array([0, 1]))
>       assert mse >= 0
E       TypeError: '>=' not supported between instances of 'MLModel' and 'int'

tests/test_ml_model_extra.py:46: TypeError
___________________________ TestProblemStatementFixes.test_meta_learning_minimum_trades_requirement ____________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_problem_statement_fixes.TestProblemStatementFixes testMethod=test_meta_learning_minimum_trades_requirement>

    def test_meta_learning_minimum_trades_requirement(self):
        """Test that meta-learning minimum trade requirement is reduced to 2."""
        # Test by reading the source code directly to avoid import issues
        bot_engine_path = "bot_engine.py"
        if os.path.exists(bot_engine_path):
            with open(bot_engine_path) as f:
                content = f.read()
    
            # Look for the environment variable default
            import re
            pattern = r'METALEARN_MIN_TRADES.*"(\d+)"'
            match = re.search(pattern, content)
            if match:
                current_value = int(match.group(1))
                expected_value = 2  # Updated from 3 to 2
                self.assertEqual(current_value, expected_value,
                               f"METALEARN_MIN_TRADES default should be {expected_value}, got {current_value}")
            else:
                self.fail("Could not find METALEARN_MIN_TRADES parameter in load_global_signal_performance")
        else:
>           self.fail("bot_engine.py not found")
E           AssertionError: bot_engine.py not found

tests/test_problem_statement_fixes.py:64: AssertionError
________________________________ TestProblemStatementFixes.test_order_quantity_tracking_clarity ________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_problem_statement_fixes.TestProblemStatementFixes testMethod=test_order_quantity_tracking_clarity>

    def test_order_quantity_tracking_clarity(self):
        """Test that order quantity tracking provides clear distinction between
        requested, submitted, and filled quantities."""
        # Check that the trade execution logs have clear field names
        trade_execution_path = "trade_execution.py"
        if os.path.exists(trade_execution_path):
            with open(trade_execution_path) as f:
                content = f.read()
    
                # Check for clear quantity field names in FULL_FILL_SUCCESS
                self.assertIn('"requested_qty":', content,
                            "FULL_FILL_SUCCESS should include clear requested_qty field")
                self.assertIn('"filled_qty":', content,
                            "FULL_FILL_SUCCESS should include clear filled_qty field")
    
                # Check for clear quantity field names in ORDER_FILL_CONSOLIDATED
                self.assertIn('"total_filled_qty":', content,
                            "ORDER_FILL_CONSOLIDATED should use clear total_filled_qty field name")
    
        else:
>           self.fail("trade_execution.py not found")
E           AssertionError: trade_execution.py not found

tests/test_problem_statement_fixes.py:102: AssertionError
__________________________________ TestProblemStatementFixes.test_pltr_sector_classification ___________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_problem_statement_fixes.TestProblemStatementFixes testMethod=test_pltr_sector_classification>

    def test_pltr_sector_classification(self):
        """Test that PLTR is classified as Technology sector."""
        # Test by reading the source code directly to avoid import issues
        bot_engine_path = "bot_engine.py"
        if os.path.exists(bot_engine_path):
            with open(bot_engine_path) as f:
                content = f.read()
    
            # Check if PLTR is in the Technology sector mapping
            if '"PLTR": "Technology"' in content:
                pass
            else:
                self.fail("PLTR not found in Technology sector mapping")
        else:
>           self.fail("bot_engine.py not found")
E           AssertionError: bot_engine.py not found

tests/test_problem_statement_fixes.py:80: AssertionError
_____________________________________________________ test_import_contract _____________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_import_contract() -> None:
        code, out = run([sys.executable, "tools/import_contract.py"])
>       assert code == 0, f"Import contract failed:\n{out}"
E       AssertionError: Import contract failed:
E         
E       assert 1 == 0

tests/test_import_wiring.py:24: AssertionError
_________________________________________________ test_meta_learning_functions _________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_meta_learning_functions():
        """Test meta-learning conversion functions."""
    
>       with patch('meta_learning.config') as mock_config:

tests/test_position_holding_simple.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7ff8d345d150>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'ai_trading.meta_learning' from '/workspace/ai-trading-bot/ai_trading/meta_learning.py'> does not have the attribute 'config'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError
____________________________________________________ test_predict_function _____________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    from __future__ import annotations
    
    from functools import lru_cache
    
    try:  # AI-AGENT-REF: optional cachetools TTL cache
>       from cachetools import TTLCache
E       ModuleNotFoundError: No module named 'cachetools'

ai_trading/predict.py:6: ModuleNotFoundError

During handling of the above exception, another exception occurred:

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_predict_function0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3947090>

    @pytest.mark.smoke
    def test_predict_function(tmp_path, monkeypatch):
>       predict = _import_predict(monkeypatch)

tests/test_predict_smoke.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_predict_smoke.py:22: in _import_predict
    return importlib.import_module("ai_trading.predict")
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1204: in _gcd_import
    ???
<frozen importlib._bootstrap>:1176: in _find_and_load
    ???
<frozen importlib._bootstrap>:1147: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:690: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:940: in exec_module
    ???
<frozen importlib._bootstrap>:241: in _call_with_frames_removed
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    from __future__ import annotations
    
    from functools import lru_cache
    
    try:  # AI-AGENT-REF: optional cachetools TTL cache
        from cachetools import TTLCache
    
        _CACHETOOLS_AVAILABLE = True
        _sentiment_cache = TTLCache(maxsize=1000, ttl=3600)
>   except (requests.RequestException, TimeoutError):
E   NameError: name 'requests' is not defined

ai_trading/predict.py:10: NameError
_________________________________________ TestIntegration.test_all_modules_importable __________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_production_fixes.TestIntegration testMethod=test_all_modules_importable>

    def test_all_modules_importable(self):
        """Test that all modified modules can be imported without errors."""
        modules_to_test = [
            'performance_monitor',
            'data_validation',
            'validate_env'
        ]
    
        for module_name in modules_to_test:
            try:
>               __import__(module_name)
E               ModuleNotFoundError: No module named 'performance_monitor'

tests/test_production_fixes.py:286: ModuleNotFoundError

During handling of the above exception, another exception occurred:

self = <tests.test_production_fixes.TestIntegration testMethod=test_all_modules_importable>

    def test_all_modules_importable(self):
        """Test that all modified modules can be imported without errors."""
        modules_to_test = [
            'performance_monitor',
            'data_validation',
            'validate_env'
        ]
    
        for module_name in modules_to_test:
            try:
                __import__(module_name)
            except ImportError as e:
                # Allow for missing dependencies in test environment
                if 'pandas' in str(e) or 'pydantic' in str(e):
                    continue
                else:
>                   self.fail(f"Failed to import {module_name}: {e}")
E                   AssertionError: Failed to import performance_monitor: No module named 'performance_monitor'

tests/test_production_fixes.py:292: AssertionError
______________________________________________ test_soft_budget_elapsed_and_over _______________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_soft_budget_elapsed_and_over():
        b = SoftBudget(interval_sec=0.1, fraction=0.5)
        time.sleep(0.02)
        assert b.elapsed_ms() >= 20
        time.sleep(0.05)
>       assert b.over() is True or b.remaining() == 0.0
E       assert (False is True or 0.009585136998794042 == 0.0)
E        +  where False = over()
E        +    where over = <ai_trading.utils.prof.SoftBudget object at 0x7ff8d3323e90>.over
E        +  and   0.009585136998794042 = remaining()
E        +    where remaining = <ai_trading.utils.prof.SoftBudget object at 0x7ff8d3323e90>.remaining

tests/test_prof_budget.py:11: AssertionError
______________________________________________ test_pydantic_v2_migration_syntax _______________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_pydantic_v2_migration_syntax():
        """Test that validate_env.py uses correct Pydantic V2 syntax."""
        validate_env_path = os.path.join(
            os.path.dirname(__file__), '..', 'ai_trading', 'validation', 'validate_env.py'
        )
    
        with open(validate_env_path) as f:
            content = f.read()
    
        # Verify V2 imports
>       assert 'from pydantic import field_validator, Field' in content
E       assert 'from pydantic import field_validator, Field' in 'from __future__ import annotations\n\nimport os\n\nfrom pydantic import BaseModel, Field, field_validator\n\n# AI-AGE...}")\n    return val\n\n\n__all__ = [\n    "Settings",\n    "debug_environment",\n    "validate_specific_env_var",\n]\n'

tests/test_pydantic_v2_migration.py:24: AssertionError
________________________________________ test_no_root_level_imports_of_migrated_modules ________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_no_root_level_imports_of_migrated_modules():
        root = pathlib.Path(__file__).resolve().parents[1]
        banned = {
            r"\bfrom\s+signals\s+import\b",
            r"\bfrom\s+data_fetcher\s+import\b",
            r"\bfrom\s+trade_execution\s+import\b",
            r"\bfrom\s+pipeline\s+import\b",
            r"\bfrom\s+indicators\s+import\b",
            r"\bfrom\s+portfolio\s+import\b",
            r"\bfrom\s+rebalancer\s+import\b",
            r"^\s*import\s+signals\b",
            r"^\s*import\s+data_fetcher\b",
            r"^\s*import\s+trade_execution\b",
            r"^\s*import\s+pipeline\b",
            r"^\s*import\s+indicators\b",
            r"^\s*import\s+portfolio\b",
            r"^\s*import\s+rebalancer\b",
        }
        offenders = []
        for p in root.rglob("*.py"):
            text = p.read_text(encoding="utf-8", errors="ignore")
            for pat in banned:
                if re.search(pat, text, re.MULTILINE):
                    offenders.append(f"{p}:{pat}")
                    break
>       assert not offenders, f"Root imports are no longer supported. Offenders: {offenders}"
E       AssertionError: Root imports are no longer supported. Offenders: ['/workspace/ai-trading-bot/scripts/system_health_checker.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-trading-bot/scripts/production_validator.py:^\\s*import\\s+indicators\\b', '/workspace/ai-trading-bot/scripts/demo_short_selling_implementation.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-trading-bot/scripts/health_check.py:^\\s*import\\s+trade_execution\\b', '/workspace/ai-trading-bot/scripts/integration_test.py:\\bfrom\\s+pipeline\\s+import\\b', '/workspace/ai-trading-bot/scripts/critical_fixes_validation.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py:\\bfrom\\s+pipeline\\s+import\\b', '/workspace/ai-trading-bot/tests/test_import_fallbacks.py:\\bfrom\\s+signals\\s+import\\b', '/workspace/ai-trading-bot/tests/test_bot_engine_imports.py:\\bfrom\\s+pipeline\\s+import\\b']
E       assert not ['/workspace/ai-trading-bot/scripts/system_health_checker.py:\\bfrom\\s+trade_execution\\s+import\\b', '/workspace/ai-...ort\\b', '/workspace/ai-trading-bot/scripts/critical_fixes_validation.py:\\bfrom\\s+trade_execution\\s+import\\b', ...]

tests/test_no_root_imports.py:30: AssertionError
_____________________________________________________ test_regime_changes ______________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_regime_changes():
>       df = pd.read_csv(
            "data/trades.csv",
            engine="python",
            on_bad_lines="skip",
            skip_blank_lines=True,
        )

tests/test_regime_filters.py:6: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026: in read_csv
    return _read(filepath_or_buffer, kwds)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620: in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620: in __init__
    self._engine = self._make_engine(f, self.engine)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880: in _make_engine
    self.handles = get_handle(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path_or_buf = 'data/trades.csv', mode = 'r'

    @doc(compression_options=_shared_docs["compression_options"] % "path_or_buf")
    def get_handle(
        path_or_buf: FilePath | BaseBuffer,
        mode: str,
        *,
        encoding: str | None = None,
        compression: CompressionOptions | None = None,
        memory_map: bool = False,
        is_text: bool = True,
        errors: str | None = None,
        storage_options: StorageOptions | None = None,
    ) -> IOHandles[str] | IOHandles[bytes]:
        """
        Get file handle for given path/buffer and mode.
    
        Parameters
        ----------
        path_or_buf : str or file handle
            File path or object.
        mode : str
            Mode to open path_or_buf with.
        encoding : str or None
            Encoding to use.
        {compression_options}
    
               May be a dict with key 'method' as compression mode
               and other keys as compression options if compression
               mode is 'zip'.
    
               Passing compression options as keys in dict is
               supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.
    
            .. versionchanged:: 1.4.0 Zstandard support.
    
        memory_map : bool, default False
            See parsers._parser_params for more information. Only used by read_csv.
        is_text : bool, default True
            Whether the type of the content passed to the file/buffer is string or
            bytes. This is not the same as `"b" not in mode`. If a string content is
            passed to a binary file/buffer, a wrapper is inserted.
        errors : str, default 'strict'
            Specifies how encoding and decoding errors are to be handled.
            See the errors argument for :func:`open` for a full list
            of options.
        storage_options: StorageOptions = None
            Passed to _get_filepath_or_buffer
    
        Returns the dataclass IOHandles
        """
        # Windows does not default to utf-8. Set to utf-8 for a consistent behavior
        encoding = encoding or "utf-8"
    
        errors = errors or "strict"
    
        # read_csv does not know whether the buffer is opened in binary/text mode
        if _is_binary_mode(path_or_buf, mode) and "b" not in mode:
            mode += "b"
    
        # validate encoding and errors
        codecs.lookup(encoding)
        if isinstance(errors, str):
            codecs.lookup_error(errors)
    
        # open URLs
        ioargs = _get_filepath_or_buffer(
            path_or_buf,
            encoding=encoding,
            compression=compression,
            mode=mode,
            storage_options=storage_options,
        )
    
        handle = ioargs.filepath_or_buffer
        handles: list[BaseBuffer]
    
        # memory mapping needs to be the first step
        # only used for read_csv
        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)
    
        is_path = isinstance(handle, str)
        compression_args = dict(ioargs.compression)
        compression = compression_args.pop("method")
    
        # Only for write methods
        if "r" not in mode and is_path:
            check_parent_directory(str(handle))
    
        if compression:
            if compression != "zstd":
                # compression libraries do not like an explicit text-mode
                ioargs.mode = ioargs.mode.replace("t", "")
            elif compression == "zstd" and "b" not in ioargs.mode:
                # python-zstandard defaults to text mode, but we always expect
                # compression libraries to use binary mode.
                ioargs.mode += "b"
    
            # GZ Compression
            if compression == "gzip":
                if isinstance(handle, str):
                    # error: Incompatible types in assignment (expression has type
                    # "GzipFile", variable has type "Union[str, BaseBuffer]")
                    handle = gzip.GzipFile(  # type: ignore[assignment]
                        filename=handle,
                        mode=ioargs.mode,
                        **compression_args,
                    )
                else:
                    handle = gzip.GzipFile(
                        # No overload variant of "GzipFile" matches argument types
                        # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                        fileobj=handle,  # type: ignore[call-overload]
                        mode=ioargs.mode,
                        **compression_args,
                    )
    
            # BZ Compression
            elif compression == "bz2":
                # Overload of "BZ2File" to handle pickle protocol 5
                # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                handle = get_bz2_file()(  # type: ignore[call-overload]
                    handle,
                    mode=ioargs.mode,
                    **compression_args,
                )
    
            # ZIP Compression
            elif compression == "zip":
                # error: Argument 1 to "_BytesZipFile" has incompatible type
                # "Union[str, BaseBuffer]"; expected "Union[Union[str, PathLike[str]],
                # ReadBuffer[bytes], WriteBuffer[bytes]]"
                handle = _BytesZipFile(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
                if handle.buffer.mode == "r":
                    handles.append(handle)
                    zip_names = handle.buffer.namelist()
                    if len(zip_names) == 1:
                        handle = handle.buffer.open(zip_names.pop())
                    elif not zip_names:
                        raise ValueError(f"Zero files found in ZIP file {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in ZIP file. "
                            f"Only one file per ZIP: {zip_names}"
                        )
    
            # TAR Encoding
            elif compression == "tar":
                compression_args.setdefault("mode", ioargs.mode)
                if isinstance(handle, str):
                    handle = _BytesTarFile(name=handle, **compression_args)
                else:
                    # error: Argument "fileobj" to "_BytesTarFile" has incompatible
                    # type "BaseBuffer"; expected "Union[ReadBuffer[bytes],
                    # WriteBuffer[bytes], None]"
                    handle = _BytesTarFile(
                        fileobj=handle, **compression_args  # type: ignore[arg-type]
                    )
                assert isinstance(handle, _BytesTarFile)
                if "r" in handle.buffer.mode:
                    handles.append(handle)
                    files = handle.buffer.getnames()
                    if len(files) == 1:
                        file = handle.buffer.extractfile(files[0])
                        assert file is not None
                        handle = file
                    elif not files:
                        raise ValueError(f"Zero files found in TAR archive {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in TAR archive. "
                            f"Only one file per TAR archive: {files}"
                        )
    
            # XZ Compression
            elif compression == "xz":
                # error: Argument 1 to "LZMAFile" has incompatible type "Union[str,
                # BaseBuffer]"; expected "Optional[Union[Union[str, bytes, PathLike[str],
                # PathLike[bytes]], IO[bytes]], None]"
                handle = get_lzma_file()(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
    
            # Zstd Compression
            elif compression == "zstd":
                zstd = import_optional_dependency("zstandard")
                if "r" in ioargs.mode:
                    open_args = {"dctx": zstd.ZstdDecompressor(**compression_args)}
                else:
                    open_args = {"cctx": zstd.ZstdCompressor(**compression_args)}
                handle = zstd.open(
                    handle,
                    mode=ioargs.mode,
                    **open_args,
                )
    
            # Unrecognized Compression
            else:
                msg = f"Unrecognized compression type: {compression}"
                raise ValueError(msg)
    
            assert not isinstance(handle, str)
            handles.append(handle)
    
        elif isinstance(handle, str):
            # Check whether the filename is to be opened in binary mode.
            # Binary mode does not support 'encoding' and 'newline'.
            if ioargs.encoding and "b" not in ioargs.mode:
                # Encoding
>               handle = open(
                    handle,
                    ioargs.mode,
                    encoding=ioargs.encoding,
                    errors=errors,
                    newline="",
                )
E               FileNotFoundError: [Errno 2] No such file or directory: 'data/trades.csv'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/common.py:873: FileNotFoundError
________________________________________________ test_backtest_cost_enforcement ________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_backtest_cost_enforcement():
        """Test that backtester respects cost model."""
        # This would be a more complex integration test
        # For now, just ensure the cost model can be imported and used
    
>       from ai_trading.execution.costs import get_cost_model

tests/test_peak_performance.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
_______________________________________ test_allocator_confidence_gate_filters_and_logs ________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7f867c24c3d0>

    def test_allocator_confidence_gate_filters_and_logs(caplog):
        caplog.set_level(logging.INFO)
        alloc = PerformanceBasedAllocator()
        cfg = TradingConfig(score_confidence_min=0.7)
        inputs = {
            "momentum": [Sig("AAPL", 0.65), Sig("MSFT", 0.71), Sig("NVDA", 0.90)],
            "meanrev": [Sig("TSLA", 0.40), Sig("AMZN", 0.72)],
        }
    
        out = alloc.allocate(inputs, cfg)
    
        kept_symbols = {s.symbol for xs in out.values() for s in xs}
        assert kept_symbols == {"MSFT", "NVDA", "AMZN"}
    
        drops = [rec for rec in caplog.records if rec.message == "CONFIDENCE_DROP"]
>       assert len(drops) >= 2
E       assert 0 >= 2
E        +  where 0 = len([])

tests/test_performance_allocator_conf_gate.py:40: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:31,425", "level": "INFO", "name": "ai_trading.logging", "msg": "Perfâ€¦ator initialized with 20 day window", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:31,426", "level": "INFO", "name": "ai_trading.logging", "msg": "CONFâ€¦DROP", "strategy": "momentum", "threshold": 0.7, "dropped": 1, "kept": 2, "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:31,426", "level": "INFO", "name": "ai_trading.logging", "msg": "CONFâ€¦DROP", "strategy": "meanrev", "threshold": 0.7, "dropped": 1, "kept": 1, "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.logging:performance_allocator.py:115 Perfâ€¦ator initialized with 20 day window
INFO     ai_trading.logging:performance_allocator.py:168 CONFâ€¦DROP
INFO     ai_trading.logging:performance_allocator.py:168 CONFâ€¦DROP
____________________________________________ test_get_daily_bars_resamples_minutes _____________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d33a0f10>

    def test_get_daily_bars_resamples_minutes(monkeypatch):
        """When daily bars are empty, minute bars are resampled."""  # AI-AGENT-REF
        empty = pd.DataFrame()
        monkeypatch.setattr(
            bars,
            "_fetch_daily_bars",
            lambda client, symbol, start, end, feed=None: empty,
        )
    
        idx = pd.date_range(
            "2024-01-02 14:30",
            periods=5,
            freq="1min",
            tz="UTC",
        )
        data = pd.DataFrame(
            {
                "open": [1, 2, 3, 4, 5],
                "high": [1, 2, 3, 4, 5],
                "low": [1, 2, 3, 4, 5],
                "close": [1, 2, 3, 4, 5],
                "volume": [10, 10, 10, 10, 10],
            },
            index=idx,
        )
        monkeypatch.setattr(
            bars, "_get_minute_bars", lambda symbol, start_dt, end_dt, feed: data
        )
    
>       out = bars.get_daily_bars(
            "SPY", None, datetime(2024, 1, 2, tzinfo=UTC), datetime(2024, 1, 3, tzinfo=UTC)
        )

tests/test_resample_daily.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

symbol = 'SPY', client = None, start = datetime.datetime(2024, 1, 2, 0, 0, tzinfo=datetime.timezone.utc)
end = datetime.datetime(2024, 1, 3, 0, 0, tzinfo=datetime.timezone.utc), feed = 'iex'

    def get_daily_bars(
        symbol: str,
        client,
        start: datetime,
        end: datetime,
        feed: str | None = None,
    ):
        """Fetch daily bars; fallback to alternate feed then resampled minutes."""  # AI-AGENT-REF
        S = get_settings()
        if feed is None:
            feed = S.alpaca_data_feed
        adjustment = S.alpaca_adjustment
        start = ensure_utc_datetime(start)
        end = ensure_utc_datetime(end)
>       df = _fetch_daily_bars(client, symbol, start, end, feed=feed, adjustment=adjustment)
E       TypeError: test_get_daily_bars_resamples_minutes.<locals>.<lambda>() got an unexpected keyword argument 'adjustment'

ai_trading/data/bars.py:332: TypeError
_______________________________________________ test_meta_learning_mixed_format ________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_meta_learning_mixed_format():
        """Test that meta-learning can handle mixed audit/meta-learning log formats."""
    
        from ai_trading.meta_learning import (
            retrain_meta_learner,
            validate_trade_data_quality,
        )
    
        # Test with the actual trades.csv file
        quality_report = validate_trade_data_quality('trades.csv')
    
        # Verify mixed format detection
        assert quality_report['file_exists'], "Trade log file should exist"
        assert quality_report['has_valid_format'], "Should have valid format"
>       assert quality_report['mixed_format_detected'], "Should detect mixed formats"
E       AssertionError: Should detect mixed formats
E       assert False

tests/test_performance_fixes.py:36: AssertionError
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.meta_learning:meta_learning.py:312 Invalid price in meta format row: could not convert string to float: 'entry_price'
______________________________________________ test_cache_performance_monitoring _______________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_cache_performance_monitoring():
        """Test that cache performance monitoring is working."""
    
>       from ai_trading.data_fetcher import _CACHE_STATS, get_cache_stats
E       ImportError: cannot import name '_CACHE_STATS' from 'ai_trading.data_fetcher' (unknown location)

tests/test_performance_fixes.py:52: ImportError
_____________________________________________ test_retrain_detect_regime_and_dump ______________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_retrain_detect_regime_and0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d832a590>

    @pytest.mark.smoke
    def test_retrain_detect_regime_and_dump(tmp_path, monkeypatch):
>       retrain = _import_retrain(monkeypatch)

tests/test_retrain_smoke.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_retrain_smoke.py:80: in _import_retrain
    return importlib.import_module("retrain")
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1204: in _gcd_import
    ???
<frozen importlib._bootstrap>:1176: in _find_and_load
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'retrain', import_ = <function _gcd_import at 0x7ff8f1353d80>

>   ???
E   ModuleNotFoundError: No module named 'retrain'

<frozen importlib._bootstrap>:1140: ModuleNotFoundError
______________________________________________ test_position_size_division_error _______________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_position_size_division_error():
        """Errors during quantity calc return zero."""
        eng = risk_engine.RiskEngine()
>       sig = TradeSignal(symbol='A', side='buy', confidence=1.0, strategy='s')
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_additional.py:42: TypeError
_________________________________________________ test_position_size_reporting _________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_position_size_reporting():
        """Test that position size reporting is consistent."""
    
>       from ai_trading.execution.engine import ExecutionEngine

tests/test_performance_fixes.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
___________________________________________________ test_apply_weight_limits ___________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_apply_weight_limits():
        """Weight adjustments respect caps."""
        eng = risk_engine.RiskEngine()
        eng.asset_limits['equity'] = 0.5
        eng.strategy_limits['s'] = 0.3
        eng.exposure['equity'] = 0.4
>       sig = TradeSignal(symbol='A', side='buy', confidence=1.0, strategy='s', weight=1.0)
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_additional.py:53: TypeError
____________________________________________________ test_latency_tracking _____________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_latency_tracking():
        """Test that order execution latency tracking is more granular."""
    
        import time
    
>       from ai_trading.execution.engine import ExecutionEngine

tests/test_performance_fixes.py:98: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
____________________________________________________ test_can_trade_limits _____________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_can_trade_limits():
        eng = RiskEngine()
>       sig = make_signal()

tests/test_risk_engine_module.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def make_signal():
>       return TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_module.py:25: TypeError
_______________________________________________ test_register_and_position_size ________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d33d5090>

    def test_register_and_position_size(monkeypatch):
        eng = RiskEngine()
>       sig = make_signal()

tests/test_risk_engine_module.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def make_signal():
>       return TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_module.py:25: TypeError
________________________________________________ test_hard_stop_blocks_trading _________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_hard_stop_blocks_trading():
        eng = RiskEngine()
        eng.hard_stop = True
>       sig = make_signal()

tests/test_risk_engine_module.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def make_signal():
>       return TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_risk_engine_module.py:25: TypeError
_________________________________ TestRiskEnginePackage.test_update_exposure_requires_context __________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_risk_engine_package.TestRiskEnginePackage testMethod=test_update_exposure_requires_context>

    def test_update_exposure_requires_context(self):
        """Test that update_exposure requires context parameter."""
>       from ai_trading.risk import RiskEngine
E       ImportError: cannot import name 'RiskEngine' from 'ai_trading.risk' (unknown location)

tests/test_risk_engine_package.py:59: ImportError
________________________________ TestRiskEnginePackage.test_update_exposure_works_with_context _________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_risk_engine_package.TestRiskEnginePackage testMethod=test_update_exposure_works_with_context>

    def test_update_exposure_works_with_context(self):
        """Test that update_exposure works with context parameter."""
>       from ai_trading.risk import RiskEngine
E       ImportError: cannot import name 'RiskEngine' from 'ai_trading.risk' (unknown location)

tests/test_risk_engine_package.py:71: ImportError
__________________________________ TestRiskEnginePackage.test_risk_engine_import_from_package __________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_risk_engine_package.TestRiskEnginePackage testMethod=test_risk_engine_import_from_package>

    def test_risk_engine_import_from_package(self):
        """Test that RiskEngine can be imported from ai_trading.risk."""
>       from ai_trading.risk import RiskEngine
E       ImportError: cannot import name 'RiskEngine' from 'ai_trading.risk' (unknown location)

tests/test_risk_engine_package.py:14: ImportError
___________________________________________________ test_rl_train_and_infer ____________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3ed2e50>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw0/test_rl_train_and_infer0')

    def test_rl_train_and_infer(monkeypatch, tmp_path):
        data = np.random.rand(20, 4)
        class DummyPPO:
            def __init__(self, *_a, **_k): pass
            def learn(self, *a, **k): return None
            def save(self, path): open(path, 'wb').write(b'0')
            def predict(self, state, deterministic=True): return (1, None)
            @classmethod
            def load(cls, path):
                return cls()
        monkeypatch.setattr(train_mod, "PPO", DummyPPO)
        import ai_trading.rl_trading as rl
        monkeypatch.setattr(rl, "PPO", DummyPPO)
        path = tmp_path / "model.zip"
>       train_mod.train(data, path, timesteps=10)
E       AttributeError: module 'ai_trading.rl_trading.train' has no attribute 'train'

tests/test_rl_module.py:20: AttributeError
_____________________________________________________ test_runner_as_main ______________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8676853350>

    def test_runner_as_main(monkeypatch):
        mod = load_runner(monkeypatch)
        monkeypatch.setattr(mod, "main", lambda: (_ for _ in ()).throw(SystemExit(0)))
>       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:62: AttributeError
_________________________________________________ test_runner_import_fallback __________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f86768b9c50>

    def test_runner_import_fallback(monkeypatch):
        monkeypatch.setitem(sys.modules, "bot", None)
        bot_engine_mod = types.ModuleType("bot_engine")
        bot_engine_mod.main = lambda: None
        monkeypatch.setitem(sys.modules, "bot_engine", bot_engine_mod)
        import importlib
        r = importlib.reload(importlib.import_module("runner"))
>       assert r.main is bot_engine_mod.main
E       AssertionError: assert <function main at 0x7f86768e07c0> is <function test_runner_import_fallback.<locals>.<lambda> at 0x7f86768e1a80>
E        +  where <function main at 0x7f86768e07c0> = <module 'runner' from '/workspace/ai-trading-bot/tests/../ai_trading/runner.py'>.main
E        +  and   <function test_runner_import_fallback.<locals>.<lambda> at 0x7f86768e1a80> = <module 'bot_engine'>.main

tests/test_runner.py:74: AssertionError
______________________________________________________ test_runner_starts ______________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_runner_starts():
>       ctx = bot_engine.ctx
E       AttributeError: module 'ai_trading.core.bot_engine' has no attribute 'ctx'

tests/test_runner_additional.py:7: AttributeError
_____________________________________________________ test_top_level_shims _____________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_top_level_shims():
        """Test that top-level shim files exist"""
    
        shims = ["signals.py", "rebalancer.py", "indicators.py"]
        success = True
    
        for shim in shims:
            if os.path.exists(shim):
                pass
            else:
                success = False
    
        # Check bot_engine.py has prepare_indicators
>       with open("bot_engine.py") as f:
E       FileNotFoundError: [Errno 2] No such file or directory: 'bot_engine.py'

tests/test_runtime_fixes.py:108: FileNotFoundError
_________________________________________ test_trading_config_has_required_parameters __________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trading_config_has_required_parameters():
        """Test that TradingConfig includes required trading parameters."""
        from ai_trading.config.management import TradingConfig
    
        cfg = TradingConfig()
    
        # Verify required parameters are present as attributes
        assert hasattr(cfg, 'capital_cap')
        assert hasattr(cfg, 'dollar_risk_limit')
        assert hasattr(cfg, 'max_position_size')
    
        # Verify default values
>       assert cfg.capital_cap == 0.04
E       assert 0.25 == 0.04
E        +  where 0.25 = TradingConfig(daily_loss_limit=0.03, conf_threshold=0.75, kelly_fraction=0.6, slow_period=21, confirmation_count=3, ca...r_hour=10, max_trades_per_day=100, volume_threshold=50000, seed=42, entry_start_offset_min=0, entry_end_offset_min=390).capital_cap

tests/test_runtime_params_hydration.py:25: AssertionError
________________________________________ test_trading_config_from_env_loads_parameters _________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trading_config_from_env_loads_parameters():
        """Test that TradingConfig.from_env() loads parameters from environment."""
        from ai_trading.config.management import TradingConfig
    
        # Test with environment variables
        env_vars = {
            'CAPITAL_CAP': '0.06',
            'DOLLAR_RISK_LIMIT': '0.08',
            'MAX_POSITION_SIZE': '2.0',
        }
    
        with patch.dict(os.environ, env_vars):
            cfg = TradingConfig.from_env()
    
            assert cfg.capital_cap == 0.06
            assert cfg.dollar_risk_limit == 0.08
>           assert cfg.max_position_size == 2.0
E           AssertionError: assert 8000.0 == 2.0
E            +  where 8000.0 = TradingConfig(daily_loss_limit=0.03, conf_threshold=0.75, kelly_fraction=0.6, slow_period=21, confirmation_count=2, ca...er_day=200, volume_threshold=0.0, seed=42, entry_start_offset_min=0, entry_end_offset_min=390, trading_mode='balanced').max_position_size

tests/test_runtime_params_hydration.py:46: AssertionError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:31,719", "level": "WARNING", "name": "ai_trading.logging", "msg": "DEPRâ€¦LIAS", "alias": "BOT_MODE", "use": "TRADING_MODE", "value": "balanced", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.logging:__init__.py:293 DEPRâ€¦LIAS
__________________________________________ test_build_runtime_hydrates_all_parameters __________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_build_runtime_hydrates_all_parameters():
        """Test that build_runtime creates runtime with all required parameters."""
        from ai_trading.config.management import TradingConfig
        from ai_trading.core.runtime import REQUIRED_PARAM_DEFAULTS, build_runtime
    
        cfg = TradingConfig()
        runtime = build_runtime(cfg)
    
        # Verify runtime has params dict
        assert hasattr(runtime, 'params')
        assert isinstance(runtime.params, dict)
    
        # Verify all required parameters are present
        for key in REQUIRED_PARAM_DEFAULTS.keys():
            assert key in runtime.params, f"Missing required parameter: {key}"
    
        # Verify specific values
>       assert runtime.params['CAPITAL_CAP'] == 0.04
E       assert 0.25 == 0.04

tests/test_runtime_params_hydration.py:75: AssertionError
____________________________________________ test_build_runtime_uses_config_values _____________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_build_runtime_uses_config_values():
        """Test that build_runtime uses values from TradingConfig."""
        from ai_trading.config.management import TradingConfig
        from ai_trading.core.runtime import build_runtime
    
        # Create config with custom values
>       cfg = TradingConfig(
            capital_cap=0.08,
            dollar_risk_limit=0.10,
            max_position_size=2.5,
            kelly_fraction=0.7,
            buy_threshold=0.8,
            conf_threshold=0.9
        )
E       pydantic_core._pydantic_core.ValidationError: 1 validation error for TradingConfig
E         Value error, capital_cap must be >= dollar_risk_limit [type=value_error, input_value={'capital_cap': 0.08, 'do..., 'conf_threshold': 0.9}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.11/v/value_error

tests/test_runtime_params_hydration.py:86: ValidationError
________________________________________________ test_http_utilities_available _________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_http_utilities_available():
        """Test that HTTP utilities are available."""
        from ai_trading.utils import http
    
        assert hasattr(http, 'get')
        assert hasattr(http, 'post')
        assert hasattr(http, 'put')
>       assert hasattr(http, 'delete')
E       AssertionError: assert False
E        +  where False = hasattr(<module 'ai_trading.utils.http' from '/workspace/ai-trading-bot/ai_trading/utils/http.py'>, 'delete')

tests/test_runtime_paths.py:62: AssertionError
______________________________________________ test_alpaca_availability_detection ______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_alpaca_availability_detection():
        """Test that _alpaca_available() function works correctly."""
        # Set test environment
        os.environ['PYTEST_RUNNING'] = '1'
        os.environ['TESTING'] = '1'
    
        # Import the function
>       from ai_trading.core.bot_engine import _alpaca_available

tests/test_problem_statement_validation.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    # ruff: noqa
    # fmt: off
    from __future__ import annotations
    
    import importlib
    import importlib.util
    import os
    import sys
    from typing import Dict, Iterable
    from zoneinfo import ZoneInfo  # AI-AGENT-REF: timezone conversions
    
    from json import JSONDecodeError
    # Safe 'requests' import with stub + RequestException binding
    try:  # pragma: no cover
        import requests  # type: ignore
        RequestException = requests.exceptions.RequestException  # type: ignore[attr-defined]
    except ImportError:  # pragma: no cover  # AI-AGENT-REF: narrow import handling
        class RequestException(Exception):
            pass
    
        # Minimal stub so runtime calls fail gracefully into COMMON_EXC
        class _RequestsStub:
            class exceptions:
                RequestException = RequestException
    
            def get(self, *a, **k):
                raise RequestException("requests not installed")
    
        requests = _RequestsStub()  # type: ignore
    
    from threading import Lock
    import warnings
    
    from ai_trading.data_fetcher import (
        get_bars,
        get_bars_batch,
        get_minute_df,
    )
>   from ai_trading.market.calendars import last_market_session
E   ImportError: cannot import name 'last_market_session' from 'ai_trading.market.calendars' (unknown location)

ai_trading/core/bot_engine.py:39: ImportError
__________________________________________________ test_settings_invalid_risk __________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f86768ab290>

    def test_settings_invalid_risk(monkeypatch):
        """Invalid risk values raise ValidationError."""  # AI-AGENT-REF
        monkeypatch.setenv("CAPITAL_CAP", "0")
        monkeypatch.setenv("DOLLAR_RISK_LIMIT", "0")
>       with pytest.raises(ValidationError):
E       Failed: DID NOT RAISE <class 'pydantic_core._pydantic_core.ValidationError'>

tests/test_settings_config.py:29: Failed
__________________________ TestShortSellingImplementation.test_current_sell_logic_blocks_no_position ___________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_short_selling_implementation.TestShortSellingImplementation testMethod=test_current_sell_logic_blocks_no_position>

    def test_current_sell_logic_blocks_no_position(self):
        """Test that current logic blocks sell orders when no position exists."""
        # This test documents the current behavior that we need to fix
>       from ai_trading.execution.engine import ExecutionEngine

tests/test_short_selling_implementation.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
____________________________________________ test_alpaca_import_exception_handling _____________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_alpaca_import_exception_handling():
        """Test that Alpaca imports handle TypeErrors and other exceptions gracefully."""
        # Set test environment
        os.environ['PYTEST_RUNNING'] = '1'
        os.environ['TESTING'] = '1'
    
        # Mock alpaca to raise TypeError (the specific error mentioned in requirements)
        with patch.dict('sys.modules', {'alpaca': MagicMock()}):
>           with patch('ai_trading.core.bot_engine._alpaca_available') as mock_available:

tests/test_problem_statement_validation.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f8d84fc72d0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'> does not have the attribute '_alpaca_available'

/root/.pyenv/versions/3.11.12/lib/python3.11/unittest/mock.py:1419: AttributeError
______________________________ TestShortSellingImplementation.test_order_status_monitoring_needed ______________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_short_selling_implementation.TestShortSellingImplementation testMethod=test_order_status_monitoring_needed>

    def test_order_status_monitoring_needed(self):
        """Test framework for order status monitoring."""
>       from ai_trading.execution.engine import ExecutionEngine

tests/test_short_selling_implementation.py:126: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
_________________________ TestShortSellingImplementation.test_sell_short_side_should_be_distinguished __________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_short_selling_implementation.TestShortSellingImplementation testMethod=test_sell_short_side_should_be_distinguished>

    def test_sell_short_side_should_be_distinguished(self):
        """Test that sell_short orders bypass position checks and validate short selling."""
>       from ai_trading.execution.engine import ExecutionEngine

tests/test_short_selling_implementation.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
_______________________________ TestShortSellingImplementation.test_sell_short_validation_exists _______________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_short_selling_implementation.TestShortSellingImplementation testMethod=test_sell_short_validation_exists>

    def test_sell_short_validation_exists(self):
        """Test that _validate_short_selling method exists and works."""
>       from ai_trading.execution.engine import ExecutionEngine

tests/test_short_selling_implementation.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
_______________________________________________________ test_skip_logic ________________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f86768ba010>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7f8677ec6150>

    def test_skip_logic(monkeypatch, caplog):
        state = bot_engine.BotState()
        state.position_cache = {"MSFT": 10, "TSLA": -10}
        bot_engine.state = state
        caplog.set_level("INFO")
    
        orders = []
        monkeypatch.setattr(bot_engine, "submit_order", lambda ctx, symbol, qty, side: orders.append((symbol, qty, side)))
        monkeypatch.setattr(bot_engine, "is_market_open", lambda: True)
        monkeypatch.setattr(bot_engine, "fetch_minute_df_safe", lambda s: pd.DataFrame({"close": [1]}, index=[pd.Timestamp("2023-01-01")]))
        monkeypatch.setattr(bot_engine, "_safe_trade", lambda *a, **k: None)
>       monkeypatch.setattr(bot_engine.prediction_executor, "submit", lambda fn, s: types.SimpleNamespace(result=lambda: fn(s)))
E       AttributeError: None has no attribute 'submit'

tests/test_skip_logic.py:18: AttributeError
_____________________________________________________ test_slippage_limits _____________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_slippage_limits():
>       df = pd.read_csv("logs/slippage.csv")

tests/test_slippage.py:5: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026: in read_csv
    return _read(filepath_or_buffer, kwds)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620: in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620: in __init__
    self._engine = self._make_engine(f, self.engine)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880: in _make_engine
    self.handles = get_handle(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path_or_buf = 'logs/slippage.csv', mode = 'r'

    @doc(compression_options=_shared_docs["compression_options"] % "path_or_buf")
    def get_handle(
        path_or_buf: FilePath | BaseBuffer,
        mode: str,
        *,
        encoding: str | None = None,
        compression: CompressionOptions | None = None,
        memory_map: bool = False,
        is_text: bool = True,
        errors: str | None = None,
        storage_options: StorageOptions | None = None,
    ) -> IOHandles[str] | IOHandles[bytes]:
        """
        Get file handle for given path/buffer and mode.
    
        Parameters
        ----------
        path_or_buf : str or file handle
            File path or object.
        mode : str
            Mode to open path_or_buf with.
        encoding : str or None
            Encoding to use.
        {compression_options}
    
               May be a dict with key 'method' as compression mode
               and other keys as compression options if compression
               mode is 'zip'.
    
               Passing compression options as keys in dict is
               supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.
    
            .. versionchanged:: 1.4.0 Zstandard support.
    
        memory_map : bool, default False
            See parsers._parser_params for more information. Only used by read_csv.
        is_text : bool, default True
            Whether the type of the content passed to the file/buffer is string or
            bytes. This is not the same as `"b" not in mode`. If a string content is
            passed to a binary file/buffer, a wrapper is inserted.
        errors : str, default 'strict'
            Specifies how encoding and decoding errors are to be handled.
            See the errors argument for :func:`open` for a full list
            of options.
        storage_options: StorageOptions = None
            Passed to _get_filepath_or_buffer
    
        Returns the dataclass IOHandles
        """
        # Windows does not default to utf-8. Set to utf-8 for a consistent behavior
        encoding = encoding or "utf-8"
    
        errors = errors or "strict"
    
        # read_csv does not know whether the buffer is opened in binary/text mode
        if _is_binary_mode(path_or_buf, mode) and "b" not in mode:
            mode += "b"
    
        # validate encoding and errors
        codecs.lookup(encoding)
        if isinstance(errors, str):
            codecs.lookup_error(errors)
    
        # open URLs
        ioargs = _get_filepath_or_buffer(
            path_or_buf,
            encoding=encoding,
            compression=compression,
            mode=mode,
            storage_options=storage_options,
        )
    
        handle = ioargs.filepath_or_buffer
        handles: list[BaseBuffer]
    
        # memory mapping needs to be the first step
        # only used for read_csv
        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)
    
        is_path = isinstance(handle, str)
        compression_args = dict(ioargs.compression)
        compression = compression_args.pop("method")
    
        # Only for write methods
        if "r" not in mode and is_path:
            check_parent_directory(str(handle))
    
        if compression:
            if compression != "zstd":
                # compression libraries do not like an explicit text-mode
                ioargs.mode = ioargs.mode.replace("t", "")
            elif compression == "zstd" and "b" not in ioargs.mode:
                # python-zstandard defaults to text mode, but we always expect
                # compression libraries to use binary mode.
                ioargs.mode += "b"
    
            # GZ Compression
            if compression == "gzip":
                if isinstance(handle, str):
                    # error: Incompatible types in assignment (expression has type
                    # "GzipFile", variable has type "Union[str, BaseBuffer]")
                    handle = gzip.GzipFile(  # type: ignore[assignment]
                        filename=handle,
                        mode=ioargs.mode,
                        **compression_args,
                    )
                else:
                    handle = gzip.GzipFile(
                        # No overload variant of "GzipFile" matches argument types
                        # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                        fileobj=handle,  # type: ignore[call-overload]
                        mode=ioargs.mode,
                        **compression_args,
                    )
    
            # BZ Compression
            elif compression == "bz2":
                # Overload of "BZ2File" to handle pickle protocol 5
                # "Union[str, BaseBuffer]", "str", "Dict[str, Any]"
                handle = get_bz2_file()(  # type: ignore[call-overload]
                    handle,
                    mode=ioargs.mode,
                    **compression_args,
                )
    
            # ZIP Compression
            elif compression == "zip":
                # error: Argument 1 to "_BytesZipFile" has incompatible type
                # "Union[str, BaseBuffer]"; expected "Union[Union[str, PathLike[str]],
                # ReadBuffer[bytes], WriteBuffer[bytes]]"
                handle = _BytesZipFile(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
                if handle.buffer.mode == "r":
                    handles.append(handle)
                    zip_names = handle.buffer.namelist()
                    if len(zip_names) == 1:
                        handle = handle.buffer.open(zip_names.pop())
                    elif not zip_names:
                        raise ValueError(f"Zero files found in ZIP file {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in ZIP file. "
                            f"Only one file per ZIP: {zip_names}"
                        )
    
            # TAR Encoding
            elif compression == "tar":
                compression_args.setdefault("mode", ioargs.mode)
                if isinstance(handle, str):
                    handle = _BytesTarFile(name=handle, **compression_args)
                else:
                    # error: Argument "fileobj" to "_BytesTarFile" has incompatible
                    # type "BaseBuffer"; expected "Union[ReadBuffer[bytes],
                    # WriteBuffer[bytes], None]"
                    handle = _BytesTarFile(
                        fileobj=handle, **compression_args  # type: ignore[arg-type]
                    )
                assert isinstance(handle, _BytesTarFile)
                if "r" in handle.buffer.mode:
                    handles.append(handle)
                    files = handle.buffer.getnames()
                    if len(files) == 1:
                        file = handle.buffer.extractfile(files[0])
                        assert file is not None
                        handle = file
                    elif not files:
                        raise ValueError(f"Zero files found in TAR archive {path_or_buf}")
                    else:
                        raise ValueError(
                            "Multiple files found in TAR archive. "
                            f"Only one file per TAR archive: {files}"
                        )
    
            # XZ Compression
            elif compression == "xz":
                # error: Argument 1 to "LZMAFile" has incompatible type "Union[str,
                # BaseBuffer]"; expected "Optional[Union[Union[str, bytes, PathLike[str],
                # PathLike[bytes]], IO[bytes]], None]"
                handle = get_lzma_file()(
                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]
                )
    
            # Zstd Compression
            elif compression == "zstd":
                zstd = import_optional_dependency("zstandard")
                if "r" in ioargs.mode:
                    open_args = {"dctx": zstd.ZstdDecompressor(**compression_args)}
                else:
                    open_args = {"cctx": zstd.ZstdCompressor(**compression_args)}
                handle = zstd.open(
                    handle,
                    mode=ioargs.mode,
                    **open_args,
                )
    
            # Unrecognized Compression
            else:
                msg = f"Unrecognized compression type: {compression}"
                raise ValueError(msg)
    
            assert not isinstance(handle, str)
            handles.append(handle)
    
        elif isinstance(handle, str):
            # Check whether the filename is to be opened in binary mode.
            # Binary mode does not support 'encoding' and 'newline'.
            if ioargs.encoding and "b" not in ioargs.mode:
                # Encoding
>               handle = open(
                    handle,
                    ioargs.mode,
                    encoding=ioargs.encoding,
                    errors=errors,
                    newline="",
                )
E               FileNotFoundError: [Errno 2] No such file or directory: 'logs/slippage.csv'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/io/common.py:873: FileNotFoundError
___________________________________ test_fetch_sentiment_graceful_when_requests_unavailable ____________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f86768f5810>

    def test_fetch_sentiment_graceful_when_requests_unavailable(monkeypatch):
        from ai_trading.core import bot_engine as be
    
        # Force a stub that raises RequestException on .get()
        class _ReqStub:
            class exceptions:
                class RequestException(Exception):
                    pass
    
            def get(self, *a, **k):
                raise self.exceptions.RequestException("no network")
    
        be.requests = _ReqStub()
        be.RequestException = _ReqStub.exceptions.RequestException
    
        # Ensure it won't bail early for missing key
        monkeypatch.setenv("SENTIMENT_API_KEY", "dummy")
        be.SENTIMENT_API_URL = "http://127.0.0.1:1"
        be._SENTIMENT_FAILURES = 0
        out = be.fetch_sentiment("AAPL")
        assert isinstance(out, float) and out == 0.0
>       assert be._SENTIMENT_FAILURES >= 1
E       AssertionError: assert 0 >= 1
E        +  where 0 = <module 'ai_trading.core.bot_engine' from '/workspace/ai-trading-bot/ai_trading/core/bot_engine.py'>._SENTIMENT_FAILURES

tests/test_stage1_1.py:35: AssertionError
______________________________________ TestStalenessGuard.test_staleness_guard_fresh_data ______________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c52bd50>

    def test_staleness_guard_fresh_data(self):
        """Test staleness guard with fresh data."""
        # Import the function we're testing
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Create a mock fetcher that returns fresh data
        now = datetime.datetime.now(datetime.UTC)
        fresh_timestamp = now - datetime.timedelta(seconds=30)  # 30 seconds old
    
        # Create test dataframe with fresh timestamp
        df = pd.DataFrame({
            'open': [100.0],
            'high': [101.0],
            'low': [99.0],
            'close': [100.5],
            'volume': [1000],
            'timestamp': [fresh_timestamp]
        })
    
        # Mock fetcher
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(return_value=df)
    
        # Should not raise any exception for fresh data
        try:
            _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
            success = True
        except (ValueError, TypeError):
            success = False
    
>       assert success, "Should not raise exception for fresh data"
E       AssertionError: Should not raise exception for fresh data
E       assert False

tests/test_staleness_guard.py:44: AssertionError
______________________________________ TestStalenessGuard.test_staleness_guard_stale_data ______________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c52a390>

    def test_staleness_guard_stale_data(self):
        """Test staleness guard with stale data."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Create a mock fetcher that returns stale data
        now = datetime.datetime.now(datetime.UTC)
        stale_timestamp = now - datetime.timedelta(seconds=600)  # 10 minutes old
    
        # Create test dataframe with stale timestamp
        df = pd.DataFrame({
            'open': [100.0],
            'high': [101.0],
            'low': [99.0],
            'close': [100.5],
            'volume': [1000],
            'timestamp': [stale_timestamp]
        })
    
        # Mock fetcher
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(return_value=df)
    
        # Should raise RuntimeError for stale data
        with pytest.raises(RuntimeError, match="Stale data for symbols"):
>           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:70: TypeError
_______________________________________ TestStalenessGuard.test_staleness_guard_no_data ________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c529710>

    def test_staleness_guard_no_data(self):
        """Test staleness guard with no data."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Mock fetcher that returns None/empty data
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(return_value=None)
    
        # Should raise RuntimeError for no data
        with pytest.raises(RuntimeError, match="Stale data for symbols"):
>           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:82: TypeError
___________________________________ TestStalenessGuard.test_staleness_guard_empty_dataframe ____________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c529990>

    def test_staleness_guard_empty_dataframe(self):
        """Test staleness guard with empty dataframe."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Mock fetcher that returns empty dataframe
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(return_value=pd.DataFrame())
    
        # Should raise RuntimeError for empty data
        with pytest.raises(RuntimeError, match="Stale data for symbols"):
>           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:94: TypeError
___________________________________ TestStalenessGuard.test_staleness_guard_multiple_symbols ___________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c52aa90>

    def test_staleness_guard_multiple_symbols(self):
        """Test staleness guard with multiple symbols."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        now = datetime.datetime.now(datetime.UTC)
    
        # Create mock fetcher that returns different data for different symbols
        def mock_get_minute_df(symbol, start, end):
            if symbol == "AAPL":
                # Fresh data for AAPL
                fresh_ts = now - datetime.timedelta(seconds=30)
                return pd.DataFrame({
                    'timestamp': [fresh_ts],
                    'close': [150.0]
                })
            elif symbol == "MSFT":
                # Stale data for MSFT
                stale_ts = now - datetime.timedelta(seconds=600)
                return pd.DataFrame({
                    'timestamp': [stale_ts],
                    'close': [300.0]
                })
            else:
                # No data for other symbols
                return None
    
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(side_effect=mock_get_minute_df)
    
        # Should raise RuntimeError mentioning the stale symbol
        with pytest.raises(RuntimeError) as exc_info:
>           _ensure_data_fresh(mock_fetcher, ["AAPL", "MSFT", "GOOGL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:127: TypeError
_____________________________________ TestStalenessGuard.test_staleness_guard_utc_logging ______________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c52b050>

    def test_staleness_guard_utc_logging(self):
        """Test that staleness guard logs UTC timestamps."""
        from unittest.mock import patch
    
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Mock logger to capture log messages
        with patch('ai_trading.core.bot_engine.logger') as mock_logger:
            now = datetime.datetime.now(datetime.UTC)
            fresh_timestamp = now - datetime.timedelta(seconds=30)
    
            df = pd.DataFrame({
                'timestamp': [fresh_timestamp],
                'close': [100.0]
            })
    
            mock_fetcher = Mock()
            mock_fetcher.get_minute_df = Mock(return_value=df)
    
            # Call the function
>           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:153: TypeError
__________________________________________________ test_package_safe_imports ___________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_package_safe_imports():
        """Test that package imports work correctly from ai_trading namespace."""
        # Set test environment
        os.environ['PYTEST_RUNNING'] = '1'
        os.environ['TESTING'] = '1'
    
        # Test logging import
        from ai_trading.logging import get_logger, setup_logging
        assert callable(setup_logging)
        assert callable(get_logger)
    
        # Test core imports
>       from ai_trading.core.bot_engine import _alpaca_available

tests/test_problem_statement_validation.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    # ruff: noqa
    # fmt: off
    from __future__ import annotations
    
    import importlib
    import importlib.util
    import os
    import sys
    from typing import Dict, Iterable
    from zoneinfo import ZoneInfo  # AI-AGENT-REF: timezone conversions
    
    from json import JSONDecodeError
    # Safe 'requests' import with stub + RequestException binding
    try:  # pragma: no cover
        import requests  # type: ignore
        RequestException = requests.exceptions.RequestException  # type: ignore[attr-defined]
    except ImportError:  # pragma: no cover  # AI-AGENT-REF: narrow import handling
        class RequestException(Exception):
            pass
    
        # Minimal stub so runtime calls fail gracefully into COMMON_EXC
        class _RequestsStub:
            class exceptions:
                RequestException = RequestException
    
            def get(self, *a, **k):
                raise RequestException("requests not installed")
    
        requests = _RequestsStub()  # type: ignore
    
    from threading import Lock
    import warnings
    
    from ai_trading.data_fetcher import (
        get_bars,
        get_bars_batch,
        get_minute_df,
    )
>   from ai_trading.market.calendars import last_market_session
E   ImportError: cannot import name 'last_market_session' from 'ai_trading.market.calendars' (unknown location)

ai_trading/core/bot_engine.py:39: ImportError
__________________________________ TestStalenessGuard.test_staleness_guard_timezone_handling ___________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c52b190>

    def test_staleness_guard_timezone_handling(self):
        """Test staleness guard handles timezone-aware and naive timestamps."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        now = datetime.datetime.now(datetime.UTC)
    
        # Test with timezone-naive timestamp (should be treated as UTC)
        naive_timestamp = datetime.datetime.now(datetime.UTC).replace(tzinfo=None) - datetime.timedelta(seconds=30)  # AI-AGENT-REF: Create naive datetime from UTC
        df_naive = pd.DataFrame({
            'timestamp': [naive_timestamp],
            'close': [100.0]
        })
    
        # Test with timezone-aware timestamp
        aware_timestamp = (now - datetime.timedelta(seconds=30)).replace(tzinfo=datetime.UTC)
        df_aware = pd.DataFrame({
            'timestamp': [aware_timestamp],
            'close': [100.0]
        })
    
        mock_fetcher = Mock()
    
        # Test both cases should work without error
        for df in [df_naive, df_aware]:
            mock_fetcher.get_minute_df = Mock(return_value=df)
            try:
                _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
                success = True
            except (ValueError, TypeError):
                success = False
>           assert success, "Should handle both timezone-aware and naive timestamps"
E           AssertionError: Should handle both timezone-aware and naive timestamps
E           assert False

tests/test_staleness_guard.py:193: AssertionError
____________________________________ TestStalenessGuard.test_staleness_guard_error_handling ____________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_staleness_guard.TestStalenessGuard object at 0x7f867c433150>

    def test_staleness_guard_error_handling(self):
        """Test staleness guard handles fetcher errors gracefully."""
        from ai_trading.core.bot_engine import _ensure_data_fresh
    
        # Mock fetcher that raises an exception
        mock_fetcher = Mock()
        mock_fetcher.get_minute_df = Mock(side_effect=Exception("Network error"))
    
        # Should raise RuntimeError with error details
        with pytest.raises(RuntimeError) as exc_info:
>           _ensure_data_fresh(mock_fetcher, ["AAPL"], max_age_seconds=300)
E           TypeError: _ensure_data_fresh() got multiple values for argument 'max_age_seconds'

tests/test_staleness_guard.py:205: TypeError
__________________________________________________ test_utc_datetime_handling __________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_utc_datetime_handling():
        """Test that datetime operations use timezone-aware UTC timestamps."""
        # Set test environment
        os.environ['PYTEST_RUNNING'] = '1'
        os.environ['TESTING'] = '1'
    
        # Test execution engine datetime handling
        from ai_trading.core.enums import OrderSide, OrderType
>       from ai_trading.execution.engine import Order

tests/test_problem_statement_validation.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:86: in <module>
    from .idempotency import OrderIdempotencyCache
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Order idempotency module to prevent duplicate orders on retries.
    
    Provides TTL cache keyed by (symbol, side, qty, intent_ts_bucket) to ensure
    orders are idempotent across retry attempts.
    """
    
    import hashlib
    import threading
    from dataclasses import dataclass
    from datetime import UTC, datetime
    
>   from cachetools import TTLCache
E   ModuleNotFoundError: No module named 'cachetools'

ai_trading/execution/idempotency.py:13: ModuleNotFoundError
_______________________________________________ test_python_version_requirements _______________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_python_version_requirements():
        """Test that pyproject.toml has correct Python version requirements."""
        with open('pyproject.toml') as f:
            content = f.read()
    
        # Should use flexible version range
>       assert 'requires-python = ">=3.12,<3.13"' in content, "Should use flexible Python 3.12 range"
E       AssertionError: Should use flexible Python 3.12 range
E       assert 'requires-python = ">=3.12,<3.13"' in '[project]\nname = "ai-trading-bot"\nversion = "0.0.0"\ndescription = "AI trading bot (lightweight testable build)"\nr...\n"tests/**" = ["T201"]\n"tools/**" = ["T201", "E402"]\n"scripts/**" = ["T201", "E402"]\n"**/__init__.py" = ["F401"]\n'

tests/test_problem_statement_validation.py:134: AssertionError
_____________________________ TestSentimentAPIConfiguration.test_sentiment_api_env_vars_in_config ______________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_production_fixes.TestSentimentAPIConfiguration testMethod=test_sentiment_api_env_vars_in_config>

    def test_sentiment_api_env_vars_in_config(self):
        """Test that sentiment API variables are properly configured."""
        from ai_trading import config
    
        # Test that the new environment variables are accessible
>       self.assertTrue(hasattr(config, 'SENTIMENT_API_KEY') or 'SENTIMENT_API_KEY' in dir(config))
E       AssertionError: False is not true

tests/test_production_fixes.py:41: AssertionError
_________________________ TestStrategyAllocatorRegression.test_config_missing_min_confidence_attribute _________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f8d85397710>

    def test_config_missing_min_confidence_attribute(self):
        """
        Regression test for missing min_confidence attribute in config.
    
        Previously, if min_confidence was missing from config, it could cause
        AttributeError or incorrect behavior.
        """
        alloc = strategy_allocator.StrategyAllocator()
    
        # Remove min_confidence attribute to simulate missing config
        if hasattr(alloc.config, 'min_confidence'):
            delattr(alloc.config, 'min_confidence')
    
        alloc.config.delta_threshold = 0.0
        alloc.config.signal_confirmation_bars = 2
    
>       sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:58: TypeError
_______________________________ TestStrategyAllocatorRegression.test_config_none_min_confidence ________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f8d85395850>

    def test_config_none_min_confidence(self):
        """
        Regression test for None min_confidence value.
    
        Previously, if min_confidence was set to None, it could cause
        comparison errors or unexpected behavior.
        """
        alloc = strategy_allocator.StrategyAllocator()
    
        alloc.config.min_confidence = None
        alloc.config.delta_threshold = 0.0
        alloc.config.signal_confirmation_bars = 2
    
>       sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:81: TypeError
_________________________________________________ test_run_all_trades_overlap __________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3986e50>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7ff8d3918750>

    def test_run_all_trades_overlap(monkeypatch, caplog):
        state = bot_engine.BotState()
        runtime = bot_engine.get_ctx()
        caplog.set_level("INFO")
    
        monkeypatch.setattr(bot_engine, "is_market_open", lambda: True)
        monkeypatch.setattr(bot_engine, "check_pdt_rule", lambda ctx: False)
        monkeypatch.setattr(bot_engine, "_prepare_run", lambda ctx, st: (0.0, True, []))
        monkeypatch.setattr(bot_engine, "_process_symbols", lambda *a, **k: ([], {}))
        monkeypatch.setattr(bot_engine, "_send_heartbeat", lambda: None)
>       monkeypatch.setattr(runtime.api, "get_account", lambda: types.SimpleNamespace(cash=0, equity=0))

tests/test_run_overlap.py:18: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:5483: in api
    self._ensure_initialized()
ai_trading/core/bot_engine.py:5453: in _ensure_initialized
    self._context.model = _load_required_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _load_required_model() -> Any:
        """Load ML model from path or module; fail fast if missing."""  # AI-AGENT-REF: strict model loader
        path = os.getenv("AI_TRADER_MODEL_PATH")
        modname = os.getenv("AI_TRADER_MODEL_MODULE")
    
        if path and os.path.isfile(path):
            mdl = joblib.load(path)
            try:
                digest = _sha256_file(path)
            except OSError:  # hashing is best-effort; missing/perm issues shouldn't crash
                digest = "unknown"
            _log.info("MODEL_LOADED", extra={"source": "file", "path": path, "sha": digest})
            return mdl
    
        if modname:
            try:
                mod = importlib.import_module(modname)
            except COMMON_EXC as e:  # noqa: BLE001
                raise RuntimeError(
                    f"Failed to import AI_TRADER_MODEL_MODULE='{modname}': {e}"
                ) from e
            factory = getattr(mod, "get_model", None) or getattr(mod, "Model", None)
            if not factory:
                raise RuntimeError(
                    f"Module '{modname}' missing get_model()/Model() factory."
                )
            mdl = factory() if callable(factory) else factory
            _log.info(
                "MODEL_LOADED",
                extra={
                    "source": "module",
                    "model_module": modname,
                },  # AI-AGENT-REF: avoid reserved key
            )
            return mdl
    
        msg = (
            "Model required but not configured. "
            "Set one of: "
            "AI_TRADER_MODEL_PATH=<abs path to .joblib/.pkl> "
            "or AI_TRADER_MODEL_MODULE=<import.path with get_model()/Model()>."
        )
        _log.error(
            "MODEL_CONFIG_MISSING",
            extra={
                "hint_paths": ["AI_TRADER_MODEL_PATH", "TradingConfig.ml_model_path"],
                "hint_modules": ["AI_TRADER_MODEL_MODULE", "TradingConfig.ml_model_module"],
            },
        )
>       raise RuntimeError(msg)
E       RuntimeError: Model required but not configured. Set one of: AI_TRADER_MODEL_PATH=<abs path to .joblib/.pkl> or AI_TRADER_MODEL_MODULE=<import.path with get_model()/Model()>.

ai_trading/core/bot_engine.py:538: RuntimeError
------------------------------------------------------ Captured log call -------------------------------------------------------
ERROR    ai_trading.core.bot_engine:bot_engine.py:531 MODEâ€¦SING
_________________________ TestStrategyAllocatorRegression.test_signal_confirmation_boundary_conditions _________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f8d854e4750>

    def test_signal_confirmation_boundary_conditions(self):
        """
        Test signal confirmation at various boundary conditions.
    
        Ensures that the confirmation logic works correctly at edge cases
        that could have caused the original failure.
        """
        test_cases = [
            # (min_confidence, signal_confidence, should_confirm)
            (0.0, 0.0, True),    # Zero threshold, zero confidence
            (0.0, 1.0, True),    # Zero threshold, high confidence
            (0.6, 0.6, True),    # Exact threshold match
            (0.8, 0.5, False),   # Below threshold
            (0.5, 0.8, True),    # Above threshold
        ]
    
        for min_conf, sig_conf, should_confirm in test_cases:
            alloc = strategy_allocator.StrategyAllocator()
            alloc.config.delta_threshold = 0.0
            alloc.config.signal_confirmation_bars = 2
            alloc.config.min_confidence = min_conf
    
>           sig = TradeSignal(symbol="AAPL", side="buy", confidence=sig_conf, strategy="s1")
E           TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:113: TypeError
___________________________ TestStrategyAllocatorRegression.test_invalid_signal_confidence_handling ____________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f8d854e7ad0>

    def test_invalid_signal_confidence_handling(self):
        """
        Test handling of invalid signal confidence values.
    
        Ensures that out-of-range confidence values are properly normalized
        and don't cause the confirmation logic to fail.
        """
        alloc = strategy_allocator.StrategyAllocator()
        alloc.config.delta_threshold = 0.0
        alloc.config.signal_confirmation_bars = 2
        alloc.config.min_confidence = 0.0
    
        # Test high confidence (> 1.0)
>       sig_high = TradeSignal(symbol="AAPL", side="buy", confidence=2.0, strategy="s1")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:137: TypeError
___________________________ TestStrategyAllocatorRegression.test_multiple_instances_no_shared_state ____________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f8d854e5350>

    def test_multiple_instances_no_shared_state(self):
        """
        Test that multiple allocator instances don't share state.
    
        Ensures that the signal confirmation works consistently across
        different allocator instances.
        """
        for i in range(3):
            alloc = strategy_allocator.StrategyAllocator()
            alloc.config.delta_threshold = 0.0
            alloc.config.signal_confirmation_bars = 2
            alloc.config.min_confidence = 0.0
    
>           sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
E           TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:174: TypeError
________________________________________________________ test_allocator ________________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    @pytest.mark.smoke
    def test_allocator():
        alloc = strategy_allocator.StrategyAllocator()
    
        # Configuration that properly tests signal confirmation workflow
        alloc.config.delta_threshold = 0.0        # Allow repeated signals
        alloc.config.signal_confirmation_bars = 2  # Require 2 bars for proper confirmation testing
        alloc.config.min_confidence = 0.0         # Ensure confidence threshold is met
    
        # AI-AGENT-REF: Add defensive verification to ensure config is applied correctly
        assert alloc.config.signal_confirmation_bars == 2, f"Expected signal_confirmation_bars=2, got {alloc.config.signal_confirmation_bars}"
        assert alloc.config.min_confidence == 0.0, f"Expected min_confidence=0.0, got {alloc.config.min_confidence}"
        assert alloc.config.delta_threshold == 0.0, f"Expected delta_threshold=0.0, got {alloc.config.delta_threshold}"
    
>       sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_smoke.py:29: TypeError
_________________________________________________ test_strategy_generate_base __________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_strategy_generate_base():
        """Base Strategy.generate returns empty list."""
>       assert Strategy().generate(None) == []
E       TypeError: Can't instantiate abstract class BaseStrategy with abstract methods calculate_position_size, generate_signals

tests/test_strategies_base_extra.py:12: TypeError
____________________________________________________ test_exit_confirmation ____________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

ensure_real_strategy_allocator = <module 'ai_trading.strategy_allocator' from '/workspace/ai-trading-bot/ai_trading/strategy_allocator.py'>

    def test_exit_confirmation(ensure_real_strategy_allocator):
        strategy_allocator = ensure_real_strategy_allocator
        alloc = strategy_allocator.StrategyAllocator()
        # Explicitly set configuration to ensure test isolation
        alloc.config.delta_threshold = 0.0  # Allow repeated signals with same confidence
        alloc.config.signal_confirmation_bars = 2  # Ensure we have expected confirmation bars
    
>       buy = TradeSignal(symbol="A", side="buy", confidence=1.0, strategy="s")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_exit.py:45: TypeError
______________________ TestStrategyAllocatorRegression.test_signal_confirmation_with_zero_min_confidence _______________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_strategy_allocator_regression.TestStrategyAllocatorRegression object at 0x7f8677fdcb50>

    def test_signal_confirmation_with_zero_min_confidence(self):
        """
        Regression test for the original failing scenario.
    
        The original issue was that with min_confidence=0.0, the second call
        to allocate() was returning an empty list instead of confirmed signals.
        """
        alloc = strategy_allocator.StrategyAllocator()
    
        # Set exact configuration from original failing test
        alloc.config.delta_threshold = 0.0
        alloc.config.signal_confirmation_bars = 2
        alloc.config.min_confidence = 0.0
    
>       sig = TradeSignal(symbol="AAPL", side="buy", confidence=1.0, strategy="s1")
E       TypeError: StrategySignal.__init__() missing 1 required positional argument: 'strength'

tests/test_strategy_allocator_regression.py:30: TypeError
________________________________________________ test_talib_import_enforcement _________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_talib_import_enforcement():
        """Test that TA library import gracefully handles missing dependency."""
        # Read the imports file to test the TA library section
        imports_file = (
            Path(__file__).parent.parent / "ai_trading" / "strategies" / "imports.py"
        )
    
        with open(imports_file) as f:
            content = f.read()
    
        # Find the TA library section
        lines = content.split("\n")
        ta_start = None
        ta_end = None
    
        for i, line in enumerate(lines):
            if "# TA library for optimized technical analysis" in line:
                ta_start = i
            elif ta_start is not None and "ta = MockTa()" in line:
                ta_end = i + 1
                break
    
        assert ta_start is not None, "Could not find TA library section"
>       assert ta_end is not None, "Could not find end of TA library section"
E       AssertionError: Could not find end of TA library section
E       assert None is not None

tests/test_talib_enforcement.py:34: AssertionError
___________________________________________ test_audit_file_creation_and_permissions ___________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw2/test_audit_file_creation_and_p0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8676851d10>

    def test_audit_file_creation_and_permissions(tmp_path, monkeypatch):
        """Test that audit.py creates trade log file with proper permissions."""
        import sys
    
        # Mock config to use temporary path
        trade_log_path = tmp_path / "data" / "trades.csv"
    
        # Create mock config module
        # Temporarily replace config module
        original_config = sys.modules.get("config")
        sys.modules["config"] = MockConfig()
    
        try:
            # Import audit after mocking config
            if "audit" in sys.modules:
                del sys.modules["audit"]
            from ai_trading import audit  # AI-AGENT-REF: canonical import
    
            # Ensure the file doesn't exist initially
            assert not trade_log_path.exists()
            assert not trade_log_path.parent.exists()
    
            # Call log_trade which should create the directory and file
>           audit.log_trade(
                symbol="TEST",
                qty=10,
                side="buy",
                fill_price=100.0,
                timestamp="2024-01-01T10:00:00Z",
                extra_info="TEST_MODE",
                exposure=0.1,
            )
E           TypeError: log_trade() got an unexpected keyword argument 'exposure'

tests/test_talib_enforcement.py:80: TypeError
_______________________________________________ test_audit_file_multiple_trades ________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw2/test_audit_file_multiple_trade0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8675c5bf90>

    def test_audit_file_multiple_trades(tmp_path, monkeypatch):
        """Test that multiple trades are appended correctly without duplicate headers."""
        import sys
    
        trade_log_path = tmp_path / "trades.csv"
    
        original_config = sys.modules.get("config")
        sys.modules["config"] = MockConfig()
    
        try:
            if "audit" in sys.modules:
                del sys.modules["audit"]
            from ai_trading import audit  # AI-AGENT-REF: canonical import
    
            # Log first trade
            audit.log_trade("AAPL", 5, "buy", 150.0, "2024-01-01T10:00:00Z", "TEST_MODE")
    
            # Log second trade
            audit.log_trade("MSFT", 3, "sell", 250.0, "2024-01-01T11:00:00Z", "TEST_MODE")
    
            # Verify both trades are in file
>           with open(trade_log_path) as f:
E           FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pytest-of-root/pytest-0/popen-gw2/test_audit_file_multiple_trade0/trades.csv'

tests/test_talib_enforcement.py:152: FileNotFoundError
____________________________________________________ test_nyse_session_dst _____________________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_nyse_session_dst():
        # July 15, 2024 (DST)
        s, e = nyse_session_utc(date(2024, 7, 15))
>       assert s.hour == 13 and s.tzinfo == ZoneInfo("UTC")
E       AssertionError: assert (13 == 13 and datetime.timezone.utc == zoneinfo.ZoneInfo(key='UTC'))
E        +  where 13 = datetime.datetime(2024, 7, 15, 13, 30, tzinfo=datetime.timezone.utc).hour
E        +  and   datetime.timezone.utc = datetime.datetime(2024, 7, 15, 13, 30, tzinfo=datetime.timezone.utc).tzinfo
E        +  and   zoneinfo.ZoneInfo(key='UTC') = ZoneInfo('UTC')

tests/test_timeutils.py:10: AssertionError
________________________________________ test_validate_trading_parameters_no_name_error ________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_validate_trading_parameters_no_name_error():
        """Test that validate_trading_parameters function references only defined parameters.
    
        This test parses the bot_engine.py source code and validates that all parameters
        referenced in validate_trading_parameters() are defined before the function call.
        """
    
        # Read the bot_engine.py source code
        src_path = Path(__file__).resolve().parents[1] / 'bot_engine.py'
>       source = src_path.read_text()

tests/test_trading_parameter_validation.py:15: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/pathlib.py:1058: in read_text
    with self.open(mode='r', encoding=encoding, errors=errors) as f:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = PosixPath('/workspace/ai-trading-bot/bot_engine.py'), mode = 'r', buffering = -1, encoding = 'locale', errors = None
newline = None

    def open(self, mode='r', buffering=-1, encoding=None,
             errors=None, newline=None):
        """
        Open the file pointed by this path and return a file object, as
        the built-in open() function does.
        """
        if "b" not in mode:
            encoding = io.text_encoding(encoding)
>       return io.open(self, mode, buffering, encoding, errors, newline)
E       FileNotFoundError: [Errno 2] No such file or directory: '/workspace/ai-trading-bot/bot_engine.py'

/root/.pyenv/versions/3.11.12/lib/python3.11/pathlib.py:1044: FileNotFoundError
_________________________________________________ test_run_strategy_no_signals _________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d3bf8450>

    def test_run_strategy_no_signals(monkeypatch):
        ctx = SimpleNamespace(
            strategies=[DummyStrategy()],
            allocator=FailAllocator(),
            api=SimpleNamespace(list_open_positions=lambda: []),
            data_fetcher=SimpleNamespace(
                get_daily_df=lambda ctx, sym: pd.DataFrame(),
                get_minute_df=lambda ctx, sym: pd.DataFrame(),
            ),
        )
    
        monkeypatch.setattr(bot_engine, "RL_AGENT", None)
>       import ai_trading.signals as sig

tests/test_run_strategy_no_signals.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/signals.py:114: in <module>
    from ai_trading.execution.transaction_costs import (
ai_trading/execution/__init__.py:36: in <module>
    from .engine import (  # AI-AGENT-REF: expose ExecutionEngine
ai_trading/execution/engine.py:35: in <module>
    _alpaca_rest = _optional_import("alpaca_trade_api.rest")
ai_trading/execution/engine.py:29: in _optional_import
    return importlib.import_module(name)
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/__init__.py:3: in <module>
    from .rest import REST, TimeFrame, TimeFrameUnit  # noqa
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import logging
    import os
    from typing import Iterator, List, Optional, Union
    import requests
    from requests.exceptions import HTTPError
    import time
    from enum import Enum
    from alpaca_trade_api import __version__
    from .common import (
        get_base_url,
        get_data_url,
        get_credentials,
        get_api_version, URL, FLOAT,
    )
    from .entity import (
        Bar, Entity, Account, AccountConfigurations, AccountActivity,
        Asset, Order, Position, Clock, Calendar,
        Trade, Quote, Watchlist, PortfolioHistory
    )
    from .entity_v2 import (
        BarV2, BarsV2, LatestBarsV2, LatestQuotesV2, LatestTradesV2,
        SnapshotV2, SnapshotsV2, TradesV2, TradeV2, QuotesV2, QuoteV2,
        NewsV2, NewsListV2, OrderbookV2, OrderbooksV2
    )
    
    logger = logging.getLogger(__name__)
    Positions = List[Position]
    Orders = List[Order]
    Assets = List[Asset]
    AccountActivities = List[AccountActivity]
    Calendars = List[Calendar]
    Watchlists = List[Watchlist]
    TradeIterator = Iterator[Union[Trade, dict]]
    QuoteIterator = Iterator[Union[Quote, dict]]
    BarIterator = Iterator[Union[Bar, dict]]
    NewsIterator = Iterator[Union[NewsV2, dict]]
    
    DATA_V2_MAX_LIMIT = 10000  # max items per api call
    NEWS_MAX_LIMIT = 50  # max items per api call
    
    
    class RetryException(Exception):
        pass
    
    
    class APIError(Exception):
        """
        Represent API related error.
        error.status_code will have http status code.
        """
    
        def __init__(self, error, http_error=None):
            super().__init__(error['message'])
            self._error = error
            self._http_error = http_error
    
        @property
        def code(self):
            return self._error.get('code', self.status_code)
    
        @property
        def status_code(self):
            http_error = self._http_error
            if http_error is not None and hasattr(http_error, 'response'):
                return http_error.response.status_code
    
        @property
        def request(self):
            if self._http_error is not None:
                return self._http_error.request
    
        @property
        def response(self):
            if self._http_error is not None:
                return self._http_error.response
    
>   def raise_api_error(resp: requests.Response, http_error: requests.HTTPError):
E   AttributeError: module 'requests' has no attribute 'Response'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca_trade_api/rest.py:77: AttributeError
_______________________________________________ test_handle_signal_sets_shutdown _______________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d37b6990>

    def test_handle_signal_sets_shutdown(monkeypatch):
        mod = load_runner(monkeypatch)
        mod._shutdown = False
>       mod._handle_signal(15, None)
E       AttributeError: module 'ai_trading.runner' has no attribute '_handle_signal'

tests/test_runner.py:14: AttributeError
____________________________________________________ test_run_forever_exit _____________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d345b350>

    def test_run_forever_exit(monkeypatch):
        mod = load_runner(monkeypatch)
        monkeypatch.setattr(mod, "main", lambda: (_ for _ in ()).throw(SystemExit(0)))
>       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:21: AttributeError
__________________________________________________ test_run_forever_exception __________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d345a2d0>

    def test_run_forever_exception(monkeypatch):
        mod = load_runner(monkeypatch)
        monkeypatch.setattr(mod, "main", lambda: (_ for _ in ()).throw(ValueError("bad")))
>       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:29: AttributeError
______________________________________________ test_run_forever_request_exception ______________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d345a310>

    def test_run_forever_request_exception(monkeypatch):
        mod = load_runner(monkeypatch)
        monkeypatch.setattr(mod, "main", lambda: (_ for _ in ()).throw(requests.exceptions.RequestException("boom")))
>       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:38: AttributeError
_____________________________________________ test_buy_threshold_definition_order ______________________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_buy_threshold_definition_order():
        """Specific test to ensure BUY_THRESHOLD is defined before validate_trading_parameters call."""
    
        src_path = Path(__file__).resolve().parents[1] / 'bot_engine.py'
>       source = src_path.read_text()

tests/test_trading_parameter_validation.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/pathlib.py:1058: in read_text
    with self.open(mode='r', encoding=encoding, errors=errors) as f:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = PosixPath('/workspace/ai-trading-bot/bot_engine.py'), mode = 'r', buffering = -1, encoding = 'locale', errors = None
newline = None

    def open(self, mode='r', buffering=-1, encoding=None,
             errors=None, newline=None):
        """
        Open the file pointed by this path and return a file object, as
        the built-in open() function does.
        """
        if "b" not in mode:
            encoding = io.text_encoding(encoding)
>       return io.open(self, mode, buffering, encoding, errors, newline)
E       FileNotFoundError: [Errno 2] No such file or directory: '/workspace/ai-trading-bot/bot_engine.py'

/root/.pyenv/versions/3.11.12/lib/python3.11/pathlib.py:1044: FileNotFoundError
____________________________________________________ test_submodules_import ____________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_submodules_import() -> None:
        pkg = importlib.import_module("ai_trading")
        for modinfo in pkgutil.walk_packages(pkg.__path__, pkg.__name__ + "."):
>           _safe_import(modinfo.name)

tests/test_imports_smoke.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_imports_smoke.py:16: in _safe_import
    importlib.import_module(name)
/root/.pyenv/versions/3.11.12/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1204: in _gcd_import
    ???
<frozen importlib._bootstrap>:1176: in _find_and_load
    ???
<frozen importlib._bootstrap>:1147: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:690: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:940: in exec_module
    ???
<frozen importlib._bootstrap>:241: in _call_with_frames_removed
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Time series cross-validation splits with purging and embargo.
    
    Provides leak-proof data splitting for financial time series,
    including purged group time series splits and walk-forward analysis.
    """
    
    from collections.abc import Iterator
    from datetime import datetime, timedelta
    
    import numpy as np
    import pandas as pd
    
    # sklearn is a hard dependency
>   from sklearn.model_selection import BaseCrossValidator
E   ModuleNotFoundError: No module named 'sklearn.model_selection'; 'sklearn' is not a package

ai_trading/data/splits.py:15: ModuleNotFoundError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:33,049", "level": "INFO", "name": "ai_trading.logging", "msg": "Paraâ€¦ator initialized with instâ€¦onal safety bounds", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.logging:parameter_validator.py:54 Paraâ€¦ator initialized with instâ€¦onal safety bounds
_____________________________________________ test_run_forever_system_exit_nonzero _____________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d36de690>

    def test_run_forever_system_exit_nonzero(monkeypatch):
        mod = load_runner(monkeypatch)
        seq = [SystemExit(1), SystemExit(0)]
    
        def side():
            exc = seq.pop(0)
            raise exc
    
        monkeypatch.setattr(mod, "main", side)
>       monkeypatch.setattr(mod.time, "sleep", lambda s: None)
E       AttributeError: module 'ai_trading.runner' has no attribute 'time'

tests/test_runner.py:53: AttributeError
_____________________________________________ test_kelly_confidence_normalization ______________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_kelly_confidence_normalization():
        """Test that high confidence values are properly normalized to probabilities."""
        # Mock BotContext for testing
        # Import the actual function (if available)
        try:
            from ai_trading.core.bot_engine import fractional_kelly_size
    
>           ctx = MockBotContext()
E           NameError: name 'MockBotContext' is not defined

tests/test_kelly_confidence_fix.py:24: NameError
_________________________________________________ test_kelly_input_validation __________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_kelly_input_validation():
        """Test that Kelly calculation properly validates all inputs."""
        # Mock BotContext for testing
        try:
            from ai_trading.core.bot_engine import fractional_kelly_size
    
>           ctx = MockBotContext()
E           NameError: name 'MockBotContext' is not defined

tests/test_kelly_confidence_fix.py:77: NameError
________________________________________________ test_setup_logging_idempotent _________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c074c0d0>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw4/test_setup_logging_idempotent0')

    def test_setup_logging_idempotent(monkeypatch, tmp_path):
        mod = reload_module(logger)
        created = []
    
        def fake_get_rotating(path, **_):
            created.append(path)
            return logging.StreamHandler()
    
        monkeypatch.setattr(mod, "get_rotating_handler", fake_get_rotating)
        lg = mod.setup_logging(debug=True, log_file=str(tmp_path / "f.log"))
        assert lg.level in (logging.DEBUG, logging.INFO)
>       assert created, f"No rotating handler paths created. Captured: {created}"
E       AssertionError: No rotating handler paths created. Captured: []
E       assert []

tests/test_logger.py:36: AssertionError
______________________________________ test_trigger_meta_learning_conversion_mixed_format ______________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trigger_meta_learning_conversion_mixed_format():
        """Test trigger function with mixed format - should attempt conversion."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            # Write mixed format data (meta headers with audit data)
            f.write("symbol,entry_time,entry_price,exit_time,exit_price,qty,side,strategy,classification,signal_tags,confidence,reward\n")
            f.write("123e4567-e89b-12d3-a456-426614174000,2025-08-05T23:17:35Z,TEST,buy,10,100.0,live,filled\n")
            f.write("234e5678-e89b-12d3-a456-426614174001,2025-08-05T23:18:35Z,TEST,sell,10,105.0,live,filled\n")
            test_file = f.name
    
        try:
            # Set the trade log file path
            MockConfig.TRADE_LOG_FILE = test_file
    
            # Test trade data
            test_trade = {
                'symbol': 'TEST',
                'qty': 10,
                'side': 'buy',
                'price': 100.0,
                'timestamp': '2025-08-05T23:17:35Z',
                'order_id': 'test-001',
                'status': 'filled'
            }
    
            # Verify quality report shows mixed format
            quality_report = meta_learning.validate_trade_data_quality(test_file)
            assert quality_report['mixed_format_detected'] is True
    
            # Test the trigger function - should attempt conversion and return True if successful
>           result = meta_learning.trigger_meta_learning_conversion(test_trade)

tests/test_trigger_meta_learning_conversion.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -> bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
>           if config is not None:
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.meta_learning:meta_learning.py:312 Invalid price in meta format row: could not convert string to float: 'entry_price'
INFO     ai_trading.meta_learning:meta_learning.py:1806 METAâ€¦GGER | symbol=TEST
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 17:37:33,128", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "METAâ€¦GGER | symbol=TEST", "bot_phase": "GENERAL"}
_______________________________________________________ test_get_logger ________________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_get_logger():
        mod = reload_module(logger)
        root = mod.setup_logging(debug=True)
        lg = mod.get_logger("test")
        assert lg is mod._loggers["test"]
>       assert len(lg.handlers) == len(root.handlers)
E       AttributeError: 'SanitizingLoggerAdapter' object has no attribute 'handlers'

tests/test_logger.py:48: AttributeError
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 17:37:33,203", "level": "INFO", "name": "ai_trading.logging", "msg": "Logging configured succâ€¦ully - no duplicates possible", "bot_phase": "GENERAL"}
_________________________________________________ test_setup_logging_with_file _________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c0c05450>
tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw4/test_setup_logging_with_file0')

    def test_setup_logging_with_file(monkeypatch, tmp_path):
        """File handler is added when log_file is provided."""
        logger._configured = False
        fake = logging.NullHandler()
    
        def fake_makedirs(path, exist_ok=False):
            pass
    
        calls = []
    
        def fake_get_handler(*args, **kwargs):
            calls.append((args, kwargs))
            return fake
    
        monkeypatch.setattr(logger.os, "makedirs", fake_makedirs)
        monkeypatch.setattr(logger, "get_rotating_handler", fake_get_handler)
    
        log_file = tmp_path / "x" / "app.log"
        logger.setup_logging(log_file=str(log_file))
>       assert calls
E       assert []

tests/test_logger_file.py:25: AssertionError
__________________________________________________ test_get_logger_singleton ___________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw4/test_get_logger_singleton0')

    def test_get_logger_singleton(tmp_path):
        lg1 = logger.get_logger("test")
        lg2 = logger.get_logger("test")
        assert lg1 is lg2
        # Updated test: With our new design, child loggers use propagation
        # instead of having their own handlers to prevent duplicates
>       assert lg1.propagate  # Should propagate to root logger
E       AttributeError: 'SanitizingLoggerAdapter' object has no attribute 'propagate'

tests/test_logger_module.py:15: AttributeError
______________________________________ test_trigger_meta_learning_conversion_missing_file ______________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trigger_meta_learning_conversion_missing_file():
        """Test trigger function with missing file - should return False."""
        # Set a non-existent file path
        MockConfig.TRADE_LOG_FILE = '/tmp/non_existent_file.csv'
    
        test_trade = {
            'symbol': 'TEST',
            'qty': 10,
            'side': 'buy',
            'price': 100.0,
            'timestamp': '2025-08-05T23:17:35Z',
            'order_id': 'test-001',
            'status': 'filled'
        }
    
        # Test the trigger function - should return False for missing file
>       result = meta_learning.trigger_meta_learning_conversion(test_trade)

tests/test_trigger_meta_learning_conversion.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -> bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
>           if config is not None:
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.meta_learning:meta_learning.py:1806 METAâ€¦GGER | symbol=TEST
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 17:37:33,199", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "METAâ€¦GGER | symbol=TEST", "bot_phase": "GENERAL"}
___________________________________________________ test_no_secrets_in_logs ____________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

caplog = <_pytest.logging.LogCaptureFixture object at 0x7ff3baf7f510>
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff3baf7dad0>

    def test_no_secrets_in_logs(caplog, monkeypatch):
        caplog.set_level(logging.INFO)
        monkeypatch.setenv("NEWS_API_KEY", "TOPSECRETKEY")
        logger = get_logger(__name__)
        logger.info("boot with key=%s", os.getenv("NEWS_API_KEY"))
        joined = "\n".join(m.message for m in caplog.records)
>       assert "TOPSECRETKEY" not in joined
E       AssertionError: assert 'TOPSECRETKEY' not in 'boot with key=TOPSECRETKEY'
E         
E         'TOPSECRETKEY' is contained here:
E           boot with key=TOPSECRETKEY

tests/test_logging_scrubbed.py:13: AssertionError
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     tests.test_logging_scrubbed:test_logging_scrubbed.py:11 boot with key=TOPSECRETKEY
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 17:37:33,278", "level": "INFO", "name": "tests.test_logging_scrubbed", "msg": "boot with key=TOPSâ€¦TKEY", "bot_phase": "GENERAL"}
______________________________________________________ test_run_flask_app ______________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c08b5b90>

    def test_run_flask_app(monkeypatch):
        """Flask app runs on provided port."""
        called = {}
    
        class App:
            def run(self, host, port):
                called["args"] = (host, port)
    
        monkeypatch.setattr(app, "create_app", lambda: App())
>       main.run_flask_app(1234)

tests/test_main_extended2.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

port = 1234, ready_signal = None

    def run_flask_app(port: int = 5000, ready_signal: threading.Event = None) -> None:
        """Launch Flask API on an available port."""
        # AI-AGENT-REF: simplified port fallback logic with get_free_port fallback
        max_attempts = 10
        original_port = port
    
        for _attempt in range(max_attempts):
            if not get_pid_on_port(port):
                break
            port += 1
        else:
            # If consecutive ports are all occupied, use get_free_port as fallback
            free_port = get_free_port()
            if free_port is None:
                raise RuntimeError(
                    f"Could not find available port starting from {original_port}"
                )
            port = free_port
    
        # Defer app import to avoid import-time side effects
        from ai_trading import app
    
        application = app.create_app()
    
        # AI-AGENT-REF: Signal ready immediately after Flask app creation for faster startup
        if ready_signal is not None:
            logger.info(f"Flask app created successfully, signaling ready on port {port}")
            ready_signal.set()
    
        logger.info(f"Starting Flask app on 0.0.0.0:{port}")
        # AI-AGENT-REF: disable debug mode in production server
>       application.run(host="0.0.0.0", port=port, debug=False)
E       TypeError: test_run_flask_app.<locals>.App.run() got an unexpected keyword argument 'debug'

ai_trading/main.py:299: TypeError
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.main:main.py:297 Starting Flask app on 0.0.0.0:1234
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 17:37:33,288", "level": "INFO", "name": "ai_trading.main", "msg": "Starting Flask app on 0.0.0.0:1234", "bot_phase": "GENERAL"}
________________________________________________ test_run_flask_app_port_in_use ________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c06e1650>

    def test_run_flask_app_port_in_use(monkeypatch):
        """Port conflict triggers fallback port."""
        called = []
    
        class App:
            def run(self, host, port):
                called.append(port)
    
        monkeypatch.setattr(app, "create_app", lambda: App())
>       monkeypatch.setattr(main.utils, "get_pid_on_port", lambda p: 111)
E       AttributeError: module 'ai_trading.main' has no attribute 'utils'

tests/test_main_extended2.py:44: AttributeError
________________________________ test_trigger_meta_learning_conversion_problem_statement_exact _________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trigger_meta_learning_conversion_problem_statement_exact():
        """Test the exact scenario from the problem statement."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            # Create exactly the scenario: mixed_format_detected=False, audit_format_rows=0, meta_format_rows=4
            f.write("symbol,entry_time,entry_price,exit_time,exit_price,qty,side,strategy,classification,signal_tags,confidence,reward\n")
            f.write("TEST,2025-08-05T23:17:35Z,100.0,2025-08-05T23:18:35Z,105.0,10,buy,test_strategy,test,signal1+signal2,0.8,5.0\n")
            f.write("AAPL,2025-08-05T23:19:35Z,150.0,2025-08-05T23:20:35Z,155.0,5,buy,test_strategy,test,signal3,0.7,25.0\n")
            f.write("MSFT,2025-08-05T23:21:35Z,300.0,2025-08-05T23:22:35Z,295.0,2,sell,test_strategy,test,signal4,0.6,-10.0\n")
            f.write("GOOGL,2025-08-05T23:23:35Z,2500.0,2025-08-05T23:24:35Z,2505.0,1,buy,test_strategy,test,signal5,0.9,5.0\n")
            test_file = f.name
    
        try:
            MockConfig.TRADE_LOG_FILE = test_file
    
            test_trade = {
                'symbol': 'TEST',
                'qty': 10,
                'side': 'buy',
                'price': 100.0,
                'timestamp': '2025-08-05T23:17:35Z',
                'order_id': 'test-001',
                'status': 'filled'
            }
    
            # Verify we have the exact scenario from problem statement
            quality_report = meta_learning.validate_trade_data_quality(test_file)
            assert quality_report['mixed_format_detected'] is False
            assert quality_report['audit_format_rows'] == 0
            assert quality_report['meta_format_rows'] > 0  # Should be 5 (4 data + 1 header)
    
            # This should return True immediately (no conversion needed)
>           result = meta_learning.trigger_meta_learning_conversion(test_trade)

tests/test_trigger_meta_learning_conversion.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -> bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
>           if config is not None:
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.meta_learning:meta_learning.py:312 Invalid price in meta format row: could not convert string to float: 'entry_price'
INFO     ai_trading.meta_learning:meta_learning.py:1806 METAâ€¦GGER | symbol=TEST
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 17:37:33,271", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "METAâ€¦GGER | symbol=TEST", "bot_phase": "GENERAL"}
_________________________________________________ test_universe_fetch_pooling __________________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d34432d0>

    def test_universe_fetch_pooling(monkeypatch):
        calls = {}
    
        def fake_map_get(urls, timeout=None, headers=None):
            calls['count'] = calls.get('count', 0) + 1
            calls['len'] = len(urls)
            return [((u, 200, f"BODY{i}".encode()), None) for i, u in enumerate(urls)]
    
        monkeypatch.setattr(http, "map_get", fake_map_get)
>       monkeypatch.setattr(data_fetcher, "_parse_bars", lambda s, c, b: b.decode())
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute '_parse_bars'

tests/test_universe_fetch_pooling.py:14: AttributeError
____________________________________ test_trigger_meta_learning_conversion_pure_meta_format ____________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trigger_meta_learning_conversion_pure_meta_format():
        """Test trigger function with pure meta-learning format - should return True immediately."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            # Write meta-learning format data
            f.write("symbol,entry_time,entry_price,exit_time,exit_price,qty,side,strategy,classification,signal_tags,confidence,reward\n")
            f.write("TEST,2025-08-05T23:17:35Z,100.0,2025-08-05T23:18:35Z,105.0,10,buy,test_strategy,test,signal1+signal2,0.8,5.0\n")
            f.write("AAPL,2025-08-05T23:19:35Z,150.0,2025-08-05T23:20:35Z,155.0,5,buy,test_strategy,test,signal3,0.7,25.0\n")
            f.write("MSFT,2025-08-05T23:21:35Z,300.0,2025-08-05T23:22:35Z,295.0,2,sell,test_strategy,test,signal4,0.6,-10.0\n")
            test_file = f.name
    
        try:
            # Set the trade log file path
            MockConfig.TRADE_LOG_FILE = test_file
    
            # Test trade data
            test_trade = {
                'symbol': 'TEST',
                'qty': 10,
                'side': 'buy',
                'price': 100.0,
                'timestamp': '2025-08-05T23:17:35Z',
                'order_id': 'test-001',
                'status': 'filled'
            }
    
            # Verify quality report shows pure meta format
            quality_report = meta_learning.validate_trade_data_quality(test_file)
            assert quality_report['mixed_format_detected'] is False
            assert quality_report['audit_format_rows'] == 0
            assert quality_report['meta_format_rows'] > 0
    
            # Test the trigger function - should return True immediately (no conversion needed)
>           result = meta_learning.trigger_meta_learning_conversion(test_trade)

tests/test_trigger_meta_learning_conversion.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -> bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
>           if config is not None:
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:33,123", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "METAâ€¦GGER | symbol=TEST", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.meta_learning:meta_learning.py:312 Invalid price in meta format row: could not convert string to float: 'entry_price'
INFO     ai_trading.meta_learning:meta_learning.py:1806 METAâ€¦GGER | symbol=TEST
___________________________________________________ test_run_bot_calls_cycle ___________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff3baf29650>

    def test_run_bot_calls_cycle(monkeypatch):
        """run_bot executes a trading cycle in-process."""
        called = {}
    
        monkeypatch.setattr(
            main, "run_cycle", lambda: called.setdefault("ran", True)
        )
>       assert main.run_bot() == 0

tests/test_main_extended2.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/main.py:245: in run_bot
    validate_environment()
ai_trading/main.py:201: in validate_environment
    if not cfg.alpaca_api_key or not cfg.alpaca_secret_key_plain:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
item = 'alpaca_secret_key_plain'

    def __getattr__(self, item: str) -> Any:
        private_attributes = object.__getattribute__(self, '__private_attributes__')
        if item in private_attributes:
            attribute = private_attributes[item]
            if hasattr(attribute, '__get__'):
                return attribute.__get__(self, type(self))  # type: ignore
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                return self.__pydantic_private__[item]  # type: ignore
            except KeyError as exc:
                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
        else:
            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.
            # See `BaseModel.__repr_args__` for more details
            try:
                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')
            except AttributeError:
                pydantic_extra = None
    
            if pydantic_extra:
                try:
                    return pydantic_extra[item]
                except KeyError as exc:
                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
            else:
                if hasattr(self.__class__, item):
                    return super().__getattribute__(item)  # Raises AttributeError if appropriate
                else:
                    # this is the current error
>                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E                   AttributeError: 'Settings' object has no attribute 'alpaca_secret_key_plain'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:991: AttributeError
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.logging:__init__.py:950 WARNING: 3 handlers detected - possible duplicate logging setup
ERROR    ai_trading.logging:__init__.py:966 Logging validation failed: ['Too many handlers detected: 3 (expected â‰¤ 2)']
ERROR    root:main.py:237 Logging validation failed: ['Too many handlers detected: 3 (expected â‰¤ 2)']
INFO     root:main.py:240 Application startup - logging configured once
___________________________ TestSystemdStartupCompatibility.test_import_no_crash_without_credentials ___________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_systemd_startup.TestSystemdStartupCompatibility object at 0x7f8d8580b1d0>

        def test_import_no_crash_without_credentials(self):
            """Test that imports don't crash without credentials."""
            # Create a test script that imports key modules
            test_script = '''
    import os
    import sys
    
    # Clear all credential environment variables
    for key in ["ALPACA_API_KEY", "APCA_API_KEY_ID", "ALPACA_SECRET_KEY", "APCA_API_SECRET_KEY"]:
        os.environ.pop(key, None)
    
    try:
        # Test importing key modules without credentials
        from ai_trading.config.management import _resolve_alpaca_env
        print("âœ“ Config management imported")
    
        from ai_trading import runner
        print("âœ“ Runner imported")
    
        from ai_trading.utils.timefmt import utc_now_iso
        print("âœ“ Time utilities imported")
    
        # Test that credential resolution works
        api_key, secret_key, base_url = _resolve_alpaca_env()
        assert api_key is None
        assert secret_key is None
        assert base_url == "https://paper-api.alpaca.markets"
        print("âœ“ Credential resolution works with missing creds")
    
        # Test UTC timestamp doesn't have double Z
        timestamp = utc_now_iso()
        assert timestamp.endswith('Z')
        assert timestamp.count('Z') == 1
        print("âœ“ UTC timestamp has single Z")
    
        print("SUCCESS: No import-time crashes!")
    
    except SystemExit as e:
        print(f"FAIL: SystemExit called: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"FAIL: Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    '''
    
            # Write test script to temporary file
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(test_script)
                script_path = f.name
    
            try:
                # Run the test script in a clean subprocess
>               result = subprocess.run(
                    [sys.executable, script_path],
                    capture_output=True,
                    text=True,
                    timeout=30,
                    check=True
                )

tests/test_systemd_startup.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 30, check = True
popenargs = (['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp28f6ub4o.py'],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}
process = <Popen: returncode: 1 args: ['/root/.pyenv/versions/3.11.12/bin/python3.11',...>
stdout = "FAIL: Unexpected error: No module named 'ai_trading'\n"
stderr = 'Traceback (most recent call last):\n  File "/tmp/tmp28f6ub4o.py", line 11, in <module>\n    from ai_trading.config.management import _resolve_alpaca_env\nModuleNotFoundError: No module named \'ai_trading\'\n'
retcode = 1

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired as exc:
                process.kill()
                if _mswindows:
                    # Windows accumulates the output in a single blocking
                    # read() call run on child threads, with the timeout
                    # being done in a join() on those threads.  communicate()
                    # _after_ kill() is required to collect that and add it
                    # to the exception.
                    exc.stdout, exc.stderr = process.communicate()
                else:
                    # POSIX _communicate already populated the output so
                    # far into the TimeoutExpired exception.
                    process.wait()
                raise
            except:  # Including KeyboardInterrupt, communicate handled that.
                process.kill()
                # We don't call process.wait() as .__exit__ does that for us.
                raise
            retcode = process.poll()
            if check and retcode:
>               raise CalledProcessError(retcode, process.args,
                                         output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp28f6ub4o.py']' returned non-zero exit status 1.

/root/.pyenv/versions/3.11.12/lib/python3.11/subprocess.py:571: CalledProcessError
___________________________________ test_trigger_meta_learning_conversion_pure_audit_format ____________________________________
[gw2] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    def test_trigger_meta_learning_conversion_pure_audit_format():
        """Test trigger function with pure audit format - should attempt conversion."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            # Write audit format data
            f.write("order_id,timestamp,symbol,side,qty,price,mode,status\n")
            f.write("123e4567-e89b-12d3-a456-426614174000,2025-08-05T23:17:35Z,TEST,buy,10,100.0,live,filled\n")
            f.write("234e5678-e89b-12d3-a456-426614174001,2025-08-05T23:18:35Z,TEST,sell,10,105.0,live,filled\n")
            f.write("345e6789-e89b-12d3-a456-426614174002,2025-08-05T23:19:35Z,AAPL,buy,5,150.0,live,filled\n")
            test_file = f.name
    
        try:
            # Set the trade log file path
            MockConfig.TRADE_LOG_FILE = test_file
    
            # Test trade data
            test_trade = {
                'symbol': 'TEST',
                'qty': 10,
                'side': 'buy',
                'price': 100.0,
                'timestamp': '2025-08-05T23:17:35Z',
                'order_id': 'test-001',
                'status': 'filled'
            }
    
            # Verify quality report shows pure audit format
            quality_report = meta_learning.validate_trade_data_quality(test_file)
            assert quality_report['mixed_format_detected'] is False
            assert quality_report['audit_format_rows'] > 0
            assert quality_report['meta_format_rows'] == 0
    
            # Test the trigger function - should attempt conversion and return True if successful
>           result = meta_learning.trigger_meta_learning_conversion(test_trade)

tests/test_trigger_meta_learning_conversion.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

trade_data = {'order_id': 'test-001', 'price': 100.0, 'qty': 10, 'side': 'buy', ...}

    def trigger_meta_learning_conversion(trade_data: dict) -> bool:
        """Automatically convert audit logs to meta-learning format after trade execution."""
        try:
            symbol = trade_data.get("symbol", "UNKNOWN")
            logger.info("META_LEARNING_TRIGGER | symbol=%s", symbol)
    
            # Get config for trade log file path - handle import timing issues
            current_config = None
    
            # First try the module-level config
>           if config is not None:
E           NameError: name 'config' is not defined

ai_trading/meta_learning.py:1812: NameError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:37:33,381", "level": "INFO", "name": "ai_trading.meta_learning", "msg": "METAâ€¦GGER | symbol=TEST", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.meta_learning:meta_learning.py:1806 METAâ€¦GGER | symbol=TEST
_____________________________________________ test_yfinance_auto_adjust_and_cache ______________________________________________
[gw0] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff8d2162fd0>

    def test_yfinance_auto_adjust_and_cache(monkeypatch):
        calls = {"auto_adjust": None, "cache_called": False}
    
        fake = types.SimpleNamespace()
    
        def set_tz_cache_location(path):  # AI-AGENT-REF: track tz cache invocation
            calls["cache_called"] = True
    
        def download(*args, auto_adjust=None, **kwargs):  # AI-AGENT-REF: capture auto_adjust
            calls["auto_adjust"] = auto_adjust
            import pandas as pd
    
            return pd.DataFrame(
                {"Open": [1.0], "High": [1.0], "Low": [1.0], "Close": [1.0], "Volume": [100]},
                index=pd.date_range(datetime(2025, 8, 1, tzinfo=UTC), periods=1, name="Date"),
            )
    
        fake.set_tz_cache_location = set_tz_cache_location
        fake.download = download
        monkeypatch.setitem(sys.modules, "yfinance", fake)
    
>       from ai_trading.data_fetcher import _yahoo_get_bars
E       ImportError: cannot import name '_yahoo_get_bars' from 'ai_trading.data_fetcher' (unknown location)

tests/test_yf_auto_adjust_and_cache.py:29: ImportError
______________________________________________ test_validate_environment_missing _______________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c0916c10>

    def test_validate_environment_missing(monkeypatch):
        """validate_environment errors when secret missing."""
>       monkeypatch.setattr(main.config, 'WEBHOOK_SECRET', '', raising=False)

tests/test_main_extended2.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:997: in __setattr__
    elif (setattr_handler := self._setattr_handler(name, value)) is not None:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
name = 'WEBHOOK_SECRET', value = ''

    def _setattr_handler(self, name: str, value: Any) -> Callable[[BaseModel, str, Any], None] | None:
        """Get a handler for setting an attribute on the model instance.
    
        Returns:
            A handler for setting an attribute on the model instance. Used for memoization of the handler.
            Memoizing the handlers leads to a dramatic performance improvement in `__setattr__`
            Returns `None` when memoization is not safe, then the attribute is set directly.
        """
        cls = self.__class__
        if name in cls.__class_vars__:
            raise AttributeError(
                f'{name!r} is a ClassVar of `{cls.__name__}` and cannot be set on an instance. '
                f'If you want to set a value on the class, use `{cls.__name__}.{name} = value`.'
            )
        elif not _fields.is_valid_field_name(name):
            if (attribute := cls.__private_attributes__.get(name)) is not None:
                if hasattr(attribute, '__set__'):
                    return lambda model, _name, val: attribute.__set__(model, val)
                else:
                    return _SIMPLE_SETATTR_HANDLERS['private']
            else:
                _object_setattr(self, name, value)
                return None  # Can not return memoized handler with possibly freeform attr names
    
        attr = getattr(cls, name, None)
        # NOTE: We currently special case properties and `cached_property`, but we might need
        # to generalize this to all data/non-data descriptors at some point. For non-data descriptors
        # (such as `cached_property`), it isn't obvious though. `cached_property` caches the value
        # to the instance's `__dict__`, but other non-data descriptors might do things differently.
        if isinstance(attr, cached_property):
            return _SIMPLE_SETATTR_HANDLERS['cached_property']
    
        _check_frozen(cls, name, value)
    
        # We allow properties to be set only on non frozen models for now (to match dataclasses).
        # This can be changed if it ever gets requested.
        if isinstance(attr, property):
            return lambda model, _name, val: attr.__set__(model, val)
        elif cls.model_config.get('validate_assignment'):
            return _SIMPLE_SETATTR_HANDLERS['validate_assignment']
        elif name not in cls.__pydantic_fields__:
            if cls.model_config.get('extra') != 'allow':
                # TODO - matching error
>               raise ValueError(f'"{cls.__name__}" object has no field "{name}"')
E               ValueError: "Settings" object has no field "WEBHOOK_SECRET"

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1044: ValueError
_____________________________________________________ test_main_runs_once ______________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff3bae7e5d0>

    def test_main_runs_once(monkeypatch):
        """main executes a single cycle when configured."""
        monkeypatch.setenv("SCHEDULER_ITERATIONS", "1")
        called = {}
    
        # AI-AGENT-REF: Fix lambda signature to accept ready_signal parameter and set it
        def mock_start_api(ready_signal=None):
            called.setdefault("api", True)
            if ready_signal:
                ready_signal.set()  # Important: signal that API is ready
        monkeypatch.setattr(main, "start_api", mock_start_api)
        def _cycle():
            called["cycle"] = called.get("cycle", 0) + 1
        monkeypatch.setattr(main, "run_cycle", _cycle)
        monkeypatch.setattr(main.time, "sleep", lambda s: None)
>       main.main()

tests/test_main_extended2.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/main.py:341: in main
    _validate_runtime_config(config, S)
ai_trading/main.py:166: in _validate_runtime_config
    setattr(tcfg, "max_position_size", float(fallback))
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:997: in __setattr__
    elif (setattr_handler := self._setattr_handler(name, value)) is not None:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Settings(env='test', market_calendar='XNYS', data_provider='mock', log_level='INFO', enable_memory_optimization=True, ...onds=300, cpu_only=False, news_api_key=None, rebalance_interval_min=60, trade_cooldown=datetime.timedelta(seconds=900))
name = 'max_position_size', value = 8000.0

    def _setattr_handler(self, name: str, value: Any) -> Callable[[BaseModel, str, Any], None] | None:
        """Get a handler for setting an attribute on the model instance.
    
        Returns:
            A handler for setting an attribute on the model instance. Used for memoization of the handler.
            Memoizing the handlers leads to a dramatic performance improvement in `__setattr__`
            Returns `None` when memoization is not safe, then the attribute is set directly.
        """
        cls = self.__class__
        if name in cls.__class_vars__:
            raise AttributeError(
                f'{name!r} is a ClassVar of `{cls.__name__}` and cannot be set on an instance. '
                f'If you want to set a value on the class, use `{cls.__name__}.{name} = value`.'
            )
        elif not _fields.is_valid_field_name(name):
            if (attribute := cls.__private_attributes__.get(name)) is not None:
                if hasattr(attribute, '__set__'):
                    return lambda model, _name, val: attribute.__set__(model, val)
                else:
                    return _SIMPLE_SETATTR_HANDLERS['private']
            else:
                _object_setattr(self, name, value)
                return None  # Can not return memoized handler with possibly freeform attr names
    
        attr = getattr(cls, name, None)
        # NOTE: We currently special case properties and `cached_property`, but we might need
        # to generalize this to all data/non-data descriptors at some point. For non-data descriptors
        # (such as `cached_property`), it isn't obvious though. `cached_property` caches the value
        # to the instance's `__dict__`, but other non-data descriptors might do things differently.
        if isinstance(attr, cached_property):
            return _SIMPLE_SETATTR_HANDLERS['cached_property']
    
        _check_frozen(cls, name, value)
    
        # We allow properties to be set only on non frozen models for now (to match dataclasses).
        # This can be changed if it ever gets requested.
        if isinstance(attr, property):
            return lambda model, _name, val: attr.__set__(model, val)
        elif cls.model_config.get('validate_assignment'):
            return _SIMPLE_SETATTR_HANDLERS['validate_assignment']
        elif name not in cls.__pydantic_fields__:
            if cls.model_config.get('extra') != 'allow':
                # TODO - matching error
>               raise ValueError(f'"{cls.__name__}" object has no field "{name}"')
E               ValueError: "Settings" object has no field "max_position_size"

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pydantic/main.py:1044: ValueError
------------------------------------------------------ Captured log call -------------------------------------------------------
INFO     ai_trading.main:main.py:335 DATA_CONFIG feed=iex adjustment=all timeframe=1Day/1Min provider=alpaca
INFO     ai_trading.position_sizing:position_sizing.py:60 CONFâ€¦OFIX
CRITICAL ai_trading.main:main.py:343 RUNTâ€¦ALID
--------------------------------------------------- Captured stdout teardown ---------------------------------------------------
{"ts": "2025-08-22 17:37:33,665", "level": "INFO", "name": "ai_trading.main", "msg": "DATA_CONFIG feed=iex adjustment=all timeframe=1Day/1Min provider=alpaca", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:33,665", "level": "INFO", "name": "ai_trading.position_sizing", "msg": "CONFâ€¦OFIX", "field": "max_position_size", "given": 0.0, "fallback": 8000.0, "reason": "derived_equity_cap", "equity": null, "capital_cap": 0.04, "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:37:33,665", "level": "CRITICAL", "name": "ai_trading.main", "msg": "RUNTâ€¦ALID", "error": "\"Settings\" object has no field \"max_position_size\"", "bot_phase": "GENERAL"}
__________________________ TestSystemdStartupCompatibility.test_dual_credential_schema_with_env_file ___________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_systemd_startup.TestSystemdStartupCompatibility object at 0x7f8d8580b450>

        def test_dual_credential_schema_with_env_file(self):
            """Test that both credential schemas work with .env files."""
            # Test ALPACA_* schema
            alpaca_env_content = """
    ALPACA_API_KEY=test_alpaca_key_from_env
    ALPACA_SECRET_KEY=test_alpaca_secret_from_env
    ALPACA_BASE_URL=https://paper-api.alpaca.markets
    """
    
            with tempfile.NamedTemporaryFile(mode='w', suffix='.env', delete=False) as f:
                f.write(alpaca_env_content)
                alpaca_env_path = f.name
    
            # Test APCA_* schema
            apca_env_content = """
    APCA_API_KEY_ID=test_apca_key_from_env
    APCA_API_SECRET_KEY=test_apca_secret_from_env
    APCA_API_BASE_URL=https://api.alpaca.markets
    """
    
            with tempfile.NamedTemporaryFile(mode='w', suffix='.env', delete=False) as f:
                f.write(apca_env_content)
                apca_env_path = f.name
    
            try:
                # Test ALPACA schema
                test_script = f'''
    import os
    from dotenv import load_dotenv
    load_dotenv("{alpaca_env_path}", override=True)
    
    from ai_trading.config.management import _resolve_alpaca_env
    api_key, secret_key, base_url = _resolve_alpaca_env()
    
    assert api_key == "test_alpaca_key_from_env"
    assert secret_key == "test_alpaca_secret_from_env"
    assert base_url == "https://paper-api.alpaca.markets"
    print("âœ“ ALPACA schema with .env file works")
    '''
    
                with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                    f.write(test_script)
                    script_path = f.name
    
>               result = subprocess.run([sys.executable, script_path], capture_output=True, text=True, timeout=30, check=True)  # AI-AGENT-REF: Added timeout and check for security

tests/test_systemd_startup.py:135: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 30, check = True
popenargs = (['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp5_crc_4s.py'],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}
process = <Popen: returncode: 1 args: ['/root/.pyenv/versions/3.11.12/bin/python3.11',...>, stdout = ''
stderr = 'Traceback (most recent call last):\n  File "/tmp/tmp5_crc_4s.py", line 6, in <module>\n    from ai_trading.config.management import _resolve_alpaca_env\nModuleNotFoundError: No module named \'ai_trading\'\n'
retcode = 1

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired as exc:
                process.kill()
                if _mswindows:
                    # Windows accumulates the output in a single blocking
                    # read() call run on child threads, with the timeout
                    # being done in a join() on those threads.  communicate()
                    # _after_ kill() is required to collect that and add it
                    # to the exception.
                    exc.stdout, exc.stderr = process.communicate()
                else:
                    # POSIX _communicate already populated the output so
                    # far into the TimeoutExpired exception.
                    process.wait()
                raise
            except:  # Including KeyboardInterrupt, communicate handled that.
                process.kill()
                # We don't call process.wait() as .__exit__ does that for us.
                raise
            retcode = process.poll()
            if check and retcode:
>               raise CalledProcessError(retcode, process.args,
                                         output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp5_crc_4s.py']' returned non-zero exit status 1.

/root/.pyenv/versions/3.11.12/lib/python3.11/subprocess.py:571: CalledProcessError
________________________________ TestSystemdStartupCompatibility.test_utc_timestamp_no_double_z ________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_systemd_startup.TestSystemdStartupCompatibility object at 0x7f8d8580ae10>

        def test_utc_timestamp_no_double_z(self):
            """Test that UTC timestamps don't have double Z suffix."""
            test_script = '''
    from ai_trading.utils.timefmt import utc_now_iso, format_datetime_utc, ensure_utc_format
    from datetime import datetime, timezone
    
    # Test utc_now_iso
    timestamp = utc_now_iso()
    assert timestamp.endswith('Z')
    assert timestamp.count('Z') == 1
    print(f"âœ“ utc_now_iso: {timestamp}")
    
    # Test format_datetime_utc
    dt = datetime(2024, 1, 1, 12, 0, 0, tzinfo=timezone.utc)
    formatted = format_datetime_utc(dt)
    assert formatted == "2024-01-01T12:00:00Z"
    assert formatted.count('Z') == 1
    print(f"âœ“ format_datetime_utc: {formatted}")
    
    # Test ensure_utc_format fixes double Z
    fixed = ensure_utc_format("2024-01-01T12:00:00ZZ")
    assert fixed == "2024-01-01T12:00:00Z"
    assert fixed.count('Z') == 1
    print(f"âœ“ ensure_utc_format: {fixed}")
    
    print("âœ“ All UTC timestamp functions work correctly")
    '''
    
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(test_script)
                script_path = f.name
    
            try:
>               result = subprocess.run([sys.executable, script_path], capture_output=True, text=True, timeout=30, check=True)  # AI-AGENT-REF: Added timeout and check for security

tests/test_systemd_startup.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 30, check = True
popenargs = (['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp0lzdplu4.py'],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}
process = <Popen: returncode: 1 args: ['/root/.pyenv/versions/3.11.12/bin/python3.11',...>, stdout = ''
stderr = 'Traceback (most recent call last):\n  File "/tmp/tmp0lzdplu4.py", line 2, in <module>\n    from ai_trading.utils.timefmt import utc_now_iso, format_datetime_utc, ensure_utc_format\nModuleNotFoundError: No module named \'ai_trading\'\n'
retcode = 1

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired as exc:
                process.kill()
                if _mswindows:
                    # Windows accumulates the output in a single blocking
                    # read() call run on child threads, with the timeout
                    # being done in a join() on those threads.  communicate()
                    # _after_ kill() is required to collect that and add it
                    # to the exception.
                    exc.stdout, exc.stderr = process.communicate()
                else:
                    # POSIX _communicate already populated the output so
                    # far into the TimeoutExpired exception.
                    process.wait()
                raise
            except:  # Including KeyboardInterrupt, communicate handled that.
                process.kill()
                # We don't call process.wait() as .__exit__ does that for us.
                raise
            retcode = process.poll()
            if check and retcode:
>               raise CalledProcessError(retcode, process.args,
                                         output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmp0lzdplu4.py']' returned non-zero exit status 1.

/root/.pyenv/versions/3.11.12/lib/python3.11/subprocess.py:571: CalledProcessError
__________________________________ TestSystemdStartupCompatibility.test_lazy_import_behavior ___________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_systemd_startup.TestSystemdStartupCompatibility object at 0x7f8d858082d0>

        def test_lazy_import_behavior(self):
            """Test that lazy imports work correctly."""
            test_script = '''
    import os
    
    # Clear credentials
    for key in ["ALPACA_API_KEY", "APCA_API_KEY_ID", "ALPACA_SECRET_KEY", "APCA_API_SECRET_KEY"]:
        os.environ.pop(key, None)
    
    # Import runner (should work without credentials)
    from ai_trading import runner
    
    # Verify lazy loading variables exist
    assert hasattr(runner, '_load_engine')
    assert hasattr(runner, '_bot_engine')
    assert hasattr(runner, '_bot_state_class')
    
    # Verify initial state is None (not loaded)
    assert runner._bot_engine is None
    assert runner._bot_state_class is None
    
    print("âœ“ Lazy import mechanism working correctly")
    '''
    
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(test_script)
                script_path = f.name
    
            try:
>               result = subprocess.run([sys.executable, script_path], capture_output=True, text=True, timeout=30, check=True)  # AI-AGENT-REF: Added timeout and check for security

tests/test_systemd_startup.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, capture_output = True, timeout = 30, check = True
popenargs = (['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmpj6_2y3b9.py'],)
kwargs = {'stderr': -1, 'stdout': -1, 'text': True}
process = <Popen: returncode: 1 args: ['/root/.pyenv/versions/3.11.12/bin/python3.11',...>, stdout = ''
stderr = 'Traceback (most recent call last):\n  File "/tmp/tmpj6_2y3b9.py", line 9, in <module>\n    from ai_trading import runner\nModuleNotFoundError: No module named \'ai_trading\'\n'
retcode = 1

    def run(*popenargs,
            input=None, capture_output=False, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,
        or pass capture_output=True to capture both.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass bytes or a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        By default, all communication is in bytes, and therefore any "input" should
        be bytes, and the stdout and stderr will be bytes. If in text mode, any
        "input" should be a string, and stdout and stderr will be strings decoded
        according to locale encoding, or by "encoding" if set. Text mode is
        triggered by setting any of text, encoding, errors or universal_newlines.
    
        The other arguments are the same as for the Popen constructor.
        """
        if input is not None:
            if kwargs.get('stdin') is not None:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        if capture_output:
            if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:
                raise ValueError('stdout and stderr arguments may not be used '
                                 'with capture_output.')
            kwargs['stdout'] = PIPE
            kwargs['stderr'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired as exc:
                process.kill()
                if _mswindows:
                    # Windows accumulates the output in a single blocking
                    # read() call run on child threads, with the timeout
                    # being done in a join() on those threads.  communicate()
                    # _after_ kill() is required to collect that and add it
                    # to the exception.
                    exc.stdout, exc.stderr = process.communicate()
                else:
                    # POSIX _communicate already populated the output so
                    # far into the TimeoutExpired exception.
                    process.wait()
                raise
            except:  # Including KeyboardInterrupt, communicate handled that.
                process.kill()
                # We don't call process.wait() as .__exit__ does that for us.
                raise
            retcode = process.poll()
            if check and retcode:
>               raise CalledProcessError(retcode, process.args,
                                         output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/root/.pyenv/versions/3.11.12/bin/python3.11', '/tmp/tmpj6_2y3b9.py']' returned non-zero exit status 1.

/root/.pyenv/versions/3.11.12/lib/python3.11/subprocess.py:571: CalledProcessError
________________________________________________ test_retry_eventually_succeeds ________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    @pytest.mark.unit
    def test_retry_eventually_succeeds() -> None:
        flaky = _Flaky()
        result = retry_call(flaky, exceptions=(RuntimeError,), retries=2)
        assert result == "ok"
>       assert flaky.calls == 2
E       assert 3 == 2
E        +  where 3 = <tests.unit.test_retry._Flaky object at 0x7ff3c0790790>.calls

tests/unit/test_retry.py:36: AssertionError
_________________________________________________ test_fast_retry_skips_sleep __________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d84adc490>

    @pytest.mark.unit
    def test_fast_retry_skips_sleep(monkeypatch: pytest.MonkeyPatch) -> None:
        monkeypatch.setenv("FAST_RETRY_IN_TESTS", "1")
    
        calls = {"n": 0}
    
        def func() -> str:
            calls["n"] += 1
            if calls["n"] < 2:
                raise RuntimeError("boom")
            return "done"
    
        start = time.perf_counter()
        result = retry_call(func, exceptions=(RuntimeError,), retries=1, backoff=0.5)
        elapsed = time.perf_counter() - start
        assert result == "done"
        assert calls["n"] == 2
>       assert elapsed < 0.01
E       assert 0.5142596170007891 < 0.01

tests/unit/test_retry.py:64: AssertionError
________________________________________________ test_retry_succeeds_and_sleeps ________________________________________________
[gw1] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f8d84adc450>

    def test_retry_succeeds_and_sleeps(monkeypatch: pytest.MonkeyPatch) -> None:
        sleeps: list[float] = []
        monkeypatch.setattr(time, "sleep", lambda s: sleeps.append(s))
        fn = Flaky(2)
        assert retry_call(fn, exceptions=(TimeoutError,), retries=3) == "ok"
        assert fn.calls == 3
>       assert len(sleeps) == 2
E       assert 0 == 2
E        +  where 0 = len([])

tests/utils/test_retry.py:30: AssertionError
______________________________________________________ test_backoff_caps _______________________________________________________
[gw4] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ff3c09da0d0>

    def test_backoff_caps(monkeypatch: pytest.MonkeyPatch) -> None:
        sleeps: list[float] = []
        monkeypatch.setattr(time, "sleep", lambda s: sleeps.append(s))
        fn = Flaky(5)
        with pytest.raises(TimeoutError):
            retry_call(fn, exceptions=(TimeoutError,), retries=4, backoff=0.1, max_backoff=0.3, jitter=0)
>       assert sleeps[-1] <= 0.3
E       IndexError: list index out of range

tests/utils/test_retry.py:45: IndexError
____________________________ TestOrderExecutionTracking.test_safe_submit_order_quantity_validation _____________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_trading_issues.TestOrderExecutionTracking testMethod=test_safe_submit_order_quantity_validation>

    def test_safe_submit_order_quantity_validation(self):
        """Test that safe_submit_order validates filled_qty matches intended qty."""
    
        # Mock order request
        mock_req = Mock()
        mock_req.symbol = "AAPL"
        mock_req.qty = 100
    
        # Mock order with partial fill
        partial_order = Mock()
        partial_order.status = "partially_filled"
        partial_order.filled_qty = "50"  # Only half filled
        partial_order.qty = "100"
    
        with patch.object(self.mock_ctx.api, 'submit_order', return_value=partial_order), \
             patch.object(self.mock_ctx.api, 'get_order_by_id', return_value=partial_order):
    
            if hasattr(bot_engine, 'safe_submit_order'):
                result = bot_engine.safe_submit_order(self.mock_ctx.api, mock_req)
    
                # The issue: function returns the order but doesn't validate
                # that filled_qty (50) matches intended qty (100)
>               self.assertEqual(result.filled_qty, "50")
E               AttributeError: 'NoneType' object has no attribute 'filled_qty'

tests/test_critical_trading_issues.py:141: AttributeError
----------------------------------------------------- Captured stdout call -----------------------------------------------------
{"ts": "2025-08-22 17:39:22,214", "level": "WARNING", "name": "ai_trading.utils.base", "msg": "No market schedule for 2025-08-22 in is_mâ€¦open (likely holiday); returning False.", "bot_phase": "GENERAL"}
{"ts": "2025-08-22 17:39:22,215", "level": "WARNING", "name": "ai_trading.core.bot_engine", "msg": "MARKâ€¦SKIP", "symbol": "AAPL", "bot_phase": "GENERAL"}
------------------------------------------------------ Captured log call -------------------------------------------------------
WARNING  ai_trading.utils.base:base.py:378 No market schedule for 2025-08-22 in is_mâ€¦open (likely holiday); returning False.
DEBUG    ai_trading.utils.base:base.py:309 Detected Market Hours today: CLOSED
WARNING  ai_trading.core.bot_engine:bot_engine.py:7539 MARKâ€¦SKIP
__________________________________ TestLiquidityManagement.test_conservative_spread_threshold __________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

self = <tests.test_critical_trading_issues.TestLiquidityManagement testMethod=test_conservative_spread_threshold>

    def test_conservative_spread_threshold(self):
        """Test that 0.05 spread threshold is too conservative."""
    
        symbol = "AAPL"
    
        # Mock quote with moderate spread
        mock_quote = Mock()
        mock_quote.ask_price = 150.05
        mock_quote.bid_price = 150.00
        mock_quote.spread = 0.05  # Exactly at threshold
    
        # Mock volume data
    
        with patch.object(self.mock_ctx.data_client, 'get_stock_latest_quote', return_value=mock_quote):
            if hasattr(bot_engine, 'liquidity_factor'):
>               bot_engine.liquidity_factor(self.mock_ctx, symbol)

tests/test_critical_trading_issues.py:263: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/core/bot_engine.py:7169: in liquidity_factor
    df = fetch_minute_df_safe(symbol)
ai_trading/core/bot_engine.py:2047: in fetch_minute_df_safe
    df = get_minute_df(symbol, start_dt, now_utc)
ai_trading/data_fetcher.py:531: in get_minute_df
    fh_fetcher.fetch(symbol, start_dt, end_dt, resolution="1")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.data_fetcher._FinnhubFetcherStub object at 0x7f3d462c2850>
args = ('AAPL', datetime.datetime(2025, 8, 21, 17, 39, 22, 250670, tzinfo=datetime.timezone.utc), datetime.datetime(2025, 8, 22, 17, 39, 22, 250670, tzinfo=datetime.timezone.utc))
kwargs = {'resolution': '1'}

    def fetch(self, *args, **kwargs):
>       raise NotImplementedError
E       NotImplementedError

ai_trading/data_fetcher.py:149: NotImplementedError
____________________________________________________ test_disk_cache_basic _____________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw3/test_disk_cache_basic0')

    def test_disk_cache_basic(tmp_path):
        """Test disk cache functionality"""
        cache_dir = str(tmp_path / "cache")
        df = pd.DataFrame({"timestamp":[1], "open":[2], "high":[3], "low":[1], "close":[2.5], "volume":[1000]})
    
        # Put data in disk cache
        mcache.put_disk(cache_dir, "TSLA", "1H", "2024-01-01", "2024-01-02", df)
    
        # Retrieve from disk cache
        retrieved = mcache.get_disk(cache_dir, "TSLA", "1H", "2024-01-01", "2024-01-02")
>       assert retrieved is not None
E       assert None is not None

tests/test_data_cache.py:25: AssertionError
------------------------------------------------------ Captured log call -------------------------------------------------------
DEBUG    ai_trading.market.cache:cache.py:84 Failed to write cache file /tmp/pytest-of-root/pytest-0/popen-gw3/test_disk_cache_basic0/cache/TSLA_1H_2024-01-01_2024-01-02.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
___________________________________________________ test_get_bars_df_spy_day ___________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

    @pytest.mark.requires_credentials
    def test_get_bars_df_spy_day():
        if not (os.getenv("ALPACA_API_KEY") and os.getenv("ALPACA_SECRET_KEY")):
            pytest.skip("missing Alpaca credentials")
>       df = get_bars_df("SPY", TimeFrame.Day)

tests/test_data_fetch.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/alpaca_api.py:174: in get_bars_df
    base_tf = tf_raw if isinstance(tf_raw, TimeFrame) else TimeFrame(1, TimeFrameUnit.Day)
/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:40: in __init__
    self.validate_timeframe(amount, unit)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amount = 1, unit = <TimeFrameUnit.Day: 'Day'>

    @staticmethod
    def validate_timeframe(amount: int, unit: TimeFrameUnit):
        """Validates the amount value against the TimeFrameUnit value for consistency
    
        Args:
            amount (int): The number of multiples of unit
            unit (TimeFrameUnit): The base unit of time interval the TimeFrame is measured by
    
        Raises:
            ValueError: Raised if the values of amount and unit are not consistent with each other
        """
        if amount <= 0:
            raise ValueError("Amount must be a positive integer value.")
    
        if unit == TimeFrameUnit.Minute and amount > 59:
            raise ValueError(
                "Second or Minute units can only be "
                + "used with amounts between 1-59."
            )
    
        if unit == TimeFrameUnit.Hour and amount > 23:
            raise ValueError("Hour units can only be used with amounts 1-23")
    
>       if unit in (TimeFrameUnit.Day, TimeFrameUnit.Week) and amount != 1:
E       AttributeError: type object '_TFUnit' has no attribute 'Week'

/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/alpaca/data/timeframe.py:94: AttributeError
______________________________________________________ test_get_minute_df ______________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f3d461bef90>

    def test_get_minute_df(monkeypatch):
        df = pd.DataFrame(
            {"open": [1.0], "high": [2.0], "low": [0.5], "close": [1.5], "volume": [100]},
            index=[pd.Timestamp("2023-01-01T09:30")],
        )
    
        monkeypatch.setattr(data_fetcher, "_fetch_bars", lambda *a, **k: df.reset_index().rename(columns={"index": "timestamp"}))
        monkeypatch.setattr(data_fetcher, "is_market_open", lambda: True)
>       result = data_fetcher.get_minute_df("AAPL", datetime.date(2023, 1, 1), datetime.date(2023, 1, 2))

tests/test_data_fetcher.py:104: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ai_trading/data_fetcher.py:531: in get_minute_df
    fh_fetcher.fetch(symbol, start_dt, end_dt, resolution="1")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_trading.data_fetcher._FinnhubFetcherStub object at 0x7f3d462c2850>
args = ('AAPL', datetime.datetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2023, 1, 2, 0, 0, tzinfo=datetime.timezone.utc))
kwargs = {'resolution': '1'}

    def fetch(self, *args, **kwargs):
>       raise NotImplementedError
E       NotImplementedError

ai_trading/data_fetcher.py:149: NotImplementedError
________________________________________________ test_subscription_error_logged ________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f3d461bf650>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7f3d46308c90>

    def test_subscription_error_logged(monkeypatch, caplog):
        df = pd.DataFrame(
            {"open": [1.0], "high": [2.0], "low": [0.5], "close": [1.5], "volume": [100]},
            index=[pd.Timestamp("2023-01-01T09:30")],
        )
    
        class DummyClient:
            def get_stock_bars(self, req):
                if getattr(req, "feed", None) == "iex":
                    return FakeBars(df)
                raise data_fetcher.APIError("subscription does not permit querying recent SIP data")
    
>       monkeypatch.setattr(data_fetcher, "client", DummyClient())
E       AttributeError: <module 'ai_trading.data_fetcher' from '/workspace/ai-trading-bot/ai_trading/data_fetcher.py'> has no attribute 'client'

tests/test_data_fetcher.py:120: AttributeError
______________________________________________ test_fetch_bars_retry_invalid_feed ______________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f3d457704d0>

    def test_fetch_bars_retry_invalid_feed(monkeypatch):
        calls = []
    
        class Resp:
            def __init__(self, status, text, data=None):
                self.status_code = status
                self.text = text
                self._data = data or {}
    
            def json(self):
                return self._data
    
        def fake_get(url, params=None, headers=None, timeout=10):
            calls.append(params["feed"])
            if len(calls) == 1:
                return Resp(400, "invalid feed")
            return Resp(200, "", {"bars": [{"t": "2023-01-01T00:00:00Z", "o": 1, "h": 1, "l": 1, "c": 1, "v": 1}]})
    
        monkeypatch.setattr(data_fetcher.requests, "get", fake_get)
    
        start = pd.Timestamp("2023-01-01", tz="UTC")
        end = start + pd.Timedelta(minutes=1)
>       df = data_fetcher._fetch_bars("AAPL", start, end, "1Min", "iex")
E       TypeError: _fetch_bars() takes 4 positional arguments but 5 were given

tests/test_data_fetcher.py:164: TypeError
__________________________________________________ test_finnhub_403_yfinance ___________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f3d458b6cd0>

    def test_finnhub_403_yfinance(monkeypatch):
        def raise_fetch(*a, **k):
            raise data_fetcher.DataFetchException("AAPL", "alpaca", "", "err")
    
        def raise_finnhub(*a, **k):
            raise data_fetcher.FinnhubAPIException(status_code=403)
    
        called = []
    
        def fake_yf(symbol, *args, **kwargs):
            called.append(symbol)
            return pd.DataFrame(
                {"open": [1], "high": [1], "low": [1], "close": [1], "volume": [1]},
                index=[pd.Timestamp("2023-01-01", tz="UTC")],
            )
    
        monkeypatch.setattr(data_fetcher, "_fetch_bars", raise_fetch)
        monkeypatch.setattr(data_fetcher.fh_fetcher, "fetch", raise_finnhub)
>       monkeypatch.setattr(data_fetcher.yf, "download", fake_yf)
E       AttributeError: None has no attribute 'download'

tests/test_data_fetcher.py:187: AttributeError
_________________________________________________ test_fetch_bars_empty_raises _________________________________________________
[gw3] linux -- Python 3.11.12 /root/.pyenv/versions/3.11.12/bin/python3.11

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f3d45af6f50>

    def test_fetch_bars_empty_raises(monkeypatch):
        """_fetch_bars propagates empty results for Yahoo fallback."""  # AI-AGENT-REF
    
        class Resp:
            status_code = 200
            text = ""
    
            def json(self):
                return {"bars": []}
    
        monkeypatch.setattr(data_fetcher.requests, "get", lambda *a, **k: Resp())
    
        with pytest.raises(ValueError):
>           data_fetcher._fetch_bars(
                "AAPL",
                pd.Timestamp("2023-01-02", tz="UTC"),
                pd.Timestamp("2023-01-02", tz="UTC"),
                "1Day",
                "iex",
            )
E           TypeError: _fetch_bars() takes 4 positional arguments but 5 were given

tests/test_data_fetcher.py:226: TypeError
------------------------------ generated xml file: /workspace/ai-trading-bot/artifacts/junit.xml -------------------------------
=================================================== short test summary info ====================================================
SKIPPED [1] tests/test_fill_rate_calculation_fix.py:21: ExecutionEngine not available
SKIPPED [1] tests/test_logger_rotator_smoke.py:10: logger_rotator not available
SKIPPED [1] tests/test_logging_behavior.py:15: TradeSignal unavailable
SKIPPED [1] tests/test_main_smoke.py:9: run module not available
SKIPPED [1] tests/unit/test_alpaca_api.py:3: alpaca_api module not found
SKIPPED [1] tests/test_critical_issues_resolution.py:35: Required modules not available
SKIPPED [1] tests/test_critical_issues_resolution.py:154: Required modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:48: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:181: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:65: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:131: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:160: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:292: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:215: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:257: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:231: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:276: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:425: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:409: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:385: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:358: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:324: Enhanced debugging modules not available
SKIPPED [1] tests/test_enhanced_execution_debugging.py:459: Enhanced debugging modules not available
SKIPPED [1] tests/test_institutional_enhancements.py:178: Pre-trade validation modules not available
SKIPPED [1] tests/test_institutional_enhancements.py:142: Pre-trade validation modules not available
SKIPPED [1] tests/test_institutional_enhancements.py:129: Pre-trade validation modules not available
SKIPPED [1] tests/test_institutional_enhancements.py:162: Pre-trade validation modules not available
SKIPPED [1] tests/test_institutional_enhancements.py:373: Tax-aware rebalancer not available
SKIPPED [1] tests/test_institutional_enhancements.py:351: Tax-aware rebalancer not available
SKIPPED [1] tests/test_institutional_enhancements.py:342: Tax-aware rebalancer not available
SKIPPED [1] tests/test_institutional_enhancements.py:69: Adaptive sizing modules not available
SKIPPED [1] tests/test_institutional_enhancements.py:60: Adaptive sizing modules not available
SKIPPED [1] tests/test_institutional_enhancements.py:36: Adaptive sizing modules not available
SKIPPED [1] tests/test_institutional_enhancements.py:45: Adaptive sizing modules not available
SKIPPED [1] tests/test_no_direct_getenv.py:9: Enable after config consolidation PR merges
SKIPPED [1] tests/test_parameter_optimization.py:131: Execution algorithm test skipped due to import error: No module named 'cachetools'
SKIPPED [1] tests/test_production_fixes.py:155: Required modules not available for data validation tests
SKIPPED [1] tests/test_production_fixes.py:207: validate_env module not available
SKIPPED [1] tests/test_production_fixes.py:226: validate_env module not available
SKIPPED [1] tests/test_production_fixes.py:243: validate_env module not available
SKIPPED [1] ../../root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/_pytest/python.py:149: async def function and no async plugin installed (see warnings)
SKIPPED [1] tests/test_pydantic_v2_migration.py:84: Cannot import validate_env module: No module named 'ai_trading.validation.require_env'
SKIPPED [1] tests/test_pydantic_v2_migration.py:125: Cannot import validate_env module
SKIPPED [1] tests/test_production_fixes.py:103: performance_monitor module not available
SKIPPED [1] tests/test_production_fixes.py:84: performance_monitor module not available
SKIPPED [1] tests/test_production_fixes.py:76: performance_monitor module not available
SKIPPED [1] tests/test_production_fixes.py:172: Required modules not available for data validation tests
SKIPPED [1] tests/test_production_fixes.py:141: Required modules not available for data validation tests
XFAIL tests/test_backtest_smoke.py::test_backtester_engine_basic - minimal data may produce no trades
ERROR tests/institutional/test_live_trading.py
ERROR tests/test_advanced_features.py
ERROR tests/test_batch_and_warmup.py
ERROR tests/test_benchmarks.py
ERROR tests/test_critical_trading_fixes.py
ERROR tests/test_enhanced_signals.py
ERROR tests/test_execution_classes.py
ERROR tests/test_execution_engine_check_stops.py
ERROR tests/test_execution_methods.py
ERROR tests/test_ml_model_loading.py
ERROR tests/test_model_registry_roundtrip.py
ERROR tests/test_parallel_speed.py
ERROR tests/test_portfolio_integration.py
ERROR tests/test_portfolio_optimization.py
ERROR tests/test_property_based.py
ERROR tests/test_signals.py
ERROR tests/test_signals_extended.py
ERROR tests/test_signals_scoring.py
ERROR tests/test_institutional_kelly.py::TestKellyCalculator::test_kelly_calculator_initialization - AttributeError: 'NoneTyp...
ERROR tests/test_institutional_kelly.py::TestKellyCalculator::test_portfolio_kelly_calculation - AttributeError: 'NoneType' o...
ERROR tests/test_institutional_kelly.py::TestKellyCalculator::test_dynamic_kelly_adjustment - AttributeError: 'NoneType' obje...
ERROR tests/test_institutional_kelly.py::TestKellyCalculator::test_kelly_with_correlation - AttributeError: 'NoneType' object...
ERROR tests/test_institutional_kelly.py::TestKellyCalculator::test_calculation_history_recording - AttributeError: 'NoneType'...
ERROR tests/test_metalearning_strategy.py::TestMetaLearning::test_strategy_initialization - ImportError: cannot import name '...
ERROR tests/test_metalearning_strategy.py::TestMetaLearning::test_extract_features - ImportError: cannot import name 'Gradien...
ERROR tests/test_metalearning_strategy.py::TestMetaLearning::test_train_model - ImportError: cannot import name 'GradientBoos...
ERROR tests/test_metalearning_strategy.py::TestMetaLearning::test_train_model_insufficient_data - ImportError: cannot import ...
ERROR tests/test_metalearning_strategy.py::TestMetaLearning::test_predict_price_movement - ImportError: cannot import name 'G...
ERROR tests/test_metalearning_strategy.py::TestMetaLearning::test_execute_strategy_with_data - ImportError: cannot import nam...
ERROR tests/test_metalearning_strategy.py::TestMetaLearning::test_execute_strategy_no_data - ImportError: cannot import name ...
ERROR tests/test_metalearning_strategy.py::TestMetaLearning::test_generate_signals - ImportError: cannot import name 'Gradien...
ERROR tests/test_metalearning_strategy.py::TestMetaLearning::test_calculate_position_size - ImportError: cannot import name '...
ERROR tests/test_metalearning_strategy.py::TestMetaLearning::test_fallback_prediction - ImportError: cannot import name 'Grad...
ERROR tests/test_metalearning_strategy.py::TestMetaLearning::test_caching_mechanism - ImportError: cannot import name 'Gradie...
ERROR tests/test_metalearning_strategy.py::TestMetaLearning::test_should_retrain - ImportError: cannot import name 'GradientB...
ERROR tests/test_metalearning_strategy.py::TestMetaLearning::test_signal_validation - ImportError: cannot import name 'Gradie...
ERROR tests/test_main_extended2.py::test_validate_environment_missing - AttributeError: 'Settings' object has no attribute 'W...
FAILED tests/test_alpaca_time_params.py::test_daily_uses_date_only - AttributeError: type object '_TFUnit' has no attribute '...
FAILED tests/test_alpaca_timeframe_mapping.py::test_day_timeframe_normalized - AttributeError: type object '_TFUnit' has no a...
FAILED tests/test_critical_fixes_focused.py::TestCriticalFixes::test_short_selling_validation_exists - ModuleNotFoundError: N...
FAILED tests/test_alpaca_timeframe_mapping.py::test_tf_object_normalized - AttributeError: type object '_TFUnit' has no attri...
FAILED tests/runtime/test_exception_narrowing_df_main.py::test_data_fetcher_json_decode_is_valueerror_only - assert None
FAILED tests/test_alpaca_timeframe_mapping.py::test_minute_normalized - AttributeError: type object '_TFUnit' has no attribut...
FAILED tests/runtime/test_http_wrapped.py::test_wrapped_get_retries_and_parses - Exception: boom
FAILED tests/test_critical_fixes_focused.py::TestCriticalFixes::test_trade_execution_quantity_fix_exists - ModuleNotFoundErro...
FAILED tests/test_alpha_quality.py::test_model_registry - _pickle.PicklingError: Can't pickle <class 'unittest.mock.Mock'>: i...
FAILED tests/test_critical_fixes_implementation.py::test_sentiment_cache_memory_leak_prevention - NameError: name 'requests' ...
FAILED tests/test_artifacts_directories.py::test_walkforward_artifacts_directory - ModuleNotFoundError: No module named 'skle...
FAILED tests/test_critical_fixes_implementation.py::test_security_manager - ModuleNotFoundError: No module named 'cryptography'
FAILED tests/test_critical_fixes_implementation.py::test_dependency_injection - NameError: name 'MockConfigManager' is not de...
FAILED tests/test_critical_fixes_implementation.py::test_performance_optimizations - AttributeError: 'IndicatorManager' objec...
FAILED tests/test_critical_fixes_validation.py::TestCriticalFixes::test_data_staleness_detection_improvement - AssertionError...
FAILED tests/test_critical_fixes_validation.py::TestCriticalFixes::test_meta_learning_price_validation - AssertionError: 3 !=...
FAILED tests/test_critical_fixes_validation.py::TestCriticalFixes::test_systemd_service_configuration - AssertionError: 'NoNe...
FAILED tests/runtime/test_import_contract_cli.py::test_import_contract_timeout_simulated - AssertionError: assert 'TIMEOUT' i...
FAILED tests/test_bot_extended.py::test_fetch_minute_df_safe_open - ImportError: cannot import name 'last_minute_bar_age_seco...
FAILED tests/test_broker_alpaca_adapter.py::test_positions_and_account_old - AssertionError: assert [] == ['pos-old']
FAILED tests/test_ellipsis_fix.py::TestEllipsisFix::test_get_runtime_context_or_none_error - Exception: Context unavailable
FAILED tests/test_broker_unavailable_paths.py::test_safe_account_none - AttributeError: '_TClient' object has no attribute 'g...
FAILED tests/test_additional_coverage.py::test_main_starts_api_thread - ValueError: "Settings" object has no field "max_posit...
FAILED tests/test_broker_unavailable_paths.py::test_pdt_rule_skips_without_false_fail - assert namespace(api=None) is False
FAILED tests/test_ellipsis_fix.py::TestEllipsisFix::test_update_risk_engine_exposure_error - AssertionError: Expected 'warnin...
FAILED tests/test_ellipsis_fix.py::TestEllipsisFix::test_update_risk_engine_exposure_no_risk_engine - AssertionError: 'No ris...
FAILED tests/test_ellipsis_fix.py::TestEllipsisFix::test_update_risk_engine_exposure_with_context - AssertionError: Expected ...
FAILED tests/test_data_fetcher.py::test_fetch_minute_df_safe_no_retry - ImportError: cannot import name 'last_minute_bar_age_...
FAILED tests/test_additional_coverage.py::test_utils_edge_cases - IndexError: single positional indexer is out-of-bounds
FAILED tests/test_additional_coverage.py::test_validate_env_main - ImportError: Error while finding module specification for ...
FAILED tests/test_alpaca_api_extended.py::test_submit_order_http_error - tests.test_alpaca_api_extended.HTTPError: 500
FAILED tests/test_alpaca_api_extended.py::test_submit_order_generic_error - Exception: boom
FAILED tests/test_alpaca_api_module.py::test_submit_order_rate_limit - Exception: fail
FAILED tests/test_alpaca_import.py::test_ai_trading_import_without_alpaca - AssertionError: assert True is False
FAILED tests/test_env_flags.py::test_disable_daily_retrain_env_parsing - AttributeError: DISABLE_DAILY_RETRAIN
FAILED tests/test_env_order_and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_env_loaded_multiple_times_safely - As...
FAILED tests/test_env_flags.py::test_disable_daily_retrain_unset - AttributeError: DISABLE_DAILY_RETRAIN
FAILED tests/test_env_order_and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_lazy_import_error_handling - Failed: ...
FAILED tests/test_env_flags.py::test_disable_daily_retrain_fallback_settings - AttributeError: _FallbackSettings
FAILED tests/test_env_order_and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_dotenv_loaded_before_settings_construction
FAILED tests/test_env_order_and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_lazy_engine_loading_caches_components
FAILED tests/test_coverage_hack.py::test_critical_imports - ImportError: Failed to import critical modules: data_fetcher (can...
FAILED tests/test_critical_datetime_fixes.py::TestDatetimeTimezoneAwareness::test_alpaca_api_format_compatibility - ImportErr...
FAILED tests/test_critical_datetime_fixes.py::TestDatetimeTimezoneAwareness::test_ensure_datetime_returns_timezone_aware - Im...
FAILED tests/test_equity_curve.py::test_equity_curve_monotonic - FileNotFoundError: [Errno 2] No such file or directory: 'dat...
FAILED tests/test_executors_sizing.py::test_executor_env_validation - ValueError: invalid literal for int() with base 10: 'in...
FAILED tests/test_fallback_concurrency.py::test_daily_fallback_parallel - AssertionError: assert set() == {'A', 'B', 'C', 'D'}
FAILED tests/test_fallback_concurrency.py::test_parallel_execution_timing - assert 0 == 4
FAILED tests/test_fallback_concurrency.py::test_bounded_concurrency_respects_limit - assert 0 == 6
FAILED tests/test_env_order_and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_run_cycle_uses_lazy_loading - Asserti...
FAILED tests/test_fetch_and_screen.py::test_fetch_fallback_to_daily - AttributeError: <module 'ai_trading.data_fetcher' from ...
FAILED tests/test_fetch_contract.py::test_get_bars_never_none - AttributeError: <module 'ai_trading.data_fetcher' from '/work...
FAILED tests/test_fetch_sample_universe_cli.py::test_run_success - AttributeError: 'module' object at ai_trading.data_fetcher...
FAILED tests/test_data_fetcher.py::test_fetch_minute_df_safe_handles_empty - ai_trading.core.bot_engine.DataFetchError: Minut...
FAILED tests/test_env_order_and_lazy_import.py::TestEnvironmentOrderAndLazyImport::test_main_loads_dotenv_before_runner_import
FAILED tests/test_fixes_minimal.py::test_data_validation_module - AssertionError: should_halt_trading function missing
FAILED tests/test_health.py::test_health_check_empty_dataframe - AssertionError: assert [('AAA', 'no_data')] == ['AAA']
FAILED tests/test_http_pooling.py::test_host_semaphore_respects_env - assert 6 == 3
FAILED tests/test_http_timeouts.py::test_httpsession_sets_default_timeout - AttributeError: module 'ai_trading.utils.http' ha...
FAILED tests/test_data_fetcher_datetime.py::test_ensure_datetime_none - TypeError: Invalid datetime input: Invalid datetime i...
FAILED tests/test_data_fetcher_datetime.py::test_ensure_datetime_empty_str - TypeError: Invalid datetime input: Invalid datet...
FAILED tests/test_institutional_enhancements.py::TestMarketMicrostructure::test_microstructure_engine - AttributeError: modul...
FAILED tests/test_import_fallbacks.py::test_bot_engine_import_fallbacks - AssertionError: Expected import pattern not found: ...
FAILED tests/test_import_fallbacks.py::test_runner_import_fallbacks - AssertionError: Expected import pattern not found in ru...
FAILED tests/test_data_fetcher_datetime.py::test_ensure_datetime_invalid_str - TypeError: Invalid datetime input: Invalid dat...
FAILED tests/test_data_fetcher_datetime.py::test_ensure_datetime_nat - Failed: DID NOT RAISE <class 'ValueError'>
FAILED tests/test_data_fetcher_extended.py::test_get_historical_data - AttributeError: <module 'ai_trading.data_fetcher' from...
FAILED tests/test_data_fetcher_extended.py::test_get_historical_data_bad_timeframe - AttributeError: <module 'ai_trading.data...
FAILED tests/test_institutional_enhancements.py::TestMarketMicrostructure::test_order_flow_analyzer - AttributeError: module ...
FAILED tests/test_import_fallbacks.py::test_backtester_import_fallbacks - ModuleNotFoundError: No module named 'cachetools'
FAILED tests/test_data_fetcher_extended.py::test_get_minute_df_market_closed - NotImplementedError
FAILED tests/test_import_fallbacks.py::test_profile_indicators_import_fallbacks - ModuleNotFoundError: No module named 'profi...
FAILED tests/test_data_fetcher_extended.py::test_get_minute_df_missing_columns - AttributeError: <module 'ai_trading.data_fet...
FAILED tests/test_import_fallbacks.py::test_data_fetcher_helpers_available - ImportError: cannot import name 'clear_cached_mi...
FAILED tests/test_data_fetcher_extended.py::test_get_minute_df_invalid_inputs - TypeError: Invalid datetime input: Invalid da...
FAILED tests/test_data_fetcher_fallbacks.py::test_minute_fallback_on_empty - AttributeError: None has no attribute 'download'
FAILED tests/test_data_fetcher_fallbacks.py::test_minute_fallback_on_exception - AttributeError: None has no attribute 'downl...
FAILED tests/test_data_fetcher_fallbacks.py::test_daily_fallback_on_empty - AttributeError: None has no attribute 'download'
FAILED tests/test_data_fetcher_timezone.py::test_yahoo_get_bars_accepts_various_datetime_types - ImportError: cannot import n...
FAILED tests/test_institutional_enhancements.py::TestMarketMicrostructure::test_spread_analyzer_initialization - AttributeErr...
FAILED tests/test_data_pipeline.py::test_position_none_safe - AttributeError: module 'ai_trading.core.bot_engine' has no attr...
FAILED tests/test_critical_datetime_fixes.py::TestSentimentCaching::test_sentiment_cache_rate_limit_handling - AttributeError...
FAILED tests/test_institutional_enhancements.py::TestMarketMicrostructure::test_spread_feature_analysis - AttributeError: mod...
FAILED tests/test_institutional_enhancements.py::TestEnhancedRebalancer::test_enhanced_rebalancer_fallback - ImportError: can...
FAILED tests/test_institutional_kelly.py::TestKellyIntegration::test_kelly_with_risk_levels - AttributeError: 'NoneType' obje...
FAILED tests/test_institutional_kelly.py::TestKellyIntegration::test_kelly_logging - AttributeError: 'NoneType' object has no...
FAILED tests/test_intelligent_position_management.py::TestTrailingStopManager::test_stop_initialization - NameError: name 'Mo...
FAILED tests/test_intelligent_position_management.py::TestTrailingStopManager::test_stop_movement - NameError: name 'MockPosi...
FAILED tests/test_intelligent_position_management.py::TestTrailingStopManager::test_stop_trigger_detection - NameError: name ...
FAILED tests/test_intelligent_position_management.py::TestProfitTakingEngine::test_profit_plan_creation - NameError: name 'Mo...
FAILED tests/test_intelligent_position_management.py::TestProfitTakingEngine::test_target_triggering - NameError: name 'MockP...
FAILED tests/test_intelligent_position_management.py::TestPortfolioCorrelationAnalyzer::test_position_data_extraction - NameE...
FAILED tests/test_intelligent_position_management.py::TestPortfolioCorrelationAnalyzer::test_concentration_analysis - NameErr...
FAILED tests/test_intelligent_position_management.py::TestIntegrationScenarios::test_profitable_position_scenario - NameError...
FAILED tests/test_intelligent_position_management.py::TestIntegrationScenarios::test_loss_position_scenario - NameError: name...
FAILED tests/test_intelligent_position_management.py::TestIntegrationScenarios::test_portfolio_level_recommendations - NameEr...
FAILED tests/test_json_formatter.py::test_json_formatter_custom_fields_and_masking - AssertionError: assert (False)
FAILED tests/test_meta_learning.py::test_update_signal_weights_norm_zero - AssertionError: assert 'Normalization factor zero'...
FAILED tests/test_deprecation_warnings.py::test_bot_engine_deprecation_warning - ImportError: cannot import name 'last_market...
FAILED tests/test_meta_learning.py::test_portfolio_rl_trigger - ModuleNotFoundError: No module named 'portfolio_rl'
FAILED tests/test_deprecation_warnings.py::test_data_fetcher_deprecation_warning - assert 0 >= 1
FAILED tests/test_initial_rebalance.py::test_partial_initial_rebalance_fill - AttributeError: 'DummyAPI' object has no attrib...
FAILED tests/test_deprecation_warnings.py::test_runner_deprecation_warning - assert 0 >= 1
FAILED tests/test_meta_learning_additional.py::test_load_weights_save_fail - OSError: fail
FAILED tests/test_mean_reversion_extra.py::test_generate_insufficient_data - AssertionError: assert 'insufficient' in 'WARNIN...
FAILED tests/test_mean_reversion_extra.py::test_generate_invalid_stats - AssertionError: assert 'invalid rolling' in 'WARNING...
FAILED tests/test_model_registry.py::TestModelRegistry::test_model_not_picklable - Exception: Cannot pickle this object
FAILED tests/test_momentum_extra.py::test_generate_insufficient_data - AssertionError: assert 'Insufficient data' in 'INFO   ...
FAILED tests/test_moving_average_crossover_extra.py::test_generate_insufficient_data - TypeError: MovingAverageCrossoverStrat...
FAILED tests/test_moving_average_crossover_extra.py::test_generate_buy_signal - TypeError: MovingAverageCrossoverStrategy.__i...
FAILED tests/test_my_fixes.py::TestMyFixes::test_confidence_normalization_improved - FileNotFoundError: [Errno 2] No such fil...
FAILED tests/test_my_fixes.py::TestMyFixes::test_data_quality_handling_improved - FileNotFoundError: [Errno 2] No such file o...
FAILED tests/test_optional_ml_imports.py::test_optional_ml_imports - ImportError
FAILED tests/test_my_fixes.py::TestMyFixes::test_duplicate_logging_fix - AssertionError: 'elif phase in [ExecutionPhase.SIGNA...
FAILED tests/test_my_fixes.py::TestMyFixes::test_liquidity_thresholds_increased - FileNotFoundError: [Errno 2] No such file o...
FAILED tests/test_meta_learning_additional.py::test_retrain_meta_learner - assert False
FAILED tests/test_my_fixes.py::TestMyFixes::test_meta_learning_thresholds_reduced - FileNotFoundError: [Errno 2] No such file...
FAILED tests/test_my_fixes.py::TestMyFixes::test_position_limit_rebalancing - FileNotFoundError: [Errno 2] No such file or di...
FAILED tests/test_net_http_timeout.py::test_timeoutsession_injects_default_timeout - AttributeError: module 'requests' has no...
FAILED tests/test_net_http_timeout.py::test_build_retrying_session_defaults - AttributeError: module 'requests' has no attrib...
FAILED tests/test_no_legacy_imports.py::test_legacy_modules_not_importable - AssertionError: assert ModuleSpec(name='metrics'...
FAILED tests/test_meta_learning_optional.py::test_optimize_signals_fallback - TypeError: optimize_signals() missing 1 require...
FAILED tests/test_no_raw_requests.py::test_no_raw_requests_in_src - AssertionError: Raw requests.* found in: ['/workspace/ai-...
FAILED tests/test_package_first_smoke.py::test_ai_trading_module_imports - ModuleNotFoundError: No module named 'cachetools'
FAILED tests/test_package_first_smoke.py::test_ai_trading_init_exports - AssertionError: assert False
FAILED tests/test_parameter_optimization.py::test_kelly_parameters_optimization - AssertionError: Expected 0.15, got 0.3
FAILED tests/test_parameter_optimization.py::test_adaptive_sizing_optimization - TypeError: object() takes no arguments
FAILED tests/test_peak_performance.py::test_order_idempotency - ModuleNotFoundError: No module named 'cachetools'
FAILED tests/test_peak_performance.py::test_position_reconciliation - ModuleNotFoundError: No module named 'cachetools'
FAILED tests/test_peak_performance.py::test_aligned_clock - AttributeError: 'types.SimpleNamespace' object has no attribute 'tz'
FAILED tests/test_peak_performance.py::test_symbol_costs - ModuleNotFoundError: No module named 'cachetools'
FAILED tests/test_peak_performance.py::test_adaptive_risk_controls - AttributeError: 'Settings' object has no attribute 'ENAB...
FAILED tests/test_peak_performance.py::test_determinism - NameError: name 'HAS_NUMPY' is not defined
FAILED tests/test_metalearning_strategy.py::test_metalearning_import - ImportError: cannot import name 'GradientBoostingClass...
FAILED tests/test_metalearning_strategy.py::test_no_metalearn_invalid_prices_error - ImportError: cannot import name 'Gradien...
FAILED tests/test_peak_performance.py::test_smart_order_routing - ModuleNotFoundError: No module named 'cachetools'
FAILED tests/test_phase2_enhancements.py::TestConfigurationEnhancements::test_order_management_config - AssertionError: False...
FAILED tests/test_phase2_enhancements.py::TestConfigurationEnhancements::test_system_health_config - AssertionError: False is...
FAILED tests/test_portfolio.py::test_short_close_queued - AttributeError: None has no attribute 'submit'
FAILED tests/test_position_holding.py::test_position_hold_signals_generation - ModuleNotFoundError: No module named 'cachetools'
FAILED tests/test_position_holding.py::test_signals_enhancement_with_position_logic - ModuleNotFoundError: No module named 'c...
FAILED tests/test_minute_fallback_debug_path.py::test_minute_fallback_debug_path_emits_record - AttributeError: 'NoneType' ob...
FAILED tests/test_position_holding.py::test_meta_learning_trigger - AttributeError: <module 'ai_trading.meta_learning' from '...
FAILED tests/test_position_holding.py::test_position_manager_cleanup - AssertionError: assert 'GOOGL' not in {'AAPL': <Mock i...
FAILED tests/test_ml_model_extra.py::test_fit_and_predict - TypeError: '>=' not supported between instances of 'MLModel' and ...
FAILED tests/test_problem_statement_fixes.py::TestProblemStatementFixes::test_meta_learning_minimum_trades_requirement - Asse...
FAILED tests/test_problem_statement_fixes.py::TestProblemStatementFixes::test_order_quantity_tracking_clarity - AssertionErro...
FAILED tests/test_problem_statement_fixes.py::TestProblemStatementFixes::test_pltr_sector_classification - AssertionError: bo...
FAILED tests/test_import_wiring.py::test_import_contract - AssertionError: Import contract failed:
FAILED tests/test_position_holding_simple.py::test_meta_learning_functions - AttributeError: <module 'ai_trading.meta_learnin...
FAILED tests/test_predict_smoke.py::test_predict_function - NameError: name 'requests' is not defined
FAILED tests/test_production_fixes.py::TestIntegration::test_all_modules_importable - AssertionError: Failed to import perfor...
FAILED tests/test_prof_budget.py::test_soft_budget_elapsed_and_over - assert (False is True or 0.009585136998794042 == 0.0)
FAILED tests/test_pydantic_v2_migration.py::test_pydantic_v2_migration_syntax - assert 'from pydantic import field_validator,...
FAILED tests/test_no_root_imports.py::test_no_root_level_imports_of_migrated_modules - AssertionError: Root imports are no lo...
FAILED tests/test_regime_filters.py::test_regime_changes - FileNotFoundError: [Errno 2] No such file or directory: 'data/trad...
FAILED tests/test_peak_performance.py::test_backtest_cost_enforcement - ModuleNotFoundError: No module named 'cachetools'
FAILED tests/test_performance_allocator_conf_gate.py::test_allocator_confidence_gate_filters_and_logs - assert 0 >= 2
FAILED tests/test_resample_daily.py::test_get_daily_bars_resamples_minutes - TypeError: test_get_daily_bars_resamples_minutes...
FAILED tests/test_performance_fixes.py::test_meta_learning_mixed_format - AssertionError: Should detect mixed formats
FAILED tests/test_performance_fixes.py::test_cache_performance_monitoring - ImportError: cannot import name '_CACHE_STATS' fr...
FAILED tests/test_retrain_smoke.py::test_retrain_detect_regime_and_dump - ModuleNotFoundError: No module named 'retrain'
FAILED tests/test_risk_engine_additional.py::test_position_size_division_error - TypeError: StrategySignal.__init__() missing...
FAILED tests/test_performance_fixes.py::test_position_size_reporting - ModuleNotFoundError: No module named 'cachetools'
FAILED tests/test_risk_engine_additional.py::test_apply_weight_limits - TypeError: StrategySignal.__init__() missing 1 requir...
FAILED tests/test_performance_fixes.py::test_latency_tracking - ModuleNotFoundError: No module named 'cachetools'
FAILED tests/test_risk_engine_module.py::test_can_trade_limits - TypeError: StrategySignal.__init__() missing 1 required posi...
FAILED tests/test_risk_engine_module.py::test_register_and_position_size - TypeError: StrategySignal.__init__() missing 1 req...
FAILED tests/test_risk_engine_module.py::test_hard_stop_blocks_trading - TypeError: StrategySignal.__init__() missing 1 requi...
FAILED tests/test_risk_engine_package.py::TestRiskEnginePackage::test_update_exposure_requires_context - ImportError: cannot ...
FAILED tests/test_risk_engine_package.py::TestRiskEnginePackage::test_update_exposure_works_with_context - ImportError: canno...
FAILED tests/test_risk_engine_package.py::TestRiskEnginePackage::test_risk_engine_import_from_package - ImportError: cannot i...
FAILED tests/test_rl_module.py::test_rl_train_and_infer - AttributeError: module 'ai_trading.rl_trading.train' has no attribu...
FAILED tests/test_runner.py::test_runner_as_main - AttributeError: module 'ai_trading.runner' has no attribute 'time'
FAILED tests/test_runner.py::test_runner_import_fallback - AssertionError: assert <function main at 0x7f86768e07c0> is <funct...
FAILED tests/test_runner_additional.py::test_runner_starts - AttributeError: module 'ai_trading.core.bot_engine' has no attri...
FAILED tests/test_runtime_fixes.py::test_top_level_shims - FileNotFoundError: [Errno 2] No such file or directory: 'bot_engin...
FAILED tests/test_runtime_params_hydration.py::test_trading_config_has_required_parameters - assert 0.25 == 0.04
FAILED tests/test_runtime_params_hydration.py::test_trading_config_from_env_loads_parameters - AssertionError: assert 8000.0 ...
FAILED tests/test_runtime_params_hydration.py::test_build_runtime_hydrates_all_parameters - assert 0.25 == 0.04
FAILED tests/test_runtime_params_hydration.py::test_build_runtime_uses_config_values - pydantic_core._pydantic_core.Validatio...
FAILED tests/test_runtime_paths.py::test_http_utilities_available - AssertionError: assert False
FAILED tests/test_problem_statement_validation.py::test_alpaca_availability_detection - ImportError: cannot import name 'last...
FAILED tests/test_settings_config.py::test_settings_invalid_risk - Failed: DID NOT RAISE <class 'pydantic_core._pydantic_core...
FAILED tests/test_short_selling_implementation.py::TestShortSellingImplementation::test_current_sell_logic_blocks_no_position
FAILED tests/test_problem_statement_validation.py::test_alpaca_import_exception_handling - AttributeError: <module 'ai_tradin...
FAILED tests/test_short_selling_implementation.py::TestShortSellingImplementation::test_order_status_monitoring_needed - Modu...
FAILED tests/test_short_selling_implementation.py::TestShortSellingImplementation::test_sell_short_side_should_be_distinguished
FAILED tests/test_short_selling_implementation.py::TestShortSellingImplementation::test_sell_short_validation_exists - Module...
FAILED tests/test_skip_logic.py::test_skip_logic - AttributeError: None has no attribute 'submit'
FAILED tests/test_slippage.py::test_slippage_limits - FileNotFoundError: [Errno 2] No such file or directory: 'logs/slippage....
FAILED tests/test_stage1_1.py::test_fetch_sentiment_graceful_when_requests_unavailable - AssertionError: assert 0 >= 1
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_fresh_data - AssertionError: Should not raise ...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_stale_data - TypeError: _ensure_data_fresh() g...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_no_data - TypeError: _ensure_data_fresh() got ...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_empty_dataframe - TypeError: _ensure_data_fres...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_multiple_symbols - TypeError: _ensure_data_fre...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_utc_logging - TypeError: _ensure_data_fresh() ...
FAILED tests/test_problem_statement_validation.py::test_package_safe_imports - ImportError: cannot import name 'last_market_s...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_timezone_handling - AssertionError: Should han...
FAILED tests/test_staleness_guard.py::TestStalenessGuard::test_staleness_guard_error_handling - TypeError: _ensure_data_fresh...
FAILED tests/test_problem_statement_validation.py::test_utc_datetime_handling - ModuleNotFoundError: No module named 'cacheto...
FAILED tests/test_problem_statement_validation.py::test_python_version_requirements - AssertionError: Should use flexible Pyt...
FAILED tests/test_production_fixes.py::TestSentimentAPIConfiguration::test_sentiment_api_env_vars_in_config - AssertionError:...
FAILED tests/test_strategy_allocator_regression.py::TestStrategyAllocatorRegression::test_config_missing_min_confidence_attribute
FAILED tests/test_strategy_allocator_regression.py::TestStrategyAllocatorRegression::test_config_none_min_confidence - TypeEr...
FAILED tests/test_run_overlap.py::test_run_all_trades_overlap - RuntimeError: Model required but not configured. Set one of: ...
FAILED tests/test_strategy_allocator_regression.py::TestStrategyAllocatorRegression::test_signal_confirmation_boundary_conditions
FAILED tests/test_strategy_allocator_regression.py::TestStrategyAllocatorRegression::test_invalid_signal_confidence_handling
FAILED tests/test_strategy_allocator_regression.py::TestStrategyAllocatorRegression::test_multiple_instances_no_shared_state
FAILED tests/test_strategy_allocator_smoke.py::test_allocator - TypeError: StrategySignal.__init__() missing 1 required posit...
FAILED tests/test_strategies_base_extra.py::test_strategy_generate_base - TypeError: Can't instantiate abstract class BaseStr...
FAILED tests/test_strategy_allocator_exit.py::test_exit_confirmation - TypeError: StrategySignal.__init__() missing 1 require...{"ts": "2025-08-22 17:37:10,506", "level": "INFO", "name": "ai_trading.logging", "msg": "Logging configured succâ€¦ully - no duplicates possible", "bot_phase": "GENERAL"}

FAILED tests/test_strategy_allocator_regression.py::TestStrategyAllocatorRegression::test_signal_confirmation_with_zero_min_confidence
FAILED tests/test_talib_enforcement.py::test_talib_import_enforcement - AssertionError: Could not find end of TA library section
FAILED tests/test_talib_enforcement.py::test_audit_file_creation_and_permissions - TypeError: log_trade() got an unexpected k...
FAILED tests/test_talib_enforcement.py::test_audit_file_multiple_trades - FileNotFoundError: [Errno 2] No such file or direct...
FAILED tests/test_timeutils.py::test_nyse_session_dst - AssertionError: assert (13 == 13 and datetime.timezone.utc == zoneinf...
FAILED tests/test_trading_parameter_validation.py::test_validate_trading_parameters_no_name_error - FileNotFoundError: [Errno...
FAILED tests/test_run_strategy_no_signals.py::test_run_strategy_no_signals - AttributeError: module 'requests' has no attribu...
FAILED tests/test_runner.py::test_handle_signal_sets_shutdown - AttributeError: module 'ai_trading.runner' has no attribute '...
FAILED tests/test_runner.py::test_run_forever_exit - AttributeError: module 'ai_trading.runner' has no attribute 'time'
FAILED tests/test_runner.py::test_run_forever_exception - AttributeError: module 'ai_trading.runner' has no attribute 'time'
FAILED tests/test_runner.py::test_run_forever_request_exception - AttributeError: module 'ai_trading.runner' has no attribute...
FAILED tests/test_trading_parameter_validation.py::test_buy_threshold_definition_order - FileNotFoundError: [Errno 2] No such...
FAILED tests/test_imports_smoke.py::test_submodules_import - ModuleNotFoundError: No module named 'sklearn.model_selection'; ...
FAILED tests/test_runner.py::test_run_forever_system_exit_nonzero - AttributeError: module 'ai_trading.runner' has no attribu...
FAILED tests/test_kelly_confidence_fix.py::test_kelly_confidence_normalization - NameError: name 'MockBotContext' is not defined
FAILED tests/test_kelly_confidence_fix.py::test_kelly_input_validation - NameError: name 'MockBotContext' is not defined
FAILED tests/test_logger.py::test_setup_logging_idempotent - AssertionError: No rotating handler paths created. Captured: []
FAILED tests/test_trigger_meta_learning_conversion.py::test_trigger_meta_learning_conversion_mixed_format - NameError: name '...
FAILED tests/test_logger.py::test_get_logger - AttributeError: 'SanitizingLoggerAdapter' object has no attribute 'handlers'
FAILED tests/test_logger_file.py::test_setup_logging_with_file - assert []
FAILED tests/test_logger_module.py::test_get_logger_singleton - AttributeError: 'SanitizingLoggerAdapter' object has no attri...
FAILED tests/test_trigger_meta_learning_conversion.py::test_trigger_meta_learning_conversion_missing_file - NameError: name '...
FAILED tests/test_logging_scrubbed.py::test_no_secrets_in_logs - AssertionError: assert 'TOPSECRETKEY' not in 'boot with key=...
FAILED tests/test_main_extended2.py::test_run_flask_app - TypeError: test_run_flask_app.<locals>.App.run() got an unexpected ...
FAILED tests/test_main_extended2.py::test_run_flask_app_port_in_use - AttributeError: module 'ai_trading.main' has no attribu...
FAILED tests/test_trigger_meta_learning_conversion.py::test_trigger_meta_learning_conversion_problem_statement_exact - NameEr...
FAILED tests/test_universe_fetch_pooling.py::test_universe_fetch_pooling - AttributeError: <module 'ai_trading.data_fetcher' ...
FAILED tests/test_trigger_meta_learning_conversion.py::test_trigger_meta_learning_conversion_pure_meta_format - NameError: na...
FAILED tests/test_main_extended2.py::test_run_bot_calls_cycle - AttributeError: 'Settings' object has no attribute 'alpaca_se...
FAILED tests/test_systemd_startup.py::TestSystemdStartupCompatibility::test_import_no_crash_without_credentials - subprocess....
FAILED tests/test_trigger_meta_learning_conversion.py::test_trigger_meta_learning_conversion_pure_audit_format - NameError: n...
FAILED tests/test_yf_auto_adjust_and_cache.py::test_yfinance_auto_adjust_and_cache - ImportError: cannot import name '_yahoo_...
FAILED tests/test_main_extended2.py::test_validate_environment_missing - ValueError: "Settings" object has no field "WEBHOOK_...
FAILED tests/test_main_extended2.py::test_main_runs_once - ValueError: "Settings" object has no field "max_position_size"
FAILED tests/test_systemd_startup.py::TestSystemdStartupCompatibility::test_dual_credential_schema_with_env_file - subprocess...
FAILED tests/test_systemd_startup.py::TestSystemdStartupCompatibility::test_utc_timestamp_no_double_z - subprocess.CalledProc...
FAILED tests/test_systemd_startup.py::TestSystemdStartupCompatibility::test_lazy_import_behavior - subprocess.CalledProcessEr...
FAILED tests/unit/test_retry.py::test_retry_eventually_succeeds - assert 3 == 2
FAILED tests/unit/test_retry.py::test_fast_retry_skips_sleep - assert 0.5142596170007891 < 0.01
FAILED tests/utils/test_retry.py::test_retry_succeeds_and_sleeps - assert 0 == 2
FAILED tests/utils/test_retry.py::test_backoff_caps - IndexError: list index out of range
FAILED tests/test_critical_trading_issues.py::TestOrderExecutionTracking::test_safe_submit_order_quantity_validation - Attrib...
FAILED tests/test_critical_trading_issues.py::TestLiquidityManagement::test_conservative_spread_threshold - NotImplementedError
FAILED tests/test_data_cache.py::test_disk_cache_basic - assert None is not None
FAILED tests/test_data_fetch.py::test_get_bars_df_spy_day - AttributeError: type object '_TFUnit' has no attribute 'Week'
FAILED tests/test_data_fetcher.py::test_get_minute_df - NotImplementedError
FAILED tests/test_data_fetcher.py::test_subscription_error_logged - AttributeError: <module 'ai_trading.data_fetcher' from '/...
FAILED tests/test_data_fetcher.py::test_fetch_bars_retry_invalid_feed - TypeError: _fetch_bars() takes 4 positional arguments...
FAILED tests/test_data_fetcher.py::test_finnhub_403_yfinance - AttributeError: None has no attribute 'download'
FAILED tests/test_data_fetcher.py::test_fetch_bars_empty_raises - TypeError: _fetch_bars() takes 4 positional arguments but 5...
263 failed, 599 passed, 48 skipped, 1 xfailed, 715 warnings, 37 errors in 133.20s (0:02:13)
